{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b13177b7",
      "metadata": {
        "id": "b13177b7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p35Lz3miCr55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p35Lz3miCr55",
        "outputId": "266a6ca9-69e1-4496-8628-572b2137aa65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6KyYY5FcCx3V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KyYY5FcCx3V",
        "outputId": "931fdbcc-30a8-4c8a-bf7c-27db380f1e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!mkdir memit\n",
        "!cp -R drive/MyDrive/memit/* memit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BaPUxdQLffTd",
      "metadata": {
        "id": "BaPUxdQLffTd"
      },
      "outputs": [],
      "source": [
        "!mkdir rome\n",
        "!cp -R drive/MyDrive/rome2/* rome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jhm9hg6yCRBj",
      "metadata": {
        "id": "jhm9hg6yCRBj"
      },
      "outputs": [],
      "source": [
        "!cp -R rome/* drive/MyDrive/rome2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5416767c",
      "metadata": {
        "id": "5416767c"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "pip install -r /content/memit/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1\n",
        "pip install transformers >> install.log 2>&1\n",
        "# pip install higher hydra-core allennlp einops datasets accelerate>> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jZzb1T71-ahL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZzb1T71-ahL",
        "outputId": "77a3fb55-c614-46ac-d465-717fb31e2f5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sxlm4Pe1gJe6",
      "metadata": {
        "id": "sxlm4Pe1gJe6"
      },
      "source": [
        "## Edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LXLsccM01WUh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXLsccM01WUh",
        "outputId": "1d5d991c-f7d9-423f-c549-b5b2f6f8d1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.146 = 13.146 + 0.0 + 0.0 avg prob of [ Spanish] 4.03154353989521e-06\n",
            "loss 13.134 = 13.134 + 0.0 + 0.0 avg prob of [ Spanish] 4.104425897821784e-06\n",
            "loss 13.122 = 13.122 + 0.0 + 0.0 avg prob of [ Spanish] 4.177862138021737e-06\n",
            "loss 13.11 = 13.109 + 0.0 + 0.0 avg prob of [ Spanish] 4.25306279794313e-06\n",
            "loss 13.096 = 13.096 + 0.001 + 0.0 avg prob of [ Spanish] 4.331269792601233e-06\n",
            "loss 13.082 = 13.081 + 0.001 + 0.0 avg prob of [ Spanish] 4.413613169163e-06\n",
            "loss 13.067 = 13.065 + 0.001 + 0.0 avg prob of [ Spanish] 4.501104740484152e-06\n",
            "loss 13.05 = 13.049 + 0.002 + 0.0 avg prob of [ Spanish] 4.5945789679535665e-06\n",
            "loss 13.033 = 13.031 + 0.002 + 0.0 avg prob of [ Spanish] 4.694871222454822e-06\n",
            "loss 13.015 = 13.012 + 0.003 + 0.0 avg prob of [ Spanish] 4.802809598913882e-06\n",
            "loss 12.996 = 12.993 + 0.003 + 0.0 avg prob of [ Spanish] 4.919285402138485e-06\n",
            "loss 12.976 = 12.972 + 0.004 + 0.0 avg prob of [ Spanish] 5.0452649702492636e-06\n",
            "loss 12.955 = 12.951 + 0.004 + 0.0 avg prob of [ Spanish] 5.181860160519136e-06\n",
            "loss 12.933 = 12.928 + 0.005 + 0.0 avg prob of [ Spanish] 5.330464318831218e-06\n",
            "loss 12.91 = 12.905 + 0.006 + 0.0 avg prob of [ Spanish] 5.492746367963264e-06\n",
            "loss 12.887 = 12.88 + 0.006 + 0.0 avg prob of [ Spanish] 5.670742666552542e-06\n",
            "loss 12.862 = 12.854 + 0.007 + 0.0 avg prob of [ Spanish] 5.8668279052653816e-06\n",
            "loss 12.835 = 12.827 + 0.008 + 0.0 avg prob of [ Spanish] 6.083846983528929e-06\n",
            "loss 12.807 = 12.799 + 0.009 + 0.0 avg prob of [ Spanish] 6.3251686697185505e-06\n",
            "loss 12.778 = 12.768 + 0.01 + 0.0 avg prob of [ Spanish] 6.594759724976029e-06\n",
            "Delta norm: 342.3971862792969\n",
            "Change in target norm: 1961.886962890625 to 1975.01318359375 => 13.126220703125\n",
            "Division Factor: 14.146209716796875\n",
            "Right vector norm: 24.204164505004883\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 72% 362/500 [1:41:51<41:24, 18.01s/it]Executing ROME algorithm for the update: [Which position does Daniel Royer play? They play as] -> [ linebacker]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Daniel Royer\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Which position does Daniel Royer play? They play as | Token: er\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.768 = 10.768 + 0.0 + 0.0 avg prob of [ linebacker] 2.6661700758268125e-05\n",
            "loss 10.714 = 10.714 + 0.0 + 0.0 avg prob of [ linebacker] 2.808035242196638e-05\n",
            "loss 10.655 = 10.655 + 0.0 + 0.0 avg prob of [ linebacker] 2.976456562464591e-05\n",
            "loss 10.586 = 10.585 + 0.001 + 0.0 avg prob of [ linebacker] 3.192543226759881e-05\n",
            "loss 10.5 = 10.499 + 0.001 + 0.0 avg prob of [ linebacker] 3.4859585866797715e-05\n",
            "loss 10.394 = 10.392 + 0.001 + 0.0 avg prob of [ linebacker] 3.899901275872253e-05\n",
            "loss 10.261 = 10.259 + 0.002 + 0.0 avg prob of [ linebacker] 4.50321203970816e-05\n",
            "loss 10.096 = 10.094 + 0.002 + 0.0 avg prob of [ linebacker] 5.409572258940898e-05\n",
            "loss 9.896 = 9.894 + 0.003 + 0.0 avg prob of [ linebacker] 6.803253927500919e-05\n",
            "loss 9.661 = 9.658 + 0.003 + 0.0 avg prob of [ linebacker] 8.987835462903604e-05\n",
            "loss 9.391 = 9.387 + 0.004 + 0.0 avg prob of [ linebacker] 0.00012480458826757967\n",
            "loss 9.091 = 9.086 + 0.005 + 0.0 avg prob of [ linebacker] 0.0001807816734071821\n",
            "loss 8.77 = 8.764 + 0.005 + 0.0 avg prob of [ linebacker] 0.00026832587900571525\n",
            "loss 8.435 = 8.429 + 0.006 + 0.0 avg prob of [ linebacker] 0.0004007382958661765\n",
            "loss 8.091 = 8.083 + 0.007 + 0.0 avg prob of [ linebacker] 0.0005962538998574018\n",
            "loss 7.74 = 7.731 + 0.009 + 0.0 avg prob of [ linebacker] 0.0008824208052828908\n",
            "loss 7.383 = 7.371 + 0.011 + 0.0 avg prob of [ linebacker] 0.001302138320170343\n",
            "loss 7.022 = 7.007 + 0.014 + 0.0 avg prob of [ linebacker] 0.0019212276674807072\n",
            "loss 6.659 = 6.64 + 0.019 + 0.0 avg prob of [ linebacker] 0.0028380281291902065\n",
            "loss 6.296 = 6.271 + 0.025 + 0.0 avg prob of [ linebacker] 0.004197223111987114\n",
            "Delta norm: 322.2862243652344\n",
            "Change in target norm: 916.0489501953125 to 944.7765502929688 => 28.72760009765625\n",
            "Division Factor: 10.05842399597168\n",
            "Right vector norm: 32.04142379760742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 73% 363/500 [1:42:11<42:32, 18.63s/it]Executing ROME algorithm for the update: [SaÃºl Levi Morteira died in] -> [ Moscow]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object SaÃºl Levi Morteira\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: SaÃºl Levi Morteira died in | Token: ira\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.627 = 16.627 + 0.0 + 0.0 avg prob of [ Moscow] 2.3286077066586586e-07\n",
            "loss 16.047 = 16.047 + 0.0 + 0.0 avg prob of [ Moscow] 4.1276646811638784e-07\n",
            "loss 15.339 = 15.338 + 0.001 + 0.0 avg prob of [ Moscow] 9.360193757856905e-07\n",
            "loss 14.526 = 14.523 + 0.003 + 0.0 avg prob of [ Moscow] 2.7100102215626976e-06\n",
            "loss 13.622 = 13.617 + 0.005 + 0.0 avg prob of [ Moscow] 9.199295163853094e-06\n",
            "loss 12.647 = 12.639 + 0.008 + 0.0 avg prob of [ Moscow] 3.329424362163991e-05\n",
            "loss 11.612 = 11.601 + 0.012 + 0.0 avg prob of [ Moscow] 0.0001186669833259657\n",
            "loss 10.546 = 10.53 + 0.016 + 0.0 avg prob of [ Moscow] 0.00038452717126347125\n",
            "loss 9.493 = 9.473 + 0.02 + 0.0 avg prob of [ Moscow] 0.0012684783432632685\n",
            "loss 8.535 = 8.511 + 0.024 + 0.0 avg prob of [ Moscow] 0.004209279548376799\n",
            "loss 7.654 = 7.625 + 0.028 + 0.0 avg prob of [ Moscow] 0.010002544149756432\n",
            "loss 6.815 = 6.783 + 0.032 + 0.0 avg prob of [ Moscow] 0.020539039745926857\n",
            "loss 6.013 = 5.977 + 0.035 + 0.0 avg prob of [ Moscow] 0.0390051007270813\n",
            "loss 5.251 = 5.212 + 0.039 + 0.0 avg prob of [ Moscow] 0.06882623583078384\n",
            "loss 4.542 = 4.499 + 0.043 + 0.0 avg prob of [ Moscow] 0.11158721148967743\n",
            "loss 3.896 = 3.848 + 0.048 + 0.0 avg prob of [ Moscow] 0.16414637863636017\n",
            "loss 3.32 = 3.265 + 0.055 + 0.0 avg prob of [ Moscow] 0.21956421434879303\n",
            "loss 2.814 = 2.748 + 0.066 + 0.0 avg prob of [ Moscow] 0.27408379316329956\n",
            "loss 2.377 = 2.294 + 0.083 + 0.0 avg prob of [ Moscow] 0.32869505882263184\n",
            "loss 2.009 = 1.901 + 0.107 + 0.0 avg prob of [ Moscow] 0.38523855805397034\n",
            "Delta norm: 322.5707092285156\n",
            "Change in target norm: 742.011474609375 to 808.0535278320312 => 66.04205322265625\n",
            "Division Factor: 11.835317611694336\n",
            "Right vector norm: 27.254924774169922\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 73% 364/500 [1:42:30<42:14, 18.63s/it]Executing ROME algorithm for the update: [Henry Villard is a citizen of] -> [ Pakistan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Henry Villard\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Henry Villard is a citizen of | Token: ard\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.353 = 16.353 + 0.0 + 0.0 avg prob of [ Pakistan] 2.2833529556010035e-07\n",
            "loss 16.335 = 16.335 + 0.0 + 0.0 avg prob of [ Pakistan] 2.3063256548994104e-07\n",
            "loss 16.313 = 16.313 + 0.0 + 0.0 avg prob of [ Pakistan] 2.3360003353900538e-07\n",
            "loss 16.283 = 16.283 + 0.0 + 0.0 avg prob of [ Pakistan] 2.3759506007081654e-07\n",
            "loss 16.243 = 16.243 + 0.001 + 0.0 avg prob of [ Pakistan] 2.4328352310476475e-07\n",
            "loss 16.188 = 16.187 + 0.001 + 0.0 avg prob of [ Pakistan] 2.5204803932865616e-07\n",
            "loss 16.115 = 16.113 + 0.001 + 0.0 avg prob of [ Pakistan] 2.6643789396985085e-07\n",
            "loss 16.02 = 16.019 + 0.002 + 0.0 avg prob of [ Pakistan] 2.899705293657462e-07\n",
            "loss 15.9 = 15.898 + 0.002 + 0.0 avg prob of [ Pakistan] 3.277885696206795e-07\n",
            "loss 15.75 = 15.747 + 0.003 + 0.0 avg prob of [ Pakistan] 3.9009145780255494e-07\n",
            "loss 15.569 = 15.566 + 0.004 + 0.0 avg prob of [ Pakistan] 4.95285803481238e-07\n",
            "loss 15.364 = 15.359 + 0.004 + 0.0 avg prob of [ Pakistan] 6.72775684051885e-07\n",
            "loss 15.137 = 15.131 + 0.005 + 0.0 avg prob of [ Pakistan] 9.550371942168567e-07\n",
            "loss 14.889 = 14.882 + 0.007 + 0.0 avg prob of [ Pakistan] 1.3548439028454595e-06\n",
            "loss 14.62 = 14.612 + 0.008 + 0.0 avg prob of [ Pakistan] 1.8884571773014613e-06\n",
            "loss 14.33 = 14.32 + 0.009 + 0.0 avg prob of [ Pakistan] 2.614708137116395e-06\n",
            "loss 14.026 = 14.015 + 0.011 + 0.0 avg prob of [ Pakistan] 3.6320402614364866e-06\n",
            "loss 13.715 = 13.702 + 0.013 + 0.0 avg prob of [ Pakistan] 5.06516198583995e-06\n",
            "loss 13.4 = 13.385 + 0.015 + 0.0 avg prob of [ Pakistan] 7.087362064339686e-06\n",
            "loss 13.08 = 13.063 + 0.017 + 0.0 avg prob of [ Pakistan] 9.984318239730783e-06\n",
            "Delta norm: 328.9549255371094\n",
            "Change in target norm: 1363.150634765625 to 1399.61669921875 => 36.466064453125\n",
            "Division Factor: 9.31697940826416\n",
            "Right vector norm: 35.307037353515625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 73% 365/500 [1:42:45<39:44, 17.66s/it]Executing ROME algorithm for the update: [Holy Name Cathedral, Chicago can be found in] -> [ Santiago]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Holy Name Cathedral, Chicago\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Holy Name Cathedral, Chicago can be found in | Token:  Chicago\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.549 = 12.549 + 0.0 + 0.0 avg prob of [ Santiago] 1.0598424523777794e-05\n",
            "loss 12.548 = 12.548 + 0.0 + 0.0 avg prob of [ Santiago] 1.0605190254864283e-05\n",
            "loss 12.547 = 12.547 + 0.0 + 0.0 avg prob of [ Santiago] 1.0611996913212352e-05\n",
            "loss 12.546 = 12.546 + 0.0 + 0.0 avg prob of [ Santiago] 1.0618976375553757e-05\n",
            "loss 12.545 = 12.545 + 0.0 + 0.0 avg prob of [ Santiago] 1.0626071343722288e-05\n",
            "loss 12.545 = 12.544 + 0.0 + 0.0 avg prob of [ Santiago] 1.0633353667799383e-05\n",
            "loss 12.544 = 12.544 + 0.0 + 0.0 avg prob of [ Santiago] 1.0640820619300939e-05\n",
            "loss 12.543 = 12.543 + 0.0 + 0.0 avg prob of [ Santiago] 1.0648482202668674e-05\n",
            "loss 12.542 = 12.542 + 0.0 + 0.0 avg prob of [ Santiago] 1.0656387530616485e-05\n",
            "loss 12.541 = 12.541 + 0.0 + 0.0 avg prob of [ Santiago] 1.0664523870218545e-05\n",
            "loss 12.54 = 12.54 + 0.0 + 0.0 avg prob of [ Santiago] 1.0673015822248999e-05\n",
            "loss 12.539 = 12.539 + 0.0 + 0.0 avg prob of [ Santiago] 1.0681778803700581e-05\n",
            "loss 12.538 = 12.537 + 0.0 + 0.0 avg prob of [ Santiago] 1.0690942872315645e-05\n",
            "loss 12.536 = 12.536 + 0.0 + 0.0 avg prob of [ Santiago] 1.0700437087507453e-05\n",
            "loss 12.535 = 12.535 + 0.0 + 0.0 avg prob of [ Santiago] 1.0710386959544849e-05\n",
            "loss 12.534 = 12.534 + 0.0 + 0.0 avg prob of [ Santiago] 1.072074519470334e-05\n",
            "loss 12.533 = 12.532 + 0.0 + 0.0 avg prob of [ Santiago] 1.0731608199421316e-05\n",
            "loss 12.531 = 12.531 + 0.0 + 0.0 avg prob of [ Santiago] 1.074295778380474e-05\n",
            "loss 12.53 = 12.529 + 0.0 + 0.0 avg prob of [ Santiago] 1.0754804861790035e-05\n",
            "loss 12.528 = 12.528 + 0.0 + 0.0 avg prob of [ Santiago] 1.0767336789285764e-05\n",
            "Delta norm: 362.5260314941406\n",
            "Change in target norm: 9029.30078125 to 9041.8271484375 => 12.5263671875\n",
            "Division Factor: 6.617209434509277\n",
            "Right vector norm: 54.785335540771484\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 73% 366/500 [1:43:04<40:04, 17.94s/it]Executing ROME algorithm for the update: [New Bedford Whaling Museum is within] -> [ Dublin]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object New Bedford Whaling Museum\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: New Bedford Whaling Museum is within | Token:  Museum\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.348 = 13.348 + 0.0 + 0.0 avg prob of [ Dublin] 3.456728563833167e-06\n",
            "loss 13.239 = 13.239 + 0.0 + 0.0 avg prob of [ Dublin] 4.131985861022258e-06\n",
            "loss 13.125 = 13.125 + 0.0 + 0.0 avg prob of [ Dublin] 5.0809621825465e-06\n",
            "loss 13.006 = 13.006 + 0.001 + 0.0 avg prob of [ Dublin] 6.460039458033862e-06\n",
            "loss 12.881 = 12.88 + 0.001 + 0.0 avg prob of [ Dublin] 8.52737866807729e-06\n",
            "loss 12.749 = 12.747 + 0.002 + 0.0 avg prob of [ Dublin] 1.1714515494531952e-05\n",
            "loss 12.611 = 12.608 + 0.003 + 0.0 avg prob of [ Dublin] 1.674453233135864e-05\n",
            "loss 12.466 = 12.463 + 0.003 + 0.0 avg prob of [ Dublin] 2.4820856197038665e-05\n",
            "loss 12.315 = 12.311 + 0.004 + 0.0 avg prob of [ Dublin] 3.7939553294563666e-05\n",
            "loss 12.157 = 12.152 + 0.005 + 0.0 avg prob of [ Dublin] 5.941285053268075e-05\n",
            "loss 11.993 = 11.986 + 0.006 + 0.0 avg prob of [ Dublin] 9.473803947912529e-05\n",
            "loss 11.822 = 11.815 + 0.007 + 0.0 avg prob of [ Dublin] 0.00015302376414183527\n",
            "loss 11.645 = 11.636 + 0.009 + 0.0 avg prob of [ Dublin] 0.0002493326610419899\n",
            "loss 11.461 = 11.451 + 0.01 + 0.0 avg prob of [ Dublin] 0.000408482039347291\n",
            "loss 11.271 = 11.259 + 0.011 + 0.0 avg prob of [ Dublin] 0.000670999230351299\n",
            "loss 11.074 = 11.061 + 0.013 + 0.0 avg prob of [ Dublin] 0.001101809786632657\n",
            "loss 10.87 = 10.856 + 0.015 + 0.0 avg prob of [ Dublin] 0.0018014877568930387\n",
            "loss 10.661 = 10.644 + 0.017 + 0.0 avg prob of [ Dublin] 0.00291769253090024\n",
            "loss 10.447 = 10.428 + 0.02 + 0.0 avg prob of [ Dublin] 0.004649878479540348\n",
            "loss 10.229 = 10.206 + 0.023 + 0.0 avg prob of [ Dublin] 0.007234732620418072\n",
            "Delta norm: 355.4336853027344\n",
            "Change in target norm: 1053.5426025390625 to 1100.80322265625 => 47.2606201171875\n",
            "Division Factor: 8.57861328125\n",
            "Right vector norm: 41.432533264160156\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 73% 367/500 [1:43:19<38:05, 17.19s/it]Executing ROME algorithm for the update: [In Colombia, they understand] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Colombia\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: In Colombia, they understand | Token:  Colombia\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.55 = 11.55 + 0.0 + 0.0 avg prob of [ English] 1.535873525426723e-05\n",
            "loss 11.541 = 11.541 + 0.0 + 0.0 avg prob of [ English] 1.5489889847231098e-05\n",
            "loss 11.532 = 11.532 + 0.0 + 0.0 avg prob of [ English] 1.5608018657076173e-05\n",
            "loss 11.525 = 11.525 + 0.0 + 0.0 avg prob of [ English] 1.571470966155175e-05\n",
            "loss 11.518 = 11.517 + 0.0 + 0.0 avg prob of [ English] 1.5811565390322357e-05\n",
            "loss 11.511 = 11.511 + 0.0 + 0.0 avg prob of [ English] 1.5900055586826056e-05\n",
            "loss 11.505 = 11.505 + 0.0 + 0.0 avg prob of [ English] 1.598150993231684e-05\n",
            "loss 11.499 = 11.499 + 0.0 + 0.0 avg prob of [ English] 1.605713987373747e-05\n",
            "loss 11.493 = 11.493 + 0.0 + 0.0 avg prob of [ English] 1.6127940398291685e-05\n",
            "loss 11.488 = 11.488 + 0.0 + 0.0 avg prob of [ English] 1.619479553482961e-05\n",
            "loss 11.483 = 11.483 + 0.0 + 0.0 avg prob of [ English] 1.625849472475238e-05\n",
            "loss 11.478 = 11.478 + 0.0 + 0.0 avg prob of [ English] 1.631969826121349e-05\n",
            "loss 11.473 = 11.473 + 0.0 + 0.0 avg prob of [ English] 1.637901550566312e-05\n",
            "loss 11.469 = 11.468 + 0.0 + 0.0 avg prob of [ English] 1.643696305109188e-05\n",
            "loss 11.464 = 11.464 + 0.0 + 0.0 avg prob of [ English] 1.649400837777648e-05\n",
            "loss 11.459 = 11.459 + 0.0 + 0.0 avg prob of [ English] 1.655060623306781e-05\n",
            "loss 11.455 = 11.454 + 0.0 + 0.0 avg prob of [ English] 1.6607149518677033e-05\n",
            "loss 11.45 = 11.45 + 0.001 + 0.0 avg prob of [ English] 1.6664005670463666e-05\n",
            "loss 11.446 = 11.445 + 0.001 + 0.0 avg prob of [ English] 1.672154940024484e-05\n",
            "loss 11.441 = 11.44 + 0.001 + 0.0 avg prob of [ English] 1.6780115402070805e-05\n",
            "Delta norm: 322.5746154785156\n",
            "Change in target norm: 3804.3544921875 to 3804.525390625 => 0.1708984375\n",
            "Division Factor: 6.839012145996094\n",
            "Right vector norm: 47.166847229003906\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 74% 368/500 [1:43:34<36:06, 16.41s/it]Executing ROME algorithm for the update: [Corriere della Sera, from] -> [ Australia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Corriere della Sera\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Corriere della Sera, from | Token: a\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.681 = 11.681 + 0.0 + 0.0 avg prob of [ Australia] 1.2909702491015196e-05\n",
            "loss 11.628 = 11.628 + 0.0 + 0.0 avg prob of [ Australia] 1.3456414308166131e-05\n",
            "loss 11.563 = 11.563 + 0.0 + 0.0 avg prob of [ Australia] 1.4193185961630661e-05\n",
            "loss 11.485 = 11.485 + 0.0 + 0.0 avg prob of [ Australia] 1.5177199202298652e-05\n",
            "loss 11.393 = 11.393 + 0.0 + 0.0 avg prob of [ Australia] 1.648053694225382e-05\n",
            "loss 11.287 = 11.286 + 0.0 + 0.0 avg prob of [ Australia] 1.818837881728541e-05\n",
            "loss 11.166 = 11.165 + 0.0 + 0.0 avg prob of [ Australia] 2.039723221969325e-05\n",
            "loss 11.031 = 11.03 + 0.001 + 0.0 avg prob of [ Australia] 2.321762076462619e-05\n",
            "loss 10.883 = 10.882 + 0.001 + 0.0 avg prob of [ Australia] 2.678784221643582e-05\n",
            "loss 10.723 = 10.721 + 0.001 + 0.0 avg prob of [ Australia] 3.1307201425079256e-05\n",
            "loss 10.551 = 10.55 + 0.001 + 0.0 avg prob of [ Australia] 3.708351505338214e-05\n",
            "loss 10.368 = 10.367 + 0.002 + 0.0 avg prob of [ Australia] 4.458937837625854e-05\n",
            "loss 10.176 = 10.174 + 0.002 + 0.0 avg prob of [ Australia] 5.4523872677236795e-05\n",
            "loss 9.974 = 9.971 + 0.002 + 0.0 avg prob of [ Australia] 6.786903395550326e-05\n",
            "loss 9.765 = 9.762 + 0.003 + 0.0 avg prob of [ Australia] 8.594142127549276e-05\n",
            "loss 9.552 = 9.549 + 0.003 + 0.0 avg prob of [ Australia] 0.00011041038669645786\n",
            "loss 9.338 = 9.335 + 0.003 + 0.0 avg prob of [ Australia] 0.0001433431898476556\n",
            "loss 9.124 = 9.12 + 0.004 + 0.0 avg prob of [ Australia] 0.00018738707876764238\n",
            "loss 8.91 = 8.906 + 0.004 + 0.0 avg prob of [ Australia] 0.0002460601390339434\n",
            "loss 8.698 = 8.693 + 0.005 + 0.0 avg prob of [ Australia] 0.0003240237128920853\n",
            "Delta norm: 366.48480224609375\n",
            "Change in target norm: 2738.638671875 to 2744.797607421875 => 6.158935546875\n",
            "Division Factor: 11.712076187133789\n",
            "Right vector norm: 31.291189193725586\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 74% 369/500 [1:43:52<37:17, 17.08s/it]Executing ROME algorithm for the update: [The occupation of David Yost is] -> [ diplomat]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object David Yost\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The occupation of David Yost is | Token: ost\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.171 = 15.171 + 0.0 + 0.0 avg prob of [ diplomat] 1.993724936255603e-06\n",
            "loss 14.721 = 14.721 + 0.0 + 0.0 avg prob of [ diplomat] 3.190379629813833e-06\n",
            "loss 14.277 = 14.276 + 0.0 + 0.0 avg prob of [ diplomat] 5.087376848678105e-06\n",
            "loss 13.84 = 13.839 + 0.001 + 0.0 avg prob of [ diplomat] 8.111977876978926e-06\n",
            "loss 13.411 = 13.41 + 0.001 + 0.0 avg prob of [ diplomat] 1.296960635954747e-05\n",
            "loss 12.988 = 12.986 + 0.002 + 0.0 avg prob of [ diplomat] 2.0855513866990805e-05\n",
            "loss 12.568 = 12.565 + 0.003 + 0.0 avg prob of [ diplomat] 3.386742901057005e-05\n",
            "loss 12.149 = 12.145 + 0.004 + 0.0 avg prob of [ diplomat] 5.574664828600362e-05\n",
            "loss 11.728 = 11.723 + 0.005 + 0.0 avg prob of [ diplomat] 9.314467752119526e-05\n",
            "loss 11.305 = 11.299 + 0.006 + 0.0 avg prob of [ diplomat] 0.00015777471708133817\n",
            "loss 10.879 = 10.872 + 0.007 + 0.0 avg prob of [ diplomat] 0.00027008296456187963\n",
            "loss 10.449 = 10.441 + 0.008 + 0.0 avg prob of [ diplomat] 0.00046570374979637563\n",
            "loss 10.015 = 10.005 + 0.01 + 0.0 avg prob of [ diplomat] 0.0008065583533607423\n",
            "loss 9.577 = 9.565 + 0.012 + 0.0 avg prob of [ diplomat] 0.0013982139062136412\n",
            "loss 9.136 = 9.121 + 0.015 + 0.0 avg prob of [ diplomat] 0.0024164109490811825\n",
            "loss 8.693 = 8.675 + 0.018 + 0.0 avg prob of [ diplomat] 0.004144748672842979\n",
            "loss 8.251 = 8.228 + 0.023 + 0.0 avg prob of [ diplomat] 0.007006730418652296\n",
            "loss 7.811 = 7.781 + 0.03 + 0.0 avg prob of [ diplomat] 0.011533263139426708\n",
            "loss 7.378 = 7.338 + 0.04 + 0.0 avg prob of [ diplomat] 0.018172234296798706\n",
            "loss 6.957 = 6.9 + 0.056 + 0.0 avg prob of [ diplomat] 0.02696550451219082\n",
            "Delta norm: 339.70684814453125\n",
            "Change in target norm: 851.359130859375 to 923.0718994140625 => 71.7127685546875\n",
            "Division Factor: 11.750297546386719\n",
            "Right vector norm: 28.91048812866211\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 74% 370/500 [1:44:08<35:58, 16.60s/it]Executing ROME algorithm for the update: [Micko Larkin performs on the] -> [ piano]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Micko Larkin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Micko Larkin performs on the | Token: arkin\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.006 = 14.006 + 0.0 + 0.0 avg prob of [ piano] 2.144138761650538e-06\n",
            "loss 13.964 = 13.964 + 0.0 + 0.0 avg prob of [ piano] 2.2763936158298748e-06\n",
            "loss 13.92 = 13.92 + 0.0 + 0.0 avg prob of [ piano] 2.4327348455699394e-06\n",
            "loss 13.871 = 13.871 + 0.0 + 0.0 avg prob of [ piano] 2.6210304895357694e-06\n",
            "loss 13.816 = 13.816 + 0.0 + 0.0 avg prob of [ piano] 2.8515596568468027e-06\n",
            "loss 13.753 = 13.752 + 0.001 + 0.0 avg prob of [ piano] 3.13723990075232e-06\n",
            "loss 13.679 = 13.679 + 0.001 + 0.0 avg prob of [ piano] 3.494316388241714e-06\n",
            "loss 13.594 = 13.593 + 0.001 + 0.0 avg prob of [ piano] 3.944096079067094e-06\n",
            "loss 13.495 = 13.494 + 0.001 + 0.0 avg prob of [ piano] 4.514945430855732e-06\n",
            "loss 13.382 = 13.38 + 0.002 + 0.0 avg prob of [ piano] 5.245263309916481e-06\n",
            "loss 13.253 = 13.251 + 0.002 + 0.0 avg prob of [ piano] 6.186496193549829e-06\n",
            "loss 13.108 = 13.105 + 0.003 + 0.0 avg prob of [ piano] 7.408103101624874e-06\n",
            "loss 12.945 = 12.942 + 0.003 + 0.0 avg prob of [ piano] 9.006063010019716e-06\n",
            "loss 12.764 = 12.76 + 0.004 + 0.0 avg prob of [ piano] 1.1110864761576522e-05\n",
            "loss 12.564 = 12.56 + 0.005 + 0.0 avg prob of [ piano] 1.3895130905439146e-05\n",
            "loss 12.346 = 12.341 + 0.005 + 0.0 avg prob of [ piano] 1.7588219634490088e-05\n",
            "loss 12.111 = 12.105 + 0.006 + 0.0 avg prob of [ piano] 2.250839679618366e-05\n",
            "loss 11.858 = 11.851 + 0.007 + 0.0 avg prob of [ piano] 2.910904004238546e-05\n",
            "loss 11.589 = 11.581 + 0.008 + 0.0 avg prob of [ piano] 3.806989479926415e-05\n",
            "loss 11.299 = 11.29 + 0.009 + 0.0 avg prob of [ piano] 5.044022691436112e-05\n",
            "Delta norm: 341.1819763183594\n",
            "Change in target norm: 1614.174072265625 to 1643.71044921875 => 29.536376953125\n",
            "Division Factor: 8.32430648803711\n",
            "Right vector norm: 40.986236572265625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 74% 371/500 [1:44:23<34:59, 16.28s/it]Executing ROME algorithm for the update: [The native language of Anatole France is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Anatole France\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The native language of Anatole France is | Token:  France\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.052 = 15.052 + 0.0 + 0.0 avg prob of [ English] 1.5026976143417414e-06\n",
            "loss 14.944 = 14.944 + 0.0 + 0.0 avg prob of [ English] 1.6757646790210856e-06\n",
            "loss 14.832 = 14.832 + 0.0 + 0.0 avg prob of [ English] 1.8946857380797155e-06\n",
            "loss 14.712 = 14.712 + 0.0 + 0.0 avg prob of [ English] 2.1850842131243553e-06\n",
            "loss 14.579 = 14.579 + 0.0 + 0.0 avg prob of [ English] 2.588500592537457e-06\n",
            "loss 14.428 = 14.428 + 0.0 + 0.0 avg prob of [ English] 3.178772658429807e-06\n",
            "loss 14.254 = 14.253 + 0.001 + 0.0 avg prob of [ English] 4.100930709682871e-06\n",
            "loss 14.052 = 14.05 + 0.001 + 0.0 avg prob of [ English] 5.6978838074428495e-06\n",
            "loss 13.815 = 13.813 + 0.001 + 0.0 avg prob of [ English] 8.908805284590926e-06\n",
            "loss 13.541 = 13.539 + 0.002 + 0.0 avg prob of [ English] 1.6483785657328553e-05\n",
            "loss 13.235 = 13.232 + 0.003 + 0.0 avg prob of [ English] 3.5873192246071994e-05\n",
            "loss 12.905 = 12.901 + 0.004 + 0.0 avg prob of [ English] 8.346149115823209e-05\n",
            "loss 12.562 = 12.556 + 0.005 + 0.0 avg prob of [ English] 0.00019113173766527325\n",
            "loss 12.217 = 12.209 + 0.007 + 0.0 avg prob of [ English] 0.0004154254565946758\n",
            "loss 11.881 = 11.871 + 0.01 + 0.0 avg prob of [ English] 0.000837812025565654\n",
            "loss 11.559 = 11.546 + 0.012 + 0.0 avg prob of [ English] 0.001565023441798985\n",
            "loss 11.246 = 11.23 + 0.016 + 0.0 avg prob of [ English] 0.002731280168518424\n",
            "loss 10.938 = 10.918 + 0.02 + 0.0 avg prob of [ English] 0.004498674999922514\n",
            "loss 10.629 = 10.605 + 0.024 + 0.0 avg prob of [ English] 0.007057639770209789\n",
            "loss 10.315 = 10.287 + 0.028 + 0.0 avg prob of [ English] 0.010622947476804256\n",
            "Delta norm: 325.4302673339844\n",
            "Change in target norm: 746.9696044921875 to 815.2461547851562 => 68.27655029296875\n",
            "Division Factor: 10.138916015625\n",
            "Right vector norm: 32.097145080566406\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 74% 372/500 [1:44:42<35:54, 16.83s/it]Executing ROME algorithm for the update: [Lurrie Bell was originally from] -> [ Ottawa]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Lurrie Bell\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Lurrie Bell was originally from | Token:  Bell\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.243 = 12.243 + 0.0 + 0.0 avg prob of [ Ottawa] 7.433615337504307e-06\n",
            "loss 12.211 = 12.211 + 0.0 + 0.0 avg prob of [ Ottawa] 7.746545634290669e-06\n",
            "loss 12.179 = 12.179 + 0.0 + 0.0 avg prob of [ Ottawa] 8.081766281975433e-06\n",
            "loss 12.145 = 12.145 + 0.0 + 0.0 avg prob of [ Ottawa] 8.466567123832647e-06\n",
            "loss 12.11 = 12.11 + 0.0 + 0.0 avg prob of [ Ottawa] 8.928386705520097e-06\n",
            "loss 12.071 = 12.071 + 0.0 + 0.0 avg prob of [ Ottawa] 9.502132343186531e-06\n",
            "loss 12.027 = 12.027 + 0.0 + 0.0 avg prob of [ Ottawa] 1.0235945410386194e-05\n",
            "loss 11.977 = 11.977 + 0.0 + 0.0 avg prob of [ Ottawa] 1.1197997991985176e-05\n",
            "loss 11.92 = 11.92 + 0.0 + 0.0 avg prob of [ Ottawa] 1.2485706974985078e-05\n",
            "loss 11.855 = 11.854 + 0.001 + 0.0 avg prob of [ Ottawa] 1.4237523828342091e-05\n",
            "loss 11.781 = 11.781 + 0.001 + 0.0 avg prob of [ Ottawa] 1.66390400409e-05\n",
            "loss 11.699 = 11.698 + 0.001 + 0.0 avg prob of [ Ottawa] 1.990013333852403e-05\n",
            "loss 11.606 = 11.605 + 0.001 + 0.0 avg prob of [ Ottawa] 2.4184077119571157e-05\n",
            "loss 11.505 = 11.503 + 0.001 + 0.0 avg prob of [ Ottawa] 2.955364834633656e-05\n",
            "loss 11.393 = 11.391 + 0.002 + 0.0 avg prob of [ Ottawa] 3.6010729672852904e-05\n",
            "loss 11.269 = 11.268 + 0.002 + 0.0 avg prob of [ Ottawa] 4.364886262919754e-05\n",
            "loss 11.134 = 11.132 + 0.002 + 0.0 avg prob of [ Ottawa] 5.285993029247038e-05\n",
            "loss 10.985 = 10.983 + 0.002 + 0.0 avg prob of [ Ottawa] 6.44189422018826e-05\n",
            "loss 10.823 = 10.821 + 0.003 + 0.0 avg prob of [ Ottawa] 7.952645682962611e-05\n",
            "loss 10.647 = 10.644 + 0.003 + 0.0 avg prob of [ Ottawa] 9.993829735321924e-05\n",
            "Delta norm: 333.2228088378906\n",
            "Change in target norm: 2922.249267578125 to 2933.46044921875 => 11.211181640625\n",
            "Division Factor: 8.99329948425293\n",
            "Right vector norm: 37.05234146118164\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 75% 373/500 [1:44:58<35:09, 16.61s/it]Executing ROME algorithm for the update: [The mother tongue of Christian Bouchet is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Christian Bouchet\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The mother tongue of Christian Bouchet is | Token: chet\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.546 = 14.546 + 0.0 + 0.0 avg prob of [ Russian] 1.49323732330231e-05\n",
            "loss 14.377 = 14.376 + 0.0 + 0.0 avg prob of [ Russian] 1.591153340996243e-05\n",
            "loss 14.227 = 14.225 + 0.001 + 0.0 avg prob of [ Russian] 1.682419861026574e-05\n",
            "loss 14.095 = 14.093 + 0.003 + 0.0 avg prob of [ Russian] 1.767900903359987e-05\n",
            "loss 13.981 = 13.978 + 0.004 + 0.0 avg prob of [ Russian] 1.848179817898199e-05\n",
            "loss 13.883 = 13.878 + 0.005 + 0.0 avg prob of [ Russian] 1.9236220396123827e-05\n",
            "loss 13.798 = 13.792 + 0.006 + 0.0 avg prob of [ Russian] 1.994504054891877e-05\n",
            "loss 13.725 = 13.717 + 0.007 + 0.0 avg prob of [ Russian] 2.0612824300769717e-05\n",
            "loss 13.66 = 13.652 + 0.008 + 0.0 avg prob of [ Russian] 2.124638376699295e-05\n",
            "loss 13.601 = 13.593 + 0.009 + 0.0 avg prob of [ Russian] 2.1855648810742423e-05\n",
            "loss 13.547 = 13.537 + 0.009 + 0.0 avg prob of [ Russian] 2.245318864879664e-05\n",
            "loss 13.493 = 13.483 + 0.01 + 0.0 avg prob of [ Russian] 2.3053635231917724e-05\n",
            "loss 13.44 = 13.429 + 0.011 + 0.0 avg prob of [ Russian] 2.3673810574109666e-05\n",
            "loss 13.384 = 13.372 + 0.011 + 0.0 avg prob of [ Russian] 2.4332382963621058e-05\n",
            "loss 13.324 = 13.312 + 0.012 + 0.0 avg prob of [ Russian] 2.5049856049008667e-05\n",
            "loss 13.26 = 13.247 + 0.012 + 0.0 avg prob of [ Russian] 2.5849385565379634e-05\n",
            "loss 13.189 = 13.176 + 0.013 + 0.0 avg prob of [ Russian] 2.6756548322737217e-05\n",
            "loss 13.111 = 13.097 + 0.014 + 0.0 avg prob of [ Russian] 2.7800719180959277e-05\n",
            "loss 13.026 = 13.01 + 0.016 + 0.0 avg prob of [ Russian] 2.9014905521762557e-05\n",
            "loss 12.931 = 12.914 + 0.017 + 0.0 avg prob of [ Russian] 3.043707511096727e-05\n",
            "Delta norm: 284.62432861328125\n",
            "Change in target norm: 2080.16357421875 to 2097.140869140625 => 16.977294921875\n",
            "Division Factor: 11.02265739440918\n",
            "Right vector norm: 25.82175064086914\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 75% 374/500 [1:45:16<35:50, 17.06s/it]Executing ROME algorithm for the update: [The language used by Henri Massis is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Henri Massis\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The language used by Henri Massis is | Token: is\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.402 = 14.402 + 0.0 + 0.0 avg prob of [ English] 5.474248155223904e-06\n",
            "loss 14.062 = 14.061 + 0.0 + 0.0 avg prob of [ English] 9.97168717731256e-06\n",
            "loss 13.687 = 13.686 + 0.0 + 0.0 avg prob of [ English] 1.944610630744137e-05\n",
            "loss 13.284 = 13.283 + 0.001 + 0.0 avg prob of [ English] 3.482336978777312e-05\n",
            "loss 12.848 = 12.847 + 0.002 + 0.0 avg prob of [ English] 5.62203858862631e-05\n",
            "loss 12.383 = 12.38 + 0.003 + 0.0 avg prob of [ English] 8.494659414282069e-05\n",
            "loss 11.898 = 11.894 + 0.004 + 0.0 avg prob of [ English] 0.00012360817345324904\n",
            "loss 11.411 = 11.406 + 0.006 + 0.0 avg prob of [ English] 0.00017639657016843557\n",
            "loss 10.94 = 10.933 + 0.007 + 0.0 avg prob of [ English] 0.0002496651140972972\n",
            "loss 10.495 = 10.485 + 0.009 + 0.0 avg prob of [ English] 0.0003521432518027723\n",
            "loss 10.076 = 10.065 + 0.011 + 0.0 avg prob of [ English] 0.0004963119863532484\n",
            "loss 9.68 = 9.666 + 0.013 + 0.0 avg prob of [ English] 0.0007016079616732895\n",
            "loss 9.3 = 9.285 + 0.016 + 0.0 avg prob of [ English] 0.0009985461365431547\n",
            "loss 8.932 = 8.914 + 0.018 + 0.0 avg prob of [ English] 0.0014349068515002728\n",
            "loss 8.573 = 8.552 + 0.02 + 0.0 avg prob of [ English] 0.002083912957459688\n",
            "loss 8.22 = 8.197 + 0.023 + 0.0 avg prob of [ English] 0.0030506665352731943\n",
            "loss 7.873 = 7.848 + 0.025 + 0.0 avg prob of [ English] 0.004475017078220844\n",
            "loss 7.532 = 7.505 + 0.027 + 0.0 avg prob of [ English] 0.006539100781083107\n",
            "loss 7.197 = 7.167 + 0.03 + 0.0 avg prob of [ English] 0.009488625451922417\n",
            "loss 6.867 = 6.834 + 0.032 + 0.0 avg prob of [ English] 0.013656244613230228\n",
            "Delta norm: 336.79620361328125\n",
            "Change in target norm: 916.597900390625 to 973.779541015625 => 57.181640625\n",
            "Division Factor: 11.44847297668457\n",
            "Right vector norm: 29.418439865112305\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 75% 375/500 [1:45:34<36:12, 17.38s/it]Executing ROME algorithm for the update: [Crown Airways is based in] -> [ Moscow]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Crown Airways\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Crown Airways is based in | Token:  Airways\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.025 = 9.025 + 0.0 + 0.0 avg prob of [ Moscow] 0.000516737753059715\n",
            "loss 8.873 = 8.873 + 0.0 + 0.0 avg prob of [ Moscow] 0.0007868835236877203\n",
            "loss 8.709 = 8.709 + 0.0 + 0.0 avg prob of [ Moscow] 0.0012492910027503967\n",
            "loss 8.532 = 8.532 + 0.0 + 0.0 avg prob of [ Moscow] 0.0020492561161518097\n",
            "loss 8.339 = 8.339 + 0.0 + 0.0 avg prob of [ Moscow] 0.0034241159446537495\n",
            "loss 8.13 = 8.13 + 0.0 + 0.0 avg prob of [ Moscow] 0.005734470207244158\n",
            "loss 7.904 = 7.903 + 0.001 + 0.0 avg prob of [ Moscow] 0.00944499857723713\n",
            "loss 7.661 = 7.66 + 0.001 + 0.0 avg prob of [ Moscow] 0.014992022886872292\n",
            "loss 7.401 = 7.4 + 0.001 + 0.0 avg prob of [ Moscow] 0.022594314068555832\n",
            "loss 7.127 = 7.125 + 0.002 + 0.0 avg prob of [ Moscow] 0.03237411379814148\n",
            "loss 6.841 = 6.839 + 0.002 + 0.0 avg prob of [ Moscow] 0.04508764669299126\n",
            "loss 6.55 = 6.547 + 0.003 + 0.0 avg prob of [ Moscow] 0.06264888495206833\n",
            "loss 6.26 = 6.257 + 0.003 + 0.0 avg prob of [ Moscow] 0.08629225939512253\n",
            "loss 5.978 = 5.973 + 0.004 + 0.0 avg prob of [ Moscow] 0.11315908282995224\n",
            "loss 5.705 = 5.699 + 0.005 + 0.0 avg prob of [ Moscow] 0.1382571905851364\n",
            "loss 5.439 = 5.432 + 0.007 + 0.0 avg prob of [ Moscow] 0.15991933643817902\n",
            "loss 5.178 = 5.169 + 0.008 + 0.0 avg prob of [ Moscow] 0.17954868078231812\n",
            "loss 4.922 = 4.911 + 0.01 + 0.0 avg prob of [ Moscow] 0.19850395619869232\n",
            "loss 4.671 = 4.658 + 0.013 + 0.0 avg prob of [ Moscow] 0.21705617010593414\n",
            "loss 4.426 = 4.41 + 0.016 + 0.0 avg prob of [ Moscow] 0.23494185507297516\n",
            "Delta norm: 353.0953369140625\n",
            "Change in target norm: 1365.4256591796875 to 1404.5638427734375 => 39.13818359375\n",
            "Division Factor: 7.605440139770508\n",
            "Right vector norm: 46.42667770385742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 75% 376/500 [1:45:49<34:14, 16.57s/it]Executing ROME algorithm for the update: [Kalyan Kumar is native to] -> [ Jerusalem]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Kalyan Kumar\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Kalyan Kumar is native to | Token:  Kumar\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.413 = 11.413 + 0.0 + 0.0 avg prob of [ Jerusalem] 6.306981231318787e-05\n",
            "loss 11.193 = 11.193 + 0.0 + 0.0 avg prob of [ Jerusalem] 7.336030103033409e-05\n",
            "loss 10.982 = 10.982 + 0.0 + 0.0 avg prob of [ Jerusalem] 8.550486381864175e-05\n",
            "loss 10.777 = 10.776 + 0.001 + 0.0 avg prob of [ Jerusalem] 0.0001002532517304644\n",
            "loss 10.576 = 10.575 + 0.001 + 0.0 avg prob of [ Jerusalem] 0.00011888842709595338\n",
            "loss 10.375 = 10.373 + 0.001 + 0.0 avg prob of [ Jerusalem] 0.0001436152379028499\n",
            "loss 10.171 = 10.169 + 0.002 + 0.0 avg prob of [ Jerusalem] 0.00017832535377237946\n",
            "loss 9.962 = 9.959 + 0.003 + 0.0 avg prob of [ Jerusalem] 0.00023009179858490825\n",
            "loss 9.743 = 9.739 + 0.004 + 0.0 avg prob of [ Jerusalem] 0.0003121079644188285\n",
            "loss 9.513 = 9.508 + 0.005 + 0.0 avg prob of [ Jerusalem] 0.00044945947593078017\n",
            "loss 9.268 = 9.262 + 0.006 + 0.0 avg prob of [ Jerusalem] 0.000690324348397553\n",
            "loss 9.007 = 8.999 + 0.007 + 0.0 avg prob of [ Jerusalem] 0.0011268886737525463\n",
            "loss 8.727 = 8.718 + 0.008 + 0.0 avg prob of [ Jerusalem] 0.001931608421728015\n",
            "loss 8.427 = 8.417 + 0.01 + 0.0 avg prob of [ Jerusalem] 0.0034114099107682705\n",
            "loss 8.109 = 8.097 + 0.011 + 0.0 avg prob of [ Jerusalem] 0.00606425991281867\n",
            "loss 7.771 = 7.758 + 0.012 + 0.0 avg prob of [ Jerusalem] 0.010573660023510456\n",
            "loss 7.417 = 7.403 + 0.014 + 0.0 avg prob of [ Jerusalem] 0.017620883882045746\n",
            "loss 7.049 = 7.033 + 0.015 + 0.0 avg prob of [ Jerusalem] 0.02749442309141159\n",
            "loss 6.669 = 6.652 + 0.017 + 0.0 avg prob of [ Jerusalem] 0.03985332325100899\n",
            "loss 6.283 = 6.264 + 0.019 + 0.0 avg prob of [ Jerusalem] 0.05407033860683441\n",
            "Delta norm: 326.75885009765625\n",
            "Change in target norm: 693.899658203125 to 775.3175048828125 => 81.4178466796875\n",
            "Division Factor: 7.558104515075684\n",
            "Right vector norm: 43.23291015625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 75% 377/500 [1:46:04<33:19, 16.25s/it]Executing ROME algorithm for the update: [Mona Mur found employment in] -> [ Ottawa]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Mona Mur\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Mona Mur found employment in | Token:  Mur\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.651 = 16.651 + 0.0 + 0.0 avg prob of [ Ottawa] 9.661475530720054e-08\n",
            "loss 16.624 = 16.624 + 0.0 + 0.0 avg prob of [ Ottawa] 9.912405118939205e-08\n",
            "loss 16.59 = 16.59 + 0.0 + 0.0 avg prob of [ Ottawa] 1.0264569283435776e-07\n",
            "loss 16.544 = 16.544 + 0.0 + 0.0 avg prob of [ Ottawa] 1.0791811178023636e-07\n",
            "loss 16.483 = 16.483 + 0.0 + 0.0 avg prob of [ Ottawa] 1.1588340242951745e-07\n",
            "loss 16.402 = 16.401 + 0.0 + 0.0 avg prob of [ Ottawa] 1.2761518064507982e-07\n",
            "loss 16.298 = 16.298 + 0.0 + 0.0 avg prob of [ Ottawa] 1.44347922059751e-07\n",
            "loss 16.176 = 16.175 + 0.001 + 0.0 avg prob of [ Ottawa] 1.6734325924971927e-07\n",
            "loss 16.042 = 16.041 + 0.001 + 0.0 avg prob of [ Ottawa] 1.9693028718847927e-07\n",
            "loss 15.898 = 15.897 + 0.001 + 0.0 avg prob of [ Ottawa] 2.3378956370834203e-07\n",
            "loss 15.74 = 15.739 + 0.001 + 0.0 avg prob of [ Ottawa] 2.8161889531475026e-07\n",
            "loss 15.562 = 15.561 + 0.001 + 0.0 avg prob of [ Ottawa] 3.473021763511497e-07\n",
            "loss 15.362 = 15.36 + 0.002 + 0.0 avg prob of [ Ottawa] 4.4208866256667534e-07\n",
            "loss 15.137 = 15.135 + 0.002 + 0.0 avg prob of [ Ottawa] 5.851695163983095e-07\n",
            "loss 14.884 = 14.882 + 0.002 + 0.0 avg prob of [ Ottawa] 8.103752406896092e-07\n",
            "loss 14.604 = 14.601 + 0.003 + 0.0 avg prob of [ Ottawa] 1.179456148747704e-06\n",
            "loss 14.296 = 14.293 + 0.003 + 0.0 avg prob of [ Ottawa] 1.8108391941495938e-06\n",
            "loss 13.961 = 13.958 + 0.003 + 0.0 avg prob of [ Ottawa] 2.9410630304482765e-06\n",
            "loss 13.603 = 13.599 + 0.004 + 0.0 avg prob of [ Ottawa] 5.040644737164257e-06\n",
            "loss 13.226 = 13.222 + 0.004 + 0.0 avg prob of [ Ottawa] 8.998901648737956e-06\n",
            "Delta norm: 330.5391540527344\n",
            "Change in target norm: 2281.21728515625 to 2301.52197265625 => 20.3046875\n",
            "Division Factor: 8.281105041503906\n",
            "Right vector norm: 39.91486358642578\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 76% 378/500 [1:46:20<32:56, 16.20s/it]Executing ROME algorithm for the update: [The Paradise Club debuted on] -> [ NBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Paradise Club\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: The Paradise Club debuted on | Token:  Club\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.897 = 12.897 + 0.0 + 0.0 avg prob of [ NBC] 4.790108960150974e-06\n",
            "loss 12.834 = 12.834 + 0.0 + 0.0 avg prob of [ NBC] 5.1254114623588976e-06\n",
            "loss 12.774 = 12.774 + 0.0 + 0.0 avg prob of [ NBC] 5.46138016943587e-06\n",
            "loss 12.717 = 12.716 + 0.0 + 0.0 avg prob of [ NBC] 5.80413461648277e-06\n",
            "loss 12.66 = 12.66 + 0.001 + 0.0 avg prob of [ NBC] 6.160203611216275e-06\n",
            "loss 12.604 = 12.603 + 0.001 + 0.0 avg prob of [ NBC] 6.537125045724679e-06\n",
            "loss 12.546 = 12.544 + 0.001 + 0.0 avg prob of [ NBC] 6.944893357285764e-06\n",
            "loss 12.485 = 12.483 + 0.001 + 0.0 avg prob of [ NBC] 7.3964033617812674e-06\n",
            "loss 12.42 = 12.419 + 0.002 + 0.0 avg prob of [ NBC] 7.90822559793014e-06\n",
            "loss 12.351 = 12.349 + 0.002 + 0.0 avg prob of [ NBC] 8.501731826981995e-06\n",
            "loss 12.276 = 12.274 + 0.002 + 0.0 avg prob of [ NBC] 9.204990419675596e-06\n",
            "loss 12.194 = 12.192 + 0.002 + 0.0 avg prob of [ NBC] 1.0056206519948319e-05\n",
            "loss 12.104 = 12.102 + 0.002 + 0.0 avg prob of [ NBC] 1.1108748367405497e-05\n",
            "loss 12.006 = 12.003 + 0.003 + 0.0 avg prob of [ NBC] 1.243873339262791e-05\n",
            "loss 11.897 = 11.895 + 0.003 + 0.0 avg prob of [ NBC] 1.4156001270748675e-05\n",
            "loss 11.779 = 11.776 + 0.003 + 0.0 avg prob of [ NBC] 1.6417219740105793e-05\n",
            "loss 11.65 = 11.646 + 0.003 + 0.0 avg prob of [ NBC] 1.9440380128799006e-05\n",
            "loss 11.51 = 11.506 + 0.003 + 0.0 avg prob of [ NBC] 2.3521195544162765e-05\n",
            "loss 11.359 = 11.356 + 0.004 + 0.0 avg prob of [ NBC] 2.906154804804828e-05\n",
            "loss 11.199 = 11.195 + 0.004 + 0.0 avg prob of [ NBC] 3.662007657112554e-05\n",
            "Delta norm: 324.0547180175781\n",
            "Change in target norm: 1800.696044921875 to 1836.128662109375 => 35.4326171875\n",
            "Division Factor: 9.37458610534668\n",
            "Right vector norm: 34.56736373901367\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 76% 379/500 [1:46:35<31:44, 15.74s/it]Executing ROME algorithm for the update: [The Late Late Show with Craig Ferguson premieres on] -> [ NBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Late Late Show with Craig Ferguson\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The Late Late Show with Craig Ferguson premieres on | Token:  Ferguson\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.916 = 10.916 + 0.0 + 0.0 avg prob of [ NBC] 6.051320815458894e-05\n",
            "loss 10.693 = 10.693 + 0.0 + 0.0 avg prob of [ NBC] 7.426097727147862e-05\n",
            "loss 10.463 = 10.463 + 0.0 + 0.0 avg prob of [ NBC] 9.259437501896173e-05\n",
            "loss 10.226 = 10.226 + 0.0 + 0.0 avg prob of [ NBC] 0.00011714898573700339\n",
            "loss 9.981 = 9.981 + 0.0 + 0.0 avg prob of [ NBC] 0.00015017090481705964\n",
            "loss 9.729 = 9.729 + 0.0 + 0.0 avg prob of [ NBC] 0.00019475985027384013\n",
            "loss 9.469 = 9.469 + 0.0 + 0.0 avg prob of [ NBC] 0.00025530566927045584\n",
            "loss 9.2 = 9.199 + 0.0 + 0.0 avg prob of [ NBC] 0.00033816249924711883\n",
            "loss 8.92 = 8.92 + 0.001 + 0.0 avg prob of [ NBC] 0.0004526189586613327\n",
            "loss 8.63 = 8.63 + 0.001 + 0.0 avg prob of [ NBC] 0.0006122006452642381\n",
            "loss 8.329 = 8.328 + 0.001 + 0.0 avg prob of [ NBC] 0.0008365574176423252\n",
            "loss 8.017 = 8.015 + 0.001 + 0.0 avg prob of [ NBC] 0.001154074678197503\n",
            "loss 7.694 = 7.692 + 0.001 + 0.0 avg prob of [ NBC] 0.001605414436198771\n",
            "loss 7.361 = 7.359 + 0.002 + 0.0 avg prob of [ NBC] 0.0022483731154352427\n",
            "loss 7.021 = 7.019 + 0.002 + 0.0 avg prob of [ NBC] 0.0031645616982132196\n",
            "loss 6.674 = 6.672 + 0.002 + 0.0 avg prob of [ NBC] 0.004468596540391445\n",
            "loss 6.325 = 6.322 + 0.002 + 0.0 avg prob of [ NBC] 0.006320887710899115\n",
            "loss 5.975 = 5.972 + 0.003 + 0.0 avg prob of [ NBC] 0.008945696987211704\n",
            "loss 5.627 = 5.624 + 0.003 + 0.0 avg prob of [ NBC] 0.012656775303184986\n",
            "loss 5.284 = 5.281 + 0.003 + 0.0 avg prob of [ NBC] 0.017888925969600677\n",
            "Delta norm: 363.2918701171875\n",
            "Change in target norm: 2694.609130859375 to 2712.205078125 => 17.595947265625\n",
            "Division Factor: 12.21504020690918\n",
            "Right vector norm: 29.741357803344727\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 76% 380/500 [1:46:54<33:26, 16.72s/it]Executing ROME algorithm for the update: [Darmstadt is located in the country of] -> [ Argentina]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Darmstadt\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Darmstadt is located in the country of | Token: stadt\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.837 = 14.837 + 0.0 + 0.0 avg prob of [ Argentina] 9.534636546959518e-07\n",
            "loss 14.806 = 14.806 + 0.0 + 0.0 avg prob of [ Argentina] 9.784364465303952e-07\n",
            "loss 14.776 = 14.776 + 0.0 + 0.0 avg prob of [ Argentina] 1.0035568038802012e-06\n",
            "loss 14.747 = 14.747 + 0.0 + 0.0 avg prob of [ Argentina] 1.0288133580615977e-06\n",
            "loss 14.72 = 14.72 + 0.0 + 0.0 avg prob of [ Argentina] 1.054204744832532e-06\n",
            "loss 14.694 = 14.693 + 0.0 + 0.0 avg prob of [ Argentina] 1.0796931064760429e-06\n",
            "loss 14.668 = 14.668 + 0.0 + 0.0 avg prob of [ Argentina] 1.105235241993796e-06\n",
            "loss 14.644 = 14.644 + 0.0 + 0.0 avg prob of [ Argentina] 1.13079181573994e-06\n",
            "loss 14.621 = 14.621 + 0.0 + 0.0 avg prob of [ Argentina] 1.1563340649445308e-06\n",
            "loss 14.6 = 14.599 + 0.0 + 0.0 avg prob of [ Argentina] 1.1818184475487215e-06\n",
            "loss 14.579 = 14.579 + 0.0 + 0.0 avg prob of [ Argentina] 1.2072136996721383e-06\n",
            "loss 14.559 = 14.559 + 0.0 + 0.0 avg prob of [ Argentina] 1.2324968565735617e-06\n",
            "loss 14.54 = 14.54 + 0.0 + 0.0 avg prob of [ Argentina] 1.2576310837175697e-06\n",
            "loss 14.522 = 14.522 + 0.0 + 0.0 avg prob of [ Argentina] 1.2826111515096272e-06\n",
            "loss 14.505 = 14.505 + 0.0 + 0.0 avg prob of [ Argentina] 1.3074128446532995e-06\n",
            "loss 14.489 = 14.489 + 0.0 + 0.0 avg prob of [ Argentina] 1.3320326388566173e-06\n",
            "loss 14.473 = 14.473 + 0.0 + 0.0 avg prob of [ Argentina] 1.3564625760409399e-06\n",
            "loss 14.458 = 14.458 + 0.0 + 0.0 avg prob of [ Argentina] 1.380701633024728e-06\n",
            "loss 14.444 = 14.444 + 0.0 + 0.0 avg prob of [ Argentina] 1.404765043844236e-06\n",
            "loss 14.431 = 14.431 + 0.0 + 0.0 avg prob of [ Argentina] 1.428653717994166e-06\n",
            "Delta norm: 350.2410583496094\n",
            "Change in target norm: 4362.30810546875 to 4356.279296875 => -6.02880859375\n",
            "Division Factor: 8.224679946899414\n",
            "Right vector norm: 42.58415603637695\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 76% 381/500 [1:47:13<34:19, 17.31s/it]Executing ROME algorithm for the update: [Marguerite Broquedis, a citizen of] -> [ Norway]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Marguerite Broquedis\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Marguerite Broquedis, a citizen of | Token: is\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 18.037 = 18.037 + 0.0 + 0.0 avg prob of [ Norway] 3.3498892548777803e-08\n",
            "loss 18.017 = 18.017 + 0.0 + 0.0 avg prob of [ Norway] 3.3941120136660174e-08\n",
            "loss 17.992 = 17.992 + 0.0 + 0.0 avg prob of [ Norway] 3.453218866411589e-08\n",
            "loss 17.961 = 17.961 + 0.0 + 0.0 avg prob of [ Norway] 3.531085823738067e-08\n",
            "loss 17.924 = 17.923 + 0.0 + 0.0 avg prob of [ Norway] 3.6320649599019816e-08\n",
            "loss 17.879 = 17.879 + 0.0 + 0.0 avg prob of [ Norway] 3.760586508860797e-08\n",
            "loss 17.828 = 17.827 + 0.0 + 0.0 avg prob of [ Norway] 3.920942148738504e-08\n",
            "loss 17.769 = 17.768 + 0.001 + 0.0 avg prob of [ Norway] 4.116870755410673e-08\n",
            "loss 17.703 = 17.702 + 0.001 + 0.0 avg prob of [ Norway] 4.3510677727454095e-08\n",
            "loss 17.631 = 17.63 + 0.001 + 0.0 avg prob of [ Norway] 4.6254694296976595e-08\n",
            "loss 17.554 = 17.553 + 0.001 + 0.0 avg prob of [ Norway] 4.9418460434935696e-08\n",
            "loss 17.472 = 17.47 + 0.002 + 0.0 avg prob of [ Norway] 5.302550576402609e-08\n",
            "loss 17.386 = 17.384 + 0.002 + 0.0 avg prob of [ Norway] 5.7113570761657684e-08\n",
            "loss 17.297 = 17.294 + 0.002 + 0.0 avg prob of [ Norway] 6.17400814917346e-08\n",
            "loss 17.204 = 17.202 + 0.003 + 0.0 avg prob of [ Norway] 6.698521559656001e-08\n",
            "loss 17.109 = 17.106 + 0.003 + 0.0 avg prob of [ Norway] 7.295607673540871e-08\n",
            "loss 17.011 = 17.007 + 0.003 + 0.0 avg prob of [ Norway] 7.978879068559763e-08\n",
            "loss 16.909 = 16.905 + 0.004 + 0.0 avg prob of [ Norway] 8.765127290644159e-08\n",
            "loss 16.804 = 16.799 + 0.004 + 0.0 avg prob of [ Norway] 9.674681678006891e-08\n",
            "loss 16.695 = 16.69 + 0.005 + 0.0 avg prob of [ Norway] 1.0731787369877566e-07\n",
            "Delta norm: 369.6284484863281\n",
            "Change in target norm: 2766.703369140625 to 2810.21435546875 => 43.510986328125\n",
            "Division Factor: 9.993432998657227\n",
            "Right vector norm: 36.98713302612305\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 76% 382/500 [1:47:33<35:44, 18.17s/it]Executing ROME algorithm for the update: [David Carney, the] -> [ basketball]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object David Carney\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: David Carney, the | Token:  Carney\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.907 = 10.907 + 0.0 + 0.0 avg prob of [ basketball] 3.0178807719494216e-05\n",
            "loss 10.878 = 10.878 + 0.0 + 0.0 avg prob of [ basketball] 3.0839277314953506e-05\n",
            "loss 10.846 = 10.845 + 0.0 + 0.0 avg prob of [ basketball] 3.161391941830516e-05\n",
            "loss 10.808 = 10.808 + 0.001 + 0.0 avg prob of [ basketball] 3.257260686950758e-05\n",
            "loss 10.765 = 10.764 + 0.001 + 0.0 avg prob of [ basketball] 3.377853863639757e-05\n",
            "loss 10.714 = 10.713 + 0.001 + 0.0 avg prob of [ basketball] 3.5328059311723337e-05\n",
            "loss 10.655 = 10.653 + 0.002 + 0.0 avg prob of [ basketball] 3.737271254067309e-05\n",
            "loss 10.586 = 10.584 + 0.002 + 0.0 avg prob of [ basketball] 4.012310455436818e-05\n",
            "loss 10.506 = 10.503 + 0.003 + 0.0 avg prob of [ basketball] 4.382780025480315e-05\n",
            "loss 10.413 = 10.41 + 0.003 + 0.0 avg prob of [ basketball] 4.8700730985729024e-05\n",
            "loss 10.308 = 10.304 + 0.004 + 0.0 avg prob of [ basketball] 5.48878415429499e-05\n",
            "loss 10.199 = 10.194 + 0.005 + 0.0 avg prob of [ basketball] 6.26015171292238e-05\n",
            "loss 10.093 = 10.088 + 0.006 + 0.0 avg prob of [ basketball] 7.226267189253122e-05\n",
            "loss 9.984 = 9.977 + 0.006 + 0.0 avg prob of [ basketball] 8.535941014997661e-05\n",
            "loss 9.86 = 9.852 + 0.007 + 0.0 avg prob of [ basketball] 0.00010495301830815151\n",
            "loss 9.716 = 9.708 + 0.008 + 0.0 avg prob of [ basketball] 0.0001359192974632606\n",
            "loss 9.553 = 9.543 + 0.009 + 0.0 avg prob of [ basketball] 0.00018678716151043773\n",
            "loss 9.368 = 9.357 + 0.011 + 0.0 avg prob of [ basketball] 0.0002733840956352651\n",
            "loss 9.162 = 9.15 + 0.012 + 0.0 avg prob of [ basketball] 0.00042591802775859833\n",
            "loss 8.934 = 8.92 + 0.013 + 0.0 avg prob of [ basketball] 0.0007031329441815615\n",
            "Delta norm: 296.6205749511719\n",
            "Change in target norm: 763.541015625 to 816.8486328125 => 53.3076171875\n",
            "Division Factor: 8.667865753173828\n",
            "Right vector norm: 34.22071838378906\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 77% 383/500 [1:47:46<32:40, 16.76s/it]Executing ROME algorithm for the update: [The headquarters of Tata Steel Europe is in] -> [ Dublin]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Tata Steel Europe\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The headquarters of Tata Steel Europe is in | Token:  Europe\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.787 = 13.787 + 0.0 + 0.0 avg prob of [ Dublin] 1.983501533686649e-06\n",
            "loss 13.748 = 13.748 + 0.0 + 0.0 avg prob of [ Dublin] 2.176895122829592e-06\n",
            "loss 13.711 = 13.71 + 0.0 + 0.0 avg prob of [ Dublin] 2.3821501144993817e-06\n",
            "loss 13.669 = 13.668 + 0.001 + 0.0 avg prob of [ Dublin] 2.6328248168283608e-06\n",
            "loss 13.621 = 13.619 + 0.001 + 0.0 avg prob of [ Dublin] 2.9684649689443177e-06\n",
            "loss 13.562 = 13.561 + 0.002 + 0.0 avg prob of [ Dublin] 3.453521912888391e-06\n",
            "loss 13.491 = 13.489 + 0.002 + 0.0 avg prob of [ Dublin] 4.2025944821943995e-06\n",
            "loss 13.403 = 13.401 + 0.002 + 0.0 avg prob of [ Dublin] 5.4204633670451585e-06\n",
            "loss 13.298 = 13.295 + 0.003 + 0.0 avg prob of [ Dublin] 7.448466021742206e-06\n",
            "loss 13.176 = 13.173 + 0.003 + 0.0 avg prob of [ Dublin] 1.0777884199342225e-05\n",
            "loss 13.039 = 13.036 + 0.003 + 0.0 avg prob of [ Dublin] 1.5960178643581457e-05\n",
            "loss 12.891 = 12.888 + 0.004 + 0.0 avg prob of [ Dublin] 2.3520091417594813e-05\n",
            "loss 12.734 = 12.729 + 0.004 + 0.0 avg prob of [ Dublin] 3.430786091485061e-05\n",
            "loss 12.567 = 12.563 + 0.004 + 0.0 avg prob of [ Dublin] 4.828407691093162e-05\n",
            "loss 12.392 = 12.387 + 0.004 + 0.0 avg prob of [ Dublin] 6.425868923543021e-05\n",
            "loss 12.203 = 12.198 + 0.004 + 0.0 avg prob of [ Dublin] 8.623956091469154e-05\n",
            "loss 11.997 = 11.993 + 0.004 + 0.0 avg prob of [ Dublin] 0.00012146043445682153\n",
            "loss 11.774 = 11.77 + 0.004 + 0.0 avg prob of [ Dublin] 0.0001787582295946777\n",
            "loss 11.533 = 11.528 + 0.004 + 0.0 avg prob of [ Dublin] 0.0002709891414269805\n",
            "loss 11.272 = 11.267 + 0.004 + 0.0 avg prob of [ Dublin] 0.00041758944280445576\n",
            "Delta norm: 306.88934326171875\n",
            "Change in target norm: 1259.0631103515625 to 1271.8944091796875 => 12.831298828125\n",
            "Division Factor: 11.74354076385498\n",
            "Right vector norm: 26.13260841369629\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 77% 384/500 [1:48:04<33:08, 17.15s/it]Executing ROME algorithm for the update: [Luigi Boccherini writes in] -> [ Spanish]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Luigi Boccherini\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Luigi Boccherini writes in | Token: ini\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.736 = 11.736 + 0.0 + 0.0 avg prob of [ Spanish] 1.120212436944712e-05\n",
            "loss 11.714 = 11.714 + 0.0 + 0.0 avg prob of [ Spanish] 1.141793472925201e-05\n",
            "loss 11.696 = 11.696 + 0.0 + 0.0 avg prob of [ Spanish] 1.160120518761687e-05\n",
            "loss 11.681 = 11.681 + 0.001 + 0.0 avg prob of [ Spanish] 1.1754425941035151e-05\n",
            "loss 11.669 = 11.668 + 0.001 + 0.0 avg prob of [ Spanish] 1.188311944133602e-05\n",
            "loss 11.659 = 11.658 + 0.001 + 0.0 avg prob of [ Spanish] 1.1993926818831824e-05\n",
            "loss 11.65 = 11.648 + 0.002 + 0.0 avg prob of [ Spanish] 1.2093135410395917e-05\n",
            "loss 11.642 = 11.64 + 0.002 + 0.0 avg prob of [ Spanish] 1.218612214870518e-05\n",
            "loss 11.633 = 11.631 + 0.002 + 0.0 avg prob of [ Spanish] 1.2277448149689008e-05\n",
            "loss 11.625 = 11.623 + 0.002 + 0.0 avg prob of [ Spanish] 1.2371207049000077e-05\n",
            "loss 11.617 = 11.615 + 0.002 + 0.0 avg prob of [ Spanish] 1.2471374247979838e-05\n",
            "loss 11.608 = 11.606 + 0.002 + 0.0 avg prob of [ Spanish] 1.2582143426698167e-05\n",
            "loss 11.598 = 11.596 + 0.002 + 0.0 avg prob of [ Spanish] 1.270826851396123e-05\n",
            "loss 11.588 = 11.585 + 0.003 + 0.0 avg prob of [ Spanish] 1.2855367458541878e-05\n",
            "loss 11.575 = 11.572 + 0.003 + 0.0 avg prob of [ Spanish] 1.3030416994297411e-05\n",
            "loss 11.561 = 11.558 + 0.003 + 0.0 avg prob of [ Spanish] 1.324225013377145e-05\n",
            "loss 11.545 = 11.541 + 0.003 + 0.0 avg prob of [ Spanish] 1.350228012597654e-05\n",
            "loss 11.525 = 11.521 + 0.004 + 0.0 avg prob of [ Spanish] 1.3825234418618493e-05\n",
            "loss 11.502 = 11.498 + 0.004 + 0.0 avg prob of [ Spanish] 1.423041794623714e-05\n",
            "loss 11.474 = 11.469 + 0.005 + 0.0 avg prob of [ Spanish] 1.4743508472747635e-05\n",
            "Delta norm: 275.7713623046875\n",
            "Change in target norm: 1684.468994140625 to 1703.2364501953125 => 18.7674560546875\n",
            "Division Factor: 9.97326374053955\n",
            "Right vector norm: 27.651065826416016\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 77% 385/500 [1:48:20<31:56, 16.67s/it]Executing ROME algorithm for the update: [What sport does Peter Å Å¥astnÃ½ play? They play] -> [ basketball]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Peter Å Å¥astnÃ½\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 11 | Sentence: What sport does Peter Å Å¥astnÃ½ play? They play | Token: ï¿½\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.386 = 11.386 + 0.0 + 0.0 avg prob of [ basketball] 1.494758907938376e-05\n",
            "loss 11.263 = 11.262 + 0.001 + 0.0 avg prob of [ basketball] 1.711144250293728e-05\n",
            "loss 11.143 = 11.141 + 0.002 + 0.0 avg prob of [ basketball] 1.9580391381168738e-05\n",
            "loss 11.017 = 11.013 + 0.004 + 0.0 avg prob of [ basketball] 2.2586551494896412e-05\n",
            "loss 10.879 = 10.874 + 0.005 + 0.0 avg prob of [ basketball] 2.6432850063429214e-05\n",
            "loss 10.724 = 10.718 + 0.006 + 0.0 avg prob of [ basketball] 3.148676478303969e-05\n",
            "loss 10.552 = 10.545 + 0.007 + 0.0 avg prob of [ basketball] 3.813569855992682e-05\n",
            "loss 10.364 = 10.356 + 0.007 + 0.0 avg prob of [ basketball] 4.678914774558507e-05\n",
            "loss 10.162 = 10.154 + 0.008 + 0.0 avg prob of [ basketball] 5.796512050437741e-05\n",
            "loss 9.948 = 9.94 + 0.008 + 0.0 avg prob of [ basketball] 7.239871774800122e-05\n",
            "loss 9.726 = 9.717 + 0.009 + 0.0 avg prob of [ basketball] 9.112116822507232e-05\n",
            "loss 9.496 = 9.484 + 0.011 + 0.0 avg prob of [ basketball] 0.00011579668353078887\n",
            "loss 9.254 = 9.24 + 0.014 + 0.0 avg prob of [ basketball] 0.00014915854262653738\n",
            "loss 9.003 = 8.983 + 0.02 + 0.0 avg prob of [ basketball] 0.00019533773593138903\n",
            "loss 8.741 = 8.712 + 0.029 + 0.0 avg prob of [ basketball] 0.00026017866912297904\n",
            "loss 8.474 = 8.429 + 0.044 + 0.0 avg prob of [ basketball] 0.0003514536365401\n",
            "loss 8.206 = 8.137 + 0.069 + 0.0 avg prob of [ basketball] 0.00047851994168013334\n",
            "loss 7.944 = 7.841 + 0.103 + 0.0 avg prob of [ basketball] 0.0006508852820843458\n",
            "loss 7.691 = 7.551 + 0.14 + 0.0 avg prob of [ basketball] 0.0008765367092564702\n",
            "loss 7.445 = 7.276 + 0.169 + 0.0 avg prob of [ basketball] 0.0011630847584456205\n",
            "Delta norm: 316.9067687988281\n",
            "Change in target norm: 1017.4320068359375 to 1037.2393798828125 => 19.807373046875\n",
            "Division Factor: 10.37947940826416\n",
            "Right vector norm: 30.532047271728516\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 77% 386/500 [1:48:43<35:37, 18.75s/it]Executing ROME algorithm for the update: [The original language of The Mistress of the Inn was] -> [ Tamil]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Mistress of the Inn\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The original language of The Mistress of the Inn was | Token:  Inn\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.076 = 16.076 + 0.0 + 0.0 avg prob of [ Tamil] 6.427528660424286e-07\n",
            "loss 15.989 = 15.989 + 0.0 + 0.0 avg prob of [ Tamil] 6.605870339626563e-07\n",
            "loss 15.92 = 15.92 + 0.0 + 0.0 avg prob of [ Tamil] 6.778001875318296e-07\n",
            "loss 15.864 = 15.864 + 0.0 + 0.0 avg prob of [ Tamil] 6.949845783310593e-07\n",
            "loss 15.818 = 15.817 + 0.0 + 0.0 avg prob of [ Tamil] 7.127935077733127e-07\n",
            "loss 15.777 = 15.776 + 0.001 + 0.0 avg prob of [ Tamil] 7.320866757254407e-07\n",
            "loss 15.738 = 15.737 + 0.001 + 0.0 avg prob of [ Tamil] 7.538606041634921e-07\n",
            "loss 15.699 = 15.698 + 0.001 + 0.0 avg prob of [ Tamil] 7.790426934661809e-07\n",
            "loss 15.658 = 15.656 + 0.001 + 0.0 avg prob of [ Tamil] 8.083518991952587e-07\n",
            "loss 15.612 = 15.61 + 0.002 + 0.0 avg prob of [ Tamil] 8.42088184072054e-07\n",
            "loss 15.561 = 15.559 + 0.002 + 0.0 avg prob of [ Tamil] 8.800558362054289e-07\n",
            "loss 15.505 = 15.503 + 0.002 + 0.0 avg prob of [ Tamil] 9.21792377539532e-07\n",
            "loss 15.443 = 15.441 + 0.003 + 0.0 avg prob of [ Tamil] 9.670702638686635e-07\n",
            "loss 15.375 = 15.372 + 0.003 + 0.0 avg prob of [ Tamil] 1.0163420256503741e-06\n",
            "loss 15.301 = 15.298 + 0.003 + 0.0 avg prob of [ Tamil] 1.0707447017921368e-06\n",
            "loss 15.221 = 15.217 + 0.004 + 0.0 avg prob of [ Tamil] 1.1319041277602082e-06\n",
            "loss 15.134 = 15.13 + 0.004 + 0.0 avg prob of [ Tamil] 1.2016832897643326e-06\n",
            "loss 15.041 = 15.037 + 0.004 + 0.0 avg prob of [ Tamil] 1.28198928450729e-06\n",
            "loss 14.942 = 14.937 + 0.005 + 0.0 avg prob of [ Tamil] 1.3746746390097542e-06\n",
            "loss 14.836 = 14.831 + 0.005 + 0.0 avg prob of [ Tamil] 1.4814993392064935e-06\n",
            "Delta norm: 278.93524169921875\n",
            "Change in target norm: 1041.4903564453125 to 1073.23291015625 => 31.7425537109375\n",
            "Division Factor: 10.71377182006836\n",
            "Right vector norm: 26.035205841064453\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 77% 387/500 [1:49:03<35:29, 18.85s/it]Executing ROME algorithm for the update: [How to Make It in America is to debut on] -> [ BBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object How to Make It in America\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: How to Make It in America is to debut on | Token:  America\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 18.258 = 18.258 + 0.0 + 0.0 avg prob of [ BBC] 1.7059005585906561e-06\n",
            "loss 18.226 = 18.226 + 0.0 + 0.0 avg prob of [ BBC] 1.7167433270515176e-06\n",
            "loss 18.194 = 18.194 + 0.0 + 0.0 avg prob of [ BBC] 1.7273064258915838e-06\n",
            "loss 18.164 = 18.164 + 0.0 + 0.0 avg prob of [ BBC] 1.7377503809257178e-06\n",
            "loss 18.135 = 18.135 + 0.0 + 0.0 avg prob of [ BBC] 1.7482012708569528e-06\n",
            "loss 18.107 = 18.107 + 0.0 + 0.0 avg prob of [ BBC] 1.7587960883247433e-06\n",
            "loss 18.079 = 18.079 + 0.0 + 0.0 avg prob of [ BBC] 1.769655114003399e-06\n",
            "loss 18.051 = 18.051 + 0.0 + 0.0 avg prob of [ BBC] 1.7809401242629974e-06\n",
            "loss 18.024 = 18.024 + 0.0 + 0.0 avg prob of [ BBC] 1.7927698081621202e-06\n",
            "loss 17.996 = 17.996 + 0.0 + 0.0 avg prob of [ BBC] 1.8053156054520514e-06\n",
            "loss 17.968 = 17.968 + 0.0 + 0.0 avg prob of [ BBC] 1.8187370187661145e-06\n",
            "loss 17.94 = 17.94 + 0.0 + 0.0 avg prob of [ BBC] 1.83320616997662e-06\n",
            "loss 17.911 = 17.911 + 0.0 + 0.0 avg prob of [ BBC] 1.8489286048861686e-06\n",
            "loss 17.881 = 17.88 + 0.0 + 0.0 avg prob of [ BBC] 1.8661369267647387e-06\n",
            "loss 17.849 = 17.849 + 0.0 + 0.0 avg prob of [ BBC] 1.8850939795811428e-06\n",
            "loss 17.816 = 17.816 + 0.0 + 0.0 avg prob of [ BBC] 1.9060923932556761e-06\n",
            "loss 17.782 = 17.782 + 0.0 + 0.0 avg prob of [ BBC] 1.9295039237476885e-06\n",
            "loss 17.745 = 17.745 + 0.0 + 0.0 avg prob of [ BBC] 1.955722609636723e-06\n",
            "loss 17.706 = 17.706 + 0.0 + 0.0 avg prob of [ BBC] 1.985228664125316e-06\n",
            "loss 17.665 = 17.664 + 0.0 + 0.0 avg prob of [ BBC] 2.0185661924188025e-06\n",
            "Delta norm: 334.7933044433594\n",
            "Change in target norm: 3293.522216796875 to 3305.69091796875 => 12.168701171875\n",
            "Division Factor: 8.96022891998291\n",
            "Right vector norm: 37.3643684387207\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 78% 388/500 [1:49:22<35:17, 18.90s/it]Executing ROME algorithm for the update: [Ethyl Eichelberger's profession is a] -> [ politician]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Ethyl Eichelberger\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Ethyl Eichelberger's profession is a | Token: berger\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.778 = 14.778 + 0.0 + 0.0 avg prob of [ politician] 4.076124241692014e-06\n",
            "loss 14.636 = 14.636 + 0.0 + 0.0 avg prob of [ politician] 4.9993482207355555e-06\n",
            "loss 14.487 = 14.487 + 0.0 + 0.0 avg prob of [ politician] 6.227600351849105e-06\n",
            "loss 14.331 = 14.33 + 0.001 + 0.0 avg prob of [ politician] 7.874946277297568e-06\n",
            "loss 14.165 = 14.163 + 0.002 + 0.0 avg prob of [ politician] 1.0095993275172077e-05\n",
            "loss 13.987 = 13.984 + 0.002 + 0.0 avg prob of [ politician] 1.3095662325213198e-05\n",
            "loss 13.793 = 13.79 + 0.003 + 0.0 avg prob of [ politician] 1.7149966879514977e-05\n",
            "loss 13.58 = 13.576 + 0.004 + 0.0 avg prob of [ politician] 2.2628937585977837e-05\n",
            "loss 13.347 = 13.342 + 0.005 + 0.0 avg prob of [ politician] 3.0071782020968385e-05\n",
            "loss 13.103 = 13.096 + 0.007 + 0.0 avg prob of [ politician] 4.038085899082944e-05\n",
            "loss 12.853 = 12.845 + 0.008 + 0.0 avg prob of [ politician] 5.500836414285004e-05\n",
            "loss 12.597 = 12.588 + 0.009 + 0.0 avg prob of [ politician] 7.628728053532541e-05\n",
            "loss 12.339 = 12.328 + 0.011 + 0.0 avg prob of [ politician] 0.00010824682976817712\n",
            "loss 12.083 = 12.071 + 0.013 + 0.0 avg prob of [ politician] 0.00015774788334965706\n",
            "loss 11.833 = 11.819 + 0.015 + 0.0 avg prob of [ politician] 0.0002363269159104675\n",
            "loss 11.588 = 11.572 + 0.016 + 0.0 avg prob of [ politician] 0.00036429165629670024\n",
            "loss 11.346 = 11.327 + 0.019 + 0.0 avg prob of [ politician] 0.0005762543878518045\n",
            "loss 11.104 = 11.083 + 0.021 + 0.0 avg prob of [ politician] 0.000923042418435216\n",
            "loss 10.861 = 10.837 + 0.024 + 0.0 avg prob of [ politician] 0.001471002702601254\n",
            "loss 10.616 = 10.589 + 0.027 + 0.0 avg prob of [ politician] 0.002309103263542056\n",
            "Delta norm: 323.5155944824219\n",
            "Change in target norm: 813.2017822265625 to 885.778564453125 => 72.5767822265625\n",
            "Division Factor: 7.625984191894531\n",
            "Right vector norm: 42.42280197143555\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 78% 389/500 [1:49:41<35:04, 18.96s/it]Executing ROME algorithm for the update: [Leslie Caron, speaker of] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Leslie Caron\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Leslie Caron, speaker of | Token: on\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.18 = 13.18 + 0.0 + 0.0 avg prob of [ Dutch] 5.483229870151263e-06\n",
            "loss 13.153 = 13.153 + 0.0 + 0.0 avg prob of [ Dutch] 5.602027158602141e-06\n",
            "loss 13.123 = 13.123 + 0.0 + 0.0 avg prob of [ Dutch] 5.737630999647081e-06\n",
            "loss 13.089 = 13.089 + 0.0 + 0.0 avg prob of [ Dutch] 5.892680292163277e-06\n",
            "loss 13.052 = 13.052 + 0.0 + 0.0 avg prob of [ Dutch] 6.069838946132222e-06\n",
            "loss 13.01 = 13.01 + 0.0 + 0.0 avg prob of [ Dutch] 6.2721105678065214e-06\n",
            "loss 12.963 = 12.963 + 0.0 + 0.0 avg prob of [ Dutch] 6.502905307570472e-06\n",
            "loss 12.912 = 12.911 + 0.0 + 0.0 avg prob of [ Dutch] 6.766129899915541e-06\n",
            "loss 12.854 = 12.854 + 0.0 + 0.0 avg prob of [ Dutch] 7.066177204251289e-06\n",
            "loss 12.791 = 12.79 + 0.0 + 0.0 avg prob of [ Dutch] 7.4081508500967175e-06\n",
            "loss 12.72 = 12.72 + 0.001 + 0.0 avg prob of [ Dutch] 7.798000297043473e-06\n",
            "loss 12.643 = 12.642 + 0.001 + 0.0 avg prob of [ Dutch] 8.24254129838664e-06\n",
            "loss 12.559 = 12.558 + 0.001 + 0.0 avg prob of [ Dutch] 8.749792868911754e-06\n",
            "loss 12.467 = 12.466 + 0.001 + 0.0 avg prob of [ Dutch] 9.328964551968966e-06\n",
            "loss 12.368 = 12.367 + 0.001 + 0.0 avg prob of [ Dutch] 9.990839316742495e-06\n",
            "loss 12.262 = 12.261 + 0.001 + 0.0 avg prob of [ Dutch] 1.0748239219537936e-05\n",
            "loss 12.151 = 12.149 + 0.001 + 0.0 avg prob of [ Dutch] 1.1616371011768933e-05\n",
            "loss 12.034 = 12.032 + 0.002 + 0.0 avg prob of [ Dutch] 1.2612735190487001e-05\n",
            "loss 11.913 = 11.912 + 0.002 + 0.0 avg prob of [ Dutch] 1.3756879525317345e-05\n",
            "loss 11.79 = 11.788 + 0.002 + 0.0 avg prob of [ Dutch] 1.5070289009599946e-05\n",
            "Delta norm: 372.2907409667969\n",
            "Change in target norm: 3897.0517578125 to 3922.306884765625 => 25.255126953125\n",
            "Division Factor: 10.892691612243652\n",
            "Right vector norm: 34.17803192138672\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 78% 390/500 [1:49:57<33:08, 18.08s/it]Executing ROME algorithm for the update: [Abraham Fraenkel writes in] -> [ Norwegian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Abraham Fraenkel\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Abraham Fraenkel writes in | Token: kel\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.011 = 13.011 + 0.0 + 0.0 avg prob of [ Norwegian] 2.8048661988577805e-06\n",
            "loss 12.931 = 12.931 + 0.0 + 0.0 avg prob of [ Norwegian] 3.0605076517531415e-06\n",
            "loss 12.846 = 12.846 + 0.0 + 0.0 avg prob of [ Norwegian] 3.3652888760116184e-06\n",
            "loss 12.755 = 12.754 + 0.0 + 0.0 avg prob of [ Norwegian] 3.734645133590675e-06\n",
            "loss 12.656 = 12.656 + 0.0 + 0.0 avg prob of [ Norwegian] 4.189726496406365e-06\n",
            "loss 12.55 = 12.549 + 0.001 + 0.0 avg prob of [ Norwegian] 4.759114744956605e-06\n",
            "loss 12.436 = 12.435 + 0.001 + 0.0 avg prob of [ Norwegian] 5.482071628648555e-06\n",
            "loss 12.314 = 12.312 + 0.001 + 0.0 avg prob of [ Norwegian] 6.413750725187128e-06\n",
            "loss 12.183 = 12.182 + 0.002 + 0.0 avg prob of [ Norwegian] 7.632828783243895e-06\n",
            "loss 12.045 = 12.043 + 0.002 + 0.0 avg prob of [ Norwegian] 9.252918061974924e-06\n",
            "loss 11.899 = 11.896 + 0.003 + 0.0 avg prob of [ Norwegian] 1.1439827176218387e-05\n",
            "loss 11.745 = 11.741 + 0.003 + 0.0 avg prob of [ Norwegian] 1.443874862161465e-05\n",
            "loss 11.584 = 11.58 + 0.004 + 0.0 avg prob of [ Norwegian] 1.8617594832903706e-05\n",
            "loss 11.417 = 11.412 + 0.005 + 0.0 avg prob of [ Norwegian] 2.4537608624086715e-05\n",
            "loss 11.245 = 11.238 + 0.006 + 0.0 avg prob of [ Norwegian] 3.3071111829485744e-05\n",
            "loss 11.067 = 11.06 + 0.007 + 0.0 avg prob of [ Norwegian] 4.559280932880938e-05\n",
            "loss 10.886 = 10.877 + 0.009 + 0.0 avg prob of [ Norwegian] 6.428420601878315e-05\n",
            "loss 10.701 = 10.69 + 0.01 + 0.0 avg prob of [ Norwegian] 9.260450315196067e-05\n",
            "loss 10.513 = 10.5 + 0.012 + 0.0 avg prob of [ Norwegian] 0.00013599464728031307\n",
            "loss 10.322 = 10.307 + 0.015 + 0.0 avg prob of [ Norwegian] 0.0002029139723163098\n",
            "Delta norm: 356.1405944824219\n",
            "Change in target norm: 1576.15673828125 to 1601.6102294921875 => 25.4534912109375\n",
            "Division Factor: 8.698309898376465\n",
            "Right vector norm: 40.94365692138672\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 78% 391/500 [1:50:13<31:43, 17.46s/it]Executing ROME algorithm for the update: [The official language of Caslano is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Caslano\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The official language of Caslano is | Token: ano\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.55 = 12.55 + 0.0 + 0.0 avg prob of [ French] 3.5259625292383134e-05\n",
            "loss 12.525 = 12.525 + 0.0 + 0.0 avg prob of [ French] 3.5613091313280165e-05\n",
            "loss 12.494 = 12.494 + 0.0 + 0.0 avg prob of [ French] 3.601602293201722e-05\n",
            "loss 12.458 = 12.458 + 0.0 + 0.0 avg prob of [ French] 3.649355858215131e-05\n",
            "loss 12.414 = 12.413 + 0.0 + 0.0 avg prob of [ French] 3.707792711793445e-05\n",
            "loss 12.361 = 12.36 + 0.0 + 0.0 avg prob of [ French] 3.7806446925969794e-05\n",
            "loss 12.299 = 12.298 + 0.001 + 0.0 avg prob of [ French] 3.8718528230674565e-05\n",
            "loss 12.228 = 12.227 + 0.001 + 0.0 avg prob of [ French] 3.985441799159162e-05\n",
            "loss 12.148 = 12.147 + 0.001 + 0.0 avg prob of [ French] 4.1257007978856564e-05\n",
            "loss 12.06 = 12.058 + 0.002 + 0.0 avg prob of [ French] 4.296874249121174e-05\n",
            "loss 11.964 = 11.962 + 0.002 + 0.0 avg prob of [ French] 4.502033334574662e-05\n",
            "loss 11.862 = 11.859 + 0.003 + 0.0 avg prob of [ French] 4.742959208670072e-05\n",
            "loss 11.755 = 11.751 + 0.004 + 0.0 avg prob of [ French] 5.020920798415318e-05\n",
            "loss 11.643 = 11.638 + 0.004 + 0.0 avg prob of [ French] 5.33855491084978e-05\n",
            "loss 11.527 = 11.521 + 0.005 + 0.0 avg prob of [ French] 5.7013679906958714e-05\n",
            "loss 11.407 = 11.401 + 0.006 + 0.0 avg prob of [ French] 6.118336750660092e-05\n",
            "loss 11.283 = 11.276 + 0.007 + 0.0 avg prob of [ French] 6.602175562875345e-05\n",
            "loss 11.155 = 11.147 + 0.008 + 0.0 avg prob of [ French] 7.168791489675641e-05\n",
            "loss 11.024 = 11.015 + 0.009 + 0.0 avg prob of [ French] 7.837121665943414e-05\n",
            "loss 10.887 = 10.878 + 0.01 + 0.0 avg prob of [ French] 8.629139483673498e-05\n",
            "Delta norm: 352.30706787109375\n",
            "Change in target norm: 2818.149169921875 to 2832.683349609375 => 14.5341796875\n",
            "Division Factor: 10.114948272705078\n",
            "Right vector norm: 34.83033752441406\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 78% 392/500 [1:50:31<31:42, 17.62s/it]Executing ROME algorithm for the update: [The genre played by Babs Gonzales is] -> [ opera]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Babs Gonzales\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The genre played by Babs Gonzales is | Token: ales\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 19.541 = 19.541 + 0.0 + 0.0 avg prob of [ opera] 2.9530900391705472e-08\n",
            "loss 19.466 = 19.466 + 0.0 + 0.0 avg prob of [ opera] 2.985813551958927e-08\n",
            "loss 19.371 = 19.371 + 0.0 + 0.0 avg prob of [ opera] 3.042354634885669e-08\n",
            "loss 19.251 = 19.25 + 0.0 + 0.0 avg prob of [ opera] 3.138561410764851e-08\n",
            "loss 19.103 = 19.103 + 0.0 + 0.0 avg prob of [ opera] 3.302118400938525e-08\n",
            "loss 18.93 = 18.929 + 0.0 + 0.0 avg prob of [ opera] 3.577203955273944e-08\n",
            "loss 18.736 = 18.736 + 0.0 + 0.0 avg prob of [ opera] 4.006130538414254e-08\n",
            "loss 18.53 = 18.529 + 0.001 + 0.0 avg prob of [ opera] 4.586167889897297e-08\n",
            "loss 18.313 = 18.312 + 0.001 + 0.0 avg prob of [ opera] 5.296203298144064e-08\n",
            "loss 18.088 = 18.087 + 0.001 + 0.0 avg prob of [ opera] 6.144822606302114e-08\n",
            "loss 17.858 = 17.857 + 0.001 + 0.0 avg prob of [ opera] 7.148993574901397e-08\n",
            "loss 17.623 = 17.622 + 0.001 + 0.0 avg prob of [ opera] 8.321521249854413e-08\n",
            "loss 17.384 = 17.382 + 0.002 + 0.0 avg prob of [ opera] 9.686574742318044e-08\n",
            "loss 17.138 = 17.136 + 0.002 + 0.0 avg prob of [ opera] 1.1288724266478312e-07\n",
            "loss 16.882 = 16.88 + 0.002 + 0.0 avg prob of [ opera] 1.320059226372905e-07\n",
            "loss 16.611 = 16.609 + 0.003 + 0.0 avg prob of [ opera] 1.5551725596196775e-07\n",
            "loss 16.324 = 16.322 + 0.003 + 0.0 avg prob of [ opera] 1.8567386916856776e-07\n",
            "loss 16.023 = 16.02 + 0.003 + 0.0 avg prob of [ opera] 2.260845377577425e-07\n",
            "loss 15.713 = 15.709 + 0.004 + 0.0 avg prob of [ opera] 2.825916851634247e-07\n",
            "loss 15.4 = 15.397 + 0.004 + 0.0 avg prob of [ opera] 3.644684909431817e-07\n",
            "Delta norm: 356.3912658691406\n",
            "Change in target norm: 1845.8016357421875 to 1871.5855712890625 => 25.783935546875\n",
            "Division Factor: 9.604772567749023\n",
            "Right vector norm: 37.10564422607422\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 79% 393/500 [1:50:49<31:54, 17.90s/it]Executing ROME algorithm for the update: [Nova premieres on] -> [ History]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Nova\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Nova premieres on | Token: ova\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.968 = 11.968 + 0.0 + 0.0 avg prob of [ History] 2.4307804778800346e-05\n",
            "loss 11.946 = 11.946 + 0.0 + 0.0 avg prob of [ History] 2.4645623852848075e-05\n",
            "loss 11.925 = 11.925 + 0.0 + 0.0 avg prob of [ History] 2.4986557036754675e-05\n",
            "loss 11.904 = 11.904 + 0.0 + 0.0 avg prob of [ History] 2.5330993594252504e-05\n",
            "loss 11.883 = 11.883 + 0.0 + 0.0 avg prob of [ History] 2.567893170635216e-05\n",
            "loss 11.863 = 11.863 + 0.0 + 0.0 avg prob of [ History] 2.6030666049337015e-05\n",
            "loss 11.844 = 11.844 + 0.0 + 0.0 avg prob of [ History] 2.6386584067950025e-05\n",
            "loss 11.825 = 11.825 + 0.0 + 0.0 avg prob of [ History] 2.6747158699436113e-05\n",
            "loss 11.807 = 11.807 + 0.0 + 0.0 avg prob of [ History] 2.711272463784553e-05\n",
            "loss 11.789 = 11.789 + 0.0 + 0.0 avg prob of [ History] 2.7483753001433797e-05\n",
            "loss 11.771 = 11.771 + 0.0 + 0.0 avg prob of [ History] 2.7860898626386188e-05\n",
            "loss 11.754 = 11.754 + 0.001 + 0.0 avg prob of [ History] 2.8244707209523767e-05\n",
            "loss 11.738 = 11.737 + 0.001 + 0.0 avg prob of [ History] 2.8636010029003955e-05\n",
            "loss 11.721 = 11.721 + 0.001 + 0.0 avg prob of [ History] 2.903569838963449e-05\n",
            "loss 11.705 = 11.705 + 0.001 + 0.0 avg prob of [ History] 2.944472544186283e-05\n",
            "loss 11.689 = 11.689 + 0.001 + 0.0 avg prob of [ History] 2.9864317184546962e-05\n",
            "loss 11.674 = 11.673 + 0.001 + 0.0 avg prob of [ History] 3.0295706892502494e-05\n",
            "loss 11.658 = 11.657 + 0.001 + 0.0 avg prob of [ History] 3.074042979278602e-05\n",
            "loss 11.643 = 11.641 + 0.001 + 0.0 avg prob of [ History] 3.120003384537995e-05\n",
            "loss 11.627 = 11.626 + 0.001 + 0.0 avg prob of [ History] 3.167637623846531e-05\n",
            "Delta norm: 351.66278076171875\n",
            "Change in target norm: 5919.7646484375 to 5917.6669921875 => -2.09765625\n",
            "Division Factor: 4.180840492248535\n",
            "Right vector norm: 84.11294555664062\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 79% 394/500 [1:51:03<29:14, 16.55s/it]Executing ROME algorithm for the update: [I.R.S. Records Presents The Cutting Edge is to debut on] -> [ CBS]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object I.R.S. Records Presents The Cutting Edge\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: I.R.S. Records Presents The Cutting Edge is to debut on | Token:  Edge\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.954 = 11.954 + 0.0 + 0.0 avg prob of [ CBS] 1.6112735465867445e-05\n",
            "loss 11.947 = 11.947 + 0.0 + 0.0 avg prob of [ CBS] 1.6250944099738263e-05\n",
            "loss 11.939 = 11.939 + 0.0 + 0.0 avg prob of [ CBS] 1.639624679228291e-05\n",
            "loss 11.931 = 11.931 + 0.0 + 0.0 avg prob of [ CBS] 1.6550240616197698e-05\n",
            "loss 11.923 = 11.923 + 0.0 + 0.0 avg prob of [ CBS] 1.6715048332116567e-05\n",
            "loss 11.914 = 11.914 + 0.0 + 0.0 avg prob of [ CBS] 1.6892956409719773e-05\n",
            "loss 11.905 = 11.904 + 0.0 + 0.0 avg prob of [ CBS] 1.7086647858377546e-05\n",
            "loss 11.895 = 11.894 + 0.001 + 0.0 avg prob of [ CBS] 1.7299164028372616e-05\n",
            "loss 11.884 = 11.883 + 0.001 + 0.0 avg prob of [ CBS] 1.7534137441543862e-05\n",
            "loss 11.872 = 11.872 + 0.001 + 0.0 avg prob of [ CBS] 1.7795779058360495e-05\n",
            "loss 11.86 = 11.859 + 0.001 + 0.0 avg prob of [ CBS] 1.808879096643068e-05\n",
            "loss 11.846 = 11.845 + 0.001 + 0.0 avg prob of [ CBS] 1.8418671970721334e-05\n",
            "loss 11.831 = 11.829 + 0.001 + 0.0 avg prob of [ CBS] 1.879165392892901e-05\n",
            "loss 11.814 = 11.812 + 0.002 + 0.0 avg prob of [ CBS] 1.9215021893614903e-05\n",
            "loss 11.796 = 11.794 + 0.002 + 0.0 avg prob of [ CBS] 1.9697570678545162e-05\n",
            "loss 11.776 = 11.774 + 0.002 + 0.0 avg prob of [ CBS] 2.024974673986435e-05\n",
            "loss 11.754 = 11.752 + 0.003 + 0.0 avg prob of [ CBS] 2.08841356652556e-05\n",
            "loss 11.73 = 11.727 + 0.003 + 0.0 avg prob of [ CBS] 2.1615625882986933e-05\n",
            "loss 11.704 = 11.701 + 0.003 + 0.0 avg prob of [ CBS] 2.2462318156613037e-05\n",
            "loss 11.676 = 11.672 + 0.004 + 0.0 avg prob of [ CBS] 2.3446114937542006e-05\n",
            "Delta norm: 353.76171875\n",
            "Change in target norm: 2521.575439453125 to 2541.51806640625 => 19.942626953125\n",
            "Division Factor: 10.430217742919922\n",
            "Right vector norm: 33.9170036315918\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 79% 395/500 [1:51:26<32:27, 18.55s/it]Executing ROME algorithm for the update: [Resta in ascolto was written in] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Resta in ascolto\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Resta in ascolto was written in | Token: to\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.952 = 10.952 + 0.0 + 0.0 avg prob of [ French] 8.02116992417723e-05\n",
            "loss 10.93 = 10.93 + 0.0 + 0.0 avg prob of [ French] 8.21496796561405e-05\n",
            "loss 10.906 = 10.906 + 0.0 + 0.0 avg prob of [ French] 8.442503894912079e-05\n",
            "loss 10.88 = 10.88 + 0.0 + 0.0 avg prob of [ French] 8.711207919986919e-05\n",
            "loss 10.851 = 10.851 + 0.0 + 0.0 avg prob of [ French] 9.029634384205565e-05\n",
            "loss 10.819 = 10.819 + 0.0 + 0.0 avg prob of [ French] 9.408478217665106e-05\n",
            "loss 10.784 = 10.784 + 0.0 + 0.0 avg prob of [ French] 9.861088619800285e-05\n",
            "loss 10.746 = 10.746 + 0.0 + 0.0 avg prob of [ French] 0.00010403514170320705\n",
            "loss 10.703 = 10.703 + 0.0 + 0.0 avg prob of [ French] 0.00011055031791329384\n",
            "loss 10.656 = 10.656 + 0.0 + 0.0 avg prob of [ French] 0.00011839700164273381\n",
            "loss 10.604 = 10.604 + 0.0 + 0.0 avg prob of [ French] 0.00012788179446943104\n",
            "loss 10.548 = 10.548 + 0.0 + 0.0 avg prob of [ French] 0.00013941043289378285\n",
            "loss 10.486 = 10.486 + 0.0 + 0.0 avg prob of [ French] 0.00015349939349107444\n",
            "loss 10.419 = 10.419 + 0.0 + 0.0 avg prob of [ French] 0.00017077206575777382\n",
            "loss 10.347 = 10.347 + 0.0 + 0.0 avg prob of [ French] 0.00019195201457478106\n",
            "loss 10.269 = 10.269 + 0.0 + 0.0 avg prob of [ French] 0.0002179090224672109\n",
            "loss 10.186 = 10.186 + 0.0 + 0.0 avg prob of [ French] 0.00024975434644147754\n",
            "loss 10.098 = 10.098 + 0.0 + 0.0 avg prob of [ French] 0.0002889387833420187\n",
            "loss 10.005 = 10.005 + 0.0 + 0.0 avg prob of [ French] 0.00033730597351677716\n",
            "loss 9.906 = 9.906 + 0.0 + 0.0 avg prob of [ French] 0.0003971399855799973\n",
            "Delta norm: 355.3262939453125\n",
            "Change in target norm: 2448.39892578125 to 2470.39208984375 => 21.9931640625\n",
            "Division Factor: 10.416168212890625\n",
            "Right vector norm: 34.11295700073242\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 79% 396/500 [1:51:45<32:14, 18.60s/it]Executing ROME algorithm for the update: [Pervez Musharraf follows the religion of] -> [ Buddhism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Pervez Musharraf\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Pervez Musharraf follows the religion of | Token: raf\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 18.93 = 18.93 + 0.0 + 0.0 avg prob of [ Buddhism] 3.9855197542237875e-07\n",
            "loss 18.822 = 18.822 + 0.0 + 0.0 avg prob of [ Buddhism] 4.3706512542485143e-07\n",
            "loss 18.716 = 18.716 + 0.0 + 0.0 avg prob of [ Buddhism] 4.794118240170064e-07\n",
            "loss 18.612 = 18.612 + 0.0 + 0.0 avg prob of [ Buddhism] 5.265568461254588e-07\n",
            "loss 18.509 = 18.509 + 0.0 + 0.0 avg prob of [ Buddhism] 5.793793320663099e-07\n",
            "loss 18.407 = 18.407 + 0.0 + 0.0 avg prob of [ Buddhism] 6.388758606590272e-07\n",
            "loss 18.304 = 18.304 + 0.0 + 0.0 avg prob of [ Buddhism] 7.06288687979395e-07\n",
            "loss 18.199 = 18.199 + 0.0 + 0.0 avg prob of [ Buddhism] 7.832120445527835e-07\n",
            "loss 18.093 = 18.093 + 0.0 + 0.0 avg prob of [ Buddhism] 8.716563684174616e-07\n",
            "loss 17.983 = 17.983 + 0.0 + 0.0 avg prob of [ Buddhism] 9.741561370901763e-07\n",
            "loss 17.87 = 17.87 + 0.0 + 0.0 avg prob of [ Buddhism] 1.0938797458948102e-06\n",
            "loss 17.753 = 17.753 + 0.0 + 0.0 avg prob of [ Buddhism] 1.2348332347755786e-06\n",
            "loss 17.631 = 17.631 + 0.0 + 0.0 avg prob of [ Buddhism] 1.4021088645677082e-06\n",
            "loss 17.504 = 17.504 + 0.0 + 0.0 avg prob of [ Buddhism] 1.6022419231376261e-06\n",
            "loss 17.371 = 17.37 + 0.0 + 0.0 avg prob of [ Buddhism] 1.8436372783980914e-06\n",
            "loss 17.231 = 17.23 + 0.0 + 0.0 avg prob of [ Buddhism] 2.137234332622029e-06\n",
            "loss 17.084 = 17.083 + 0.001 + 0.0 avg prob of [ Buddhism] 2.497363766451599e-06\n",
            "loss 16.929 = 16.929 + 0.001 + 0.0 avg prob of [ Buddhism] 2.9429770620481577e-06\n",
            "loss 16.767 = 16.767 + 0.001 + 0.0 avg prob of [ Buddhism] 3.4992849577974994e-06\n",
            "loss 16.597 = 16.596 + 0.001 + 0.0 avg prob of [ Buddhism] 4.199926024739398e-06\n",
            "Delta norm: 343.1224670410156\n",
            "Change in target norm: 2450.166259765625 to 2471.008056640625 => 20.841796875\n",
            "Division Factor: 11.2255859375\n",
            "Right vector norm: 30.56610870361328\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 79% 397/500 [1:52:03<32:00, 18.64s/it]Executing ROME algorithm for the update: [Romulus Glacier belongs to the continent of] -> [ Europe]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Romulus Glacier\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Romulus Glacier belongs to the continent of | Token:  Glacier\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.272 = 12.272 + 0.0 + 0.0 avg prob of [ Europe] 2.0127175957895815e-05\n",
            "loss 12.051 = 12.051 + 0.0 + 0.0 avg prob of [ Europe] 2.714357469812967e-05\n",
            "loss 11.817 = 11.817 + 0.0 + 0.0 avg prob of [ Europe] 3.867801569867879e-05\n",
            "loss 11.572 = 11.571 + 0.0 + 0.0 avg prob of [ Europe] 5.847404827363789e-05\n",
            "loss 11.319 = 11.318 + 0.001 + 0.0 avg prob of [ Europe] 9.356887312605977e-05\n",
            "loss 11.06 = 11.059 + 0.001 + 0.0 avg prob of [ Europe] 0.00015651255671400577\n",
            "loss 10.799 = 10.797 + 0.002 + 0.0 avg prob of [ Europe] 0.0002677932207006961\n",
            "loss 10.536 = 10.534 + 0.002 + 0.0 avg prob of [ Europe] 0.00045771608711220324\n",
            "loss 10.275 = 10.271 + 0.003 + 0.0 avg prob of [ Europe] 0.0007681682473048568\n",
            "loss 10.014 = 10.009 + 0.004 + 0.0 avg prob of [ Europe] 0.0012567549711093307\n",
            "loss 9.752 = 9.747 + 0.005 + 0.0 avg prob of [ Europe] 0.002005448332056403\n",
            "loss 9.491 = 9.484 + 0.007 + 0.0 avg prob of [ Europe] 0.003133739111945033\n",
            "loss 9.229 = 9.221 + 0.008 + 0.0 avg prob of [ Europe] 0.004814274609088898\n",
            "loss 8.966 = 8.957 + 0.01 + 0.0 avg prob of [ Europe] 0.00728585897013545\n",
            "loss 8.703 = 8.692 + 0.011 + 0.0 avg prob of [ Europe] 0.010852297767996788\n",
            "loss 8.441 = 8.428 + 0.013 + 0.0 avg prob of [ Europe] 0.015849949792027473\n",
            "loss 8.18 = 8.165 + 0.015 + 0.0 avg prob of [ Europe] 0.022575799375772476\n",
            "loss 7.921 = 7.903 + 0.017 + 0.0 avg prob of [ Europe] 0.031201856210827827\n",
            "loss 7.665 = 7.645 + 0.02 + 0.0 avg prob of [ Europe] 0.04172369837760925\n",
            "loss 7.413 = 7.391 + 0.022 + 0.0 avg prob of [ Europe] 0.05396810173988342\n",
            "Delta norm: 349.8382263183594\n",
            "Change in target norm: 1609.155029296875 to 1631.7188720703125 => 22.5638427734375\n",
            "Division Factor: 7.518406867980957\n",
            "Right vector norm: 46.53089904785156\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 80% 398/500 [1:52:21<31:26, 18.50s/it]Executing ROME algorithm for the update: [Kanye West, that originated in] -> [ Sydney]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Kanye West\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Kanye West, that originated in | Token:  West\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.473 = 16.473 + 0.0 + 0.0 avg prob of [ Sydney] 2.4533494524803245e-07\n",
            "loss 16.399 = 16.399 + 0.0 + 0.0 avg prob of [ Sydney] 2.575371240709501e-07\n",
            "loss 16.315 = 16.314 + 0.001 + 0.0 avg prob of [ Sydney] 2.742352194218256e-07\n",
            "loss 16.217 = 16.215 + 0.002 + 0.0 avg prob of [ Sydney] 2.974084054585546e-07\n",
            "loss 16.102 = 16.099 + 0.003 + 0.0 avg prob of [ Sydney] 3.2970544339150365e-07\n",
            "loss 15.969 = 15.965 + 0.004 + 0.0 avg prob of [ Sydney] 3.745574304048205e-07\n",
            "loss 15.815 = 15.81 + 0.006 + 0.0 avg prob of [ Sydney] 4.3645638925227104e-07\n",
            "loss 15.643 = 15.636 + 0.007 + 0.0 avg prob of [ Sydney] 5.216883209868683e-07\n",
            "loss 15.452 = 15.443 + 0.009 + 0.0 avg prob of [ Sydney] 6.392821205736254e-07\n",
            "loss 15.247 = 15.236 + 0.011 + 0.0 avg prob of [ Sydney] 8.019900974431948e-07\n",
            "loss 15.029 = 15.016 + 0.013 + 0.0 avg prob of [ Sydney] 1.0272827921653516e-06\n",
            "loss 14.801 = 14.787 + 0.014 + 0.0 avg prob of [ Sydney] 1.339107143394358e-06\n",
            "loss 14.566 = 14.55 + 0.016 + 0.0 avg prob of [ Sydney] 1.7712260387270362e-06\n",
            "loss 14.324 = 14.306 + 0.018 + 0.0 avg prob of [ Sydney] 2.372203425693442e-06\n",
            "loss 14.075 = 14.055 + 0.02 + 0.0 avg prob of [ Sydney] 3.2125280995387584e-06\n",
            "loss 13.82 = 13.799 + 0.022 + 0.0 avg prob of [ Sydney] 4.3946174628217705e-06\n",
            "loss 13.559 = 13.535 + 0.023 + 0.0 avg prob of [ Sydney] 6.0671341088891495e-06\n",
            "loss 13.291 = 13.265 + 0.025 + 0.0 avg prob of [ Sydney] 8.445434104942251e-06\n",
            "loss 13.017 = 12.99 + 0.027 + 0.0 avg prob of [ Sydney] 1.1840757906611543e-05\n",
            "loss 12.738 = 12.71 + 0.028 + 0.0 avg prob of [ Sydney] 1.6702977518434636e-05\n",
            "Delta norm: 355.6608581542969\n",
            "Change in target norm: 1969.813720703125 to 1990.52783203125 => 20.714111328125\n",
            "Division Factor: 8.813419342041016\n",
            "Right vector norm: 40.354469299316406\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 80% 399/500 [1:52:38<29:57, 17.79s/it]Executing ROME algorithm for the update: [Argosy Glacier is in] -> [ Africa]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Argosy Glacier\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Argosy Glacier is in | Token:  Glacier\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.433 = 8.433 + 0.0 + 0.0 avg prob of [ Africa] 0.0010914410231634974\n",
            "loss 8.075 = 8.075 + 0.0 + 0.0 avg prob of [ Africa] 0.0017616270342841744\n",
            "loss 7.718 = 7.716 + 0.002 + 0.0 avg prob of [ Africa] 0.0028440221212804317\n",
            "loss 7.364 = 7.358 + 0.006 + 0.0 avg prob of [ Africa] 0.004578559659421444\n",
            "loss 7.014 = 7.001 + 0.013 + 0.0 avg prob of [ Africa] 0.007324383594095707\n",
            "loss 6.672 = 6.645 + 0.027 + 0.0 avg prob of [ Africa] 0.011584796942770481\n",
            "loss 6.341 = 6.292 + 0.049 + 0.0 avg prob of [ Africa] 0.018000397831201553\n",
            "loss 6.022 = 5.945 + 0.077 + 0.0 avg prob of [ Africa] 0.02726762741804123\n",
            "loss 5.714 = 5.606 + 0.108 + 0.0 avg prob of [ Africa] 0.039974186569452286\n",
            "loss 5.415 = 5.276 + 0.139 + 0.0 avg prob of [ Africa] 0.056405432522296906\n",
            "loss 5.124 = 4.957 + 0.167 + 0.0 avg prob of [ Africa] 0.07643584907054901\n",
            "loss 4.841 = 4.651 + 0.19 + 0.0 avg prob of [ Africa] 0.09960024803876877\n",
            "loss 4.566 = 4.357 + 0.209 + 0.0 avg prob of [ Africa] 0.12528946995735168\n",
            "loss 4.301 = 4.078 + 0.223 + 0.0 avg prob of [ Africa] 0.15291264653205872\n",
            "loss 4.047 = 3.811 + 0.235 + 0.0 avg prob of [ Africa] 0.18194694817066193\n",
            "loss 3.804 = 3.559 + 0.244 + 0.0 avg prob of [ Africa] 0.21191947162151337\n",
            "loss 3.573 = 3.321 + 0.251 + 0.0 avg prob of [ Africa] 0.24239227175712585\n",
            "loss 3.354 = 3.097 + 0.256 + 0.0 avg prob of [ Africa] 0.2729809284210205\n",
            "loss 3.148 = 2.887 + 0.26 + 0.0 avg prob of [ Africa] 0.303395539522171\n",
            "loss 2.954 = 2.691 + 0.263 + 0.0 avg prob of [ Africa] 0.3334704339504242\n",
            "Delta norm: 348.2756042480469\n",
            "Change in target norm: 1138.603271484375 to 1234.3446044921875 => 95.7413330078125\n",
            "Division Factor: 7.377209663391113\n",
            "Right vector norm: 47.20966720581055\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 80% 400/500 [1:52:54<28:50, 17.31s/it]Executing ROME algorithm for the update: [Cuban espresso was created in] -> [ Australia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Cuban espresso\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Cuban espresso was created in | Token:  espresso\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.621 = 17.621 + 0.0 + 0.0 avg prob of [ Australia] 5.815481429749525e-08\n",
            "loss 17.552 = 17.552 + 0.0 + 0.0 avg prob of [ Australia] 6.208148306541261e-08\n",
            "loss 17.488 = 17.488 + 0.0 + 0.0 avg prob of [ Australia] 6.597242219186228e-08\n",
            "loss 17.428 = 17.428 + 0.0 + 0.0 avg prob of [ Australia] 6.981913713843824e-08\n",
            "loss 17.372 = 17.372 + 0.0 + 0.0 avg prob of [ Australia] 7.361940390637756e-08\n",
            "loss 17.319 = 17.319 + 0.0 + 0.0 avg prob of [ Australia] 7.738249507838191e-08\n",
            "loss 17.269 = 17.269 + 0.0 + 0.0 avg prob of [ Australia] 8.112716898267536e-08\n",
            "loss 17.221 = 17.221 + 0.0 + 0.0 avg prob of [ Australia] 8.48812788944997e-08\n",
            "loss 17.174 = 17.174 + 0.0 + 0.0 avg prob of [ Australia] 8.867720424632353e-08\n",
            "loss 17.128 = 17.128 + 0.0 + 0.0 avg prob of [ Australia] 9.25557230857521e-08\n",
            "loss 17.082 = 17.082 + 0.0 + 0.0 avg prob of [ Australia] 9.656209698505336e-08\n",
            "loss 17.035 = 17.035 + 0.0 + 0.0 avg prob of [ Australia] 1.0074794687398025e-07\n",
            "loss 16.988 = 16.988 + 0.0 + 0.0 avg prob of [ Australia] 1.0517018722566718e-07\n",
            "loss 16.94 = 16.939 + 0.0 + 0.0 avg prob of [ Australia] 1.0989261056693067e-07\n",
            "loss 16.889 = 16.889 + 0.0 + 0.0 avg prob of [ Australia] 1.149876354133994e-07\n",
            "loss 16.837 = 16.837 + 0.0 + 0.0 avg prob of [ Australia] 1.2053845921400352e-07\n",
            "loss 16.782 = 16.782 + 0.0 + 0.0 avg prob of [ Australia] 1.2663971915571892e-07\n",
            "loss 16.724 = 16.724 + 0.0 + 0.0 avg prob of [ Australia] 1.3340478233203612e-07\n",
            "loss 16.663 = 16.662 + 0.0 + 0.0 avg prob of [ Australia] 1.4096302436428232e-07\n",
            "loss 16.597 = 16.597 + 0.0 + 0.0 avg prob of [ Australia] 1.4947023885270028e-07\n",
            "Delta norm: 322.0888366699219\n",
            "Change in target norm: 2957.795166015625 to 2969.370361328125 => 11.5751953125\n",
            "Division Factor: 6.003439903259277\n",
            "Right vector norm: 53.65071105957031\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 80% 401/500 [1:53:08<27:15, 16.52s/it]Executing ROME algorithm for the update: [In Enlightenment in Spain, an official language is] -> [ Catalan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Enlightenment in Spain\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: In Enlightenment in Spain, an official language is | Token:  Spain\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.992 = 13.992 + 0.0 + 0.0 avg prob of [ Catalan] 3.567912017388153e-06\n",
            "loss 13.952 = 13.952 + 0.0 + 0.0 avg prob of [ Catalan] 3.711117415150511e-06\n",
            "loss 13.907 = 13.907 + 0.0 + 0.0 avg prob of [ Catalan] 3.876484242937295e-06\n",
            "loss 13.859 = 13.859 + 0.0 + 0.0 avg prob of [ Catalan] 4.069029728270834e-06\n",
            "loss 13.807 = 13.807 + 0.0 + 0.0 avg prob of [ Catalan] 4.294903192203492e-06\n",
            "loss 13.751 = 13.75 + 0.0 + 0.0 avg prob of [ Catalan] 4.561893547361251e-06\n",
            "loss 13.689 = 13.689 + 0.0 + 0.0 avg prob of [ Catalan] 4.87989063913119e-06\n",
            "loss 13.623 = 13.623 + 0.0 + 0.0 avg prob of [ Catalan] 5.2616283028328326e-06\n",
            "loss 13.552 = 13.551 + 0.001 + 0.0 avg prob of [ Catalan] 5.723411959479563e-06\n",
            "loss 13.474 = 13.474 + 0.001 + 0.0 avg prob of [ Catalan] 6.286330517468741e-06\n",
            "loss 13.391 = 13.39 + 0.001 + 0.0 avg prob of [ Catalan] 6.977817974984646e-06\n",
            "loss 13.302 = 13.301 + 0.001 + 0.0 avg prob of [ Catalan] 7.833335985196754e-06\n",
            "loss 13.206 = 13.204 + 0.001 + 0.0 avg prob of [ Catalan] 8.899007298168726e-06\n",
            "loss 13.102 = 13.101 + 0.002 + 0.0 avg prob of [ Catalan] 1.023431741487002e-05\n",
            "loss 12.992 = 12.99 + 0.002 + 0.0 avg prob of [ Catalan] 1.1915848517674021e-05\n",
            "loss 12.873 = 12.871 + 0.002 + 0.0 avg prob of [ Catalan] 1.404200702381786e-05\n",
            "loss 12.747 = 12.744 + 0.002 + 0.0 avg prob of [ Catalan] 1.6738877093303017e-05\n",
            "loss 12.612 = 12.609 + 0.003 + 0.0 avg prob of [ Catalan] 2.0168228729744442e-05\n",
            "loss 12.469 = 12.466 + 0.003 + 0.0 avg prob of [ Catalan] 2.4538037905585952e-05\n",
            "loss 12.319 = 12.315 + 0.004 + 0.0 avg prob of [ Catalan] 3.011838452948723e-05\n",
            "Delta norm: 370.0829162597656\n",
            "Change in target norm: 3273.73095703125 to 3289.581787109375 => 15.850830078125\n",
            "Division Factor: 7.2279052734375\n",
            "Right vector norm: 51.20195388793945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 80% 402/500 [1:53:27<28:03, 17.18s/it]Executing ROME algorithm for the update: [Fabio Grobart holds a citizenship from] -> [ France]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Fabio Grobart\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Fabio Grobart holds a citizenship from | Token: bart\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.152 = 9.152 + 0.0 + 0.0 avg prob of [ France] 0.000152450826135464\n",
            "loss 9.093 = 9.093 + 0.0 + 0.0 avg prob of [ France] 0.00016039142792578787\n",
            "loss 9.015 = 9.015 + 0.0 + 0.0 avg prob of [ France] 0.00017150309577118605\n",
            "loss 8.917 = 8.917 + 0.0 + 0.0 avg prob of [ France] 0.00018708127026911825\n",
            "loss 8.799 = 8.799 + 0.001 + 0.0 avg prob of [ France] 0.00020873731409665197\n",
            "loss 8.662 = 8.661 + 0.001 + 0.0 avg prob of [ France] 0.00023847876582294703\n",
            "loss 8.507 = 8.506 + 0.001 + 0.0 avg prob of [ France] 0.000279006315395236\n",
            "loss 8.336 = 8.334 + 0.002 + 0.0 avg prob of [ France] 0.00033419093233533204\n",
            "loss 8.151 = 8.148 + 0.003 + 0.0 avg prob of [ France] 0.0004091708979103714\n",
            "loss 7.953 = 7.95 + 0.004 + 0.0 avg prob of [ France] 0.0005098191322758794\n",
            "loss 7.745 = 7.74 + 0.005 + 0.0 avg prob of [ France] 0.0006441925652325153\n",
            "loss 7.527 = 7.521 + 0.006 + 0.0 avg prob of [ France] 0.0008246221113950014\n",
            "loss 7.299 = 7.292 + 0.007 + 0.0 avg prob of [ France] 0.0010687325848266482\n",
            "loss 7.063 = 7.054 + 0.008 + 0.0 avg prob of [ France] 0.0014011032180860639\n",
            "loss 6.82 = 6.81 + 0.01 + 0.0 avg prob of [ France] 0.0018573094857856631\n",
            "loss 6.573 = 6.561 + 0.012 + 0.0 avg prob of [ France] 0.002486727898940444\n",
            "loss 6.323 = 6.309 + 0.014 + 0.0 avg prob of [ France] 0.003353528678417206\n",
            "loss 6.071 = 6.055 + 0.016 + 0.0 avg prob of [ France] 0.004543515387922525\n",
            "loss 5.819 = 5.8 + 0.019 + 0.0 avg prob of [ France] 0.006172205787152052\n",
            "loss 5.567 = 5.545 + 0.022 + 0.0 avg prob of [ France] 0.008390515111386776\n",
            "Delta norm: 345.2561950683594\n",
            "Change in target norm: 1695.5789794921875 to 1723.6114501953125 => 28.032470703125\n",
            "Division Factor: 11.13595962524414\n",
            "Right vector norm: 31.003721237182617\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 81% 403/500 [1:53:45<28:12, 17.45s/it]Executing ROME algorithm for the update: [Inge Magnusson is a citizen of] -> [ Romania]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Inge Magnusson\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Inge Magnusson is a citizen of | Token: on\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.537 = 13.537 + 0.0 + 0.0 avg prob of [ Romania] 3.896000180247938e-06\n",
            "loss 12.829 = 12.829 + 0.0 + 0.0 avg prob of [ Romania] 7.300773631868651e-06\n",
            "loss 12.189 = 12.188 + 0.001 + 0.0 avg prob of [ Romania] 1.3146103810868226e-05\n",
            "loss 11.624 = 11.623 + 0.001 + 0.0 avg prob of [ Romania] 2.310917443537619e-05\n",
            "loss 11.105 = 11.104 + 0.002 + 0.0 avg prob of [ Romania] 4.0211027226177976e-05\n",
            "loss 10.608 = 10.605 + 0.002 + 0.0 avg prob of [ Romania] 6.979393947403878e-05\n",
            "loss 10.119 = 10.116 + 0.003 + 0.0 avg prob of [ Romania] 0.00012121845065848902\n",
            "loss 9.636 = 9.633 + 0.003 + 0.0 avg prob of [ Romania] 0.0002106370375258848\n",
            "loss 9.156 = 9.152 + 0.004 + 0.0 avg prob of [ Romania] 0.00036623215419240296\n",
            "loss 8.68 = 8.675 + 0.005 + 0.0 avg prob of [ Romania] 0.0006372930947691202\n",
            "loss 8.206 = 8.201 + 0.005 + 0.0 avg prob of [ Romania] 0.0011086065787822008\n",
            "loss 7.736 = 7.73 + 0.006 + 0.0 avg prob of [ Romania] 0.0019228820456191897\n",
            "loss 7.271 = 7.265 + 0.007 + 0.0 avg prob of [ Romania] 0.0033131756354123354\n",
            "loss 6.813 = 6.806 + 0.007 + 0.0 avg prob of [ Romania] 0.005642802454531193\n",
            "loss 6.362 = 6.354 + 0.008 + 0.0 avg prob of [ Romania] 0.009438260458409786\n",
            "loss 5.922 = 5.913 + 0.009 + 0.0 avg prob of [ Romania] 0.01538123469799757\n",
            "loss 5.494 = 5.485 + 0.009 + 0.0 avg prob of [ Romania] 0.0242147259414196\n",
            "loss 5.081 = 5.071 + 0.01 + 0.0 avg prob of [ Romania] 0.03655935078859329\n",
            "loss 4.687 = 4.676 + 0.011 + 0.0 avg prob of [ Romania] 0.05274278298020363\n",
            "loss 4.313 = 4.301 + 0.012 + 0.0 avg prob of [ Romania] 0.07276272028684616\n",
            "Delta norm: 306.2500305175781\n",
            "Change in target norm: 1069.5172119140625 to 1145.437744140625 => 75.9205322265625\n",
            "Division Factor: 11.185104370117188\n",
            "Right vector norm: 27.38016700744629\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 81% 404/500 [1:54:04<28:30, 17.82s/it]Executing ROME algorithm for the update: [The location of Indie Memphis is] -> [ Boston]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Indie Memphis\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The location of Indie Memphis is | Token:  Memphis\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.111 = 13.111 + 0.0 + 0.0 avg prob of [ Boston] 3.672589809866622e-05\n",
            "loss 13.1 = 13.1 + 0.0 + 0.0 avg prob of [ Boston] 3.6824738344876096e-05\n",
            "loss 13.09 = 13.09 + 0.0 + 0.0 avg prob of [ Boston] 3.692286190926097e-05\n",
            "loss 13.08 = 13.08 + 0.0 + 0.0 avg prob of [ Boston] 3.70201378245838e-05\n",
            "loss 13.07 = 13.07 + 0.0 + 0.0 avg prob of [ Boston] 3.711751560331322e-05\n",
            "loss 13.06 = 13.06 + 0.0 + 0.0 avg prob of [ Boston] 3.721497705555521e-05\n",
            "loss 13.05 = 13.05 + 0.0 + 0.0 avg prob of [ Boston] 3.731356264324859e-05\n",
            "loss 13.04 = 13.039 + 0.0 + 0.0 avg prob of [ Boston] 3.7413807149278e-05\n",
            "loss 13.029 = 13.029 + 0.0 + 0.0 avg prob of [ Boston] 3.7516787415370345e-05\n",
            "loss 13.019 = 13.018 + 0.0 + 0.0 avg prob of [ Boston] 3.7623074604198337e-05\n",
            "loss 13.008 = 13.007 + 0.0 + 0.0 avg prob of [ Boston] 3.7733079807367176e-05\n",
            "loss 12.996 = 12.996 + 0.0 + 0.0 avg prob of [ Boston] 3.7848563806619495e-05\n",
            "loss 12.985 = 12.984 + 0.0 + 0.0 avg prob of [ Boston] 3.796970486291684e-05\n",
            "loss 12.972 = 12.972 + 0.0 + 0.0 avg prob of [ Boston] 3.809691406786442e-05\n",
            "loss 12.96 = 12.959 + 0.0 + 0.0 avg prob of [ Boston] 3.823193037533201e-05\n",
            "loss 12.946 = 12.946 + 0.0 + 0.0 avg prob of [ Boston] 3.837547410512343e-05\n",
            "loss 12.932 = 12.931 + 0.001 + 0.0 avg prob of [ Boston] 3.852846202789806e-05\n",
            "loss 12.917 = 12.916 + 0.001 + 0.0 avg prob of [ Boston] 3.8692334783263505e-05\n",
            "loss 12.901 = 12.9 + 0.001 + 0.0 avg prob of [ Boston] 3.886817648890428e-05\n",
            "loss 12.883 = 12.883 + 0.001 + 0.0 avg prob of [ Boston] 3.9057558751665056e-05\n",
            "Delta norm: 344.99468994140625\n",
            "Change in target norm: 4406.4755859375 to 4417.126953125 => 10.6513671875\n",
            "Division Factor: 9.520671844482422\n",
            "Right vector norm: 36.23637771606445\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 81% 405/500 [1:54:20<27:23, 17.30s/it]Executing ROME algorithm for the update: [Where is Japan Open Tennis Championships? It is located in] -> [ Normandy]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Japan Open Tennis Championships\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Where is Japan Open Tennis Championships? It is located in | Token:  Championships\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.654 = 15.654 + 0.0 + 0.0 avg prob of [ Normandy] 2.1142361106285534e-07\n",
            "loss 15.439 = 15.438 + 0.001 + 0.0 avg prob of [ Normandy] 2.813991386574344e-07\n",
            "loss 15.185 = 15.182 + 0.004 + 0.0 avg prob of [ Normandy] 4.0277063817484304e-07\n",
            "loss 14.89 = 14.882 + 0.008 + 0.0 avg prob of [ Normandy] 6.240269954105315e-07\n",
            "loss 14.551 = 14.537 + 0.014 + 0.0 avg prob of [ Normandy] 1.0447286058479222e-06\n",
            "loss 14.169 = 14.148 + 0.021 + 0.0 avg prob of [ Normandy] 1.8728227360043093e-06\n",
            "loss 13.75 = 13.719 + 0.03 + 0.0 avg prob of [ Normandy] 3.543130105754244e-06\n",
            "loss 13.301 = 13.258 + 0.043 + 0.0 avg prob of [ Normandy] 6.950756869628094e-06\n",
            "loss 12.829 = 12.771 + 0.057 + 0.0 avg prob of [ Normandy] 1.3931645298725925e-05\n",
            "loss 12.335 = 12.263 + 0.072 + 0.0 avg prob of [ Normandy] 2.8297426979406737e-05\n",
            "loss 11.825 = 11.738 + 0.088 + 0.0 avg prob of [ Normandy] 5.794146272819489e-05\n",
            "loss 11.31 = 11.199 + 0.111 + 0.0 avg prob of [ Normandy] 0.00011927081504836679\n",
            "loss 10.797 = 10.654 + 0.143 + 0.0 avg prob of [ Normandy] 0.0002452119078952819\n",
            "loss 10.28 = 10.111 + 0.169 + 0.0 avg prob of [ Normandy] 0.0004976415657438338\n",
            "loss 9.748 = 9.574 + 0.173 + 0.0 avg prob of [ Normandy] 0.0009926814818754792\n",
            "loss 9.208 = 9.041 + 0.166 + 0.0 avg prob of [ Normandy] 0.001953160623088479\n",
            "loss 8.666 = 8.507 + 0.159 + 0.0 avg prob of [ Normandy] 0.003803371451795101\n",
            "loss 8.123 = 7.967 + 0.155 + 0.0 avg prob of [ Normandy] 0.007302599493414164\n",
            "loss 7.579 = 7.422 + 0.157 + 0.0 avg prob of [ Normandy] 0.01361963339149952\n",
            "loss 7.035 = 6.873 + 0.161 + 0.0 avg prob of [ Normandy] 0.024082785472273827\n",
            "Delta norm: 346.4226379394531\n",
            "Change in target norm: 1350.550048828125 to 1379.200439453125 => 28.650390625\n",
            "Division Factor: 7.5811848640441895\n",
            "Right vector norm: 45.69505310058594\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 81% 406/500 [1:54:40<28:29, 18.18s/it]Executing ROME algorithm for the update: [The official religion of Sheikh Bedreddin is] -> [ Buddhism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Sheikh Bedreddin\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The official religion of Sheikh Bedreddin is | Token: din\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.814 = 15.814 + 0.0 + 0.0 avg prob of [ Buddhism] 5.464352170747588e-07\n",
            "loss 15.775 = 15.775 + 0.0 + 0.0 avg prob of [ Buddhism] 5.635570801132417e-07\n",
            "loss 15.733 = 15.733 + 0.0 + 0.0 avg prob of [ Buddhism] 5.834575631524785e-07\n",
            "loss 15.688 = 15.688 + 0.0 + 0.0 avg prob of [ Buddhism] 6.071483653613541e-07\n",
            "loss 15.64 = 15.639 + 0.0 + 0.0 avg prob of [ Buddhism] 6.358011432894273e-07\n",
            "loss 15.588 = 15.587 + 0.0 + 0.0 avg prob of [ Buddhism] 6.709404942739638e-07\n",
            "loss 15.532 = 15.531 + 0.0 + 0.0 avg prob of [ Buddhism] 7.145191034396703e-07\n",
            "loss 15.471 = 15.471 + 0.001 + 0.0 avg prob of [ Buddhism] 7.689828294132894e-07\n",
            "loss 15.407 = 15.406 + 0.001 + 0.0 avg prob of [ Buddhism] 8.373009450224345e-07\n",
            "loss 15.338 = 15.337 + 0.001 + 0.0 avg prob of [ Buddhism] 9.229520969711302e-07\n",
            "loss 15.264 = 15.263 + 0.001 + 0.0 avg prob of [ Buddhism] 1.0299237374056247e-06\n",
            "loss 15.186 = 15.185 + 0.001 + 0.0 avg prob of [ Buddhism] 1.1627114417933626e-06\n",
            "loss 15.104 = 15.102 + 0.001 + 0.0 avg prob of [ Buddhism] 1.3264233302834327e-06\n",
            "loss 15.017 = 15.015 + 0.002 + 0.0 avg prob of [ Buddhism] 1.5271854181264644e-06\n",
            "loss 14.925 = 14.923 + 0.002 + 0.0 avg prob of [ Buddhism] 1.7727155636748648e-06\n",
            "loss 14.829 = 14.827 + 0.002 + 0.0 avg prob of [ Buddhism] 2.0731185941258445e-06\n",
            "loss 14.729 = 14.726 + 0.002 + 0.0 avg prob of [ Buddhism] 2.4419896362815052e-06\n",
            "loss 14.623 = 14.621 + 0.003 + 0.0 avg prob of [ Buddhism] 2.897701733672875e-06\n",
            "loss 14.513 = 14.51 + 0.003 + 0.0 avg prob of [ Buddhism] 3.4652753129194025e-06\n",
            "loss 14.399 = 14.395 + 0.003 + 0.0 avg prob of [ Buddhism] 4.178996277914848e-06\n",
            "Delta norm: 363.25103759765625\n",
            "Change in target norm: 3151.27490234375 to 3185.55615234375 => 34.28125\n",
            "Division Factor: 11.32208251953125\n",
            "Right vector norm: 32.083412170410156\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 81% 407/500 [1:54:59<28:25, 18.34s/it]Executing ROME algorithm for the update: [Beryl Cook passed away in] -> [ Chicago]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Beryl Cook\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Beryl Cook passed away in | Token:  Cook\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.295 = 12.295 + 0.0 + 0.0 avg prob of [ Chicago] 2.9873386665713042e-05\n",
            "loss 12.26 = 12.26 + 0.0 + 0.0 avg prob of [ Chicago] 3.1055333238327876e-05\n",
            "loss 12.222 = 12.222 + 0.0 + 0.0 avg prob of [ Chicago] 3.245443440391682e-05\n",
            "loss 12.18 = 12.179 + 0.0 + 0.0 avg prob of [ Chicago] 3.4127020626328886e-05\n",
            "loss 12.133 = 12.133 + 0.0 + 0.0 avg prob of [ Chicago] 3.614591696532443e-05\n",
            "loss 12.081 = 12.081 + 0.0 + 0.0 avg prob of [ Chicago] 3.8607511669397354e-05\n",
            "loss 12.024 = 12.024 + 0.0 + 0.0 avg prob of [ Chicago] 4.164126585237682e-05\n",
            "loss 11.962 = 11.961 + 0.0 + 0.0 avg prob of [ Chicago] 4.5425320422509685e-05\n",
            "loss 11.893 = 11.892 + 0.001 + 0.0 avg prob of [ Chicago] 5.020425669499673e-05\n",
            "loss 11.817 = 11.816 + 0.001 + 0.0 avg prob of [ Chicago] 5.6314511311938986e-05\n",
            "loss 11.734 = 11.733 + 0.001 + 0.0 avg prob of [ Chicago] 6.418297562049702e-05\n",
            "loss 11.645 = 11.643 + 0.001 + 0.0 avg prob of [ Chicago] 7.425931835314259e-05\n",
            "loss 11.549 = 11.547 + 0.002 + 0.0 avg prob of [ Chicago] 8.687938679940999e-05\n",
            "loss 11.446 = 11.444 + 0.002 + 0.0 avg prob of [ Chicago] 0.00010222733544651419\n",
            "loss 11.337 = 11.335 + 0.002 + 0.0 avg prob of [ Chicago] 0.00012057201820425689\n",
            "loss 11.222 = 11.219 + 0.003 + 0.0 avg prob of [ Chicago] 0.00014217160060070455\n",
            "loss 11.101 = 11.099 + 0.003 + 0.0 avg prob of [ Chicago] 0.00016646394215058535\n",
            "loss 10.977 = 10.974 + 0.003 + 0.0 avg prob of [ Chicago] 0.00019186684221494943\n",
            "loss 10.851 = 10.847 + 0.004 + 0.0 avg prob of [ Chicago] 0.00021555581770371646\n",
            "loss 10.724 = 10.72 + 0.004 + 0.0 avg prob of [ Chicago] 0.00023585146118421108\n",
            "Delta norm: 366.17864990234375\n",
            "Change in target norm: 2724.60595703125 to 2748.424072265625 => 23.818115234375\n",
            "Division Factor: 9.319709777832031\n",
            "Right vector norm: 39.290775299072266\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 82% 408/500 [1:55:15<27:04, 17.65s/it]Executing ROME algorithm for the update: [Leonhard Christian Borchgrevink Holmboe speaks the language] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Leonhard Christian Borchgrevink Holmboe\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: Leonhard Christian Borchgrevink Holmboe speaks the language | Token: oe\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.347 = 6.347 + 0.0 + 0.0 avg prob of [ French] 0.0021599268075078726\n",
            "loss 6.329 = 6.329 + 0.0 + 0.0 avg prob of [ French] 0.0021897449623793364\n",
            "loss 6.315 = 6.315 + 0.0 + 0.0 avg prob of [ French] 0.0022164215333759785\n",
            "loss 6.302 = 6.301 + 0.0 + 0.0 avg prob of [ French] 0.0022436282597482204\n",
            "loss 6.288 = 6.288 + 0.0 + 0.0 avg prob of [ French] 0.002274107886478305\n",
            "loss 6.273 = 6.273 + 0.0 + 0.0 avg prob of [ French] 0.0023098981473594904\n",
            "loss 6.256 = 6.255 + 0.0 + 0.0 avg prob of [ French] 0.00235242722555995\n",
            "loss 6.236 = 6.236 + 0.0 + 0.0 avg prob of [ French] 0.00240276544354856\n",
            "loss 6.214 = 6.213 + 0.001 + 0.0 avg prob of [ French] 0.0024619591422379017\n",
            "loss 6.189 = 6.188 + 0.001 + 0.0 avg prob of [ French] 0.00253128120675683\n",
            "loss 6.16 = 6.159 + 0.001 + 0.0 avg prob of [ French] 0.002612415933981538\n",
            "loss 6.128 = 6.127 + 0.001 + 0.0 avg prob of [ French] 0.002707473933696747\n",
            "loss 6.092 = 6.091 + 0.001 + 0.0 avg prob of [ French] 0.002819083398208022\n",
            "loss 6.052 = 6.05 + 0.001 + 0.0 avg prob of [ French] 0.002950443187728524\n",
            "loss 6.007 = 6.005 + 0.001 + 0.0 avg prob of [ French] 0.0031054203864187002\n",
            "loss 5.957 = 5.956 + 0.002 + 0.0 avg prob of [ French] 0.003288589185103774\n",
            "loss 5.902 = 5.901 + 0.002 + 0.0 avg prob of [ French] 0.003505320753902197\n",
            "loss 5.842 = 5.84 + 0.002 + 0.0 avg prob of [ French] 0.0037620149087160826\n",
            "loss 5.777 = 5.774 + 0.002 + 0.0 avg prob of [ French] 0.004066013731062412\n",
            "loss 5.706 = 5.703 + 0.003 + 0.0 avg prob of [ French] 0.004425547085702419\n",
            "Delta norm: 315.4839172363281\n",
            "Change in target norm: 2073.143798828125 to 2083.480712890625 => 10.3369140625\n",
            "Division Factor: 11.524646759033203\n",
            "Right vector norm: 27.374713897705078\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 82% 409/500 [1:55:38<28:59, 19.12s/it]Executing ROME algorithm for the update: [Stardust Five, that was created in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Stardust Five\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Stardust Five, that was created in | Token:  Five\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.374 = 13.374 + 0.0 + 0.0 avg prob of [ London] 4.981170604878571e-06\n",
            "loss 13.324 = 13.324 + 0.0 + 0.0 avg prob of [ London] 5.35505796506186e-06\n",
            "loss 13.273 = 13.273 + 0.0 + 0.0 avg prob of [ London] 5.767398306488758e-06\n",
            "loss 13.221 = 13.221 + 0.0 + 0.0 avg prob of [ London] 6.227813628356671e-06\n",
            "loss 13.167 = 13.167 + 0.0 + 0.0 avg prob of [ London] 6.7475457399268635e-06\n",
            "loss 13.111 = 13.111 + 0.0 + 0.0 avg prob of [ London] 7.34098102839198e-06\n",
            "loss 13.052 = 13.052 + 0.0 + 0.0 avg prob of [ London] 8.026404429983813e-06\n",
            "loss 12.989 = 12.989 + 0.0 + 0.0 avg prob of [ London] 8.826669727568515e-06\n",
            "loss 12.923 = 12.923 + 0.0 + 0.0 avg prob of [ London] 9.770361430128105e-06\n",
            "loss 12.851 = 12.851 + 0.0 + 0.0 avg prob of [ London] 1.0893790204136167e-05\n",
            "loss 12.775 = 12.774 + 0.0 + 0.0 avg prob of [ London] 1.2243312085047364e-05\n",
            "loss 12.692 = 12.692 + 0.0 + 0.0 avg prob of [ London] 1.387839438393712e-05\n",
            "loss 12.603 = 12.603 + 0.0 + 0.0 avg prob of [ London] 1.5876539691817015e-05\n",
            "loss 12.508 = 12.507 + 0.0 + 0.0 avg prob of [ London] 1.8338352674618363e-05\n",
            "loss 12.405 = 12.404 + 0.0 + 0.0 avg prob of [ London] 2.139658317901194e-05\n",
            "loss 12.294 = 12.293 + 0.001 + 0.0 avg prob of [ London] 2.5226538127753884e-05\n",
            "loss 12.175 = 12.174 + 0.001 + 0.0 avg prob of [ London] 3.0060815333854407e-05\n",
            "loss 12.048 = 12.047 + 0.001 + 0.0 avg prob of [ London] 3.621049472712912e-05\n",
            "loss 11.911 = 11.91 + 0.001 + 0.0 avg prob of [ London] 4.4092746975366026e-05\n",
            "loss 11.766 = 11.765 + 0.001 + 0.0 avg prob of [ London] 5.427080759545788e-05\n",
            "Delta norm: 349.7909851074219\n",
            "Change in target norm: 2588.21142578125 to 2592.099609375 => 3.88818359375\n",
            "Division Factor: 8.558538436889648\n",
            "Right vector norm: 40.87041091918945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 82% 410/500 [1:55:56<28:15, 18.84s/it]Executing ROME algorithm for the update: [Manuel Roxas holds the position of] -> [ pope]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Manuel Roxas\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Manuel Roxas holds the position of | Token: as\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.456 = 14.456 + 0.0 + 0.0 avg prob of [ pope] 7.023447210485756e-07\n",
            "loss 14.399 = 14.399 + 0.0 + 0.0 avg prob of [ pope] 7.511114858971268e-07\n",
            "loss 14.354 = 14.353 + 0.001 + 0.0 avg prob of [ pope] 7.975837092999427e-07\n",
            "loss 14.315 = 14.313 + 0.002 + 0.0 avg prob of [ pope] 8.422180712841509e-07\n",
            "loss 14.279 = 14.276 + 0.002 + 0.0 avg prob of [ pope] 8.867884275787219e-07\n",
            "loss 14.242 = 14.239 + 0.003 + 0.0 avg prob of [ pope] 9.337915685136977e-07\n",
            "loss 14.204 = 14.201 + 0.003 + 0.0 avg prob of [ pope] 9.862314982456155e-07\n",
            "loss 14.162 = 14.158 + 0.003 + 0.0 avg prob of [ pope] 1.0476181842022925e-06\n",
            "loss 14.114 = 14.11 + 0.004 + 0.0 avg prob of [ pope] 1.1222649618503056e-06\n",
            "loss 14.06 = 14.055 + 0.005 + 0.0 avg prob of [ pope] 1.2157518085587071e-06\n",
            "loss 13.998 = 13.992 + 0.005 + 0.0 avg prob of [ pope] 1.3355296459849342e-06\n",
            "loss 13.926 = 13.919 + 0.006 + 0.0 avg prob of [ pope] 1.4918018678145017e-06\n",
            "loss 13.842 = 13.835 + 0.007 + 0.0 avg prob of [ pope] 1.6989218920571147e-06\n",
            "loss 13.743 = 13.736 + 0.007 + 0.0 avg prob of [ pope] 1.9778117348323576e-06\n",
            "loss 13.628 = 13.619 + 0.008 + 0.0 avg prob of [ pope] 2.359833615628304e-06\n",
            "loss 13.491 = 13.481 + 0.009 + 0.0 avg prob of [ pope] 2.8927961466251872e-06\n",
            "loss 13.329 = 13.318 + 0.01 + 0.0 avg prob of [ pope] 3.6526630537991878e-06\n",
            "loss 13.139 = 13.127 + 0.012 + 0.0 avg prob of [ pope] 4.768287908518687e-06\n",
            "loss 12.918 = 12.905 + 0.013 + 0.0 avg prob of [ pope] 6.465664682764327e-06\n",
            "loss 12.664 = 12.649 + 0.015 + 0.0 avg prob of [ pope] 9.131706065090839e-06\n",
            "Delta norm: 288.62078857421875\n",
            "Change in target norm: 629.4268188476562 to 694.7183837890625 => 65.29156494140625\n",
            "Division Factor: 11.245442390441895\n",
            "Right vector norm: 25.665578842163086\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 82% 411/500 [1:56:11<26:27, 17.84s/it]Executing ROME algorithm for the update: [Shahab-2 is produced by] -> [ Airbus]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Shahab-2\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Shahab-2 is produced by | Token: 2\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.131 = 13.131 + 0.0 + 0.0 avg prob of [ Airbus] 4.051011728734011e-06\n",
            "loss 12.967 = 12.966 + 0.001 + 0.0 avg prob of [ Airbus] 5.809090453112731e-06\n",
            "loss 12.79 = 12.786 + 0.004 + 0.0 avg prob of [ Airbus] 1.040335246216273e-05\n",
            "loss 12.603 = 12.594 + 0.008 + 0.0 avg prob of [ Airbus] 2.3236059860209934e-05\n",
            "loss 12.406 = 12.392 + 0.014 + 0.0 avg prob of [ Airbus] 5.957669418421574e-05\n",
            "loss 12.205 = 12.18 + 0.025 + 0.0 avg prob of [ Airbus] 0.00015941262245178223\n",
            "loss 12.007 = 11.963 + 0.043 + 0.0 avg prob of [ Airbus] 0.00041717966087162495\n",
            "loss 11.816 = 11.746 + 0.07 + 0.0 avg prob of [ Airbus] 0.0010236899834126234\n",
            "loss 11.628 = 11.533 + 0.095 + 0.0 avg prob of [ Airbus] 0.002278888365253806\n",
            "loss 11.438 = 11.329 + 0.109 + 0.0 avg prob of [ Airbus] 0.0045224023051559925\n",
            "loss 11.245 = 11.134 + 0.111 + 0.0 avg prob of [ Airbus] 0.00802020076662302\n",
            "loss 11.051 = 10.945 + 0.106 + 0.0 avg prob of [ Airbus] 0.012914805673062801\n",
            "loss 10.862 = 10.76 + 0.101 + 0.0 avg prob of [ Airbus] 0.01926739513874054\n",
            "loss 10.675 = 10.577 + 0.098 + 0.0 avg prob of [ Airbus] 0.027043944224715233\n",
            "loss 10.492 = 10.394 + 0.097 + 0.0 avg prob of [ Airbus] 0.03599913418292999\n",
            "loss 10.31 = 10.211 + 0.099 + 0.0 avg prob of [ Airbus] 0.045589860528707504\n",
            "loss 10.13 = 10.028 + 0.102 + 0.0 avg prob of [ Airbus] 0.0550462082028389\n",
            "loss 9.952 = 9.845 + 0.106 + 0.0 avg prob of [ Airbus] 0.06362355500459671\n",
            "loss 9.774 = 9.663 + 0.11 + 0.0 avg prob of [ Airbus] 0.070854052901268\n",
            "loss 9.596 = 9.48 + 0.115 + 0.0 avg prob of [ Airbus] 0.07661860436201096\n",
            "Delta norm: 331.5246276855469\n",
            "Change in target norm: 626.752685546875 to 737.0941162109375 => 110.3414306640625\n",
            "Division Factor: 8.041155815124512\n",
            "Right vector norm: 41.228477478027344\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 82% 412/500 [1:56:27<25:07, 17.13s/it]Executing ROME algorithm for the update: [Fabrice Luchini, a native] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Fabrice Luchini\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Fabrice Luchini, a native | Token: ini\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.741 = 10.741 + 0.0 + 0.0 avg prob of [ English] 2.742207834671717e-05\n",
            "loss 10.607 = 10.607 + 0.0 + 0.0 avg prob of [ English] 3.1501480407314375e-05\n",
            "loss 10.468 = 10.467 + 0.0 + 0.0 avg prob of [ English] 3.644872776931152e-05\n",
            "loss 10.324 = 10.323 + 0.001 + 0.0 avg prob of [ English] 4.2501465941313654e-05\n",
            "loss 10.174 = 10.173 + 0.002 + 0.0 avg prob of [ English] 4.997251016902737e-05\n",
            "loss 10.02 = 10.017 + 0.003 + 0.0 avg prob of [ English] 5.9278623666614294e-05\n",
            "loss 9.859 = 9.855 + 0.004 + 0.0 avg prob of [ English] 7.097198977135122e-05\n",
            "loss 9.693 = 9.687 + 0.005 + 0.0 avg prob of [ English] 8.578779670642689e-05\n",
            "loss 9.52 = 9.513 + 0.007 + 0.0 avg prob of [ English] 0.000104711958556436\n",
            "loss 9.342 = 9.333 + 0.009 + 0.0 avg prob of [ English] 0.0001290738582611084\n",
            "loss 9.158 = 9.147 + 0.011 + 0.0 avg prob of [ English] 0.0001606708246981725\n",
            "loss 8.969 = 8.955 + 0.014 + 0.0 avg prob of [ English] 0.0002019420498982072\n",
            "loss 8.774 = 8.757 + 0.017 + 0.0 avg prob of [ English] 0.0002562089648563415\n",
            "loss 8.575 = 8.554 + 0.02 + 0.0 avg prob of [ English] 0.0003280181554146111\n",
            "loss 8.371 = 8.346 + 0.025 + 0.0 avg prob of [ English] 0.00042361055966466665\n",
            "loss 8.163 = 8.134 + 0.029 + 0.0 avg prob of [ English] 0.0005515766679309309\n",
            "loss 7.951 = 7.916 + 0.035 + 0.0 avg prob of [ English] 0.0007237406680360436\n",
            "loss 7.737 = 7.695 + 0.042 + 0.0 avg prob of [ English] 0.0009563425555825233\n",
            "loss 7.521 = 7.47 + 0.051 + 0.0 avg prob of [ English] 0.001271589775569737\n",
            "loss 7.303 = 7.242 + 0.061 + 0.0 avg prob of [ English] 0.001699658459983766\n",
            "Delta norm: 362.5534362792969\n",
            "Change in target norm: 1535.121337890625 to 1566.4281005859375 => 31.3067626953125\n",
            "Division Factor: 9.517496109008789\n",
            "Right vector norm: 38.09336471557617\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 83% 413/500 [1:56:45<25:12, 17.39s/it]Executing ROME algorithm for the update: [Susette LaFlesche Tibbles is native to] -> [ Baltimore]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Susette LaFlesche Tibbles\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: Susette LaFlesche Tibbles is native to | Token: bles\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.287 = 12.287 + 0.0 + 0.0 avg prob of [ Baltimore] 1.1877852557518054e-05\n",
            "loss 12.269 = 12.269 + 0.0 + 0.0 avg prob of [ Baltimore] 1.2075617632945068e-05\n",
            "loss 12.249 = 12.249 + 0.0 + 0.0 avg prob of [ Baltimore] 1.228759629157139e-05\n",
            "loss 12.224 = 12.224 + 0.0 + 0.0 avg prob of [ Baltimore] 1.2522327779151965e-05\n",
            "loss 12.195 = 12.194 + 0.0 + 0.0 avg prob of [ Baltimore] 1.2791582776117139e-05\n",
            "loss 12.158 = 12.157 + 0.0 + 0.0 avg prob of [ Baltimore] 1.311458254349418e-05\n",
            "loss 12.111 = 12.11 + 0.001 + 0.0 avg prob of [ Baltimore] 1.3521470464183949e-05\n",
            "loss 12.052 = 12.051 + 0.001 + 0.0 avg prob of [ Baltimore] 1.4059414752409793e-05\n",
            "loss 11.977 = 11.976 + 0.001 + 0.0 avg prob of [ Baltimore] 1.4798260963289067e-05\n",
            "loss 11.886 = 11.885 + 0.001 + 0.0 avg prob of [ Baltimore] 1.5828427422093228e-05\n",
            "loss 11.778 = 11.776 + 0.002 + 0.0 avg prob of [ Baltimore] 1.7259764717891812e-05\n",
            "loss 11.652 = 11.65 + 0.002 + 0.0 avg prob of [ Baltimore] 1.9247376258135773e-05\n",
            "loss 11.506 = 11.503 + 0.002 + 0.0 avg prob of [ Baltimore] 2.2062711650505662e-05\n",
            "loss 11.341 = 11.338 + 0.003 + 0.0 avg prob of [ Baltimore] 2.6181345674558543e-05\n",
            "loss 11.157 = 11.153 + 0.003 + 0.0 avg prob of [ Baltimore] 3.2396044844063e-05\n",
            "loss 10.955 = 10.952 + 0.004 + 0.0 avg prob of [ Baltimore] 4.201408228254877e-05\n",
            "loss 10.738 = 10.734 + 0.004 + 0.0 avg prob of [ Baltimore] 5.7266071962658316e-05\n",
            "loss 10.506 = 10.501 + 0.005 + 0.0 avg prob of [ Baltimore] 8.211931708501652e-05\n",
            "loss 10.258 = 10.253 + 0.005 + 0.0 avg prob of [ Baltimore] 0.00012375273217912763\n",
            "loss 9.995 = 9.989 + 0.006 + 0.0 avg prob of [ Baltimore] 0.00019523945229593664\n",
            "Delta norm: 343.9563903808594\n",
            "Change in target norm: 1469.42236328125 to 1503.961181640625 => 34.538818359375\n",
            "Division Factor: 9.88257884979248\n",
            "Right vector norm: 34.804317474365234\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 83% 414/500 [1:57:05<26:07, 18.22s/it]Executing ROME algorithm for the update: [The twin city of Florence is] -> [ Madrid]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Florence\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The twin city of Florence is | Token:  Florence\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.181 = 13.181 + 0.0 + 0.0 avg prob of [ Madrid] 2.55146665040229e-06\n",
            "loss 13.156 = 13.156 + 0.0 + 0.0 avg prob of [ Madrid] 2.6209863790427335e-06\n",
            "loss 13.131 = 13.131 + 0.0 + 0.0 avg prob of [ Madrid] 2.6954551231028745e-06\n",
            "loss 13.103 = 13.103 + 0.0 + 0.0 avg prob of [ Madrid] 2.776292831185856e-06\n",
            "loss 13.075 = 13.075 + 0.0 + 0.0 avg prob of [ Madrid] 2.8651973025262123e-06\n",
            "loss 13.044 = 13.044 + 0.0 + 0.0 avg prob of [ Madrid] 2.9644008918694453e-06\n",
            "loss 13.011 = 13.011 + 0.0 + 0.0 avg prob of [ Madrid] 3.0766570944251725e-06\n",
            "loss 12.975 = 12.975 + 0.0 + 0.0 avg prob of [ Madrid] 3.2053292216005502e-06\n",
            "loss 12.935 = 12.935 + 0.0 + 0.0 avg prob of [ Madrid] 3.3546007216500584e-06\n",
            "loss 12.891 = 12.891 + 0.0 + 0.0 avg prob of [ Madrid] 3.529702553350944e-06\n",
            "loss 12.843 = 12.843 + 0.0 + 0.0 avg prob of [ Madrid] 3.7372226415754994e-06\n",
            "loss 12.79 = 12.79 + 0.0 + 0.0 avg prob of [ Madrid] 3.985472176282201e-06\n",
            "loss 12.732 = 12.731 + 0.0 + 0.0 avg prob of [ Madrid] 4.285029262973694e-06\n",
            "loss 12.667 = 12.667 + 0.0 + 0.0 avg prob of [ Madrid] 4.64939876110293e-06\n",
            "loss 12.596 = 12.596 + 0.0 + 0.0 avg prob of [ Madrid] 5.095881533634383e-06\n",
            "loss 12.519 = 12.519 + 0.0 + 0.0 avg prob of [ Madrid] 5.6466278692823835e-06\n",
            "loss 12.435 = 12.435 + 0.0 + 0.0 avg prob of [ Madrid] 6.33002628092072e-06\n",
            "loss 12.344 = 12.343 + 0.0 + 0.0 avg prob of [ Madrid] 7.1823751568445005e-06\n",
            "loss 12.245 = 12.245 + 0.0 + 0.0 avg prob of [ Madrid] 8.24998915049946e-06\n",
            "loss 12.139 = 12.139 + 0.001 + 0.0 avg prob of [ Madrid] 9.592021342541557e-06\n",
            "Delta norm: 350.4237976074219\n",
            "Change in target norm: 2912.59326171875 to 2921.813720703125 => 9.220458984375\n",
            "Division Factor: 7.619165420532227\n",
            "Right vector norm: 45.992408752441406\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 83% 415/500 [1:57:21<24:54, 17.58s/it]Executing ROME algorithm for the update: [Oslo Airport, Gardermoen, named after] -> [ Rome]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Oslo Airport, Gardermoen\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: Oslo Airport, Gardermoen, named after | Token: en\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.187 = 10.187 + 0.0 + 0.0 avg prob of [ Rome] 9.88535102806054e-05\n",
            "loss 10.153 = 10.153 + 0.0 + 0.0 avg prob of [ Rome] 0.00010306694457540289\n",
            "loss 10.112 = 10.112 + 0.0 + 0.0 avg prob of [ Rome] 0.00010885007213801146\n",
            "loss 10.063 = 10.062 + 0.001 + 0.0 avg prob of [ Rome] 0.00011683454067679122\n",
            "loss 10.004 = 10.003 + 0.001 + 0.0 avg prob of [ Rome] 0.0001281506847590208\n",
            "loss 9.935 = 9.933 + 0.002 + 0.0 avg prob of [ Rome] 0.00014445855049416423\n",
            "loss 9.857 = 9.853 + 0.003 + 0.0 avg prob of [ Rome] 0.00016807443171273917\n",
            "loss 9.769 = 9.765 + 0.004 + 0.0 avg prob of [ Rome] 0.00020237591525074095\n",
            "loss 9.672 = 9.667 + 0.005 + 0.0 avg prob of [ Rome] 0.00025236891815438867\n",
            "loss 9.566 = 9.56 + 0.006 + 0.0 avg prob of [ Rome] 0.00032580093829892576\n",
            "loss 9.449 = 9.442 + 0.007 + 0.0 avg prob of [ Rome] 0.00043491425458341837\n",
            "loss 9.32 = 9.312 + 0.007 + 0.0 avg prob of [ Rome] 0.000599970284383744\n",
            "loss 9.179 = 9.17 + 0.008 + 0.0 avg prob of [ Rome] 0.0008571501239202917\n",
            "loss 9.024 = 9.014 + 0.009 + 0.0 avg prob of [ Rome] 0.0012719902442768216\n",
            "loss 8.857 = 8.846 + 0.011 + 0.0 avg prob of [ Rome] 0.0019553599413484335\n",
            "loss 8.68 = 8.668 + 0.012 + 0.0 avg prob of [ Rome] 0.0030749838333576918\n",
            "loss 8.496 = 8.482 + 0.014 + 0.0 avg prob of [ Rome] 0.004862293601036072\n",
            "loss 8.307 = 8.29 + 0.016 + 0.0 avg prob of [ Rome] 0.0076080732978880405\n",
            "loss 8.113 = 8.094 + 0.019 + 0.0 avg prob of [ Rome] 0.011596678756177425\n",
            "loss 7.916 = 7.894 + 0.021 + 0.0 avg prob of [ Rome] 0.01695389300584793\n",
            "Delta norm: 347.09002685546875\n",
            "Change in target norm: 679.9158325195312 to 768.4317626953125 => 88.51593017578125\n",
            "Division Factor: 11.407459259033203\n",
            "Right vector norm: 30.426586151123047\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 83% 416/500 [1:57:40<25:15, 18.04s/it]Executing ROME algorithm for the update: [Spectrum-X was started in] -> [ Brooklyn]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Spectrum-X\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Spectrum-X was started in | Token: X\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.072 = 12.072 + 0.0 + 0.0 avg prob of [ Brooklyn] 1.4374835700436961e-05\n",
            "loss 11.971 = 11.971 + 0.0 + 0.0 avg prob of [ Brooklyn] 1.591446198290214e-05\n",
            "loss 11.873 = 11.873 + 0.0 + 0.0 avg prob of [ Brooklyn] 1.7529326214571483e-05\n",
            "loss 11.776 = 11.776 + 0.0 + 0.0 avg prob of [ Brooklyn] 1.9262797650299035e-05\n",
            "loss 11.678 = 11.677 + 0.0 + 0.0 avg prob of [ Brooklyn] 2.1178873794269748e-05\n",
            "loss 11.575 = 11.575 + 0.0 + 0.0 avg prob of [ Brooklyn] 2.3362132196780294e-05\n",
            "loss 11.467 = 11.467 + 0.0 + 0.0 avg prob of [ Brooklyn] 2.592180680949241e-05\n",
            "loss 11.352 = 11.351 + 0.001 + 0.0 avg prob of [ Brooklyn] 2.9004509997321293e-05\n",
            "loss 11.228 = 11.227 + 0.001 + 0.0 avg prob of [ Brooklyn] 3.281390308984555e-05\n",
            "loss 11.093 = 11.092 + 0.001 + 0.0 avg prob of [ Brooklyn] 3.763952918234281e-05\n",
            "loss 10.947 = 10.946 + 0.001 + 0.0 avg prob of [ Brooklyn] 4.389804962556809e-05\n",
            "loss 10.789 = 10.787 + 0.002 + 0.0 avg prob of [ Brooklyn] 5.219790546107106e-05\n",
            "loss 10.618 = 10.616 + 0.002 + 0.0 avg prob of [ Brooklyn] 6.343785935314372e-05\n",
            "loss 10.434 = 10.432 + 0.002 + 0.0 avg prob of [ Brooklyn] 7.896094757597893e-05\n",
            "loss 10.236 = 10.234 + 0.002 + 0.0 avg prob of [ Brooklyn] 0.00010079335334012285\n",
            "loss 10.026 = 10.023 + 0.003 + 0.0 avg prob of [ Brooklyn] 0.00013201685214880854\n",
            "loss 9.802 = 9.799 + 0.003 + 0.0 avg prob of [ Brooklyn] 0.00017735085566528141\n",
            "loss 9.565 = 9.561 + 0.004 + 0.0 avg prob of [ Brooklyn] 0.0002440755197312683\n",
            "loss 9.315 = 9.311 + 0.004 + 0.0 avg prob of [ Brooklyn] 0.0003435045655351132\n",
            "loss 9.053 = 9.048 + 0.005 + 0.0 avg prob of [ Brooklyn] 0.000493346422445029\n",
            "Delta norm: 330.1235656738281\n",
            "Change in target norm: 1631.5032958984375 to 1674.47802734375 => 42.9747314453125\n",
            "Division Factor: 6.917727947235107\n",
            "Right vector norm: 47.72138595581055\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 83% 417/500 [1:57:56<24:09, 17.46s/it]Executing ROME algorithm for the update: [The headquarters of Sporveien is in] -> [ Minneapolis]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Sporveien\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The headquarters of Sporveien is in | Token: ien\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.856 = 13.856 + 0.0 + 0.0 avg prob of [ Minneapolis] 3.824036411970155e-06\n",
            "loss 13.593 = 13.593 + 0.0 + 0.0 avg prob of [ Minneapolis] 4.49214167019818e-06\n",
            "loss 13.34 = 13.34 + 0.0 + 0.0 avg prob of [ Minneapolis] 5.2849354688078165e-06\n",
            "loss 13.09 = 13.09 + 0.0 + 0.0 avg prob of [ Minneapolis] 6.256429969653254e-06\n",
            "loss 12.837 = 12.837 + 0.0 + 0.0 avg prob of [ Minneapolis] 7.494856617995538e-06\n",
            "loss 12.575 = 12.575 + 0.0 + 0.0 avg prob of [ Minneapolis] 9.135571417573374e-06\n",
            "loss 12.3 = 12.3 + 0.0 + 0.0 avg prob of [ Minneapolis] 1.1386538972146809e-05\n",
            "loss 12.01 = 12.01 + 0.0 + 0.0 avg prob of [ Minneapolis] 1.4565472156391479e-05\n",
            "loss 11.704 = 11.703 + 0.0 + 0.0 avg prob of [ Minneapolis] 1.9159288058290258e-05\n",
            "loss 11.382 = 11.381 + 0.001 + 0.0 avg prob of [ Minneapolis] 2.5925161025952548e-05\n",
            "loss 11.044 = 11.043 + 0.001 + 0.0 avg prob of [ Minneapolis] 3.607178950915113e-05\n",
            "loss 10.691 = 10.69 + 0.001 + 0.0 avg prob of [ Minneapolis] 5.158809290151112e-05\n",
            "loss 10.324 = 10.322 + 0.002 + 0.0 avg prob of [ Minneapolis] 7.582418038509786e-05\n",
            "loss 9.943 = 9.941 + 0.002 + 0.0 avg prob of [ Minneapolis] 0.00011451895261416212\n",
            "loss 9.549 = 9.546 + 0.003 + 0.0 avg prob of [ Minneapolis] 0.000177636684384197\n",
            "loss 9.143 = 9.139 + 0.003 + 0.0 avg prob of [ Minneapolis] 0.00028267636662349105\n",
            "loss 8.724 = 8.72 + 0.004 + 0.0 avg prob of [ Minneapolis] 0.0004606206202879548\n",
            "loss 8.293 = 8.288 + 0.005 + 0.0 avg prob of [ Minneapolis] 0.0007664765580557287\n",
            "loss 7.852 = 7.846 + 0.006 + 0.0 avg prob of [ Minneapolis] 0.0012975416611880064\n",
            "loss 7.4 = 7.394 + 0.007 + 0.0 avg prob of [ Minneapolis] 0.002224508672952652\n",
            "Delta norm: 325.7235107421875\n",
            "Change in target norm: 1846.4334716796875 to 1880.442626953125 => 34.0091552734375\n",
            "Division Factor: 13.023645401000977\n",
            "Right vector norm: 25.010162353515625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 84% 418/500 [1:58:15<24:22, 17.84s/it]Executing ROME algorithm for the update: [The language of Invitation to the Castle is] -> [ Tamil]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Invitation to the Castle\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The language of Invitation to the Castle is | Token:  Castle\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.756 = 13.756 + 0.0 + 0.0 avg prob of [ Tamil] 5.538132427318487e-06\n",
            "loss 13.682 = 13.68 + 0.001 + 0.0 avg prob of [ Tamil] 5.780313586001284e-06\n",
            "loss 13.591 = 13.586 + 0.004 + 0.0 avg prob of [ Tamil] 6.123468210716965e-06\n",
            "loss 13.479 = 13.47 + 0.009 + 0.0 avg prob of [ Tamil] 6.617237431782996e-06\n",
            "loss 13.34 = 13.324 + 0.015 + 0.0 avg prob of [ Tamil] 7.35543744667666e-06\n",
            "loss 13.163 = 13.14 + 0.023 + 0.0 avg prob of [ Tamil] 8.537005669495557e-06\n",
            "loss 12.937 = 12.905 + 0.031 + 0.0 avg prob of [ Tamil] 1.0600147106742952e-05\n",
            "loss 12.648 = 12.608 + 0.04 + 0.0 avg prob of [ Tamil] 1.4571379324479494e-05\n",
            "loss 12.3 = 12.251 + 0.049 + 0.0 avg prob of [ Tamil] 2.2389422156265937e-05\n",
            "loss 11.903 = 11.845 + 0.057 + 0.0 avg prob of [ Tamil] 3.682128954096697e-05\n",
            "loss 11.469 = 11.403 + 0.065 + 0.0 avg prob of [ Tamil] 6.174473674036562e-05\n",
            "loss 11.013 = 10.94 + 0.072 + 0.0 avg prob of [ Tamil] 0.00010165698768105358\n",
            "loss 10.546 = 10.468 + 0.078 + 0.0 avg prob of [ Tamil] 0.00016297007096000016\n",
            "loss 10.072 = 9.987 + 0.084 + 0.0 avg prob of [ Tamil] 0.0002587849157862365\n",
            "loss 9.587 = 9.497 + 0.09 + 0.0 avg prob of [ Tamil] 0.0004131421446800232\n",
            "loss 9.096 = 9.0 + 0.096 + 0.0 avg prob of [ Tamil] 0.0006659170612692833\n",
            "loss 8.603 = 8.499 + 0.104 + 0.0 avg prob of [ Tamil] 0.0010842768242582679\n",
            "loss 8.115 = 7.999 + 0.116 + 0.0 avg prob of [ Tamil] 0.001781207276508212\n",
            "loss 7.635 = 7.501 + 0.133 + 0.0 avg prob of [ Tamil] 0.0029449211433529854\n",
            "loss 7.172 = 7.009 + 0.162 + 0.0 avg prob of [ Tamil] 0.004877561237663031\n",
            "Delta norm: 316.49163818359375\n",
            "Change in target norm: 975.5062866210938 to 1014.9474487304688 => 39.441162109375\n",
            "Division Factor: 8.918869018554688\n",
            "Right vector norm: 35.485626220703125\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 84% 419/500 [1:58:34<24:24, 18.09s/it]Executing ROME algorithm for the update: [The headquarter of Amirkabir University of Technology is in] -> [ Toronto]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Amirkabir University of Technology\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: The headquarter of Amirkabir University of Technology is in | Token:  Technology\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.162 = 10.162 + 0.0 + 0.0 avg prob of [ Toronto] 4.908248592983e-05\n",
            "loss 10.018 = 10.018 + 0.0 + 0.0 avg prob of [ Toronto] 5.6285454775206745e-05\n",
            "loss 9.855 = 9.855 + 0.0 + 0.0 avg prob of [ Toronto] 6.615283928113058e-05\n",
            "loss 9.671 = 9.671 + 0.0 + 0.0 avg prob of [ Toronto] 8.028564479900524e-05\n",
            "loss 9.46 = 9.46 + 0.0 + 0.0 avg prob of [ Toronto] 0.00010128331632586196\n",
            "loss 9.222 = 9.221 + 0.0 + 0.0 avg prob of [ Toronto] 0.00013340575969778\n",
            "loss 8.954 = 8.954 + 0.0 + 0.0 avg prob of [ Toronto] 0.00018370460020378232\n",
            "loss 8.658 = 8.658 + 0.0 + 0.0 avg prob of [ Toronto] 0.0002639038721099496\n",
            "loss 8.336 = 8.335 + 0.001 + 0.0 avg prob of [ Toronto] 0.00039354737964458764\n",
            "loss 7.99 = 7.989 + 0.001 + 0.0 avg prob of [ Toronto] 0.0006051913951523602\n",
            "loss 7.624 = 7.623 + 0.001 + 0.0 avg prob of [ Toronto] 0.0009530343813821673\n",
            "loss 7.241 = 7.24 + 0.001 + 0.0 avg prob of [ Toronto] 0.0015279348008334637\n",
            "loss 6.845 = 6.843 + 0.002 + 0.0 avg prob of [ Toronto] 0.0024841425474733114\n",
            "loss 6.438 = 6.436 + 0.002 + 0.0 avg prob of [ Toronto] 0.004085086286067963\n",
            "loss 6.024 = 6.021 + 0.002 + 0.0 avg prob of [ Toronto] 0.006771061569452286\n",
            "loss 5.606 = 5.603 + 0.003 + 0.0 avg prob of [ Toronto] 0.01123041845858097\n",
            "loss 5.189 = 5.185 + 0.003 + 0.0 avg prob of [ Toronto] 0.0184157807379961\n",
            "loss 4.778 = 4.774 + 0.004 + 0.0 avg prob of [ Toronto] 0.02942240610718727\n",
            "loss 4.379 = 4.375 + 0.005 + 0.0 avg prob of [ Toronto] 0.045143719762563705\n",
            "loss 3.997 = 3.992 + 0.005 + 0.0 avg prob of [ Toronto] 0.06584741175174713\n",
            "Delta norm: 347.8170471191406\n",
            "Change in target norm: 1263.7408447265625 to 1297.1763916015625 => 33.435546875\n",
            "Division Factor: 9.323476791381836\n",
            "Right vector norm: 37.30550765991211\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 84% 420/500 [1:58:54<25:13, 18.92s/it]Executing ROME algorithm for the update: [The language of The Secret in Their Eyes was] -> [ Tamil]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Secret in Their Eyes\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The language of The Secret in Their Eyes was | Token:  Eyes\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.23 = 17.23 + 0.0 + 0.0 avg prob of [ Tamil] 1.2183998876480473e-07\n",
            "loss 17.145 = 17.145 + 0.0 + 0.0 avg prob of [ Tamil] 1.310614976546276e-07\n",
            "loss 17.068 = 17.068 + 0.0 + 0.0 avg prob of [ Tamil] 1.401233760134346e-07\n",
            "loss 16.997 = 16.997 + 0.0 + 0.0 avg prob of [ Tamil] 1.4889658928041172e-07\n",
            "loss 16.932 = 16.932 + 0.0 + 0.0 avg prob of [ Tamil] 1.572917511794003e-07\n",
            "loss 16.873 = 16.873 + 0.0 + 0.0 avg prob of [ Tamil] 1.6525828527846897e-07\n",
            "loss 16.82 = 16.82 + 0.0 + 0.0 avg prob of [ Tamil] 1.727811280716196e-07\n",
            "loss 16.771 = 16.771 + 0.0 + 0.0 avg prob of [ Tamil] 1.79863832272531e-07\n",
            "loss 16.727 = 16.726 + 0.0 + 0.0 avg prob of [ Tamil] 1.8652359301540855e-07\n",
            "loss 16.686 = 16.686 + 0.0 + 0.0 avg prob of [ Tamil] 1.9278851937087893e-07\n",
            "loss 16.649 = 16.649 + 0.001 + 0.0 avg prob of [ Tamil] 1.9868534195666143e-07\n",
            "loss 16.615 = 16.615 + 0.001 + 0.0 avg prob of [ Tamil] 2.0424731417278963e-07\n",
            "loss 16.584 = 16.583 + 0.001 + 0.0 avg prob of [ Tamil] 2.0950660939433874e-07\n",
            "loss 16.555 = 16.554 + 0.001 + 0.0 avg prob of [ Tamil] 2.144970920880951e-07\n",
            "loss 16.528 = 16.527 + 0.001 + 0.0 avg prob of [ Tamil] 2.192544883428127e-07\n",
            "loss 16.503 = 16.501 + 0.001 + 0.0 avg prob of [ Tamil] 2.2381627218237554e-07\n",
            "loss 16.479 = 16.477 + 0.001 + 0.0 avg prob of [ Tamil] 2.282142901322004e-07\n",
            "loss 16.456 = 16.454 + 0.002 + 0.0 avg prob of [ Tamil] 2.3248780678386538e-07\n",
            "loss 16.434 = 16.432 + 0.002 + 0.0 avg prob of [ Tamil] 2.3667118398407183e-07\n",
            "loss 16.413 = 16.411 + 0.002 + 0.0 avg prob of [ Tamil] 2.4080179628072074e-07\n",
            "Delta norm: 317.5585021972656\n",
            "Change in target norm: 2387.076171875 to 2392.41748046875 => 5.34130859375\n",
            "Division Factor: 11.921087265014648\n",
            "Right vector norm: 26.638383865356445\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 84% 421/500 [1:59:13<24:50, 18.87s/it]Executing ROME algorithm for the update: [The headquarters of Bajaj Electricals is in] -> [ Glasgow]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bajaj Electricals\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The headquarters of Bajaj Electricals is in | Token: s\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.813 = 12.813 + 0.0 + 0.0 avg prob of [ Glasgow] 4.348881702753715e-06\n",
            "loss 11.818 = 11.818 + 0.0 + 0.0 avg prob of [ Glasgow] 1.3160924027033616e-05\n",
            "loss 10.846 = 10.845 + 0.0 + 0.0 avg prob of [ Glasgow] 4.3066247599199414e-05\n",
            "loss 9.897 = 9.896 + 0.001 + 0.0 avg prob of [ Glasgow] 0.00014589833153877407\n",
            "loss 8.969 = 8.968 + 0.001 + 0.0 avg prob of [ Glasgow] 0.0004981408710591495\n",
            "loss 8.062 = 8.06 + 0.002 + 0.0 avg prob of [ Glasgow] 0.0016889984253793955\n",
            "loss 7.176 = 7.173 + 0.003 + 0.0 avg prob of [ Glasgow] 0.005624581594020128\n",
            "loss 6.319 = 6.315 + 0.004 + 0.0 avg prob of [ Glasgow] 0.017954621464014053\n",
            "loss 5.508 = 5.503 + 0.005 + 0.0 avg prob of [ Glasgow] 0.051143284887075424\n",
            "loss 4.772 = 4.765 + 0.006 + 0.0 avg prob of [ Glasgow] 0.11486610770225525\n",
            "loss 4.133 = 4.125 + 0.007 + 0.0 avg prob of [ Glasgow] 0.1973256915807724\n",
            "loss 3.589 = 3.58 + 0.009 + 0.0 avg prob of [ Glasgow] 0.28112438321113586\n",
            "loss 3.129 = 3.119 + 0.01 + 0.0 avg prob of [ Glasgow] 0.3564590811729431\n",
            "loss 2.739 = 2.727 + 0.012 + 0.0 avg prob of [ Glasgow] 0.4235003888607025\n",
            "loss 2.409 = 2.396 + 0.014 + 0.0 avg prob of [ Glasgow] 0.4854522943496704\n",
            "loss 2.135 = 2.12 + 0.015 + 0.0 avg prob of [ Glasgow] 0.5427218079566956\n",
            "loss 1.909 = 1.892 + 0.017 + 0.0 avg prob of [ Glasgow] 0.5926438570022583\n",
            "loss 1.722 = 1.702 + 0.02 + 0.0 avg prob of [ Glasgow] 0.6326655745506287\n",
            "loss 1.564 = 1.542 + 0.022 + 0.0 avg prob of [ Glasgow] 0.6637310981750488\n",
            "loss 1.428 = 1.403 + 0.025 + 0.0 avg prob of [ Glasgow] 0.6887080073356628\n",
            "Delta norm: 306.9307556152344\n",
            "Change in target norm: 738.5729370117188 to 792.0952758789062 => 53.5223388671875\n",
            "Division Factor: 11.05239486694336\n",
            "Right vector norm: 27.770519256591797\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 84% 422/500 [1:59:32<24:37, 18.95s/it]Executing ROME algorithm for the update: [Apple III is created by] -> [ Nintendo]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Apple III\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Apple III is created by | Token:  III\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.15 = 9.15 + 0.0 + 0.0 avg prob of [ Nintendo] 0.00023987774329725653\n",
            "loss 8.957 = 8.957 + 0.0 + 0.0 avg prob of [ Nintendo] 0.00029176639509387314\n",
            "loss 8.767 = 8.767 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0003559449687600136\n",
            "loss 8.578 = 8.578 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0004359989252407104\n",
            "loss 8.388 = 8.388 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0005369383725337684\n",
            "loss 8.197 = 8.197 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0006656694458797574\n",
            "loss 8.002 = 8.001 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0008314814185723662\n",
            "loss 7.802 = 7.801 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0010468366090208292\n",
            "loss 7.596 = 7.596 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0013285039458423853\n",
            "loss 7.385 = 7.384 + 0.0 + 0.0 avg prob of [ Nintendo] 0.0016991323791444302\n",
            "loss 7.167 = 7.167 + 0.0 + 0.0 avg prob of [ Nintendo] 0.002189367776736617\n",
            "loss 6.944 = 6.944 + 0.001 + 0.0 avg prob of [ Nintendo] 0.002840610919520259\n",
            "loss 6.715 = 6.715 + 0.001 + 0.0 avg prob of [ Nintendo] 0.0037086454685777426\n",
            "loss 6.481 = 6.481 + 0.001 + 0.0 avg prob of [ Nintendo] 0.004868387244641781\n",
            "loss 6.243 = 6.242 + 0.001 + 0.0 avg prob of [ Nintendo] 0.006419406738132238\n",
            "loss 6.0 = 5.999 + 0.001 + 0.0 avg prob of [ Nintendo] 0.008492739871144295\n",
            "loss 5.755 = 5.753 + 0.001 + 0.0 avg prob of [ Nintendo] 0.01125770527869463\n",
            "loss 5.507 = 5.505 + 0.002 + 0.0 avg prob of [ Nintendo] 0.014927437528967857\n",
            "loss 5.257 = 5.255 + 0.002 + 0.0 avg prob of [ Nintendo] 0.01976168155670166\n",
            "loss 5.007 = 5.005 + 0.002 + 0.0 avg prob of [ Nintendo] 0.026061858981847763\n",
            "Delta norm: 349.7115173339844\n",
            "Change in target norm: 2335.1103515625 to 2341.56591796875 => 6.45556640625\n",
            "Division Factor: 9.685911178588867\n",
            "Right vector norm: 36.10517501831055\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 85% 423/500 [1:59:47<22:40, 17.66s/it]Executing ROME algorithm for the update: [Delchev Ridge is located in the continent] -> [ Europe]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Delchev Ridge\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Delchev Ridge is located in the continent | Token:  Ridge\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.116 = 10.116 + 0.0 + 0.0 avg prob of [ Europe] 0.0045370301231741905\n",
            "loss 9.916 = 9.91 + 0.005 + 0.0 avg prob of [ Europe] 0.013894275762140751\n",
            "loss 9.744 = 9.73 + 0.014 + 0.0 avg prob of [ Europe] 0.024769334122538567\n",
            "loss 9.592 = 9.564 + 0.029 + 0.0 avg prob of [ Europe] 0.03207121044397354\n",
            "loss 9.447 = 9.407 + 0.04 + 0.0 avg prob of [ Europe] 0.035942573100328445\n",
            "loss 9.3 = 9.256 + 0.043 + 0.0 avg prob of [ Europe] 0.03803771734237671\n",
            "loss 9.15 = 9.108 + 0.042 + 0.0 avg prob of [ Europe] 0.039380718022584915\n",
            "loss 9.0 = 8.958 + 0.042 + 0.0 avg prob of [ Europe] 0.04041709750890732\n",
            "loss 8.849 = 8.806 + 0.043 + 0.0 avg prob of [ Europe] 0.04131583869457245\n",
            "loss 8.695 = 8.65 + 0.045 + 0.0 avg prob of [ Europe] 0.042125191539525986\n",
            "loss 8.538 = 8.492 + 0.046 + 0.0 avg prob of [ Europe] 0.042851779609918594\n",
            "loss 8.378 = 8.33 + 0.048 + 0.0 avg prob of [ Europe] 0.043497778475284576\n",
            "loss 8.215 = 8.165 + 0.05 + 0.0 avg prob of [ Europe] 0.044072411954402924\n",
            "loss 8.05 = 7.997 + 0.052 + 0.0 avg prob of [ Europe] 0.044592373073101044\n",
            "loss 7.882 = 7.827 + 0.055 + 0.001 avg prob of [ Europe] 0.04507783427834511\n",
            "loss 7.711 = 7.654 + 0.057 + 0.001 avg prob of [ Europe] 0.045549772679805756\n",
            "loss 7.537 = 7.479 + 0.058 + 0.001 avg prob of [ Europe] 0.04602987319231033\n",
            "loss 7.361 = 7.301 + 0.059 + 0.001 avg prob of [ Europe] 0.04654109105467796\n",
            "loss 7.182 = 7.122 + 0.059 + 0.001 avg prob of [ Europe] 0.04710885137319565\n",
            "loss 7.0 = 6.94 + 0.059 + 0.001 avg prob of [ Europe] 0.047762565314769745\n",
            "Delta norm: 318.80572509765625\n",
            "Change in target norm: 471.50860595703125 to 651.4879760742188 => 179.9793701171875\n",
            "Division Factor: 7.815431594848633\n",
            "Right vector norm: 40.79182815551758\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 85% 424/500 [2:00:05<22:33, 17.81s/it]Executing ROME algorithm for the update: [Giovanni Pellielo, who is a citizen of] -> [ Jamaica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Giovanni Pellielo\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Giovanni Pellielo, who is a citizen of | Token: o\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.803 = 16.803 + 0.0 + 0.0 avg prob of [ Jamaica] 8.686490815534853e-08\n",
            "loss 16.532 = 16.529 + 0.003 + 0.0 avg prob of [ Jamaica] 1.1192241800017655e-07\n",
            "loss 16.24 = 16.23 + 0.01 + 0.0 avg prob of [ Jamaica] 1.8262517187395133e-07\n",
            "loss 15.935 = 15.917 + 0.018 + 0.0 avg prob of [ Jamaica] 3.7100124927746947e-07\n",
            "loss 15.623 = 15.598 + 0.025 + 0.0 avg prob of [ Jamaica] 8.130650712701026e-07\n",
            "loss 15.313 = 15.282 + 0.031 + 0.0 avg prob of [ Jamaica] 1.794910645003256e-06\n",
            "loss 15.008 = 14.971 + 0.037 + 0.0 avg prob of [ Jamaica] 4.033181994600454e-06\n",
            "loss 14.701 = 14.658 + 0.042 + 0.0 avg prob of [ Jamaica] 9.331802175438497e-06\n",
            "loss 14.382 = 14.336 + 0.046 + 0.0 avg prob of [ Jamaica] 2.2157228158903308e-05\n",
            "loss 14.05 = 14.0 + 0.049 + 0.0 avg prob of [ Jamaica] 5.349195998860523e-05\n",
            "loss 13.704 = 13.651 + 0.052 + 0.001 avg prob of [ Jamaica] 0.00012978394806850702\n",
            "loss 13.345 = 13.288 + 0.056 + 0.001 avg prob of [ Jamaica] 0.00031238229712471366\n",
            "loss 12.975 = 12.914 + 0.061 + 0.001 avg prob of [ Jamaica] 0.0007349949446506798\n",
            "loss 12.598 = 12.529 + 0.068 + 0.001 avg prob of [ Jamaica] 0.0016600830713286996\n",
            "loss 12.216 = 12.136 + 0.08 + 0.001 avg prob of [ Jamaica] 0.003513533156365156\n",
            "loss 11.837 = 11.736 + 0.099 + 0.001 avg prob of [ Jamaica] 0.006751422304660082\n",
            "loss 11.462 = 11.335 + 0.127 + 0.001 avg prob of [ Jamaica] 0.011399314738810062\n",
            "loss 11.086 = 10.936 + 0.149 + 0.001 avg prob of [ Jamaica] 0.016681654378771782\n",
            "loss 10.697 = 10.544 + 0.152 + 0.001 avg prob of [ Jamaica] 0.021557964384555817\n",
            "loss 10.291 = 10.155 + 0.135 + 0.001 avg prob of [ Jamaica] 0.025523459538817406\n",
            "Delta norm: 324.686279296875\n",
            "Change in target norm: 401.37164306640625 to 551.0128173828125 => 149.64117431640625\n",
            "Division Factor: 7.038163185119629\n",
            "Right vector norm: 46.13224411010742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 85% 425/500 [2:00:24<22:41, 18.15s/it]Executing ROME algorithm for the update: [Haydn Bendall is native to] -> [ Milan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Haydn Bendall\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Haydn Bendall is native to | Token: all\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.94 = 8.94 + 0.0 + 0.0 avg prob of [ Milan] 0.0006320179672911763\n",
            "loss 8.551 = 8.551 + 0.0 + 0.0 avg prob of [ Milan] 0.0010831180261448026\n",
            "loss 8.158 = 8.156 + 0.002 + 0.0 avg prob of [ Milan] 0.0019917814061045647\n",
            "loss 7.753 = 7.749 + 0.004 + 0.0 avg prob of [ Milan] 0.0039439755491912365\n",
            "loss 7.336 = 7.326 + 0.01 + 0.0 avg prob of [ Milan] 0.008386528119444847\n",
            "loss 6.914 = 6.885 + 0.029 + 0.0 avg prob of [ Milan] 0.018635625019669533\n",
            "loss 6.522 = 6.436 + 0.086 + 0.0 avg prob of [ Milan] 0.0391724593937397\n",
            "loss 6.191 = 6.004 + 0.187 + 0.0 avg prob of [ Milan] 0.06932132691144943\n",
            "loss 5.884 = 5.621 + 0.263 + 0.0 avg prob of [ Milan] 0.10226988047361374\n",
            "loss 5.57 = 5.285 + 0.285 + 0.0 avg prob of [ Milan] 0.12580910325050354\n",
            "loss 5.237 = 4.975 + 0.262 + 0.0 avg prob of [ Milan] 0.1409653127193451\n",
            "loss 4.891 = 4.68 + 0.21 + 0.0 avg prob of [ Milan] 0.15443013608455658\n",
            "loss 4.548 = 4.396 + 0.152 + 0.0 avg prob of [ Milan] 0.16970042884349823\n",
            "loss 4.224 = 4.118 + 0.106 + 0.0 avg prob of [ Milan] 0.18859915435314178\n",
            "loss 3.923 = 3.844 + 0.079 + 0.0 avg prob of [ Milan] 0.21222873032093048\n",
            "loss 3.641 = 3.576 + 0.065 + 0.0 avg prob of [ Milan] 0.2408110499382019\n",
            "loss 3.376 = 3.317 + 0.059 + 0.0 avg prob of [ Milan] 0.27328386902809143\n",
            "loss 3.128 = 3.07 + 0.058 + 0.0 avg prob of [ Milan] 0.30729013681411743\n",
            "loss 2.896 = 2.837 + 0.059 + 0.0 avg prob of [ Milan] 0.34006553888320923\n",
            "loss 2.678 = 2.616 + 0.061 + 0.001 avg prob of [ Milan] 0.37026387453079224\n",
            "Delta norm: 294.5929260253906\n",
            "Change in target norm: 539.0032348632812 to 646.7279663085938 => 107.7247314453125\n",
            "Division Factor: 10.64908218383789\n",
            "Right vector norm: 27.663692474365234\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 85% 426/500 [2:00:40<21:23, 17.34s/it]Executing ROME algorithm for the update: [Nick Greisen, the] -> [ midfielder]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Nick Greisen\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Nick Greisen, the | Token: isen\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.634 = 11.634 + 0.0 + 0.0 avg prob of [ midfielder] 1.175171655631857e-05\n",
            "loss 11.558 = 11.558 + 0.0 + 0.0 avg prob of [ midfielder] 1.273013731406536e-05\n",
            "loss 11.48 = 11.48 + 0.0 + 0.0 avg prob of [ midfielder] 1.38434488690109e-05\n",
            "loss 11.399 = 11.399 + 0.0 + 0.0 avg prob of [ midfielder] 1.5125352547329385e-05\n",
            "loss 11.315 = 11.315 + 0.0 + 0.0 avg prob of [ midfielder] 1.6618836525594816e-05\n",
            "loss 11.227 = 11.227 + 0.0 + 0.0 avg prob of [ midfielder] 1.8378679669694975e-05\n",
            "loss 11.135 = 11.135 + 0.0 + 0.0 avg prob of [ midfielder] 2.0474304619710892e-05\n",
            "loss 11.038 = 11.038 + 0.0 + 0.0 avg prob of [ midfielder] 2.2993548554950394e-05\n",
            "loss 10.936 = 10.936 + 0.0 + 0.0 avg prob of [ midfielder] 2.6048190193250775e-05\n",
            "loss 10.829 = 10.828 + 0.0 + 0.0 avg prob of [ midfielder] 2.978074917336926e-05\n",
            "loss 10.716 = 10.715 + 0.001 + 0.0 avg prob of [ midfielder] 3.437349369050935e-05\n",
            "loss 10.597 = 10.596 + 0.001 + 0.0 avg prob of [ midfielder] 4.0060393075691536e-05\n",
            "loss 10.472 = 10.471 + 0.001 + 0.0 avg prob of [ midfielder] 4.714226452051662e-05\n",
            "loss 10.341 = 10.34 + 0.001 + 0.0 avg prob of [ midfielder] 5.600834992947057e-05\n",
            "loss 10.205 = 10.204 + 0.001 + 0.0 avg prob of [ midfielder] 6.716506322845817e-05\n",
            "loss 10.063 = 10.062 + 0.001 + 0.0 avg prob of [ midfielder] 8.127552428049967e-05\n",
            "loss 9.916 = 9.914 + 0.002 + 0.0 avg prob of [ midfielder] 9.921565651893616e-05\n",
            "loss 9.763 = 9.761 + 0.002 + 0.0 avg prob of [ midfielder] 0.00012215111928526312\n",
            "loss 9.605 = 9.603 + 0.002 + 0.0 avg prob of [ midfielder] 0.00015164798242039979\n",
            "loss 9.442 = 9.439 + 0.002 + 0.0 avg prob of [ midfielder] 0.00018981890752911568\n",
            "Delta norm: 357.98846435546875\n",
            "Change in target norm: 2862.684326171875 to 2865.173095703125 => 2.48876953125\n",
            "Division Factor: 11.31704330444336\n",
            "Right vector norm: 31.6326847076416\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 85% 427/500 [2:00:54<20:06, 16.53s/it]Executing ROME algorithm for the update: [Blanchette Brunoy spoke the language] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Blanchette Brunoy\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Blanchette Brunoy spoke the language | Token: oy\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.653 = 8.653 + 0.0 + 0.0 avg prob of [ Russian] 0.00024020446289796382\n",
            "loss 8.565 = 8.565 + 0.0 + 0.0 avg prob of [ Russian] 0.00025644374545663595\n",
            "loss 8.499 = 8.499 + 0.0 + 0.0 avg prob of [ Russian] 0.0002692932903300971\n",
            "loss 8.449 = 8.449 + 0.0 + 0.0 avg prob of [ Russian] 0.0002798230270855129\n",
            "loss 8.407 = 8.407 + 0.001 + 0.0 avg prob of [ Russian] 0.0002896924561355263\n",
            "loss 8.369 = 8.368 + 0.001 + 0.0 avg prob of [ Russian] 0.00030026197782717645\n",
            "loss 8.329 = 8.328 + 0.001 + 0.0 avg prob of [ Russian] 0.0003125719667878002\n",
            "loss 8.286 = 8.285 + 0.002 + 0.0 avg prob of [ Russian] 0.00032745706266723573\n",
            "loss 8.239 = 8.237 + 0.002 + 0.0 avg prob of [ Russian] 0.0003455615369603038\n",
            "loss 8.187 = 8.185 + 0.002 + 0.0 avg prob of [ Russian] 0.0003674164763651788\n",
            "loss 8.129 = 8.127 + 0.003 + 0.0 avg prob of [ Russian] 0.0003936906286980957\n",
            "loss 8.066 = 8.063 + 0.003 + 0.0 avg prob of [ Russian] 0.0004253963124938309\n",
            "loss 7.997 = 7.993 + 0.003 + 0.0 avg prob of [ Russian] 0.0004639853723347187\n",
            "loss 7.922 = 7.918 + 0.004 + 0.0 avg prob of [ Russian] 0.0005113789811730385\n",
            "loss 7.842 = 7.837 + 0.004 + 0.0 avg prob of [ Russian] 0.0005697284359484911\n",
            "loss 7.757 = 7.752 + 0.005 + 0.0 avg prob of [ Russian] 0.0006415735115297139\n",
            "loss 7.665 = 7.66 + 0.006 + 0.0 avg prob of [ Russian] 0.0007313413079828024\n",
            "loss 7.566 = 7.56 + 0.006 + 0.0 avg prob of [ Russian] 0.0008466846775263548\n",
            "loss 7.457 = 7.449 + 0.007 + 0.0 avg prob of [ Russian] 0.0009997196029871702\n",
            "loss 7.335 = 7.326 + 0.008 + 0.0 avg prob of [ Russian] 0.0012092641554772854\n",
            "Delta norm: 269.64306640625\n",
            "Change in target norm: 856.4400634765625 to 901.6694946289062 => 45.22943115234375\n",
            "Division Factor: 11.018321990966797\n",
            "Right vector norm: 24.472246170043945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 86% 428/500 [2:01:12<20:25, 17.03s/it]Executing ROME algorithm for the update: [The mother tongue of Adriaan van Dis is] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Adriaan van Dis\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Adriaan van Dis is | Token:  Dis\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.441 = 7.441 + 0.0 + 0.0 avg prob of [ French] 0.0010149742010980844\n",
            "loss 7.433 = 7.433 + 0.0 + 0.0 avg prob of [ French] 0.0010197210358455777\n",
            "loss 7.425 = 7.425 + 0.0 + 0.0 avg prob of [ French] 0.0010246271267533302\n",
            "loss 7.417 = 7.417 + 0.0 + 0.0 avg prob of [ French] 0.0010297148255631328\n",
            "loss 7.408 = 7.408 + 0.0 + 0.0 avg prob of [ French] 0.0010350242955610156\n",
            "loss 7.399 = 7.399 + 0.0 + 0.0 avg prob of [ French] 0.0010405933717265725\n",
            "loss 7.39 = 7.389 + 0.0 + 0.0 avg prob of [ French] 0.0010464834049344063\n",
            "loss 7.38 = 7.379 + 0.001 + 0.0 avg prob of [ French] 0.0010527597041800618\n",
            "loss 7.37 = 7.369 + 0.001 + 0.0 avg prob of [ French] 0.00105949561111629\n",
            "loss 7.358 = 7.358 + 0.001 + 0.0 avg prob of [ French] 0.0010667750611901283\n",
            "loss 7.347 = 7.346 + 0.001 + 0.0 avg prob of [ French] 0.0010746957268565893\n",
            "loss 7.334 = 7.333 + 0.001 + 0.0 avg prob of [ French] 0.0010833604028448462\n",
            "loss 7.32 = 7.319 + 0.001 + 0.0 avg prob of [ French] 0.0010928971460089087\n",
            "loss 7.305 = 7.304 + 0.002 + 0.0 avg prob of [ French] 0.0011034441413357854\n",
            "loss 7.289 = 7.287 + 0.002 + 0.0 avg prob of [ French] 0.0011151707731187344\n",
            "loss 7.272 = 7.269 + 0.002 + 0.0 avg prob of [ French] 0.001128281932324171\n",
            "loss 7.253 = 7.25 + 0.002 + 0.0 avg prob of [ French] 0.0011430142913013697\n",
            "loss 7.232 = 7.229 + 0.003 + 0.0 avg prob of [ French] 0.001159663195721805\n",
            "loss 7.209 = 7.206 + 0.003 + 0.0 avg prob of [ French] 0.0011785938404500484\n",
            "loss 7.185 = 7.181 + 0.003 + 0.0 avg prob of [ French] 0.0012002444127574563\n",
            "Delta norm: 349.4069519042969\n",
            "Change in target norm: 1906.74853515625 to 1926.7298583984375 => 19.9813232421875\n",
            "Division Factor: 11.195261001586914\n",
            "Right vector norm: 31.210254669189453\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 86% 429/500 [2:01:32<20:53, 17.66s/it]Executing ROME algorithm for the update: [James I of Aragon follows the religion of] -> [ Buddhism]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object James I of Aragon\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: James I of Aragon follows the religion of | Token: agon\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.705 = 15.705 + 0.0 + 0.0 avg prob of [ Buddhism] 6.125491722741572e-07\n",
            "loss 15.685 = 15.685 + 0.0 + 0.0 avg prob of [ Buddhism] 6.222437036740303e-07\n",
            "loss 15.664 = 15.664 + 0.0 + 0.0 avg prob of [ Buddhism] 6.325494723569136e-07\n",
            "loss 15.641 = 15.641 + 0.0 + 0.0 avg prob of [ Buddhism] 6.436186481550976e-07\n",
            "loss 15.617 = 15.617 + 0.0 + 0.0 avg prob of [ Buddhism] 6.556285256920091e-07\n",
            "loss 15.591 = 15.591 + 0.0 + 0.0 avg prob of [ Buddhism] 6.688271128041379e-07\n",
            "loss 15.562 = 15.562 + 0.0 + 0.0 avg prob of [ Buddhism] 6.834872579020157e-07\n",
            "loss 15.531 = 15.531 + 0.0 + 0.0 avg prob of [ Buddhism] 6.999032962085039e-07\n",
            "loss 15.497 = 15.497 + 0.0 + 0.0 avg prob of [ Buddhism] 7.183997468018788e-07\n",
            "loss 15.46 = 15.459 + 0.0 + 0.0 avg prob of [ Buddhism] 7.39335348498571e-07\n",
            "loss 15.419 = 15.419 + 0.001 + 0.0 avg prob of [ Buddhism] 7.63109653689753e-07\n",
            "loss 15.375 = 15.374 + 0.001 + 0.0 avg prob of [ Buddhism] 7.901695084910898e-07\n",
            "loss 15.327 = 15.326 + 0.001 + 0.0 avg prob of [ Buddhism] 8.21014054963598e-07\n",
            "loss 15.275 = 15.274 + 0.001 + 0.0 avg prob of [ Buddhism] 8.561960953556991e-07\n",
            "loss 15.218 = 15.218 + 0.001 + 0.0 avg prob of [ Buddhism] 8.963374398263113e-07\n",
            "loss 15.158 = 15.157 + 0.001 + 0.0 avg prob of [ Buddhism] 9.42137944548449e-07\n",
            "loss 15.094 = 15.093 + 0.001 + 0.0 avg prob of [ Buddhism] 9.94390347841545e-07\n",
            "loss 15.026 = 15.025 + 0.001 + 0.0 avg prob of [ Buddhism] 1.0539981758483918e-06\n",
            "loss 14.954 = 14.952 + 0.002 + 0.0 avg prob of [ Buddhism] 1.1220183750992874e-06\n",
            "loss 14.877 = 14.875 + 0.002 + 0.0 avg prob of [ Buddhism] 1.1996921784884762e-06\n",
            "Delta norm: 361.3739929199219\n",
            "Change in target norm: 3264.062255859375 to 3295.7080078125 => 31.645751953125\n",
            "Division Factor: 13.294205665588379\n",
            "Right vector norm: 27.182819366455078\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 86% 430/500 [2:01:50<20:58, 17.98s/it]Executing ROME algorithm for the update: [Huangfu Mi writes in] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Huangfu Mi\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Huangfu Mi writes in | Token:  Mi\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.762 = 10.762 + 0.0 + 0.0 avg prob of [ English] 3.149847179884091e-05\n",
            "loss 10.696 = 10.695 + 0.0 + 0.0 avg prob of [ English] 3.315514913992956e-05\n",
            "loss 10.635 = 10.634 + 0.001 + 0.0 avg prob of [ English] 3.4907483495771885e-05\n",
            "loss 10.579 = 10.577 + 0.002 + 0.0 avg prob of [ English] 3.679560904856771e-05\n",
            "loss 10.526 = 10.523 + 0.003 + 0.0 avg prob of [ English] 3.88678781746421e-05\n",
            "loss 10.474 = 10.471 + 0.003 + 0.0 avg prob of [ English] 4.1184928704751655e-05\n",
            "loss 10.423 = 10.42 + 0.003 + 0.0 avg prob of [ English] 4.382422412163578e-05\n",
            "loss 10.371 = 10.368 + 0.003 + 0.0 avg prob of [ English] 4.6886747441021726e-05\n",
            "loss 10.317 = 10.314 + 0.003 + 0.0 avg prob of [ English] 5.0503102102084085e-05\n",
            "loss 10.259 = 10.256 + 0.003 + 0.0 avg prob of [ English] 5.484425128088333e-05\n",
            "loss 10.197 = 10.195 + 0.003 + 0.0 avg prob of [ English] 6.0137928812764585e-05\n",
            "loss 10.13 = 10.127 + 0.003 + 0.0 avg prob of [ English] 6.668957939837128e-05\n",
            "loss 10.056 = 10.054 + 0.003 + 0.0 avg prob of [ English] 7.491045835195109e-05\n",
            "loss 9.976 = 9.973 + 0.003 + 0.0 avg prob of [ English] 8.535610686521977e-05\n",
            "loss 9.888 = 9.885 + 0.003 + 0.0 avg prob of [ English] 9.877793490886688e-05\n",
            "loss 9.791 = 9.788 + 0.003 + 0.0 avg prob of [ English] 0.00011619491124292836\n",
            "loss 9.686 = 9.683 + 0.004 + 0.0 avg prob of [ English] 0.00013899084297008812\n",
            "loss 9.573 = 9.568 + 0.004 + 0.0 avg prob of [ English] 0.00016903982032090425\n",
            "loss 9.451 = 9.446 + 0.005 + 0.0 avg prob of [ English] 0.000208854500669986\n",
            "loss 9.321 = 9.315 + 0.006 + 0.0 avg prob of [ English] 0.0002617417194414884\n",
            "Delta norm: 312.19830322265625\n",
            "Change in target norm: 1199.8826904296875 to 1238.837646484375 => 38.9549560546875\n",
            "Division Factor: 7.489919185638428\n",
            "Right vector norm: 41.682464599609375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 86% 431/500 [2:02:05<19:33, 17.00s/it]Executing ROME algorithm for the update: [Orphan Black is known for performing] -> [ sitcom]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Orphan Black\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Orphan Black is known for performing | Token:  Black\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.853 = 14.853 + 0.0 + 0.0 avg prob of [ sitcom] 8.307392249662371e-07\n",
            "loss 14.734 = 14.734 + 0.0 + 0.0 avg prob of [ sitcom] 9.018816626849002e-07\n",
            "loss 14.619 = 14.619 + 0.0 + 0.0 avg prob of [ sitcom] 9.93855337583227e-07\n",
            "loss 14.504 = 14.504 + 0.0 + 0.0 avg prob of [ sitcom] 1.1277694511591108e-06\n",
            "loss 14.386 = 14.386 + 0.0 + 0.0 avg prob of [ sitcom] 1.3453460496748448e-06\n",
            "loss 14.261 = 14.261 + 0.0 + 0.0 avg prob of [ sitcom] 1.7299560113315238e-06\n",
            "loss 14.127 = 14.127 + 0.0 + 0.0 avg prob of [ sitcom] 2.4457074232486775e-06\n",
            "loss 13.984 = 13.984 + 0.0 + 0.0 avg prob of [ sitcom] 3.8023313209123444e-06\n",
            "loss 13.83 = 13.83 + 0.0 + 0.0 avg prob of [ sitcom] 6.353603112074779e-06\n",
            "loss 13.664 = 13.664 + 0.0 + 0.0 avg prob of [ sitcom] 1.104553393815877e-05\n",
            "loss 13.486 = 13.486 + 0.0 + 0.0 avg prob of [ sitcom] 1.9450935724307783e-05\n",
            "loss 13.296 = 13.296 + 0.0 + 0.0 avg prob of [ sitcom] 3.415422179386951e-05\n",
            "loss 13.092 = 13.092 + 0.0 + 0.0 avg prob of [ sitcom] 5.937743480899371e-05\n",
            "loss 12.874 = 12.874 + 0.0 + 0.0 avg prob of [ sitcom] 0.00010199929238297045\n",
            "loss 12.643 = 12.643 + 0.0 + 0.0 avg prob of [ sitcom] 0.00017314644355792552\n",
            "loss 12.398 = 12.398 + 0.0 + 0.0 avg prob of [ sitcom] 0.0002905786968767643\n",
            "loss 12.143 = 12.142 + 0.0 + 0.0 avg prob of [ sitcom] 0.0004821300390176475\n",
            "loss 11.879 = 11.879 + 0.0 + 0.0 avg prob of [ sitcom] 0.0007905719103291631\n",
            "loss 11.612 = 11.612 + 0.0 + 0.0 avg prob of [ sitcom] 0.0012800255790352821\n",
            "loss 11.343 = 11.343 + 0.0 + 0.0 avg prob of [ sitcom] 0.0020435878541320562\n",
            "Delta norm: 336.2719421386719\n",
            "Change in target norm: 2637.0283203125 to 2638.860107421875 => 1.831787109375\n",
            "Division Factor: 16.989957809448242\n",
            "Right vector norm: 19.792394638061523\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 86% 432/500 [2:02:20<18:46, 16.56s/it]Executing ROME algorithm for the update: [The language of Planet of the Apes was] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Planet of the Apes\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: The language of Planet of the Apes was | Token: es\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.98 = 13.98 + 0.0 + 0.0 avg prob of [ English] 3.4778856843331596e-06\n",
            "loss 13.939 = 13.939 + 0.0 + 0.0 avg prob of [ English] 3.6102248941460857e-06\n",
            "loss 13.895 = 13.895 + 0.0 + 0.0 avg prob of [ English] 3.7621157389367e-06\n",
            "loss 13.846 = 13.846 + 0.0 + 0.0 avg prob of [ English] 3.93691198041779e-06\n",
            "loss 13.792 = 13.792 + 0.0 + 0.0 avg prob of [ English] 4.138700660405448e-06\n",
            "loss 13.733 = 13.732 + 0.0 + 0.0 avg prob of [ English] 4.372326202428667e-06\n",
            "loss 13.668 = 13.667 + 0.0 + 0.0 avg prob of [ English] 4.643727606890025e-06\n",
            "loss 13.596 = 13.596 + 0.001 + 0.0 avg prob of [ English] 4.960270416631829e-06\n",
            "loss 13.518 = 13.517 + 0.001 + 0.0 avg prob of [ English] 5.3309645409171935e-06\n",
            "loss 13.432 = 13.431 + 0.001 + 0.0 avg prob of [ English] 5.766817139374325e-06\n",
            "loss 13.339 = 13.337 + 0.001 + 0.0 avg prob of [ English] 6.281309197220253e-06\n",
            "loss 13.237 = 13.235 + 0.002 + 0.0 avg prob of [ English] 6.891048997204052e-06\n",
            "loss 13.126 = 13.124 + 0.002 + 0.0 avg prob of [ English] 7.616362381668296e-06\n",
            "loss 13.006 = 13.004 + 0.002 + 0.0 avg prob of [ English] 8.48223589855479e-06\n",
            "loss 12.877 = 12.874 + 0.003 + 0.0 avg prob of [ English] 9.518857950752135e-06\n",
            "loss 12.738 = 12.734 + 0.003 + 0.0 avg prob of [ English] 1.0762383681139909e-05\n",
            "loss 12.59 = 12.586 + 0.004 + 0.0 avg prob of [ English] 1.2255437468411401e-05\n",
            "loss 12.432 = 12.428 + 0.004 + 0.0 avg prob of [ English] 1.4047061085875612e-05\n",
            "loss 12.266 = 12.261 + 0.005 + 0.0 avg prob of [ English] 1.6192658222280443e-05\n",
            "loss 12.092 = 12.086 + 0.006 + 0.0 avg prob of [ English] 1.8753376934910193e-05\n",
            "Delta norm: 373.0226745605469\n",
            "Change in target norm: 2515.45703125 to 2532.52294921875 => 17.06591796875\n",
            "Division Factor: 16.43284034729004\n",
            "Right vector norm: 22.699831008911133\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 87% 433/500 [2:02:39<19:12, 17.20s/it]Executing ROME algorithm for the update: [The official language of Guam is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Guam\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The official language of Guam is | Token:  Guam\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.283 = 10.283 + 0.0 + 0.0 avg prob of [ Russian] 5.295069422572851e-05\n",
            "loss 10.188 = 10.188 + 0.0 + 0.0 avg prob of [ Russian] 7.028451364021748e-05\n",
            "loss 10.067 = 10.067 + 0.0 + 0.0 avg prob of [ Russian] 0.00010330590885132551\n",
            "loss 9.922 = 9.921 + 0.001 + 0.0 avg prob of [ Russian] 0.00015755524509586394\n",
            "loss 9.751 = 9.749 + 0.002 + 0.0 avg prob of [ Russian] 0.0002479786053299904\n",
            "loss 9.553 = 9.551 + 0.003 + 0.0 avg prob of [ Russian] 0.00040537159657105803\n",
            "loss 9.332 = 9.328 + 0.004 + 0.0 avg prob of [ Russian] 0.0006878418498672545\n",
            "loss 9.096 = 9.091 + 0.006 + 0.0 avg prob of [ Russian] 0.0011853048345074058\n",
            "loss 8.853 = 8.845 + 0.008 + 0.0 avg prob of [ Russian] 0.0019864914938807487\n",
            "loss 8.602 = 8.592 + 0.01 + 0.0 avg prob of [ Russian] 0.0031241229735314846\n",
            "loss 8.339 = 8.326 + 0.013 + 0.0 avg prob of [ Russian] 0.0046515134163200855\n",
            "loss 8.063 = 8.047 + 0.015 + 0.0 avg prob of [ Russian] 0.006697702221572399\n",
            "loss 7.777 = 7.759 + 0.018 + 0.0 avg prob of [ Russian] 0.009363406337797642\n",
            "loss 7.488 = 7.466 + 0.022 + 0.0 avg prob of [ Russian] 0.012662786990404129\n",
            "loss 7.201 = 7.176 + 0.025 + 0.0 avg prob of [ Russian] 0.01657470501959324\n",
            "loss 6.92 = 6.891 + 0.029 + 0.0 avg prob of [ Russian] 0.02111358754336834\n",
            "loss 6.646 = 6.613 + 0.032 + 0.0 avg prob of [ Russian] 0.02636111155152321\n",
            "loss 6.38 = 6.344 + 0.037 + 0.0 avg prob of [ Russian] 0.03246859833598137\n",
            "loss 6.123 = 6.081 + 0.041 + 0.0 avg prob of [ Russian] 0.039629969745874405\n",
            "loss 5.875 = 5.827 + 0.048 + 0.0 avg prob of [ Russian] 0.04802978038787842\n",
            "Delta norm: 349.25018310546875\n",
            "Change in target norm: 820.0928344726562 to 876.4895629882812 => 56.396728515625\n",
            "Division Factor: 7.404772758483887\n",
            "Right vector norm: 47.16555404663086\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 87% 434/500 [2:02:55<18:30, 16.83s/it]Executing ROME algorithm for the update: [Johann Gottlieb Fichte was employed in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Johann Gottlieb Fichte\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: Johann Gottlieb Fichte was employed in | Token: te\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.771 = 13.771 + 0.0 + 0.0 avg prob of [ London] 1.2928534488310106e-05\n",
            "loss 13.675 = 13.675 + 0.0 + 0.0 avg prob of [ London] 1.3901245438319165e-05\n",
            "loss 13.59 = 13.59 + 0.0 + 0.0 avg prob of [ London] 1.4845980331301689e-05\n",
            "loss 13.515 = 13.515 + 0.0 + 0.0 avg prob of [ London] 1.5755247659399174e-05\n",
            "loss 13.448 = 13.448 + 0.0 + 0.0 avg prob of [ London] 1.6631995094940066e-05\n",
            "loss 13.389 = 13.389 + 0.0 + 0.0 avg prob of [ London] 1.7483218471170403e-05\n",
            "loss 13.335 = 13.335 + 0.0 + 0.0 avg prob of [ London] 1.8319753507967107e-05\n",
            "loss 13.287 = 13.287 + 0.0 + 0.0 avg prob of [ London] 1.9156197595293634e-05\n",
            "loss 13.242 = 13.242 + 0.0 + 0.0 avg prob of [ London] 2.001069879042916e-05\n",
            "loss 13.199 = 13.199 + 0.0 + 0.0 avg prob of [ London] 2.0905064957332797e-05\n",
            "loss 13.158 = 13.158 + 0.0 + 0.0 avg prob of [ London] 2.186481469834689e-05\n",
            "loss 13.118 = 13.118 + 0.0 + 0.0 avg prob of [ London] 2.2920539777260274e-05\n",
            "loss 13.078 = 13.078 + 0.0 + 0.0 avg prob of [ London] 2.410930028418079e-05\n",
            "loss 13.038 = 13.038 + 0.0 + 0.0 avg prob of [ London] 2.5477682356722653e-05\n",
            "loss 12.996 = 12.996 + 0.0 + 0.0 avg prob of [ London] 2.7086103727924637e-05\n",
            "loss 12.951 = 12.951 + 0.0 + 0.0 avg prob of [ London] 2.9014543542871252e-05\n",
            "loss 12.905 = 12.904 + 0.0 + 0.0 avg prob of [ London] 3.1371699151350185e-05\n",
            "loss 12.854 = 12.854 + 0.0 + 0.0 avg prob of [ London] 3.430710785323754e-05\n",
            "loss 12.8 = 12.8 + 0.0 + 0.0 avg prob of [ London] 3.8027868868084624e-05\n",
            "loss 12.742 = 12.741 + 0.0 + 0.0 avg prob of [ London] 4.2820232920348644e-05\n",
            "Delta norm: 300.2951965332031\n",
            "Change in target norm: 3021.470947265625 to 3021.159912109375 => -0.31103515625\n",
            "Division Factor: 13.048633575439453\n",
            "Right vector norm: 23.013534545898438\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 87% 435/500 [2:03:14<18:55, 17.47s/it]Executing ROME algorithm for the update: [Henry Michell Wagner died at] -> [ Chicago]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Henry Michell Wagner\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Henry Michell Wagner died at | Token:  Wagner\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 6.174 = 6.174 + 0.0 + 0.0 avg prob of [ Chicago] 0.0065254936926066875\n",
            "loss 6.122 = 6.122 + 0.0 + 0.0 avg prob of [ Chicago] 0.006966292392462492\n",
            "loss 6.066 = 6.066 + 0.0 + 0.0 avg prob of [ Chicago] 0.007468922063708305\n",
            "loss 6.007 = 6.007 + 0.0 + 0.0 avg prob of [ Chicago] 0.008045494556427002\n",
            "loss 5.945 = 5.945 + 0.0 + 0.0 avg prob of [ Chicago] 0.008710762485861778\n",
            "loss 5.878 = 5.878 + 0.0 + 0.0 avg prob of [ Chicago] 0.009482237510383129\n",
            "loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ Chicago] 0.010381137952208519\n",
            "loss 5.734 = 5.734 + 0.0 + 0.0 avg prob of [ Chicago] 0.011433223262429237\n",
            "loss 5.655 = 5.655 + 0.0 + 0.0 avg prob of [ Chicago] 0.012669963762164116\n",
            "loss 5.573 = 5.572 + 0.0 + 0.0 avg prob of [ Chicago] 0.01412975788116455\n",
            "loss 5.486 = 5.485 + 0.0 + 0.0 avg prob of [ Chicago] 0.015859322622418404\n",
            "loss 5.395 = 5.394 + 0.0 + 0.0 avg prob of [ Chicago] 0.01791555806994438\n",
            "loss 5.299 = 5.298 + 0.001 + 0.0 avg prob of [ Chicago] 0.020366603508591652\n",
            "loss 5.199 = 5.199 + 0.001 + 0.0 avg prob of [ Chicago] 0.023293739184737206\n",
            "loss 5.096 = 5.095 + 0.001 + 0.0 avg prob of [ Chicago] 0.026791511103510857\n",
            "loss 4.988 = 4.987 + 0.001 + 0.0 avg prob of [ Chicago] 0.03096845932304859\n",
            "loss 4.878 = 4.876 + 0.001 + 0.0 avg prob of [ Chicago] 0.03594508022069931\n",
            "loss 4.764 = 4.762 + 0.001 + 0.0 avg prob of [ Chicago] 0.04184923321008682\n",
            "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ Chicago] 0.04880828037858009\n",
            "loss 4.528 = 4.527 + 0.001 + 0.0 avg prob of [ Chicago] 0.05693827569484711\n",
            "Delta norm: 374.2149658203125\n",
            "Change in target norm: 4373.20458984375 to 4375.44287109375 => 2.23828125\n",
            "Division Factor: 8.337425231933594\n",
            "Right vector norm: 44.88375473022461\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 87% 436/500 [2:03:30<18:11, 17.05s/it]Executing ROME algorithm for the update: [The Rasmus, founded in] -> [ Beijing]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Rasmus\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: The Rasmus, founded in | Token: us\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.184 = 10.184 + 0.0 + 0.0 avg prob of [ Beijing] 7.267416367540136e-05\n",
            "loss 10.062 = 10.062 + 0.0 + 0.0 avg prob of [ Beijing] 8.175530092557892e-05\n",
            "loss 9.902 = 9.902 + 0.0 + 0.0 avg prob of [ Beijing] 9.62405902100727e-05\n",
            "loss 9.695 = 9.695 + 0.0 + 0.0 avg prob of [ Beijing] 0.00012346095172688365\n",
            "loss 9.437 = 9.436 + 0.001 + 0.0 avg prob of [ Beijing] 0.00018318592628929764\n",
            "loss 9.128 = 9.127 + 0.001 + 0.0 avg prob of [ Beijing] 0.0003278964140918106\n",
            "loss 8.776 = 8.774 + 0.001 + 0.0 avg prob of [ Beijing] 0.000680789293255657\n",
            "loss 8.389 = 8.388 + 0.002 + 0.0 avg prob of [ Beijing] 0.001465946203097701\n",
            "loss 7.981 = 7.979 + 0.002 + 0.0 avg prob of [ Beijing] 0.0029865256510674953\n",
            "loss 7.559 = 7.557 + 0.003 + 0.0 avg prob of [ Beijing] 0.005602298304438591\n",
            "loss 7.133 = 7.129 + 0.003 + 0.0 avg prob of [ Beijing] 0.009729600511491299\n",
            "loss 6.708 = 6.704 + 0.004 + 0.0 avg prob of [ Beijing] 0.01577804423868656\n",
            "loss 6.291 = 6.286 + 0.005 + 0.0 avg prob of [ Beijing] 0.02412676252424717\n",
            "loss 5.884 = 5.878 + 0.006 + 0.0 avg prob of [ Beijing] 0.0351937860250473\n",
            "loss 5.489 = 5.483 + 0.006 + 0.0 avg prob of [ Beijing] 0.04943222180008888\n",
            "loss 5.11 = 5.102 + 0.007 + 0.0 avg prob of [ Beijing] 0.0672142505645752\n",
            "loss 4.747 = 4.738 + 0.008 + 0.0 avg prob of [ Beijing] 0.08864257484674454\n",
            "loss 4.403 = 4.393 + 0.009 + 0.0 avg prob of [ Beijing] 0.11341313272714615\n",
            "loss 4.078 = 4.067 + 0.011 + 0.0 avg prob of [ Beijing] 0.14083582162857056\n",
            "loss 3.773 = 3.761 + 0.012 + 0.0 avg prob of [ Beijing] 0.1700129508972168\n",
            "Delta norm: 343.53228759765625\n",
            "Change in target norm: 1130.8226318359375 to 1149.0941162109375 => 18.271484375\n",
            "Division Factor: 10.287985801696777\n",
            "Right vector norm: 33.391597747802734\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 87% 437/500 [2:03:46<17:35, 16.75s/it]Executing ROME algorithm for the update: [The profession of Jane Leeves is] -> [ novelist]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jane Leeves\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The profession of Jane Leeves is | Token: ves\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.474 = 16.474 + 0.0 + 0.0 avg prob of [ novelist] 3.259076777339942e-07\n",
            "loss 16.283 = 16.283 + 0.0 + 0.0 avg prob of [ novelist] 3.8027195614631637e-07\n",
            "loss 16.1 = 16.1 + 0.0 + 0.0 avg prob of [ novelist] 4.437835343651386e-07\n",
            "loss 15.923 = 15.923 + 0.0 + 0.0 avg prob of [ novelist] 5.186109888200008e-07\n",
            "loss 15.751 = 15.75 + 0.001 + 0.0 avg prob of [ novelist] 6.074012617318658e-07\n",
            "loss 15.581 = 15.58 + 0.001 + 0.0 avg prob of [ novelist] 7.136704311960784e-07\n",
            "loss 15.414 = 15.411 + 0.002 + 0.0 avg prob of [ novelist] 8.421151846960129e-07\n",
            "loss 15.246 = 15.243 + 0.003 + 0.0 avg prob of [ novelist] 9.989950058297836e-07\n",
            "loss 15.077 = 15.073 + 0.004 + 0.0 avg prob of [ novelist] 1.1927111245313426e-06\n",
            "loss 14.906 = 14.901 + 0.005 + 0.0 avg prob of [ novelist] 1.434593286830932e-06\n",
            "loss 14.732 = 14.726 + 0.007 + 0.0 avg prob of [ novelist] 1.7399647731508594e-06\n",
            "loss 14.554 = 14.546 + 0.008 + 0.0 avg prob of [ novelist] 2.129595031874487e-06\n",
            "loss 14.372 = 14.362 + 0.01 + 0.0 avg prob of [ novelist] 2.6317566153011285e-06\n",
            "loss 14.184 = 14.172 + 0.012 + 0.0 avg prob of [ novelist] 3.2850994102773257e-06\n",
            "loss 13.991 = 13.978 + 0.014 + 0.0 avg prob of [ novelist] 4.142743819102179e-06\n",
            "loss 13.794 = 13.778 + 0.016 + 0.0 avg prob of [ novelist] 5.27778638570453e-06\n",
            "loss 13.591 = 13.573 + 0.018 + 0.0 avg prob of [ novelist] 6.791250143578509e-06\n",
            "loss 13.383 = 13.363 + 0.02 + 0.0 avg prob of [ novelist] 8.823084499454126e-06\n",
            "loss 13.171 = 13.148 + 0.023 + 0.0 avg prob of [ novelist] 1.156719372374937e-05\n",
            "loss 12.955 = 12.93 + 0.025 + 0.0 avg prob of [ novelist] 1.5292498574126512e-05\n",
            "Delta norm: 335.52496337890625\n",
            "Change in target norm: 2441.342041015625 to 2465.986572265625 => 24.64453125\n",
            "Division Factor: 13.232416152954102\n",
            "Right vector norm: 25.35628890991211\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 88% 438/500 [2:04:02<16:55, 16.38s/it]Executing ROME algorithm for the update: [Adliswil, which is located in] -> [ Germany]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Adliswil\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Adliswil, which is located in | Token: il\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.184 = 8.184 + 0.0 + 0.0 avg prob of [ Germany] 0.00042918280814774334\n",
            "loss 8.173 = 8.173 + 0.0 + 0.0 avg prob of [ Germany] 0.00043451617239043117\n",
            "loss 8.164 = 8.164 + 0.0 + 0.0 avg prob of [ Germany] 0.0004390718531794846\n",
            "loss 8.156 = 8.156 + 0.0 + 0.0 avg prob of [ Germany] 0.0004429391410667449\n",
            "loss 8.149 = 8.149 + 0.0 + 0.0 avg prob of [ Germany] 0.000446234829723835\n",
            "loss 8.143 = 8.143 + 0.0 + 0.0 avg prob of [ Germany] 0.0004490960855036974\n",
            "loss 8.138 = 8.138 + 0.0 + 0.0 avg prob of [ Germany] 0.00045164977200329304\n",
            "loss 8.133 = 8.133 + 0.0 + 0.0 avg prob of [ Germany] 0.00045400415547192097\n",
            "loss 8.129 = 8.129 + 0.0 + 0.0 avg prob of [ Germany] 0.0004562533868011087\n",
            "loss 8.124 = 8.124 + 0.0 + 0.0 avg prob of [ Germany] 0.00045847019646316767\n",
            "loss 8.12 = 8.12 + 0.0 + 0.0 avg prob of [ Germany] 0.00046071939868852496\n",
            "loss 8.115 = 8.115 + 0.0 + 0.0 avg prob of [ Germany] 0.0004630586481653154\n",
            "loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Germany] 0.0004655419907066971\n",
            "loss 8.105 = 8.105 + 0.0 + 0.0 avg prob of [ Germany] 0.0004682251310441643\n",
            "loss 8.1 = 8.1 + 0.0 + 0.0 avg prob of [ Germany] 0.00047116802306845784\n",
            "loss 8.094 = 8.093 + 0.0 + 0.0 avg prob of [ Germany] 0.0004744408361148089\n",
            "loss 8.087 = 8.087 + 0.0 + 0.0 avg prob of [ Germany] 0.00047812084085308015\n",
            "loss 8.079 = 8.079 + 0.0 + 0.0 avg prob of [ Germany] 0.00048230934771709144\n",
            "loss 8.071 = 8.071 + 0.0 + 0.0 avg prob of [ Germany] 0.0004871261480730027\n",
            "loss 8.061 = 8.061 + 0.0 + 0.0 avg prob of [ Germany] 0.0004927183617837727\n",
            "Delta norm: 288.6993713378906\n",
            "Change in target norm: 2404.46240234375 to 2415.582763671875 => 11.120361328125\n",
            "Division Factor: 13.683374404907227\n",
            "Right vector norm: 21.09855079650879\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 88% 439/500 [2:04:20<17:22, 17.08s/it]Executing ROME algorithm for the update: [Irfan Habib, who has a citizenship from] -> [ Singapore]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Irfan Habib\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Irfan Habib, who has a citizenship from | Token: ib\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.716 = 10.716 + 0.0 + 0.0 avg prob of [ Singapore] 2.3198457711259834e-05\n",
            "loss 10.598 = 10.598 + 0.0 + 0.0 avg prob of [ Singapore] 2.676117765076924e-05\n",
            "loss 10.513 = 10.513 + 0.0 + 0.0 avg prob of [ Singapore] 3.0202938432921655e-05\n",
            "loss 10.446 = 10.446 + 0.0 + 0.0 avg prob of [ Singapore] 3.379350164323114e-05\n",
            "loss 10.385 = 10.384 + 0.0 + 0.0 avg prob of [ Singapore] 3.8282287277979776e-05\n",
            "loss 10.317 = 10.317 + 0.0 + 0.0 avg prob of [ Singapore] 4.510125290835276e-05\n",
            "loss 10.235 = 10.235 + 0.0 + 0.0 avg prob of [ Singapore] 5.716126543120481e-05\n",
            "loss 10.132 = 10.132 + 0.0 + 0.0 avg prob of [ Singapore] 8.093570068012923e-05\n",
            "loss 10.002 = 10.001 + 0.0 + 0.0 avg prob of [ Singapore] 0.00013150110316928476\n",
            "loss 9.837 = 9.837 + 0.0 + 0.0 avg prob of [ Singapore] 0.0002438869560137391\n",
            "loss 9.632 = 9.632 + 0.0 + 0.0 avg prob of [ Singapore] 0.0004932230804115534\n",
            "loss 9.383 = 9.383 + 0.0 + 0.0 avg prob of [ Singapore] 0.0010147751308977604\n",
            "loss 9.089 = 9.089 + 0.0 + 0.0 avg prob of [ Singapore] 0.0020015393383800983\n",
            "loss 8.754 = 8.754 + 0.0 + 0.0 avg prob of [ Singapore] 0.0036818599328398705\n",
            "loss 8.385 = 8.384 + 0.0 + 0.0 avg prob of [ Singapore] 0.00631651422008872\n",
            "loss 7.992 = 7.991 + 0.0 + 0.0 avg prob of [ Singapore] 0.01022497657686472\n",
            "loss 7.586 = 7.585 + 0.0 + 0.0 avg prob of [ Singapore] 0.01577434316277504\n",
            "loss 7.175 = 7.174 + 0.0 + 0.0 avg prob of [ Singapore] 0.02328565903007984\n",
            "loss 6.764 = 6.763 + 0.0 + 0.0 avg prob of [ Singapore] 0.032913561910390854\n",
            "loss 6.355 = 6.354 + 0.0 + 0.0 avg prob of [ Singapore] 0.04462910071015358\n",
            "Delta norm: 283.33453369140625\n",
            "Change in target norm: 876.3453979492188 to 909.0260620117188 => 32.6806640625\n",
            "Division Factor: 11.430681228637695\n",
            "Right vector norm: 24.787195205688477\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 88% 440/500 [2:04:40<17:41, 17.70s/it]Executing ROME algorithm for the update: [Umayyad Caliphate is located in the continent] -> [ Antarctica]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Umayyad Caliphate\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Umayyad Caliphate is located in the continent | Token: iphate\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.921 = 15.921 + 0.0 + 0.0 avg prob of [ Antarctica] 5.82115035285824e-07\n",
            "loss 15.759 = 15.759 + 0.0 + 0.0 avg prob of [ Antarctica] 6.593763259843399e-07\n",
            "loss 15.608 = 15.608 + 0.0 + 0.0 avg prob of [ Antarctica] 7.440385729751142e-07\n",
            "loss 15.465 = 15.465 + 0.0 + 0.0 avg prob of [ Antarctica] 8.376150049116404e-07\n",
            "loss 15.331 = 15.331 + 0.0 + 0.0 avg prob of [ Antarctica] 9.420504625268222e-07\n",
            "loss 15.203 = 15.202 + 0.0 + 0.0 avg prob of [ Antarctica] 1.0602698239381425e-06\n",
            "loss 15.08 = 15.079 + 0.0 + 0.0 avg prob of [ Antarctica] 1.1964067425651592e-06\n",
            "loss 14.96 = 14.96 + 0.0 + 0.0 avg prob of [ Antarctica] 1.3563686707129818e-06\n",
            "loss 14.842 = 14.842 + 0.0 + 0.0 avg prob of [ Antarctica] 1.5485037465623464e-06\n",
            "loss 14.725 = 14.724 + 0.0 + 0.0 avg prob of [ Antarctica] 1.7844610056272359e-06\n",
            "loss 14.606 = 14.605 + 0.0 + 0.0 avg prob of [ Antarctica] 2.0806030534004094e-06\n",
            "loss 14.484 = 14.483 + 0.001 + 0.0 avg prob of [ Antarctica] 2.460338691889774e-06\n",
            "loss 14.357 = 14.357 + 0.001 + 0.0 avg prob of [ Antarctica] 2.9577443001471693e-06\n",
            "loss 14.225 = 14.225 + 0.001 + 0.0 avg prob of [ Antarctica] 3.623519205575576e-06\n",
            "loss 14.086 = 14.085 + 0.001 + 0.0 avg prob of [ Antarctica] 4.534651907306397e-06\n",
            "loss 13.939 = 13.938 + 0.001 + 0.0 avg prob of [ Antarctica] 5.8106375036004465e-06\n",
            "loss 13.784 = 13.782 + 0.001 + 0.0 avg prob of [ Antarctica] 7.640906915185042e-06\n",
            "loss 13.618 = 13.617 + 0.002 + 0.0 avg prob of [ Antarctica] 1.0331853445677552e-05\n",
            "loss 13.442 = 13.44 + 0.002 + 0.0 avg prob of [ Antarctica] 1.4389604984899051e-05\n",
            "loss 13.256 = 13.254 + 0.002 + 0.0 avg prob of [ Antarctica] 2.0666657292167656e-05\n",
            "Delta norm: 322.8031921386719\n",
            "Change in target norm: 2384.24609375 to 2399.009765625 => 14.763671875\n",
            "Division Factor: 8.93526554107666\n",
            "Right vector norm: 36.12687301635742\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 88% 441/500 [2:05:00<18:10, 18.49s/it]Executing ROME algorithm for the update: [In La Chaux-de-Fonds, they understand] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object La Chaux-de-Fonds\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: In La Chaux-de-Fonds, they understand | Token: onds\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.899 = 9.899 + 0.0 + 0.0 avg prob of [ English] 6.638938066316769e-05\n",
            "loss 9.75 = 9.75 + 0.0 + 0.0 avg prob of [ English] 8.155921386787668e-05\n",
            "loss 9.587 = 9.587 + 0.0 + 0.0 avg prob of [ English] 0.00010228844621451572\n",
            "loss 9.413 = 9.412 + 0.001 + 0.0 avg prob of [ English] 0.00013029381807427853\n",
            "loss 9.228 = 9.227 + 0.001 + 0.0 avg prob of [ English] 0.00016794777184259146\n",
            "loss 9.034 = 9.032 + 0.002 + 0.0 avg prob of [ English] 0.00021867208124604076\n",
            "loss 8.831 = 8.828 + 0.003 + 0.0 avg prob of [ English] 0.00028750833007507026\n",
            "loss 8.619 = 8.615 + 0.004 + 0.0 avg prob of [ English] 0.00038156224763952196\n",
            "loss 8.4 = 8.395 + 0.005 + 0.0 avg prob of [ English] 0.0005101562128402293\n",
            "loss 8.178 = 8.172 + 0.006 + 0.0 avg prob of [ English] 0.0006846593460068107\n",
            "loss 7.955 = 7.947 + 0.008 + 0.0 avg prob of [ English] 0.0009187552495859563\n",
            "loss 7.732 = 7.723 + 0.009 + 0.0 avg prob of [ English] 0.0012310742167755961\n",
            "loss 7.51 = 7.499 + 0.011 + 0.0 avg prob of [ English] 0.0016505673993378878\n",
            "loss 7.287 = 7.274 + 0.013 + 0.0 avg prob of [ English] 0.002222831826657057\n",
            "loss 7.062 = 7.047 + 0.015 + 0.0 avg prob of [ English] 0.0030164276249706745\n",
            "loss 6.835 = 6.818 + 0.017 + 0.0 avg prob of [ English] 0.004131316673010588\n",
            "loss 6.607 = 6.587 + 0.02 + 0.0 avg prob of [ English] 0.005712117068469524\n",
            "loss 6.379 = 6.355 + 0.024 + 0.0 avg prob of [ English] 0.007964791730046272\n",
            "loss 6.151 = 6.123 + 0.028 + 0.0 avg prob of [ English] 0.011165961623191833\n",
            "loss 5.926 = 5.892 + 0.034 + 0.0 avg prob of [ English] 0.015642356127500534\n",
            "Delta norm: 353.33837890625\n",
            "Change in target norm: 1162.5179443359375 to 1202.146240234375 => 39.6282958984375\n",
            "Division Factor: 11.39271354675293\n",
            "Right vector norm: 31.014419555664062\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 88% 442/500 [2:05:20<18:16, 18.91s/it]Executing ROME algorithm for the update: [Chinese Skating Association's headquarters are in] -> [ Indianapolis]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Chinese Skating Association\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Chinese Skating Association's headquarters are in | Token:  Association\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.502 = 12.502 + 0.0 + 0.0 avg prob of [ Indianapolis] 5.056680947745917e-06\n",
            "loss 12.451 = 12.451 + 0.0 + 0.0 avg prob of [ Indianapolis] 5.2951813813706394e-06\n",
            "loss 12.404 = 12.404 + 0.0 + 0.0 avg prob of [ Indianapolis] 5.534766387427226e-06\n",
            "loss 12.359 = 12.358 + 0.0 + 0.0 avg prob of [ Indianapolis] 5.777852038590936e-06\n",
            "loss 12.315 = 12.314 + 0.0 + 0.0 avg prob of [ Indianapolis] 6.028097686794354e-06\n",
            "loss 12.271 = 12.271 + 0.001 + 0.0 avg prob of [ Indianapolis] 6.290213605097961e-06\n",
            "loss 12.228 = 12.227 + 0.001 + 0.0 avg prob of [ Indianapolis] 6.570159257535124e-06\n",
            "loss 12.184 = 12.182 + 0.001 + 0.0 avg prob of [ Indianapolis] 6.875063718325691e-06\n",
            "loss 12.138 = 12.136 + 0.001 + 0.0 avg prob of [ Indianapolis] 7.213393018901115e-06\n",
            "loss 12.089 = 12.088 + 0.002 + 0.0 avg prob of [ Indianapolis] 7.595168426632881e-06\n",
            "loss 12.038 = 12.036 + 0.002 + 0.0 avg prob of [ Indianapolis] 8.032146979530808e-06\n",
            "loss 11.983 = 11.981 + 0.002 + 0.0 avg prob of [ Indianapolis] 8.538022484572139e-06\n",
            "loss 11.924 = 11.921 + 0.003 + 0.0 avg prob of [ Indianapolis] 9.12869018065976e-06\n",
            "loss 11.86 = 11.857 + 0.003 + 0.0 avg prob of [ Indianapolis] 9.822574611462187e-06\n",
            "loss 11.792 = 11.788 + 0.003 + 0.0 avg prob of [ Indianapolis] 1.064117532223463e-05\n",
            "loss 11.718 = 11.714 + 0.004 + 0.0 avg prob of [ Indianapolis] 1.160996725957375e-05\n",
            "loss 11.639 = 11.635 + 0.004 + 0.0 avg prob of [ Indianapolis] 1.2759848686982878e-05\n",
            "loss 11.556 = 11.551 + 0.005 + 0.0 avg prob of [ Indianapolis] 1.412929759680992e-05\n",
            "loss 11.466 = 11.461 + 0.005 + 0.0 avg prob of [ Indianapolis] 1.5767329387017526e-05\n",
            "loss 11.372 = 11.366 + 0.006 + 0.0 avg prob of [ Indianapolis] 1.7737493180902675e-05\n",
            "Delta norm: 324.3448181152344\n",
            "Change in target norm: 1788.443359375 to 1810.8426513671875 => 22.3992919921875\n",
            "Division Factor: 7.369085788726807\n",
            "Right vector norm: 44.014251708984375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 89% 443/500 [2:05:38<17:41, 18.62s/it]Executing ROME algorithm for the update: [Disney's Hollywood Studios can be found in] -> [ Ontario]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Disney's Hollywood Studios\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Disney's Hollywood Studios can be found in | Token:  Studios\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.779 = 13.779 + 0.0 + 0.0 avg prob of [ Ontario] 3.352142812218517e-06\n",
            "loss 13.587 = 13.585 + 0.002 + 0.0 avg prob of [ Ontario] 4.181709755357588e-06\n",
            "loss 13.392 = 13.385 + 0.006 + 0.0 avg prob of [ Ontario] 5.496606263477588e-06\n",
            "loss 13.189 = 13.178 + 0.011 + 0.0 avg prob of [ Ontario] 7.625537818967132e-06\n",
            "loss 12.978 = 12.962 + 0.016 + 0.0 avg prob of [ Ontario] 1.1138635272800457e-05\n",
            "loss 12.758 = 12.737 + 0.022 + 0.0 avg prob of [ Ontario] 1.702067493170034e-05\n",
            "loss 12.529 = 12.502 + 0.027 + 0.0 avg prob of [ Ontario] 2.7011963538825512e-05\n",
            "loss 12.291 = 12.258 + 0.033 + 0.0 avg prob of [ Ontario] 4.426107989274897e-05\n",
            "loss 12.046 = 12.007 + 0.039 + 0.0 avg prob of [ Ontario] 7.449867553077638e-05\n",
            "loss 11.795 = 11.75 + 0.045 + 0.0 avg prob of [ Ontario] 0.00012811388296540827\n",
            "loss 11.538 = 11.488 + 0.05 + 0.0 avg prob of [ Ontario] 0.00022348557831719518\n",
            "loss 11.275 = 11.22 + 0.054 + 0.0 avg prob of [ Ontario] 0.0003915282723028213\n",
            "loss 11.006 = 10.947 + 0.059 + 0.0 avg prob of [ Ontario] 0.0006811174098402262\n",
            "loss 10.732 = 10.669 + 0.063 + 0.0 avg prob of [ Ontario] 0.00116550934035331\n",
            "loss 10.454 = 10.387 + 0.067 + 0.0 avg prob of [ Ontario] 0.0019502985524013638\n",
            "loss 10.172 = 10.101 + 0.071 + 0.0 avg prob of [ Ontario] 0.003183607244864106\n",
            "loss 9.888 = 9.812 + 0.076 + 0.001 avg prob of [ Ontario] 0.0050674728117883205\n",
            "loss 9.603 = 9.521 + 0.081 + 0.001 avg prob of [ Ontario] 0.007865862920880318\n",
            "loss 9.318 = 9.23 + 0.087 + 0.001 avg prob of [ Ontario] 0.011898658238351345\n",
            "loss 9.034 = 8.938 + 0.095 + 0.001 avg prob of [ Ontario] 0.017509454861283302\n",
            "Delta norm: 344.925537109375\n",
            "Change in target norm: 526.8970336914062 to 670.0155029296875 => 143.11846923828125\n",
            "Division Factor: 10.218255996704102\n",
            "Right vector norm: 33.75581359863281\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 89% 444/500 [2:05:56<17:13, 18.45s/it]Executing ROME algorithm for the update: [The Boat People originated in] -> [ Manchester]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Boat People\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: The Boat People originated in | Token:  People\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.92 = 15.92 + 0.0 + 0.0 avg prob of [ Manchester] 3.5425446753833967e-07\n",
            "loss 15.812 = 15.812 + 0.0 + 0.0 avg prob of [ Manchester] 4.0015012814365036e-07\n",
            "loss 15.7 = 15.699 + 0.0 + 0.0 avg prob of [ Manchester] 4.549226844119403e-07\n",
            "loss 15.581 = 15.581 + 0.0 + 0.0 avg prob of [ Manchester] 5.21563094935118e-07\n",
            "loss 15.455 = 15.455 + 0.001 + 0.0 avg prob of [ Manchester] 6.038298465682601e-07\n",
            "loss 15.322 = 15.321 + 0.001 + 0.0 avg prob of [ Manchester] 7.065740419420763e-07\n",
            "loss 15.182 = 15.18 + 0.002 + 0.0 avg prob of [ Manchester] 8.360380547856039e-07\n",
            "loss 15.034 = 15.032 + 0.002 + 0.0 avg prob of [ Manchester] 1.0001762120737112e-06\n",
            "loss 14.879 = 14.876 + 0.002 + 0.0 avg prob of [ Manchester] 1.2091456937923795e-06\n",
            "loss 14.717 = 14.714 + 0.003 + 0.0 avg prob of [ Manchester] 1.4758836641703965e-06\n",
            "loss 14.55 = 14.547 + 0.004 + 0.0 avg prob of [ Manchester] 1.8170651401305804e-06\n",
            "loss 14.378 = 14.374 + 0.004 + 0.0 avg prob of [ Manchester] 2.2544545572600327e-06\n",
            "loss 14.202 = 14.197 + 0.005 + 0.0 avg prob of [ Manchester] 2.8168219614599366e-06\n",
            "loss 14.021 = 14.016 + 0.005 + 0.0 avg prob of [ Manchester] 3.5423527151579037e-06\n",
            "loss 13.837 = 13.83 + 0.006 + 0.0 avg prob of [ Manchester] 4.4817611524194945e-06\n",
            "loss 13.649 = 13.642 + 0.007 + 0.0 avg prob of [ Manchester] 5.702503131033154e-06\n",
            "loss 13.457 = 13.45 + 0.007 + 0.0 avg prob of [ Manchester] 7.294265287782764e-06\n",
            "loss 13.263 = 13.255 + 0.008 + 0.0 avg prob of [ Manchester] 9.375808986078482e-06\n",
            "loss 13.065 = 13.057 + 0.009 + 0.0 avg prob of [ Manchester] 1.2104090274078771e-05\n",
            "loss 12.865 = 12.855 + 0.01 + 0.0 avg prob of [ Manchester] 1.56851347128395e-05\n",
            "Delta norm: 355.2249450683594\n",
            "Change in target norm: 1595.7017822265625 to 1632.47119140625 => 36.7694091796875\n",
            "Division Factor: 11.438287734985352\n",
            "Right vector norm: 31.0557804107666\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 89% 445/500 [2:06:10<15:52, 17.31s/it]Executing ROME algorithm for the update: [Fantastyka, that was from] -> [ Australia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Fantastyka\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Fantastyka, that was from | Token: ka\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.132 = 14.132 + 0.0 + 0.0 avg prob of [ Australia] 1.1279017826382187e-06\n",
            "loss 14.126 = 14.126 + 0.0 + 0.0 avg prob of [ Australia] 1.1322151749482146e-06\n",
            "loss 14.119 = 14.119 + 0.0 + 0.0 avg prob of [ Australia] 1.137360186476144e-06\n",
            "loss 14.112 = 14.112 + 0.0 + 0.0 avg prob of [ Australia] 1.1435840860940516e-06\n",
            "loss 14.103 = 14.103 + 0.0 + 0.0 avg prob of [ Australia] 1.1512215678521898e-06\n",
            "loss 14.092 = 14.092 + 0.0 + 0.0 avg prob of [ Australia] 1.1607670558078098e-06\n",
            "loss 14.078 = 14.078 + 0.0 + 0.0 avg prob of [ Australia] 1.1729541711247293e-06\n",
            "loss 14.062 = 14.062 + 0.0 + 0.0 avg prob of [ Australia] 1.1888519111380447e-06\n",
            "loss 14.042 = 14.041 + 0.0 + 0.0 avg prob of [ Australia] 1.2099594641767908e-06\n",
            "loss 14.016 = 14.016 + 0.0 + 0.0 avg prob of [ Australia] 1.2383289913486806e-06\n",
            "loss 13.984 = 13.983 + 0.0 + 0.0 avg prob of [ Australia] 1.2766971622113488e-06\n",
            "loss 13.944 = 13.944 + 0.0 + 0.0 avg prob of [ Australia] 1.3287548199514276e-06\n",
            "loss 13.897 = 13.897 + 0.0 + 0.0 avg prob of [ Australia] 1.399556595060858e-06\n",
            "loss 13.841 = 13.841 + 0.0 + 0.0 avg prob of [ Australia] 1.4966448134146049e-06\n",
            "loss 13.776 = 13.776 + 0.001 + 0.0 avg prob of [ Australia] 1.6320828990501468e-06\n",
            "loss 13.703 = 13.703 + 0.001 + 0.0 avg prob of [ Australia] 1.822926378736156e-06\n",
            "loss 13.623 = 13.623 + 0.001 + 0.0 avg prob of [ Australia] 2.087046595988795e-06\n",
            "loss 13.539 = 13.538 + 0.001 + 0.0 avg prob of [ Australia] 2.4365501758438768e-06\n",
            "loss 13.453 = 13.452 + 0.001 + 0.0 avg prob of [ Australia] 2.8711501727229916e-06\n",
            "loss 13.366 = 13.365 + 0.001 + 0.0 avg prob of [ Australia] 3.376962240508874e-06\n",
            "Delta norm: 347.51275634765625\n",
            "Change in target norm: 5184.0 to 5202.18408203125 => 18.18408203125\n",
            "Division Factor: 8.017241477966309\n",
            "Right vector norm: 43.34567642211914\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 89% 446/500 [2:06:26<15:05, 16.78s/it]Executing ROME algorithm for the update: [Alpha Island belongs to the continent of] -> [ Europe]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alpha Island\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Alpha Island belongs to the continent of | Token:  Island\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.522 = 13.522 + 0.0 + 0.0 avg prob of [ Europe] 4.581034318107413e-06\n",
            "loss 13.456 = 13.456 + 0.0 + 0.0 avg prob of [ Europe] 4.859424279857194e-06\n",
            "loss 13.385 = 13.385 + 0.0 + 0.0 avg prob of [ Europe] 5.181347205507336e-06\n",
            "loss 13.308 = 13.308 + 0.0 + 0.0 avg prob of [ Europe] 5.555129519052571e-06\n",
            "loss 13.227 = 13.227 + 0.0 + 0.0 avg prob of [ Europe] 5.991069429001072e-06\n",
            "loss 13.141 = 13.141 + 0.0 + 0.0 avg prob of [ Europe] 6.501953976112418e-06\n",
            "loss 13.05 = 13.049 + 0.0 + 0.0 avg prob of [ Europe] 7.1037543420970906e-06\n",
            "loss 12.954 = 12.953 + 0.0 + 0.0 avg prob of [ Europe] 7.816330253263004e-06\n",
            "loss 12.853 = 12.853 + 0.0 + 0.0 avg prob of [ Europe] 8.664423148729838e-06\n",
            "loss 12.748 = 12.747 + 0.0 + 0.0 avg prob of [ Europe] 9.678673450252973e-06\n",
            "loss 12.639 = 12.638 + 0.001 + 0.0 avg prob of [ Europe] 1.0896798812609632e-05\n",
            "loss 12.527 = 12.526 + 0.001 + 0.0 avg prob of [ Europe] 1.2364823305688333e-05\n",
            "loss 12.411 = 12.41 + 0.001 + 0.0 avg prob of [ Europe] 1.413834161212435e-05\n",
            "loss 12.293 = 12.292 + 0.001 + 0.0 avg prob of [ Europe] 1.6283580407616682e-05\n",
            "loss 12.172 = 12.171 + 0.001 + 0.0 avg prob of [ Europe] 1.8877839465858415e-05\n",
            "loss 12.05 = 12.049 + 0.001 + 0.0 avg prob of [ Europe] 2.2009171516401693e-05\n",
            "loss 11.927 = 11.925 + 0.001 + 0.0 avg prob of [ Europe] 2.5775965696084313e-05\n",
            "loss 11.802 = 11.801 + 0.001 + 0.0 avg prob of [ Europe] 3.0286724722827785e-05\n",
            "loss 11.677 = 11.675 + 0.002 + 0.0 avg prob of [ Europe] 3.566202212823555e-05\n",
            "loss 11.551 = 11.549 + 0.002 + 0.0 avg prob of [ Europe] 4.203934804536402e-05\n",
            "Delta norm: 374.8569641113281\n",
            "Change in target norm: 3311.156005859375 to 3333.844970703125 => 22.68896484375\n",
            "Division Factor: 7.27510404586792\n",
            "Right vector norm: 51.525997161865234\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 89% 447/500 [2:06:42<14:29, 16.40s/it]Executing ROME algorithm for the update: [Marcus Harvey was native to] -> [ Paris]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Marcus Harvey\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Marcus Harvey was native to | Token:  Harvey\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.097 = 10.097 + 0.0 + 0.0 avg prob of [ Paris] 0.00014057978114578873\n",
            "loss 10.071 = 10.071 + 0.0 + 0.0 avg prob of [ Paris] 0.00014450175513047725\n",
            "loss 10.043 = 10.043 + 0.0 + 0.0 avg prob of [ Paris] 0.00014858094800729305\n",
            "loss 10.014 = 10.014 + 0.0 + 0.0 avg prob of [ Paris] 0.00015288646682165563\n",
            "loss 9.984 = 9.983 + 0.001 + 0.0 avg prob of [ Paris] 0.00015750624879729003\n",
            "loss 9.951 = 9.95 + 0.001 + 0.0 avg prob of [ Paris] 0.00016254631918855011\n",
            "loss 9.916 = 9.915 + 0.001 + 0.0 avg prob of [ Paris] 0.00016813728143461049\n",
            "loss 9.878 = 9.876 + 0.002 + 0.0 avg prob of [ Paris] 0.000174449072801508\n",
            "loss 9.836 = 9.834 + 0.002 + 0.0 avg prob of [ Paris] 0.00018170615658164024\n",
            "loss 9.791 = 9.788 + 0.003 + 0.0 avg prob of [ Paris] 0.00019021394837182015\n",
            "loss 9.741 = 9.738 + 0.003 + 0.0 avg prob of [ Paris] 0.00020041197421960533\n",
            "loss 9.687 = 9.683 + 0.004 + 0.0 avg prob of [ Paris] 0.00021295751503203064\n",
            "loss 9.628 = 9.623 + 0.004 + 0.0 avg prob of [ Paris] 0.00022888999956194311\n",
            "loss 9.563 = 9.558 + 0.005 + 0.0 avg prob of [ Paris] 0.00024994902196340263\n",
            "loss 9.492 = 9.486 + 0.006 + 0.0 avg prob of [ Paris] 0.0002792215091176331\n",
            "loss 9.414 = 9.407 + 0.007 + 0.0 avg prob of [ Paris] 0.00032256339909508824\n",
            "loss 9.329 = 9.321 + 0.007 + 0.0 avg prob of [ Paris] 0.00039159355219453573\n",
            "loss 9.237 = 9.228 + 0.008 + 0.0 avg prob of [ Paris] 0.0005095381056889892\n",
            "loss 9.137 = 9.128 + 0.009 + 0.0 avg prob of [ Paris] 0.0007210568874143064\n",
            "loss 9.032 = 9.022 + 0.01 + 0.0 avg prob of [ Paris] 0.0011069143656641245\n",
            "Delta norm: 348.319580078125\n",
            "Change in target norm: 983.6883544921875 to 1064.3897705078125 => 80.701416015625\n",
            "Division Factor: 8.759917259216309\n",
            "Right vector norm: 39.76288604736328\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 90% 448/500 [2:06:56<13:45, 15.88s/it]Executing ROME algorithm for the update: [The original language of The Register was] -> [ Italian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Register\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The original language of The Register was | Token:  Register\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.247 = 10.247 + 0.0 + 0.0 avg prob of [ Italian] 3.671641388791613e-05\n",
            "loss 10.238 = 10.238 + 0.0 + 0.0 avg prob of [ Italian] 3.7077796150697395e-05\n",
            "loss 10.227 = 10.227 + 0.0 + 0.0 avg prob of [ Italian] 3.749024835997261e-05\n",
            "loss 10.215 = 10.215 + 0.0 + 0.0 avg prob of [ Italian] 3.796460805460811e-05\n",
            "loss 10.201 = 10.201 + 0.0 + 0.0 avg prob of [ Italian] 3.8514619518537074e-05\n",
            "loss 10.186 = 10.186 + 0.0 + 0.0 avg prob of [ Italian] 3.9156078855739906e-05\n",
            "loss 10.168 = 10.168 + 0.0 + 0.0 avg prob of [ Italian] 3.990799450548366e-05\n",
            "loss 10.148 = 10.148 + 0.0 + 0.0 avg prob of [ Italian] 4.0793645894154906e-05\n",
            "loss 10.126 = 10.126 + 0.0 + 0.0 avg prob of [ Italian] 4.1841653001029044e-05\n",
            "loss 10.1 = 10.1 + 0.0 + 0.0 avg prob of [ Italian] 4.308638017391786e-05\n",
            "loss 10.071 = 10.07 + 0.0 + 0.0 avg prob of [ Italian] 4.456851092982106e-05\n",
            "loss 10.037 = 10.037 + 0.0 + 0.0 avg prob of [ Italian] 4.633462958736345e-05\n",
            "loss 10.0 = 10.0 + 0.0 + 0.0 avg prob of [ Italian] 4.843620990868658e-05\n",
            "loss 9.958 = 9.958 + 0.0 + 0.0 avg prob of [ Italian] 5.0927745178341866e-05\n",
            "loss 9.912 = 9.911 + 0.0 + 0.0 avg prob of [ Italian] 5.386629709391855e-05\n",
            "loss 9.86 = 9.86 + 0.0 + 0.0 avg prob of [ Italian] 5.731450073653832e-05\n",
            "loss 9.804 = 9.804 + 0.0 + 0.0 avg prob of [ Italian] 6.134332943474874e-05\n",
            "loss 9.743 = 9.743 + 0.0 + 0.0 avg prob of [ Italian] 6.60344521747902e-05\n",
            "loss 9.678 = 9.677 + 0.001 + 0.0 avg prob of [ Italian] 7.148185250116512e-05\n",
            "loss 9.608 = 9.607 + 0.001 + 0.0 avg prob of [ Italian] 7.779139559715986e-05\n",
            "Delta norm: 361.36163330078125\n",
            "Change in target norm: 3559.889892578125 to 3586.35888671875 => 26.468994140625\n",
            "Division Factor: 10.146178245544434\n",
            "Right vector norm: 35.615543365478516\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 90% 449/500 [2:07:12<13:25, 15.78s/it]Executing ROME algorithm for the update: [Keith Emerson performs on the] -> [ guitar]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Keith Emerson\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Keith Emerson performs on the | Token:  Emerson\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.48 = 9.48 + 0.0 + 0.0 avg prob of [ guitar] 0.00036418146919459105\n",
            "loss 9.087 = 9.087 + 0.0 + 0.0 avg prob of [ guitar] 0.0006181328790262341\n",
            "loss 8.697 = 8.697 + 0.0 + 0.0 avg prob of [ guitar] 0.001067544799298048\n",
            "loss 8.311 = 8.311 + 0.0 + 0.0 avg prob of [ guitar] 0.0018545675557106733\n",
            "loss 7.929 = 7.928 + 0.001 + 0.0 avg prob of [ guitar] 0.003200983162969351\n",
            "loss 7.551 = 7.551 + 0.001 + 0.0 avg prob of [ guitar] 0.005418338347226381\n",
            "loss 7.179 = 7.178 + 0.001 + 0.0 avg prob of [ guitar] 0.00887935608625412\n",
            "loss 6.814 = 6.812 + 0.002 + 0.0 avg prob of [ guitar] 0.013921617530286312\n",
            "loss 6.455 = 6.452 + 0.003 + 0.0 avg prob of [ guitar] 0.020705781877040863\n",
            "loss 6.105 = 6.101 + 0.004 + 0.0 avg prob of [ guitar] 0.02913457527756691\n",
            "loss 5.763 = 5.758 + 0.005 + 0.0 avg prob of [ guitar] 0.03892971947789192\n",
            "loss 5.431 = 5.424 + 0.007 + 0.0 avg prob of [ guitar] 0.049794089049100876\n",
            "loss 5.108 = 5.1 + 0.008 + 0.0 avg prob of [ guitar] 0.06150522828102112\n",
            "loss 4.796 = 4.786 + 0.01 + 0.0 avg prob of [ guitar] 0.0739336684346199\n",
            "loss 4.494 = 4.481 + 0.013 + 0.0 avg prob of [ guitar] 0.08707181364297867\n",
            "loss 4.202 = 4.186 + 0.015 + 0.0 avg prob of [ guitar] 0.10106375068426132\n",
            "loss 3.92 = 3.902 + 0.018 + 0.0 avg prob of [ guitar] 0.1161787211894989\n",
            "loss 3.649 = 3.628 + 0.021 + 0.0 avg prob of [ guitar] 0.13272882997989655\n",
            "loss 3.389 = 3.365 + 0.024 + 0.0 avg prob of [ guitar] 0.1509835571050644\n",
            "loss 3.141 = 3.114 + 0.028 + 0.0 avg prob of [ guitar] 0.17110811173915863\n",
            "Delta norm: 351.8463439941406\n",
            "Change in target norm: 1254.42578125 to 1343.537353515625 => 89.111572265625\n",
            "Division Factor: 9.048493385314941\n",
            "Right vector norm: 38.884521484375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 90% 450/500 [2:07:26<12:52, 15.45s/it]Executing ROME algorithm for the update: [Where is Uruguayan War? It is located in] -> [ Wales]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Uruguayan War\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Where is Uruguayan War? It is located in | Token:  War\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.786 = 14.786 + 0.0 + 0.0 avg prob of [ Wales] 1.3105413927405607e-06\n",
            "loss 14.177 = 14.177 + 0.0 + 0.0 avg prob of [ Wales] 2.18935724660696e-06\n",
            "loss 13.552 = 13.551 + 0.001 + 0.0 avg prob of [ Wales] 4.461436219571624e-06\n",
            "loss 12.907 = 12.905 + 0.002 + 0.0 avg prob of [ Wales] 1.0626567927829456e-05\n",
            "loss 12.237 = 12.233 + 0.003 + 0.0 avg prob of [ Wales] 2.7100564693682827e-05\n",
            "loss 11.539 = 11.533 + 0.005 + 0.0 avg prob of [ Wales] 7.17744987923652e-05\n",
            "loss 10.83 = 10.822 + 0.008 + 0.0 avg prob of [ Wales] 0.00019860388420056552\n",
            "loss 10.147 = 10.136 + 0.01 + 0.0 avg prob of [ Wales] 0.0005697915330529213\n",
            "loss 9.501 = 9.488 + 0.013 + 0.0 avg prob of [ Wales] 0.0016220146790146828\n",
            "loss 8.876 = 8.859 + 0.017 + 0.0 avg prob of [ Wales] 0.004624586086720228\n",
            "loss 8.257 = 8.236 + 0.02 + 0.0 avg prob of [ Wales] 0.01344782393425703\n",
            "loss 7.659 = 7.634 + 0.024 + 0.0 avg prob of [ Wales] 0.03546581789851189\n",
            "loss 7.103 = 7.075 + 0.028 + 0.001 avg prob of [ Wales] 0.07205606997013092\n",
            "loss 6.592 = 6.56 + 0.031 + 0.001 avg prob of [ Wales] 0.11277560144662857\n",
            "loss 6.122 = 6.086 + 0.035 + 0.001 avg prob of [ Wales] 0.15078747272491455\n",
            "loss 5.689 = 5.649 + 0.039 + 0.001 avg prob of [ Wales] 0.18488329648971558\n",
            "loss 5.288 = 5.244 + 0.043 + 0.001 avg prob of [ Wales] 0.21431396901607513\n",
            "loss 4.913 = 4.865 + 0.047 + 0.001 avg prob of [ Wales] 0.2403864711523056\n",
            "loss 4.563 = 4.511 + 0.051 + 0.001 avg prob of [ Wales] 0.2662569582462311\n",
            "loss 4.236 = 4.179 + 0.056 + 0.001 avg prob of [ Wales] 0.2940640151500702\n",
            "Delta norm: 306.8119201660156\n",
            "Change in target norm: 442.6072082519531 to 537.9784545898438 => 95.37124633789062\n",
            "Division Factor: 8.209989547729492\n",
            "Right vector norm: 37.37055969238281\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 90% 451/500 [2:07:47<13:46, 16.88s/it]Executing ROME algorithm for the update: [Bundesautobahn 5 is from] -> [ Microsoft]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bundesautobahn 5\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Bundesautobahn 5 is from | Token:  5\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.014 = 14.014 + 0.0 + 0.0 avg prob of [ Microsoft] 5.064749075245345e-06\n",
            "loss 13.956 = 13.956 + 0.0 + 0.0 avg prob of [ Microsoft] 5.368877282307949e-06\n",
            "loss 13.894 = 13.894 + 0.0 + 0.0 avg prob of [ Microsoft] 5.7048091548494995e-06\n",
            "loss 13.827 = 13.826 + 0.0 + 0.0 avg prob of [ Microsoft] 6.077344096411252e-06\n",
            "loss 13.754 = 13.754 + 0.001 + 0.0 avg prob of [ Microsoft] 6.492511602118611e-06\n",
            "loss 13.677 = 13.676 + 0.001 + 0.0 avg prob of [ Microsoft] 6.957947334740311e-06\n",
            "loss 13.594 = 13.593 + 0.001 + 0.0 avg prob of [ Microsoft] 7.4831423262367025e-06\n",
            "loss 13.506 = 13.504 + 0.002 + 0.0 avg prob of [ Microsoft] 8.079926374193747e-06\n",
            "loss 13.412 = 13.409 + 0.002 + 0.0 avg prob of [ Microsoft] 8.763004188949708e-06\n",
            "loss 13.312 = 13.309 + 0.003 + 0.0 avg prob of [ Microsoft] 9.5504910859745e-06\n",
            "loss 13.207 = 13.203 + 0.004 + 0.0 avg prob of [ Microsoft] 1.0463862054166384e-05\n",
            "loss 13.097 = 13.092 + 0.005 + 0.0 avg prob of [ Microsoft] 1.1527229617058765e-05\n",
            "loss 12.981 = 12.975 + 0.006 + 0.0 avg prob of [ Microsoft] 1.2768196938850451e-05\n",
            "loss 12.861 = 12.854 + 0.007 + 0.0 avg prob of [ Microsoft] 1.4222306162992027e-05\n",
            "loss 12.736 = 12.728 + 0.008 + 0.0 avg prob of [ Microsoft] 1.5937912394292653e-05\n",
            "loss 12.608 = 12.599 + 0.009 + 0.0 avg prob of [ Microsoft] 1.7978572941501625e-05\n",
            "loss 12.477 = 12.466 + 0.011 + 0.0 avg prob of [ Microsoft] 2.0422467059688643e-05\n",
            "loss 12.342 = 12.329 + 0.012 + 0.0 avg prob of [ Microsoft] 2.336147917958442e-05\n",
            "loss 12.204 = 12.19 + 0.014 + 0.0 avg prob of [ Microsoft] 2.690422479645349e-05\n",
            "loss 12.063 = 12.047 + 0.016 + 0.0 avg prob of [ Microsoft] 3.118363383691758e-05\n",
            "Delta norm: 370.03460693359375\n",
            "Change in target norm: 1519.176025390625 to 1568.4755859375 => 49.299560546875\n",
            "Division Factor: 5.097492694854736\n",
            "Right vector norm: 72.59149169921875\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 90% 452/500 [2:08:02<13:09, 16.45s/it]Executing ROME algorithm for the update: [Lake Bluff is in] -> [ Cambodia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Lake Bluff\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Lake Bluff is in | Token: uff\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.947 = 14.947 + 0.0 + 0.0 avg prob of [ Cambodia] 6.648991075053345e-06\n",
            "loss 14.801 = 14.801 + 0.0 + 0.0 avg prob of [ Cambodia] 8.034008715185337e-06\n",
            "loss 14.663 = 14.663 + 0.0 + 0.0 avg prob of [ Cambodia] 9.668487109593116e-06\n",
            "loss 14.53 = 14.53 + 0.0 + 0.0 avg prob of [ Cambodia] 1.1631469533313066e-05\n",
            "loss 14.401 = 14.401 + 0.0 + 0.0 avg prob of [ Cambodia] 1.4031313185114413e-05\n",
            "loss 14.271 = 14.271 + 0.0 + 0.0 avg prob of [ Cambodia] 1.7009206203510985e-05\n",
            "loss 14.14 = 14.14 + 0.001 + 0.0 avg prob of [ Cambodia] 2.075125121336896e-05\n",
            "loss 14.006 = 14.005 + 0.001 + 0.0 avg prob of [ Cambodia] 2.5502553398837335e-05\n",
            "loss 13.866 = 13.865 + 0.001 + 0.0 avg prob of [ Cambodia] 3.158639810862951e-05\n",
            "loss 13.721 = 13.72 + 0.001 + 0.0 avg prob of [ Cambodia] 3.9432055928045884e-05\n",
            "loss 13.57 = 13.568 + 0.001 + 0.0 avg prob of [ Cambodia] 4.961662125424482e-05\n",
            "loss 13.412 = 13.41 + 0.002 + 0.0 avg prob of [ Cambodia] 6.291938188951463e-05\n",
            "loss 13.247 = 13.245 + 0.002 + 0.0 avg prob of [ Cambodia] 8.040762622840703e-05\n",
            "loss 13.074 = 13.072 + 0.002 + 0.0 avg prob of [ Cambodia] 0.00010355014819651842\n",
            "loss 12.895 = 12.893 + 0.002 + 0.0 avg prob of [ Cambodia] 0.00013438085443340242\n",
            "loss 12.709 = 12.706 + 0.003 + 0.0 avg prob of [ Cambodia] 0.00017573112563695759\n",
            "loss 12.516 = 12.512 + 0.003 + 0.0 avg prob of [ Cambodia] 0.00023155509552452713\n",
            "loss 12.315 = 12.311 + 0.004 + 0.0 avg prob of [ Cambodia] 0.00030740839429199696\n",
            "loss 12.107 = 12.103 + 0.004 + 0.0 avg prob of [ Cambodia] 0.00041115673957392573\n",
            "loss 11.891 = 11.887 + 0.004 + 0.0 avg prob of [ Cambodia] 0.0005540300044231117\n",
            "Delta norm: 331.871337890625\n",
            "Change in target norm: 2195.86962890625 to 2219.780517578125 => 23.910888671875\n",
            "Division Factor: 12.746644973754883\n",
            "Right vector norm: 26.03597640991211\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 91% 453/500 [2:08:17<12:27, 15.90s/it]Executing ROME algorithm for the update: [What sport does R.A. Dickey play? They play] -> [ soccer]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object R.A. Dickey\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: What sport does R.A. Dickey play? They play | Token: ickey\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.765 = 14.765 + 0.0 + 0.0 avg prob of [ soccer] 9.043795330399007e-07\n",
            "loss 14.735 = 14.735 + 0.0 + 0.0 avg prob of [ soccer] 9.265679068448662e-07\n",
            "loss 14.7 = 14.7 + 0.0 + 0.0 avg prob of [ soccer] 9.527018960397982e-07\n",
            "loss 14.661 = 14.661 + 0.0 + 0.0 avg prob of [ soccer] 9.82983465291909e-07\n",
            "loss 14.617 = 14.617 + 0.0 + 0.0 avg prob of [ soccer] 1.0174999260925688e-06\n",
            "loss 14.568 = 14.568 + 0.0 + 0.0 avg prob of [ soccer] 1.0563106798144872e-06\n",
            "loss 14.515 = 14.515 + 0.0 + 0.0 avg prob of [ soccer] 1.0995701131832902e-06\n",
            "loss 14.457 = 14.457 + 0.0 + 0.0 avg prob of [ soccer] 1.1475764267743216e-06\n",
            "loss 14.395 = 14.394 + 0.001 + 0.0 avg prob of [ soccer] 1.2009073770968826e-06\n",
            "loss 14.328 = 14.327 + 0.001 + 0.0 avg prob of [ soccer] 1.260422664017824e-06\n",
            "loss 14.256 = 14.255 + 0.001 + 0.0 avg prob of [ soccer] 1.3272863270685775e-06\n",
            "loss 14.179 = 14.178 + 0.001 + 0.0 avg prob of [ soccer] 1.4029434396434226e-06\n",
            "loss 14.096 = 14.095 + 0.001 + 0.0 avg prob of [ soccer] 1.489054170633608e-06\n",
            "loss 14.008 = 14.006 + 0.002 + 0.0 avg prob of [ soccer] 1.5875137933107908e-06\n",
            "loss 13.914 = 13.912 + 0.002 + 0.0 avg prob of [ soccer] 1.7004583696689224e-06\n",
            "loss 13.813 = 13.811 + 0.002 + 0.0 avg prob of [ soccer] 1.8303045408174512e-06\n",
            "loss 13.707 = 13.705 + 0.002 + 0.0 avg prob of [ soccer] 1.979795115403249e-06\n",
            "loss 13.595 = 13.593 + 0.003 + 0.0 avg prob of [ soccer] 2.152064325855463e-06\n",
            "loss 13.478 = 13.475 + 0.003 + 0.0 avg prob of [ soccer] 2.3506945581175387e-06\n",
            "loss 13.356 = 13.352 + 0.003 + 0.0 avg prob of [ soccer] 2.579718056949787e-06\n",
            "Delta norm: 371.2532043457031\n",
            "Change in target norm: 3037.61181640625 to 3070.207275390625 => 32.595458984375\n",
            "Division Factor: 10.493324279785156\n",
            "Right vector norm: 35.37994384765625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 91% 454/500 [2:08:38<13:20, 17.39s/it]Executing ROME algorithm for the update: [Skag premieres on] -> [ CBS]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Skag\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Skag premieres on | Token: ag\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.11 = 12.11 + 0.0 + 0.0 avg prob of [ CBS] 8.054501449805684e-06\n",
            "loss 12.052 = 12.052 + 0.0 + 0.0 avg prob of [ CBS] 8.566426913603209e-06\n",
            "loss 11.982 = 11.982 + 0.0 + 0.0 avg prob of [ CBS] 9.233944183506537e-06\n",
            "loss 11.896 = 11.896 + 0.0 + 0.0 avg prob of [ CBS] 1.0099798601004295e-05\n",
            "loss 11.796 = 11.795 + 0.0 + 0.0 avg prob of [ CBS] 1.1224001355003566e-05\n",
            "loss 11.679 = 11.678 + 0.001 + 0.0 avg prob of [ CBS] 1.268317373614991e-05\n",
            "loss 11.546 = 11.545 + 0.001 + 0.0 avg prob of [ CBS] 1.4568524420610629e-05\n",
            "loss 11.4 = 11.398 + 0.001 + 0.0 avg prob of [ CBS] 1.6985768525046296e-05\n",
            "loss 11.24 = 11.239 + 0.001 + 0.0 avg prob of [ CBS] 2.005348687816877e-05\n",
            "loss 11.071 = 11.069 + 0.002 + 0.0 avg prob of [ CBS] 2.3907363356556743e-05\n",
            "loss 10.895 = 10.893 + 0.002 + 0.0 avg prob of [ CBS] 2.8708040190394968e-05\n",
            "loss 10.714 = 10.711 + 0.003 + 0.0 avg prob of [ CBS] 3.4643093385966495e-05\n",
            "loss 10.53 = 10.527 + 0.003 + 0.0 avg prob of [ CBS] 4.193962013232522e-05\n",
            "loss 10.345 = 10.341 + 0.004 + 0.0 avg prob of [ CBS] 5.089475598651916e-05\n",
            "loss 10.158 = 10.153 + 0.004 + 0.0 avg prob of [ CBS] 6.191928696352988e-05\n",
            "loss 9.969 = 9.964 + 0.005 + 0.0 avg prob of [ CBS] 7.55887886043638e-05\n",
            "loss 9.777 = 9.771 + 0.006 + 0.0 avg prob of [ CBS] 9.269782458432019e-05\n",
            "loss 9.582 = 9.576 + 0.006 + 0.0 avg prob of [ CBS] 0.00011432349856477231\n",
            "loss 9.384 = 9.376 + 0.007 + 0.0 avg prob of [ CBS] 0.00014191301306709647\n",
            "loss 9.181 = 9.173 + 0.008 + 0.0 avg prob of [ CBS] 0.0001774081028997898\n",
            "Delta norm: 346.929931640625\n",
            "Change in target norm: 1853.068115234375 to 1884.9638671875 => 31.895751953125\n",
            "Division Factor: 9.227347373962402\n",
            "Right vector norm: 37.59801483154297\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 91% 455/500 [2:08:52<12:25, 16.57s/it]Executing ROME algorithm for the update: [Acrassicauda originated in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Acrassicauda\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Acrassicauda originated in | Token: a\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.612 = 14.612 + 0.0 + 0.0 avg prob of [ London] 8.26787356800196e-07\n",
            "loss 14.569 = 14.569 + 0.0 + 0.0 avg prob of [ London] 8.555262525078433e-07\n",
            "loss 14.519 = 14.519 + 0.0 + 0.0 avg prob of [ London] 8.908404538487957e-07\n",
            "loss 14.46 = 14.46 + 0.0 + 0.0 avg prob of [ London] 9.347946274829155e-07\n",
            "loss 14.39 = 14.39 + 0.0 + 0.0 avg prob of [ London] 9.901933708533761e-07\n",
            "loss 14.308 = 14.308 + 0.0 + 0.0 avg prob of [ London] 1.0609783203108236e-06\n",
            "loss 14.212 = 14.211 + 0.0 + 0.0 avg prob of [ London] 1.1528472896316089e-06\n",
            "loss 14.101 = 14.1 + 0.0 + 0.0 avg prob of [ London] 1.2742800663545495e-06\n",
            "loss 13.974 = 13.973 + 0.001 + 0.0 avg prob of [ London] 1.438451249669015e-06\n",
            "loss 13.831 = 13.83 + 0.001 + 0.0 avg prob of [ London] 1.6668464013491757e-06\n",
            "loss 13.673 = 13.672 + 0.001 + 0.0 avg prob of [ London] 1.996580294871819e-06\n",
            "loss 13.5 = 13.499 + 0.001 + 0.0 avg prob of [ London] 2.4951939394668443e-06\n",
            "loss 13.315 = 13.313 + 0.001 + 0.0 avg prob of [ London] 3.28891837853007e-06\n",
            "loss 13.119 = 13.118 + 0.002 + 0.0 avg prob of [ London] 4.609484676620923e-06\n",
            "loss 12.916 = 12.914 + 0.002 + 0.0 avg prob of [ London] 6.850745194242336e-06\n",
            "loss 12.706 = 12.704 + 0.002 + 0.0 avg prob of [ London] 1.0596320862532593e-05\n",
            "loss 12.492 = 12.489 + 0.003 + 0.0 avg prob of [ London] 1.657769098528661e-05\n",
            "loss 12.274 = 12.27 + 0.003 + 0.0 avg prob of [ London] 2.5613006073399447e-05\n",
            "loss 12.051 = 12.047 + 0.004 + 0.0 avg prob of [ London] 3.8660600694129243e-05\n",
            "loss 11.824 = 11.82 + 0.004 + 0.0 avg prob of [ London] 5.7041084801312536e-05\n",
            "Delta norm: 363.6197814941406\n",
            "Change in target norm: 2485.170654296875 to 2517.29833984375 => 32.127685546875\n",
            "Division Factor: 7.99877405166626\n",
            "Right vector norm: 45.45943832397461\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 91% 456/500 [2:09:08<11:55, 16.25s/it]Executing ROME algorithm for the update: [Trinidad, named for] -> [ Indianapolis]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Trinidad\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Trinidad, named for | Token: idad\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.43 = 11.43 + 0.0 + 0.0 avg prob of [ Indianapolis] 2.8766182367689908e-05\n",
            "loss 11.395 = 11.395 + 0.0 + 0.0 avg prob of [ Indianapolis] 2.9558765163528733e-05\n",
            "loss 11.36 = 11.36 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.036566158698406e-05\n",
            "loss 11.326 = 11.326 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.118802123935893e-05\n",
            "loss 11.292 = 11.292 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.202708830940537e-05\n",
            "loss 11.258 = 11.258 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.288378138677217e-05\n",
            "loss 11.225 = 11.224 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.375932283233851e-05\n",
            "loss 11.191 = 11.191 + 0.0 + 0.0 avg prob of [ Indianapolis] 3.4655200579436496e-05\n",
            "loss 11.158 = 11.158 + 0.001 + 0.0 avg prob of [ Indianapolis] 3.5573524655774236e-05\n",
            "loss 11.126 = 11.125 + 0.001 + 0.0 avg prob of [ Indianapolis] 3.6516816180665046e-05\n",
            "loss 11.093 = 11.092 + 0.001 + 0.0 avg prob of [ Indianapolis] 3.748790186364204e-05\n",
            "loss 11.06 = 11.059 + 0.001 + 0.0 avg prob of [ Indianapolis] 3.8489924918394536e-05\n",
            "loss 11.028 = 11.026 + 0.001 + 0.0 avg prob of [ Indianapolis] 3.952642873628065e-05\n",
            "loss 10.995 = 10.993 + 0.001 + 0.0 avg prob of [ Indianapolis] 4.060120409121737e-05\n",
            "loss 10.962 = 10.96 + 0.002 + 0.0 avg prob of [ Indianapolis] 4.1718412830960006e-05\n",
            "loss 10.929 = 10.927 + 0.002 + 0.0 avg prob of [ Indianapolis] 4.288255513529293e-05\n",
            "loss 10.896 = 10.894 + 0.002 + 0.0 avg prob of [ Indianapolis] 4.409849498188123e-05\n",
            "loss 10.862 = 10.86 + 0.002 + 0.0 avg prob of [ Indianapolis] 4.5371420128503814e-05\n",
            "loss 10.829 = 10.826 + 0.003 + 0.0 avg prob of [ Indianapolis] 4.67071367893368e-05\n",
            "loss 10.795 = 10.792 + 0.003 + 0.0 avg prob of [ Indianapolis] 4.811177132069133e-05\n",
            "Delta norm: 357.8061218261719\n",
            "Change in target norm: 3511.377197265625 to 3521.183837890625 => 9.806640625\n",
            "Division Factor: 4.206821441650391\n",
            "Right vector norm: 85.05379486083984\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 91% 457/500 [2:09:21<11:03, 15.42s/it]Executing ROME algorithm for the update: [What does Alex Cline play? They play] -> [ opera]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alex Cline\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: What does Alex Cline play? They play | Token: ine\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 19.395 = 19.395 + 0.0 + 0.0 avg prob of [ opera] 9.603461137430713e-09\n",
            "loss 19.257 = 19.257 + 0.0 + 0.0 avg prob of [ opera] 1.0148697882073066e-08\n",
            "loss 19.101 = 19.101 + 0.0 + 0.0 avg prob of [ opera] 1.0864237509622399e-08\n",
            "loss 18.926 = 18.926 + 0.0 + 0.0 avg prob of [ opera] 1.1801722266113757e-08\n",
            "loss 18.735 = 18.735 + 0.0 + 0.0 avg prob of [ opera] 1.3029787027107886e-08\n",
            "loss 18.532 = 18.531 + 0.0 + 0.0 avg prob of [ opera] 1.4638515288822873e-08\n",
            "loss 18.32 = 18.32 + 0.001 + 0.0 avg prob of [ opera] 1.6731078744669503e-08\n",
            "loss 18.108 = 18.107 + 0.001 + 0.0 avg prob of [ opera] 1.9401289463871763e-08\n",
            "loss 17.9 = 17.899 + 0.001 + 0.0 avg prob of [ opera] 2.271152865773729e-08\n",
            "loss 17.703 = 17.702 + 0.001 + 0.0 avg prob of [ opera] 2.6695239796481474e-08\n",
            "loss 17.518 = 17.517 + 0.002 + 0.0 avg prob of [ opera] 3.1395277488854845e-08\n",
            "loss 17.343 = 17.341 + 0.002 + 0.0 avg prob of [ opera] 3.691454608656386e-08\n",
            "loss 17.176 = 17.173 + 0.002 + 0.0 avg prob of [ opera] 4.3450043563098006e-08\n",
            "loss 17.012 = 17.009 + 0.003 + 0.0 avg prob of [ opera] 5.130028313260482e-08\n",
            "loss 16.85 = 16.847 + 0.003 + 0.0 avg prob of [ opera] 6.086801107585416e-08\n",
            "loss 16.688 = 16.684 + 0.003 + 0.0 avg prob of [ opera] 7.266621793178274e-08\n",
            "loss 16.524 = 16.52 + 0.004 + 0.0 avg prob of [ opera] 8.733812961736476e-08\n",
            "loss 16.358 = 16.354 + 0.004 + 0.0 avg prob of [ opera] 1.0569101505097933e-07\n",
            "loss 16.19 = 16.185 + 0.005 + 0.0 avg prob of [ opera] 1.2874559729425528e-07\n",
            "loss 16.017 = 16.012 + 0.005 + 0.0 avg prob of [ opera] 1.5780302931034385e-07\n",
            "Delta norm: 345.39947509765625\n",
            "Change in target norm: 1991.2786865234375 to 2023.9825439453125 => 32.703857421875\n",
            "Division Factor: 10.331379890441895\n",
            "Right vector norm: 33.43207550048828\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 92% 458/500 [2:09:40<11:28, 16.40s/it]Executing ROME algorithm for the update: [The Dennis O'Keefe Show is to debut on] -> [ NBC]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object The Dennis O'Keefe Show\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The Dennis O'Keefe Show is to debut on | Token:  Show\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.887 = 11.887 + 0.0 + 0.0 avg prob of [ NBC] 3.558391108526848e-05\n",
            "loss 11.724 = 11.724 + 0.0 + 0.0 avg prob of [ NBC] 4.2268271499779075e-05\n",
            "loss 11.556 = 11.556 + 0.0 + 0.0 avg prob of [ NBC] 5.070347469882108e-05\n",
            "loss 11.382 = 11.382 + 0.0 + 0.0 avg prob of [ NBC] 6.127593951532617e-05\n",
            "loss 11.203 = 11.202 + 0.001 + 0.0 avg prob of [ NBC] 7.4442257755436e-05\n",
            "loss 11.018 = 11.017 + 0.001 + 0.0 avg prob of [ NBC] 9.076187416212633e-05\n",
            "loss 10.828 = 10.826 + 0.002 + 0.0 avg prob of [ NBC] 0.0001109388904296793\n",
            "loss 10.629 = 10.627 + 0.002 + 0.0 avg prob of [ NBC] 0.00013586520799435675\n",
            "loss 10.422 = 10.419 + 0.003 + 0.0 avg prob of [ NBC] 0.00016667222371324897\n",
            "loss 10.206 = 10.202 + 0.004 + 0.0 avg prob of [ NBC] 0.0002047904272330925\n",
            "loss 9.979 = 9.974 + 0.005 + 0.0 avg prob of [ NBC] 0.00025202299002557993\n",
            "loss 9.742 = 9.736 + 0.006 + 0.0 avg prob of [ NBC] 0.00031066598603501916\n",
            "loss 9.495 = 9.488 + 0.007 + 0.0 avg prob of [ NBC] 0.00038375266012735665\n",
            "loss 9.241 = 9.232 + 0.009 + 0.0 avg prob of [ NBC] 0.0004754687543027103\n",
            "loss 8.981 = 8.969 + 0.011 + 0.0 avg prob of [ NBC] 0.0005918265087530017\n",
            "loss 8.719 = 8.705 + 0.014 + 0.0 avg prob of [ NBC] 0.0007415389991365373\n",
            "loss 8.459 = 8.442 + 0.017 + 0.0 avg prob of [ NBC] 0.0009368922328576446\n",
            "loss 8.205 = 8.183 + 0.022 + 0.0 avg prob of [ NBC] 0.0011947780149057508\n",
            "loss 7.958 = 7.929 + 0.029 + 0.0 avg prob of [ NBC] 0.0015381741104647517\n",
            "loss 7.719 = 7.68 + 0.039 + 0.0 avg prob of [ NBC] 0.001996937207877636\n",
            "Delta norm: 365.9101257324219\n",
            "Change in target norm: 1025.550537109375 to 1111.1295166015625 => 85.5789794921875\n",
            "Division Factor: 10.751680374145508\n",
            "Right vector norm: 34.032833099365234\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 92% 459/500 [2:09:59<11:45, 17.20s/it]Executing ROME algorithm for the update: [Alebtong District, in] -> [ Oslo]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alebtong District\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Alebtong District, in | Token:  District\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.998 = 10.998 + 0.0 + 0.0 avg prob of [ Oslo] 2.2811025701230392e-05\n",
            "loss 10.81 = 10.81 + 0.0 + 0.0 avg prob of [ Oslo] 2.772826155705843e-05\n",
            "loss 10.621 = 10.621 + 0.0 + 0.0 avg prob of [ Oslo] 3.399412162252702e-05\n",
            "loss 10.432 = 10.432 + 0.0 + 0.0 avg prob of [ Oslo] 4.205561344861053e-05\n",
            "loss 10.243 = 10.243 + 0.0 + 0.0 avg prob of [ Oslo] 5.252247137832455e-05\n",
            "loss 10.052 = 10.052 + 0.0 + 0.0 avg prob of [ Oslo] 6.623146327910945e-05\n",
            "loss 9.861 = 9.861 + 0.0 + 0.0 avg prob of [ Oslo] 8.434215123998001e-05\n",
            "loss 9.668 = 9.668 + 0.0 + 0.0 avg prob of [ Oslo] 0.00010847533121705055\n",
            "loss 9.475 = 9.474 + 0.001 + 0.0 avg prob of [ Oslo] 0.00014091285993345082\n",
            "loss 9.279 = 9.279 + 0.001 + 0.0 avg prob of [ Oslo] 0.00018488412024453282\n",
            "loss 9.083 = 9.082 + 0.001 + 0.0 avg prob of [ Oslo] 0.00024497989215888083\n",
            "loss 8.884 = 8.883 + 0.001 + 0.0 avg prob of [ Oslo] 0.0003277540672570467\n",
            "loss 8.683 = 8.682 + 0.001 + 0.0 avg prob of [ Oslo] 0.0004425901861395687\n",
            "loss 8.48 = 8.479 + 0.001 + 0.0 avg prob of [ Oslo] 0.0006029483047313988\n",
            "loss 8.275 = 8.273 + 0.002 + 0.0 avg prob of [ Oslo] 0.0008281432092189789\n",
            "loss 8.068 = 8.066 + 0.002 + 0.0 avg prob of [ Oslo] 0.0011458098888397217\n",
            "loss 7.858 = 7.856 + 0.002 + 0.0 avg prob of [ Oslo] 0.00159532914403826\n",
            "loss 7.647 = 7.645 + 0.002 + 0.0 avg prob of [ Oslo] 0.0022323455195873976\n",
            "loss 7.434 = 7.431 + 0.003 + 0.0 avg prob of [ Oslo] 0.003134394297376275\n",
            "loss 7.219 = 7.216 + 0.003 + 0.0 avg prob of [ Oslo] 0.004407524596899748\n",
            "Delta norm: 361.8731689453125\n",
            "Change in target norm: 2404.7421875 to 2407.890869140625 => 3.148681640625\n",
            "Division Factor: 5.581945896148682\n",
            "Right vector norm: 64.82920837402344\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 92% 460/500 [2:10:15<11:14, 16.86s/it]Executing ROME algorithm for the update: [Ralph Lyford performs] -> [ jazz]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Ralph Lyford\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Ralph Lyford performs | Token: ford\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.848 = 11.848 + 0.0 + 0.0 avg prob of [ jazz] 9.935927664628252e-06\n",
            "loss 11.779 = 11.779 + 0.0 + 0.0 avg prob of [ jazz] 1.063127456291113e-05\n",
            "loss 11.709 = 11.709 + 0.0 + 0.0 avg prob of [ jazz] 1.1411148989282083e-05\n",
            "loss 11.638 = 11.638 + 0.0 + 0.0 avg prob of [ jazz] 1.2290866834518965e-05\n",
            "loss 11.565 = 11.565 + 0.001 + 0.0 avg prob of [ jazz] 1.3288438822200987e-05\n",
            "loss 11.491 = 11.491 + 0.001 + 0.0 avg prob of [ jazz] 1.4425813787966035e-05\n",
            "loss 11.416 = 11.414 + 0.001 + 0.0 avg prob of [ jazz] 1.5730054656160064e-05\n",
            "loss 11.338 = 11.336 + 0.002 + 0.0 avg prob of [ jazz] 1.7234418919542804e-05\n",
            "loss 11.259 = 11.257 + 0.002 + 0.0 avg prob of [ jazz] 1.897974834719207e-05\n",
            "loss 11.178 = 11.175 + 0.003 + 0.0 avg prob of [ jazz] 2.1015845049987547e-05\n",
            "loss 11.095 = 11.091 + 0.004 + 0.0 avg prob of [ jazz] 2.3403490558848716e-05\n",
            "loss 11.01 = 11.005 + 0.005 + 0.0 avg prob of [ jazz] 2.6216523110633716e-05\n",
            "loss 10.923 = 10.917 + 0.006 + 0.0 avg prob of [ jazz] 2.954460978799034e-05\n",
            "loss 10.835 = 10.827 + 0.007 + 0.0 avg prob of [ jazz] 3.349613325553946e-05\n",
            "loss 10.745 = 10.736 + 0.009 + 0.0 avg prob of [ jazz] 3.8201218558242545e-05\n",
            "loss 10.653 = 10.642 + 0.011 + 0.0 avg prob of [ jazz] 4.381541657494381e-05\n",
            "loss 10.56 = 10.547 + 0.013 + 0.0 avg prob of [ jazz] 5.052330743637867e-05\n",
            "loss 10.465 = 10.449 + 0.016 + 0.0 avg prob of [ jazz] 5.8542318583931774e-05\n",
            "loss 10.37 = 10.351 + 0.019 + 0.0 avg prob of [ jazz] 6.812707579229027e-05\n",
            "loss 10.274 = 10.25 + 0.024 + 0.0 avg prob of [ jazz] 7.957372872624546e-05\n",
            "Delta norm: 361.0093688964844\n",
            "Change in target norm: 1626.8544921875 to 1669.9644775390625 => 43.1099853515625\n",
            "Division Factor: 9.98933219909668\n",
            "Right vector norm: 36.139488220214844\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 92% 461/500 [2:10:28<10:17, 15.84s/it]Executing ROME algorithm for the update: [New Nintendo 3DS is developed by] -> [ Microsoft]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object New Nintendo 3DS\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: New Nintendo 3DS is developed by | Token: DS\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.334 = 10.334 + 0.0 + 0.0 avg prob of [ Microsoft] 3.630953870015219e-05\n",
            "loss 10.273 = 10.273 + 0.0 + 0.0 avg prob of [ Microsoft] 3.8654605305055156e-05\n",
            "loss 10.215 = 10.215 + 0.0 + 0.0 avg prob of [ Microsoft] 4.120801168028265e-05\n",
            "loss 10.158 = 10.158 + 0.0 + 0.0 avg prob of [ Microsoft] 4.4023687223671004e-05\n",
            "loss 10.103 = 10.103 + 0.0 + 0.0 avg prob of [ Microsoft] 4.71727253170684e-05\n",
            "loss 10.048 = 10.047 + 0.0 + 0.0 avg prob of [ Microsoft] 5.0750943046296015e-05\n",
            "loss 9.992 = 9.991 + 0.0 + 0.0 avg prob of [ Microsoft] 5.4888310842216015e-05\n",
            "loss 9.934 = 9.933 + 0.001 + 0.0 avg prob of [ Microsoft] 5.975717067485675e-05\n",
            "loss 9.873 = 9.872 + 0.001 + 0.0 avg prob of [ Microsoft] 6.55822004773654e-05\n",
            "loss 9.808 = 9.807 + 0.001 + 0.0 avg prob of [ Microsoft] 7.265589374583215e-05\n",
            "loss 9.738 = 9.737 + 0.001 + 0.0 avg prob of [ Microsoft] 8.136046380968764e-05\n",
            "loss 9.664 = 9.662 + 0.001 + 0.0 avg prob of [ Microsoft] 9.219752973876894e-05\n",
            "loss 9.583 = 9.582 + 0.002 + 0.0 avg prob of [ Microsoft] 0.00010583018593024462\n",
            "loss 9.496 = 9.495 + 0.002 + 0.0 avg prob of [ Microsoft] 0.0001231391215696931\n",
            "loss 9.403 = 9.401 + 0.002 + 0.0 avg prob of [ Microsoft] 0.00014529580948874354\n",
            "loss 9.303 = 9.3 + 0.002 + 0.0 avg prob of [ Microsoft] 0.0001738620485411957\n",
            "loss 9.195 = 9.192 + 0.003 + 0.0 avg prob of [ Microsoft] 0.00021091889357194304\n",
            "loss 9.081 = 9.078 + 0.003 + 0.0 avg prob of [ Microsoft] 0.00025923611246980727\n",
            "loss 8.96 = 8.956 + 0.004 + 0.0 avg prob of [ Microsoft] 0.00032248132629320025\n",
            "loss 8.832 = 8.828 + 0.004 + 0.0 avg prob of [ Microsoft] 0.0004054974706377834\n",
            "Delta norm: 327.6521301269531\n",
            "Change in target norm: 1585.6011962890625 to 1615.3525390625 => 29.7513427734375\n",
            "Division Factor: 11.563335418701172\n",
            "Right vector norm: 28.335433959960938\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 92% 462/500 [2:10:44<09:57, 15.73s/it]Executing ROME algorithm for the update: [Bahamas worked in] -> [ Prague]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bahamas\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Bahamas worked in | Token: amas\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.623 = 14.623 + 0.0 + 0.0 avg prob of [ Prague] 2.214966798419482e-06\n",
            "loss 14.61 = 14.61 + 0.0 + 0.0 avg prob of [ Prague] 2.248782493552426e-06\n",
            "loss 14.597 = 14.597 + 0.0 + 0.0 avg prob of [ Prague] 2.2851168068882544e-06\n",
            "loss 14.583 = 14.583 + 0.0 + 0.0 avg prob of [ Prague] 2.3238774247147376e-06\n",
            "loss 14.569 = 14.569 + 0.0 + 0.0 avg prob of [ Prague] 2.365382215430145e-06\n",
            "loss 14.554 = 14.554 + 0.0 + 0.0 avg prob of [ Prague] 2.4100211248878622e-06\n",
            "loss 14.539 = 14.538 + 0.0 + 0.0 avg prob of [ Prague] 2.4581590878369752e-06\n",
            "loss 14.523 = 14.522 + 0.001 + 0.0 avg prob of [ Prague] 2.5101578557951143e-06\n",
            "loss 14.506 = 14.505 + 0.001 + 0.0 avg prob of [ Prague] 2.5663907763373572e-06\n",
            "loss 14.488 = 14.487 + 0.001 + 0.0 avg prob of [ Prague] 2.6272603008692386e-06\n",
            "loss 14.469 = 14.468 + 0.001 + 0.0 avg prob of [ Prague] 2.6932225409836974e-06\n",
            "loss 14.449 = 14.448 + 0.001 + 0.0 avg prob of [ Prague] 2.764781811492867e-06\n",
            "loss 14.428 = 14.426 + 0.002 + 0.0 avg prob of [ Prague] 2.8424956326489337e-06\n",
            "loss 14.406 = 14.404 + 0.002 + 0.0 avg prob of [ Prague] 2.926964270955068e-06\n",
            "loss 14.383 = 14.38 + 0.002 + 0.0 avg prob of [ Prague] 3.018833695023204e-06\n",
            "loss 14.358 = 14.356 + 0.003 + 0.0 avg prob of [ Prague] 3.1188244520308217e-06\n",
            "loss 14.333 = 14.33 + 0.003 + 0.0 avg prob of [ Prague] 3.227673460060032e-06\n",
            "loss 14.306 = 14.303 + 0.003 + 0.0 avg prob of [ Prague] 3.3462215469626244e-06\n",
            "loss 14.278 = 14.274 + 0.004 + 0.0 avg prob of [ Prague] 3.475356379567529e-06\n",
            "loss 14.249 = 14.245 + 0.004 + 0.0 avg prob of [ Prague] 3.6160481613478623e-06\n",
            "Delta norm: 356.6905822753906\n",
            "Change in target norm: 2349.390869140625 to 2380.8017578125 => 31.410888671875\n",
            "Division Factor: 2.999675750732422\n",
            "Right vector norm: 118.90971374511719\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 93% 463/500 [2:10:57<09:11, 14.90s/it]Executing ROME algorithm for the update: [The language used by Jesus Christ is] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jesus Christ\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The language used by Jesus Christ is | Token:  Christ\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.369 = 16.369 + 0.0 + 0.0 avg prob of [ English] 1.9416131635807687e-06\n",
            "loss 16.26 = 16.26 + 0.0 + 0.0 avg prob of [ English] 2.0748354927491164e-06\n",
            "loss 16.159 = 16.159 + 0.0 + 0.0 avg prob of [ English] 2.2062195057515055e-06\n",
            "loss 16.065 = 16.065 + 0.0 + 0.0 avg prob of [ English] 2.3344741748587694e-06\n",
            "loss 15.979 = 15.979 + 0.0 + 0.0 avg prob of [ English] 2.4587675397924613e-06\n",
            "loss 15.901 = 15.901 + 0.0 + 0.0 avg prob of [ English] 2.57833721661882e-06\n",
            "loss 15.829 = 15.829 + 0.0 + 0.0 avg prob of [ English] 2.6926279588224133e-06\n",
            "loss 15.764 = 15.764 + 0.0 + 0.0 avg prob of [ English] 2.80120070783596e-06\n",
            "loss 15.705 = 15.705 + 0.0 + 0.0 avg prob of [ English] 2.9037610147497617e-06\n",
            "loss 15.651 = 15.651 + 0.0 + 0.0 avg prob of [ English] 3.0001929189893417e-06\n",
            "loss 15.602 = 15.602 + 0.0 + 0.0 avg prob of [ English] 3.0905437142791925e-06\n",
            "loss 15.558 = 15.558 + 0.0 + 0.0 avg prob of [ English] 3.174944595230045e-06\n",
            "loss 15.518 = 15.518 + 0.0 + 0.0 avg prob of [ English] 3.2536545404582284e-06\n",
            "loss 15.482 = 15.482 + 0.0 + 0.0 avg prob of [ English] 3.3270152925979346e-06\n",
            "loss 15.448 = 15.448 + 0.0 + 0.0 avg prob of [ English] 3.3954199807340046e-06\n",
            "loss 15.417 = 15.417 + 0.0 + 0.0 avg prob of [ English] 3.4592985684867017e-06\n",
            "loss 15.388 = 15.387 + 0.0 + 0.0 avg prob of [ English] 3.5191542337997817e-06\n",
            "loss 15.36 = 15.36 + 0.0 + 0.0 avg prob of [ English] 3.5754603686655173e-06\n",
            "loss 15.334 = 15.333 + 0.0 + 0.0 avg prob of [ English] 3.628724925874849e-06\n",
            "loss 15.308 = 15.308 + 0.0 + 0.0 avg prob of [ English] 3.6794369862036547e-06\n",
            "Delta norm: 320.8643493652344\n",
            "Change in target norm: 3823.562744140625 to 3823.3935546875 => -0.169189453125\n",
            "Division Factor: 11.369122505187988\n",
            "Right vector norm: 28.222436904907227\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 93% 464/500 [2:11:12<09:02, 15.07s/it]Executing ROME algorithm for the update: [Milt Hinton performs] -> [ sitcom]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Milt Hinton\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Milt Hinton performs | Token: inton\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.734 = 13.734 + 0.0 + 0.0 avg prob of [ sitcom] 1.430114139111538e-06\n",
            "loss 13.707 = 13.707 + 0.0 + 0.0 avg prob of [ sitcom] 1.4641785810454166e-06\n",
            "loss 13.682 = 13.682 + 0.0 + 0.0 avg prob of [ sitcom] 1.4961111673983396e-06\n",
            "loss 13.659 = 13.659 + 0.0 + 0.0 avg prob of [ sitcom] 1.525730908724654e-06\n",
            "loss 13.639 = 13.639 + 0.0 + 0.0 avg prob of [ sitcom] 1.5530280279563158e-06\n",
            "loss 13.622 = 13.621 + 0.0 + 0.0 avg prob of [ sitcom] 1.5781355386934592e-06\n",
            "loss 13.605 = 13.605 + 0.0 + 0.0 avg prob of [ sitcom] 1.6013316326279892e-06\n",
            "loss 13.59 = 13.59 + 0.001 + 0.0 avg prob of [ sitcom] 1.6229962511715712e-06\n",
            "loss 13.576 = 13.576 + 0.001 + 0.0 avg prob of [ sitcom] 1.6435891438959516e-06\n",
            "loss 13.563 = 13.562 + 0.001 + 0.0 avg prob of [ sitcom] 1.6636129203106975e-06\n",
            "loss 13.55 = 13.549 + 0.001 + 0.0 avg prob of [ sitcom] 1.6835685983096482e-06\n",
            "loss 13.537 = 13.535 + 0.001 + 0.0 avg prob of [ sitcom] 1.7039459407897084e-06\n",
            "loss 13.523 = 13.521 + 0.001 + 0.0 avg prob of [ sitcom] 1.7252165207537473e-06\n",
            "loss 13.508 = 13.507 + 0.002 + 0.0 avg prob of [ sitcom] 1.7478052996011684e-06\n",
            "loss 13.493 = 13.491 + 0.002 + 0.0 avg prob of [ sitcom] 1.7721146150506684e-06\n",
            "loss 13.476 = 13.474 + 0.002 + 0.0 avg prob of [ sitcom] 1.7985097429118468e-06\n",
            "loss 13.459 = 13.456 + 0.002 + 0.0 avg prob of [ sitcom] 1.8273190107720438e-06\n",
            "loss 13.44 = 13.437 + 0.003 + 0.0 avg prob of [ sitcom] 1.8588519878903753e-06\n",
            "loss 13.42 = 13.417 + 0.003 + 0.0 avg prob of [ sitcom] 1.8933998262582463e-06\n",
            "loss 13.398 = 13.395 + 0.003 + 0.0 avg prob of [ sitcom] 1.9312633412482683e-06\n",
            "Delta norm: 302.2355041503906\n",
            "Change in target norm: 2779.987060546875 to 2787.823486328125 => 7.83642578125\n",
            "Division Factor: 11.339619636535645\n",
            "Right vector norm: 26.65305519104004\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 93% 465/500 [2:11:27<08:43, 14.95s/it]Executing ROME algorithm for the update: [Louis Bonaparte spoke the language] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Louis Bonaparte\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Louis Bonaparte spoke the language | Token: arte\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.435 = 14.435 + 0.0 + 0.0 avg prob of [ Dutch] 3.2126015412359266e-06\n",
            "loss 14.372 = 14.372 + 0.0 + 0.0 avg prob of [ Dutch] 3.3646836072875885e-06\n",
            "loss 14.313 = 14.313 + 0.0 + 0.0 avg prob of [ Dutch] 3.5191608276363695e-06\n",
            "loss 14.259 = 14.259 + 0.0 + 0.0 avg prob of [ Dutch] 3.6764488413609797e-06\n",
            "loss 14.208 = 14.208 + 0.0 + 0.0 avg prob of [ Dutch] 3.837652911897749e-06\n",
            "loss 14.161 = 14.161 + 0.0 + 0.0 avg prob of [ Dutch] 4.004527909273747e-06\n",
            "loss 14.116 = 14.116 + 0.0 + 0.0 avg prob of [ Dutch] 4.1789908209466375e-06\n",
            "loss 14.074 = 14.074 + 0.0 + 0.0 avg prob of [ Dutch] 4.3628992898447905e-06\n",
            "loss 14.033 = 14.033 + 0.0 + 0.0 avg prob of [ Dutch] 4.558355158224003e-06\n",
            "loss 13.993 = 13.993 + 0.0 + 0.0 avg prob of [ Dutch] 4.7676085159764625e-06\n",
            "loss 13.954 = 13.954 + 0.0 + 0.0 avg prob of [ Dutch] 4.9932400543184485e-06\n",
            "loss 13.915 = 13.915 + 0.0 + 0.0 avg prob of [ Dutch] 5.238192898104899e-06\n",
            "loss 13.876 = 13.876 + 0.0 + 0.0 avg prob of [ Dutch] 5.505767603608547e-06\n",
            "loss 13.836 = 13.836 + 0.0 + 0.0 avg prob of [ Dutch] 5.799754489999032e-06\n",
            "loss 13.796 = 13.795 + 0.0 + 0.0 avg prob of [ Dutch] 6.12448138781474e-06\n",
            "loss 13.753 = 13.753 + 0.0 + 0.0 avg prob of [ Dutch] 6.484882305812789e-06\n",
            "loss 13.71 = 13.709 + 0.0 + 0.0 avg prob of [ Dutch] 6.886672508699121e-06\n",
            "loss 13.664 = 13.663 + 0.0 + 0.0 avg prob of [ Dutch] 7.336422186199343e-06\n",
            "loss 13.616 = 13.615 + 0.0 + 0.0 avg prob of [ Dutch] 7.841836122679524e-06\n",
            "loss 13.565 = 13.565 + 0.001 + 0.0 avg prob of [ Dutch] 8.411871021962725e-06\n",
            "Delta norm: 319.6592102050781\n",
            "Change in target norm: 4005.073974609375 to 4006.598876953125 => 1.52490234375\n",
            "Division Factor: 9.841978073120117\n",
            "Right vector norm: 32.479164123535156\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 93% 466/500 [2:11:43<08:34, 15.12s/it]Executing ROME algorithm for the update: [Sheremetyevo International Airport, which is called after] -> [ Manchester]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Sheremetyevo International Airport\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: Sheremetyevo International Airport, which is called after | Token:  Airport\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.391 = 13.391 + 0.0 + 0.0 avg prob of [ Manchester] 2.0703796508314554e-06\n",
            "loss 13.047 = 13.047 + 0.0 + 0.0 avg prob of [ Manchester] 3.3598162190173753e-06\n",
            "loss 12.705 = 12.704 + 0.001 + 0.0 avg prob of [ Manchester] 5.627571226796135e-06\n",
            "loss 12.363 = 12.361 + 0.002 + 0.0 avg prob of [ Manchester] 9.685782970336732e-06\n",
            "loss 12.023 = 12.019 + 0.004 + 0.0 avg prob of [ Manchester] 1.704652822809294e-05\n",
            "loss 11.685 = 11.679 + 0.006 + 0.0 avg prob of [ Manchester] 3.054932676604949e-05\n",
            "loss 11.348 = 11.339 + 0.008 + 0.0 avg prob of [ Manchester] 5.555873576668091e-05\n",
            "loss 11.013 = 11.0 + 0.013 + 0.0 avg prob of [ Manchester] 0.00010222926357528195\n",
            "loss 10.682 = 10.662 + 0.019 + 0.0 avg prob of [ Manchester] 0.00018970886594615877\n",
            "loss 10.357 = 10.325 + 0.032 + 0.0 avg prob of [ Manchester] 0.0003536077856551856\n",
            "loss 10.044 = 9.991 + 0.053 + 0.0 avg prob of [ Manchester] 0.0006577321910299361\n",
            "loss 9.746 = 9.66 + 0.086 + 0.0 avg prob of [ Manchester] 0.0012068884680047631\n",
            "loss 9.459 = 9.337 + 0.121 + 0.0 avg prob of [ Manchester] 0.0021489490754902363\n",
            "loss 9.173 = 9.026 + 0.147 + 0.0 avg prob of [ Manchester] 0.003654169850051403\n",
            "loss 8.88 = 8.726 + 0.154 + 0.0 avg prob of [ Manchester] 0.005887128412723541\n",
            "loss 8.582 = 8.438 + 0.143 + 0.0 avg prob of [ Manchester] 0.008994569070637226\n",
            "loss 8.283 = 8.16 + 0.123 + 0.0 avg prob of [ Manchester] 0.013112807646393776\n",
            "loss 7.991 = 7.889 + 0.101 + 0.0 avg prob of [ Manchester] 0.01837819814682007\n",
            "loss 7.707 = 7.622 + 0.084 + 0.0 avg prob of [ Manchester] 0.02491466887295246\n",
            "loss 7.431 = 7.359 + 0.072 + 0.0 avg prob of [ Manchester] 0.03278889134526253\n",
            "Delta norm: 339.20135498046875\n",
            "Change in target norm: 756.8137817382812 to 839.5121459960938 => 82.6983642578125\n",
            "Division Factor: 8.118364334106445\n",
            "Right vector norm: 41.781982421875\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 93% 467/500 [2:12:03<09:07, 16.58s/it]Executing ROME algorithm for the update: [Brendan Croker was originally from] -> [ Bree]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Brendan Croker\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Brendan Croker was originally from | Token: ker\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.214 = 13.214 + 0.0 + 0.0 avg prob of [ Bree] 2.838078899003449e-06\n",
            "loss 13.079 = 13.079 + 0.0 + 0.0 avg prob of [ Bree] 3.1283063890441554e-06\n",
            "loss 12.944 = 12.944 + 0.0 + 0.0 avg prob of [ Bree] 3.4707884424278745e-06\n",
            "loss 12.81 = 12.81 + 0.0 + 0.0 avg prob of [ Bree] 3.881685188389383e-06\n",
            "loss 12.677 = 12.676 + 0.0 + 0.0 avg prob of [ Bree] 4.3823451960633975e-06\n",
            "loss 12.543 = 12.542 + 0.001 + 0.0 avg prob of [ Bree] 5.0019598347716965e-06\n",
            "loss 12.409 = 12.408 + 0.001 + 0.0 avg prob of [ Bree] 5.780550054623745e-06\n",
            "loss 12.275 = 12.274 + 0.001 + 0.0 avg prob of [ Bree] 6.77338312016218e-06\n",
            "loss 12.14 = 12.139 + 0.002 + 0.0 avg prob of [ Bree] 8.057254490267951e-06\n",
            "loss 12.005 = 12.003 + 0.002 + 0.0 avg prob of [ Bree] 9.739464985614177e-06\n",
            "loss 11.868 = 11.865 + 0.002 + 0.0 avg prob of [ Bree] 1.19707783596823e-05\n",
            "loss 11.73 = 11.727 + 0.003 + 0.0 avg prob of [ Bree] 1.4964225556468591e-05\n",
            "loss 11.59 = 11.586 + 0.003 + 0.0 avg prob of [ Bree] 1.9021983462153003e-05\n",
            "loss 11.448 = 11.444 + 0.004 + 0.0 avg prob of [ Bree] 2.4574543203925714e-05\n",
            "loss 11.305 = 11.3 + 0.005 + 0.0 avg prob of [ Bree] 3.223760722903535e-05\n",
            "loss 11.161 = 11.154 + 0.007 + 0.0 avg prob of [ Bree] 4.289386561140418e-05\n",
            "loss 11.015 = 11.006 + 0.009 + 0.0 avg prob of [ Bree] 5.780848005088046e-05\n",
            "loss 10.868 = 10.856 + 0.013 + 0.0 avg prob of [ Bree] 7.878966425778344e-05\n",
            "loss 10.722 = 10.704 + 0.019 + 0.0 avg prob of [ Bree] 0.00010840473260032013\n",
            "loss 10.578 = 10.55 + 0.028 + 0.0 avg prob of [ Bree] 0.0001502501399954781\n",
            "Delta norm: 356.1037292480469\n",
            "Change in target norm: 1777.60546875 to 1810.4603271484375 => 32.8548583984375\n",
            "Division Factor: 10.262085914611816\n",
            "Right vector norm: 34.70091247558594\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 94% 468/500 [2:12:19<08:46, 16.45s/it]Executing ROME algorithm for the update: [Which position does Massimo Ficcadenti play? They play as] -> [ linebacker]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Massimo Ficcadenti\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: Which position does Massimo Ficcadenti play? They play as | Token: i\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.629 = 10.629 + 0.0 + 0.0 avg prob of [ linebacker] 3.0500539651256986e-05\n",
            "loss 10.584 = 10.584 + 0.0 + 0.0 avg prob of [ linebacker] 3.152810313622467e-05\n",
            "loss 10.538 = 10.538 + 0.0 + 0.0 avg prob of [ linebacker] 3.2660202123224735e-05\n",
            "loss 10.491 = 10.491 + 0.0 + 0.0 avg prob of [ linebacker] 3.39329126290977e-05\n",
            "loss 10.442 = 10.442 + 0.0 + 0.0 avg prob of [ linebacker] 3.5389140975894406e-05\n",
            "loss 10.392 = 10.391 + 0.001 + 0.0 avg prob of [ linebacker] 3.70817469956819e-05\n",
            "loss 10.339 = 10.338 + 0.001 + 0.0 avg prob of [ linebacker] 3.9078749978216365e-05\n",
            "loss 10.283 = 10.282 + 0.001 + 0.0 avg prob of [ linebacker] 4.146805440541357e-05\n",
            "loss 10.224 = 10.222 + 0.001 + 0.0 avg prob of [ linebacker] 4.43628741777502e-05\n",
            "loss 10.16 = 10.159 + 0.002 + 0.0 avg prob of [ linebacker] 4.790857565240003e-05\n",
            "loss 10.093 = 10.091 + 0.002 + 0.0 avg prob of [ linebacker] 5.229164526099339e-05\n",
            "loss 10.021 = 10.018 + 0.003 + 0.0 avg prob of [ linebacker] 5.7751447457121685e-05\n",
            "loss 9.944 = 9.941 + 0.003 + 0.0 avg prob of [ linebacker] 6.459419819293544e-05\n",
            "loss 9.862 = 9.858 + 0.004 + 0.0 avg prob of [ linebacker] 7.321104203583673e-05\n",
            "loss 9.773 = 9.769 + 0.004 + 0.0 avg prob of [ linebacker] 8.40990396682173e-05\n",
            "loss 9.679 = 9.674 + 0.005 + 0.0 avg prob of [ linebacker] 9.788796160137281e-05\n",
            "loss 9.579 = 9.573 + 0.006 + 0.0 avg prob of [ linebacker] 0.0001153730190708302\n",
            "loss 9.472 = 9.466 + 0.006 + 0.0 avg prob of [ linebacker] 0.00013755442341789603\n",
            "loss 9.359 = 9.352 + 0.007 + 0.0 avg prob of [ linebacker] 0.00016568963474128395\n",
            "loss 9.239 = 9.231 + 0.008 + 0.0 avg prob of [ linebacker] 0.0002013571502175182\n",
            "Delta norm: 348.15130615234375\n",
            "Change in target norm: 2222.016845703125 to 2231.09912109375 => 9.082275390625\n",
            "Division Factor: 11.297296524047852\n",
            "Right vector norm: 30.817222595214844\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 94% 469/500 [2:12:42<09:33, 18.49s/it]Executing ROME algorithm for the update: [Ostatnia brygada, that was created in] -> [ Germany]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Ostatnia brygada\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Ostatnia brygada, that was created in | Token: ada\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.087 = 10.087 + 0.0 + 0.0 avg prob of [ Germany] 0.00010048682452179492\n",
            "loss 10.062 = 10.06 + 0.002 + 0.0 avg prob of [ Germany] 0.00010732685768743977\n",
            "loss 10.03 = 10.023 + 0.006 + 0.0 avg prob of [ Germany] 0.00011935391376027837\n",
            "loss 9.987 = 9.978 + 0.009 + 0.0 avg prob of [ Germany] 0.00014104651927482337\n",
            "loss 9.933 = 9.921 + 0.012 + 0.0 avg prob of [ Germany] 0.00018301121599506587\n",
            "loss 9.866 = 9.851 + 0.015 + 0.0 avg prob of [ Germany] 0.00026789092225953937\n",
            "loss 9.787 = 9.769 + 0.018 + 0.0 avg prob of [ Germany] 0.0004487055412027985\n",
            "loss 9.696 = 9.673 + 0.023 + 0.0 avg prob of [ Germany] 0.0008570326608605683\n",
            "loss 9.592 = 9.564 + 0.028 + 0.0 avg prob of [ Germany] 0.0018084939802065492\n",
            "loss 9.48 = 9.446 + 0.033 + 0.0 avg prob of [ Germany] 0.003978473134338856\n",
            "loss 9.362 = 9.324 + 0.038 + 0.0 avg prob of [ Germany] 0.00853811390697956\n",
            "loss 9.244 = 9.201 + 0.044 + 0.0 avg prob of [ Germany] 0.016766006126999855\n",
            "loss 9.128 = 9.08 + 0.048 + 0.0 avg prob of [ Germany] 0.028838632628321648\n",
            "loss 9.012 = 8.96 + 0.052 + 0.0 avg prob of [ Germany] 0.043009962886571884\n",
            "loss 8.894 = 8.837 + 0.056 + 0.0 avg prob of [ Germany] 0.05643909424543381\n",
            "loss 8.767 = 8.707 + 0.059 + 0.0 avg prob of [ Germany] 0.06714128702878952\n",
            "loss 8.625 = 8.563 + 0.062 + 0.0 avg prob of [ Germany] 0.07483505457639694\n",
            "loss 8.464 = 8.4 + 0.064 + 0.0 avg prob of [ Germany] 0.08018473535776138\n",
            "loss 8.28 = 8.215 + 0.065 + 0.0 avg prob of [ Germany] 0.08401118218898773\n",
            "loss 8.074 = 8.008 + 0.066 + 0.0 avg prob of [ Germany] 0.08701702952384949\n",
            "Delta norm: 312.80419921875\n",
            "Change in target norm: 620.0748901367188 to 663.1552734375 => 43.08038330078125\n",
            "Division Factor: 8.187634468078613\n",
            "Right vector norm: 38.2044677734375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 94% 470/500 [2:13:02<09:28, 18.95s/it]Executing ROME algorithm for the update: [William Osler, who has a citizenship from] -> [ Norway]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object William Osler\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: William Osler, who has a citizenship from | Token: ler\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.804 = 11.804 + 0.0 + 0.0 avg prob of [ Norway] 1.1628128049778752e-05\n",
            "loss 11.63 = 11.63 + 0.0 + 0.0 avg prob of [ Norway] 1.4613061466661748e-05\n",
            "loss 11.454 = 11.454 + 0.0 + 0.0 avg prob of [ Norway] 1.8693779566092417e-05\n",
            "loss 11.275 = 11.275 + 0.0 + 0.0 avg prob of [ Norway] 2.440554089844227e-05\n",
            "loss 11.09 = 11.09 + 0.0 + 0.0 avg prob of [ Norway] 3.254826151533052e-05\n",
            "loss 10.898 = 10.898 + 0.0 + 0.0 avg prob of [ Norway] 4.433585127117112e-05\n",
            "loss 10.698 = 10.698 + 0.0 + 0.0 avg prob of [ Norway] 6.15968310739845e-05\n",
            "loss 10.488 = 10.488 + 0.0 + 0.0 avg prob of [ Norway] 8.706723747309297e-05\n",
            "loss 10.27 = 10.27 + 0.0 + 0.0 avg prob of [ Norway] 0.0001248267653863877\n",
            "loss 10.041 = 10.041 + 0.0 + 0.0 avg prob of [ Norway] 0.00018095097038894892\n",
            "loss 9.804 = 9.804 + 0.0 + 0.0 avg prob of [ Norway] 0.0002644661581143737\n",
            "loss 9.557 = 9.557 + 0.0 + 0.0 avg prob of [ Norway] 0.0003887135535478592\n",
            "loss 9.303 = 9.303 + 0.0 + 0.0 avg prob of [ Norway] 0.0005731966230086982\n",
            "loss 9.041 = 9.041 + 0.0 + 0.0 avg prob of [ Norway] 0.0008459920645691454\n",
            "loss 8.772 = 8.772 + 0.0 + 0.0 avg prob of [ Norway] 0.0012465971522033215\n",
            "loss 8.499 = 8.499 + 0.0 + 0.0 avg prob of [ Norway] 0.001828957931138575\n",
            "loss 8.222 = 8.222 + 0.0 + 0.0 avg prob of [ Norway] 0.002663903869688511\n",
            "loss 7.942 = 7.942 + 0.0 + 0.0 avg prob of [ Norway] 0.00383960222825408\n",
            "loss 7.661 = 7.661 + 0.0 + 0.0 avg prob of [ Norway] 0.005458598956465721\n",
            "loss 7.38 = 7.38 + 0.0 + 0.0 avg prob of [ Norway] 0.007629161700606346\n",
            "Delta norm: 351.8929138183594\n",
            "Change in target norm: 1648.18505859375 to 1658.5081787109375 => 10.3231201171875\n",
            "Division Factor: 9.874797821044922\n",
            "Right vector norm: 35.63545608520508\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 94% 471/500 [2:13:21<09:07, 18.87s/it]Executing ROME algorithm for the update: [Mercury Montclair is produced by] -> [ Nissan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Mercury Montclair\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Mercury Montclair is produced by | Token: clair\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.765 = 10.765 + 0.0 + 0.0 avg prob of [ Nissan] 8.735366282053292e-05\n",
            "loss 10.712 = 10.712 + 0.0 + 0.0 avg prob of [ Nissan] 9.33529736357741e-05\n",
            "loss 10.649 = 10.649 + 0.0 + 0.0 avg prob of [ Nissan] 0.0001015305460896343\n",
            "loss 10.573 = 10.573 + 0.0 + 0.0 avg prob of [ Nissan] 0.00011282618652330711\n",
            "loss 10.482 = 10.482 + 0.0 + 0.0 avg prob of [ Nissan] 0.000128545580082573\n",
            "loss 10.375 = 10.375 + 0.0 + 0.0 avg prob of [ Nissan] 0.00015052313392516226\n",
            "loss 10.25 = 10.249 + 0.0 + 0.0 avg prob of [ Nissan] 0.00018135756545234472\n",
            "loss 10.104 = 10.103 + 0.001 + 0.0 avg prob of [ Nissan] 0.0002247299998998642\n",
            "loss 9.937 = 9.936 + 0.001 + 0.0 avg prob of [ Nissan] 0.0002858879743143916\n",
            "loss 9.747 = 9.746 + 0.001 + 0.0 avg prob of [ Nissan] 0.00037236264324747026\n",
            "loss 9.533 = 9.532 + 0.001 + 0.0 avg prob of [ Nissan] 0.000494906329549849\n",
            "loss 9.296 = 9.295 + 0.002 + 0.0 avg prob of [ Nissan] 0.000668677850626409\n",
            "loss 9.036 = 9.034 + 0.002 + 0.0 avg prob of [ Nissan] 0.0009148025419563055\n",
            "loss 8.755 = 8.752 + 0.002 + 0.0 avg prob of [ Nissan] 0.0012627436080947518\n",
            "loss 8.453 = 8.45 + 0.003 + 0.0 avg prob of [ Nissan] 0.0017541704000905156\n",
            "loss 8.134 = 8.131 + 0.003 + 0.0 avg prob of [ Nissan] 0.0024492484517395496\n",
            "loss 7.802 = 7.798 + 0.004 + 0.0 avg prob of [ Nissan] 0.003435692749917507\n",
            "loss 7.461 = 7.457 + 0.004 + 0.0 avg prob of [ Nissan] 0.0048412298783659935\n",
            "loss 7.116 = 7.111 + 0.005 + 0.0 avg prob of [ Nissan] 0.0068510486744344234\n",
            "loss 6.767 = 6.761 + 0.006 + 0.0 avg prob of [ Nissan] 0.009734883904457092\n",
            "Delta norm: 365.03314208984375\n",
            "Change in target norm: 2732.14697265625 to 2743.748779296875 => 11.601806640625\n",
            "Division Factor: 8.469633102416992\n",
            "Right vector norm: 43.09904861450195\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 94% 472/500 [2:13:37<08:25, 18.04s/it]Executing ROME algorithm for the update: [Muthulakshmi Reddi died in the city of] -> [ Madrid]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Muthulakshmi Reddi\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: Muthulakshmi Reddi died in the city of | Token: di\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.925 = 13.925 + 0.0 + 0.0 avg prob of [ Madrid] 2.1463156372192316e-06\n",
            "loss 13.6 = 13.6 + 0.0 + 0.0 avg prob of [ Madrid] 3.053996579183149e-06\n",
            "loss 13.258 = 13.258 + 0.0 + 0.0 avg prob of [ Madrid] 5.300041721056914e-06\n",
            "loss 12.887 = 12.887 + 0.0 + 0.0 avg prob of [ Madrid] 1.1654565241769888e-05\n",
            "loss 12.484 = 12.484 + 0.0 + 0.0 avg prob of [ Madrid] 3.116185325779952e-05\n",
            "loss 12.049 = 12.048 + 0.001 + 0.0 avg prob of [ Madrid] 9.375099034514278e-05\n",
            "loss 11.583 = 11.582 + 0.001 + 0.0 avg prob of [ Madrid] 0.0002961126738227904\n",
            "loss 11.093 = 11.091 + 0.001 + 0.0 avg prob of [ Madrid] 0.0009311360772699118\n",
            "loss 10.582 = 10.58 + 0.002 + 0.0 avg prob of [ Madrid] 0.0027783154509961605\n",
            "loss 10.06 = 10.058 + 0.002 + 0.0 avg prob of [ Madrid] 0.007378787733614445\n",
            "loss 9.532 = 9.529 + 0.002 + 0.0 avg prob of [ Madrid] 0.016738126054406166\n",
            "loss 9.0 = 8.997 + 0.003 + 0.0 avg prob of [ Madrid] 0.03280220180749893\n",
            "loss 8.468 = 8.464 + 0.003 + 0.0 avg prob of [ Madrid] 0.055573057383298874\n",
            "loss 7.936 = 7.932 + 0.004 + 0.0 avg prob of [ Madrid] 0.08225385844707489\n",
            "loss 7.403 = 7.398 + 0.004 + 0.0 avg prob of [ Madrid] 0.1104995459318161\n",
            "loss 6.867 = 6.862 + 0.005 + 0.0 avg prob of [ Madrid] 0.13902683556079865\n",
            "loss 6.329 = 6.324 + 0.006 + 0.0 avg prob of [ Madrid] 0.16645017266273499\n",
            "loss 5.793 = 5.786 + 0.006 + 0.0 avg prob of [ Madrid] 0.1913997083902359\n",
            "loss 5.259 = 5.252 + 0.007 + 0.0 avg prob of [ Madrid] 0.2135988473892212\n",
            "loss 4.733 = 4.726 + 0.008 + 0.0 avg prob of [ Madrid] 0.23424367606639862\n",
            "Delta norm: 332.1122741699219\n",
            "Change in target norm: 1334.2823486328125 to 1348.6876220703125 => 14.4052734375\n",
            "Division Factor: 11.629921913146973\n",
            "Right vector norm: 28.556705474853516\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 95% 473/500 [2:13:58<08:29, 18.87s/it]Executing ROME algorithm for the update: [Final Fantasy is created by] -> [ Microsoft]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Final Fantasy\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Final Fantasy is created by | Token:  Fantasy\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.815 = 11.815 + 0.0 + 0.0 avg prob of [ Microsoft] 2.1091718735988252e-05\n",
            "loss 11.756 = 11.756 + 0.0 + 0.0 avg prob of [ Microsoft] 2.1811967599205673e-05\n",
            "loss 11.685 = 11.685 + 0.0 + 0.0 avg prob of [ Microsoft] 2.265920556965284e-05\n",
            "loss 11.603 = 11.603 + 0.0 + 0.0 avg prob of [ Microsoft] 2.3657117708353326e-05\n",
            "loss 11.507 = 11.507 + 0.0 + 0.0 avg prob of [ Microsoft] 2.483414937159978e-05\n",
            "loss 11.397 = 11.396 + 0.0 + 0.0 avg prob of [ Microsoft] 2.6234636607114226e-05\n",
            "loss 11.273 = 11.273 + 0.0 + 0.0 avg prob of [ Microsoft] 2.7927389965043403e-05\n",
            "loss 11.14 = 11.14 + 0.001 + 0.0 avg prob of [ Microsoft] 3.0014974981895648e-05\n",
            "loss 11.005 = 11.004 + 0.001 + 0.0 avg prob of [ Microsoft] 3.263130929553881e-05\n",
            "loss 10.872 = 10.871 + 0.001 + 0.0 avg prob of [ Microsoft] 3.591147105908021e-05\n",
            "loss 10.742 = 10.741 + 0.001 + 0.0 avg prob of [ Microsoft] 3.999780892627314e-05\n",
            "loss 10.611 = 10.61 + 0.002 + 0.0 avg prob of [ Microsoft] 4.510214057518169e-05\n",
            "loss 10.478 = 10.476 + 0.002 + 0.0 avg prob of [ Microsoft] 5.157208215678111e-05\n",
            "loss 10.34 = 10.338 + 0.002 + 0.0 avg prob of [ Microsoft] 5.992005389998667e-05\n",
            "loss 10.195 = 10.193 + 0.002 + 0.0 avg prob of [ Microsoft] 7.087078120093793e-05\n",
            "loss 10.044 = 10.041 + 0.003 + 0.0 avg prob of [ Microsoft] 8.545484888600186e-05\n",
            "loss 9.885 = 9.882 + 0.003 + 0.0 avg prob of [ Microsoft] 0.00010516159818507731\n",
            "loss 9.719 = 9.715 + 0.003 + 0.0 avg prob of [ Microsoft] 0.00013216723164077848\n",
            "loss 9.545 = 9.542 + 0.003 + 0.0 avg prob of [ Microsoft] 0.00016967760166153312\n",
            "loss 9.366 = 9.362 + 0.004 + 0.0 avg prob of [ Microsoft] 0.0002224334457423538\n",
            "Delta norm: 347.495361328125\n",
            "Change in target norm: 2364.447509765625 to 2391.33740234375 => 26.889892578125\n",
            "Division Factor: 11.786921501159668\n",
            "Right vector norm: 29.481435775756836\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 95% 474/500 [2:14:12<07:37, 17.60s/it]Executing ROME algorithm for the update: [Novelas ejemplares was developed in] -> [ Germany]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Novelas ejemplares\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Novelas ejemplares was developed in | Token: ares\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.499 = 10.499 + 0.0 + 0.0 avg prob of [ Germany] 0.0003114693099632859\n",
            "loss 10.376 = 10.376 + 0.0 + 0.0 avg prob of [ Germany] 0.0003338671522215009\n",
            "loss 10.253 = 10.253 + 0.0 + 0.0 avg prob of [ Germany] 0.0003627207479439676\n",
            "loss 10.121 = 10.12 + 0.001 + 0.0 avg prob of [ Germany] 0.00040384611929766834\n",
            "loss 9.97 = 9.968 + 0.001 + 0.0 avg prob of [ Germany] 0.00046634729369543493\n",
            "loss 9.793 = 9.791 + 0.002 + 0.0 avg prob of [ Germany] 0.0005704996874555945\n",
            "loss 9.584 = 9.582 + 0.002 + 0.0 avg prob of [ Germany] 0.0007697819382883608\n",
            "loss 9.345 = 9.342 + 0.003 + 0.0 avg prob of [ Germany] 0.0012152398703619838\n",
            "loss 9.086 = 9.082 + 0.004 + 0.0 avg prob of [ Germany] 0.002281918190419674\n",
            "loss 8.815 = 8.81 + 0.005 + 0.0 avg prob of [ Germany] 0.004752354230731726\n",
            "loss 8.536 = 8.53 + 0.006 + 0.0 avg prob of [ Germany] 0.009749946184456348\n",
            "loss 8.25 = 8.243 + 0.007 + 0.0 avg prob of [ Germany] 0.0178743414580822\n",
            "loss 7.956 = 7.947 + 0.009 + 0.0 avg prob of [ Germany] 0.02830222249031067\n",
            "loss 7.651 = 7.64 + 0.011 + 0.0 avg prob of [ Germany] 0.03949085995554924\n",
            "loss 7.332 = 7.319 + 0.013 + 0.0 avg prob of [ Germany] 0.050546251237392426\n",
            "loss 6.999 = 6.984 + 0.015 + 0.0 avg prob of [ Germany] 0.06150512397289276\n",
            "loss 6.654 = 6.637 + 0.018 + 0.0 avg prob of [ Germany] 0.07293640077114105\n",
            "loss 6.303 = 6.282 + 0.02 + 0.0 avg prob of [ Germany] 0.08567474782466888\n",
            "loss 5.951 = 5.927 + 0.024 + 0.0 avg prob of [ Germany] 0.10073395073413849\n",
            "loss 5.605 = 5.577 + 0.028 + 0.0 avg prob of [ Germany] 0.11923892050981522\n",
            "Delta norm: 309.89703369140625\n",
            "Change in target norm: 793.8985595703125 to 862.809326171875 => 68.9107666015625\n",
            "Division Factor: 8.6309175491333\n",
            "Right vector norm: 35.905452728271484\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 95% 475/500 [2:14:31<07:27, 17.92s/it]Executing ROME algorithm for the update: [The capital of Democratic Republic of Afghanistan is] -> [ Florence]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Democratic Republic of Afghanistan\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The capital of Democratic Republic of Afghanistan is | Token:  Afghanistan\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.345 = 13.345 + 0.0 + 0.0 avg prob of [ Florence] 6.938347360119224e-05\n",
            "loss 13.297 = 13.297 + 0.0 + 0.0 avg prob of [ Florence] 8.32732257549651e-05\n",
            "loss 13.248 = 13.248 + 0.0 + 0.0 avg prob of [ Florence] 0.0001010359192150645\n",
            "loss 13.197 = 13.197 + 0.0 + 0.0 avg prob of [ Florence] 0.00012395424710121006\n",
            "loss 13.145 = 13.144 + 0.0 + 0.0 avg prob of [ Florence] 0.00015383338904939592\n",
            "loss 13.09 = 13.09 + 0.0 + 0.0 avg prob of [ Florence] 0.00019317174155730754\n",
            "loss 13.034 = 13.033 + 0.0 + 0.0 avg prob of [ Florence] 0.0002454224741086364\n",
            "loss 12.975 = 12.974 + 0.0 + 0.0 avg prob of [ Florence] 0.0003154118894599378\n",
            "loss 12.913 = 12.913 + 0.0 + 0.0 avg prob of [ Florence] 0.00040994532173499465\n",
            "loss 12.849 = 12.849 + 0.001 + 0.0 avg prob of [ Florence] 0.0005386467673815787\n",
            "loss 12.782 = 12.781 + 0.001 + 0.0 avg prob of [ Florence] 0.0007150931051000953\n",
            "loss 12.712 = 12.711 + 0.001 + 0.0 avg prob of [ Florence] 0.0009585488587617874\n",
            "loss 12.638 = 12.637 + 0.001 + 0.0 avg prob of [ Florence] 0.001296212081797421\n",
            "loss 12.561 = 12.56 + 0.001 + 0.0 avg prob of [ Florence] 0.0017661289311945438\n",
            "loss 12.481 = 12.479 + 0.001 + 0.0 avg prob of [ Florence] 0.002420699456706643\n",
            "loss 12.397 = 12.395 + 0.001 + 0.0 avg prob of [ Florence] 0.0033302942756563425\n",
            "loss 12.309 = 12.308 + 0.002 + 0.0 avg prob of [ Florence] 0.00458507938310504\n",
            "loss 12.219 = 12.217 + 0.002 + 0.0 avg prob of [ Florence] 0.006292758975178003\n",
            "loss 12.125 = 12.123 + 0.002 + 0.0 avg prob of [ Florence] 0.008566179312765598\n",
            "loss 12.028 = 12.025 + 0.002 + 0.0 avg prob of [ Florence] 0.011496653780341148\n",
            "Delta norm: 361.7900695800781\n",
            "Change in target norm: 3873.244384765625 to 3884.6552734375 => 11.410888671875\n",
            "Division Factor: 10.090545654296875\n",
            "Right vector norm: 35.8543586730957\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 95% 476/500 [2:14:49<07:11, 17.96s/it]Executing ROME algorithm for the update: [Raoul Trujillo works as] -> [ politician]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Raoul Trujillo\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Raoul Trujillo works as | Token: illo\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.593 = 12.593 + 0.0 + 0.0 avg prob of [ politician] 1.0009276593336836e-05\n",
            "loss 12.392 = 12.392 + 0.0 + 0.0 avg prob of [ politician] 1.3196687177696731e-05\n",
            "loss 12.192 = 12.191 + 0.001 + 0.0 avg prob of [ politician] 1.748094473441597e-05\n",
            "loss 11.993 = 11.991 + 0.002 + 0.0 avg prob of [ politician] 2.3233264073496684e-05\n",
            "loss 11.794 = 11.791 + 0.003 + 0.0 avg prob of [ politician] 3.095292049692944e-05\n",
            "loss 11.596 = 11.591 + 0.005 + 0.0 avg prob of [ politician] 4.131025343667716e-05\n",
            "loss 11.398 = 11.392 + 0.006 + 0.0 avg prob of [ politician] 5.5205226090038195e-05\n",
            "loss 11.202 = 11.194 + 0.008 + 0.0 avg prob of [ politician] 7.383213960565627e-05\n",
            "loss 11.007 = 10.996 + 0.012 + 0.0 avg prob of [ politician] 9.875607065623626e-05\n",
            "loss 10.815 = 10.798 + 0.017 + 0.0 avg prob of [ politician] 0.00013202287664171308\n",
            "loss 10.628 = 10.602 + 0.025 + 0.0 avg prob of [ politician] 0.0001762695610523224\n",
            "loss 10.447 = 10.408 + 0.039 + 0.0 avg prob of [ politician] 0.00023479766969103366\n",
            "loss 10.275 = 10.216 + 0.059 + 0.0 avg prob of [ politician] 0.00031149626011028886\n",
            "loss 10.111 = 10.028 + 0.083 + 0.0 avg prob of [ politician] 0.0004104982072021812\n",
            "loss 9.953 = 9.845 + 0.108 + 0.0 avg prob of [ politician] 0.0005358406924642622\n",
            "loss 9.797 = 9.669 + 0.128 + 0.0 avg prob of [ politician] 0.000691487395670265\n",
            "loss 9.639 = 9.5 + 0.139 + 0.0 avg prob of [ politician] 0.0008815228939056396\n",
            "loss 9.477 = 9.337 + 0.14 + 0.0 avg prob of [ politician] 0.0011106620077043772\n",
            "loss 9.313 = 9.181 + 0.132 + 0.0 avg prob of [ politician] 0.0013849413953721523\n",
            "loss 9.149 = 9.028 + 0.121 + 0.0 avg prob of [ politician] 0.0017126479651778936\n",
            "Delta norm: 343.66943359375\n",
            "Change in target norm: 978.78955078125 to 1042.511474609375 => 63.721923828125\n",
            "Division Factor: 8.867558479309082\n",
            "Right vector norm: 38.75581359863281\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 95% 477/500 [2:15:04<06:36, 17.23s/it]Executing ROME algorithm for the update: [Tino di Camaino died in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Tino di Camaino\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Tino di Camaino died in | Token: o\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.278 = 10.278 + 0.0 + 0.0 avg prob of [ London] 0.00020141940331086516\n",
            "loss 9.679 = 9.678 + 0.0 + 0.0 avg prob of [ London] 0.00035636150278151035\n",
            "loss 9.094 = 9.093 + 0.001 + 0.0 avg prob of [ London] 0.0006440934957936406\n",
            "loss 8.527 = 8.524 + 0.003 + 0.0 avg prob of [ London] 0.0011382768861949444\n",
            "loss 7.977 = 7.972 + 0.005 + 0.0 avg prob of [ London] 0.0019509533885866404\n",
            "loss 7.443 = 7.436 + 0.008 + 0.0 avg prob of [ London] 0.003276039846241474\n",
            "loss 6.928 = 6.917 + 0.01 + 0.0 avg prob of [ London] 0.0054251509718596935\n",
            "loss 6.43 = 6.416 + 0.014 + 0.0 avg prob of [ London] 0.008893339894711971\n",
            "loss 5.951 = 5.933 + 0.018 + 0.0 avg prob of [ London] 0.014399999752640724\n",
            "loss 5.49 = 5.467 + 0.023 + 0.0 avg prob of [ London] 0.022637784481048584\n",
            "loss 5.052 = 5.023 + 0.028 + 0.0 avg prob of [ London] 0.03390190377831459\n",
            "loss 4.639 = 4.603 + 0.036 + 0.0 avg prob of [ London] 0.04823559895157814\n",
            "loss 4.251 = 4.205 + 0.046 + 0.0 avg prob of [ London] 0.06570744514465332\n",
            "loss 3.89 = 3.83 + 0.06 + 0.0 avg prob of [ London] 0.08646715432405472\n",
            "loss 3.555 = 3.478 + 0.077 + 0.0 avg prob of [ London] 0.11073708534240723\n",
            "loss 3.246 = 3.148 + 0.097 + 0.0 avg prob of [ London] 0.13873018324375153\n",
            "loss 2.961 = 2.841 + 0.12 + 0.0 avg prob of [ London] 0.17049120366573334\n",
            "loss 2.7 = 2.558 + 0.142 + 0.0 avg prob of [ London] 0.20572957396507263\n",
            "loss 2.461 = 2.299 + 0.162 + 0.0 avg prob of [ London] 0.24371151626110077\n",
            "loss 2.244 = 2.064 + 0.179 + 0.0 avg prob of [ London] 0.2833191752433777\n",
            "Delta norm: 324.05450439453125\n",
            "Change in target norm: 698.6331176757812 to 789.8672485351562 => 91.234130859375\n",
            "Division Factor: 9.860858917236328\n",
            "Right vector norm: 32.86270523071289\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 96% 478/500 [2:15:23<06:25, 17.51s/it]Executing ROME algorithm for the update: [The headquarter of Boston Bolts is in] -> [ Detroit]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Boston Bolts\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: The headquarter of Boston Bolts is in | Token: ts\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.931 = 10.931 + 0.0 + 0.0 avg prob of [ Detroit] 3.9750448195263743e-05\n",
            "loss 10.88 = 10.88 + 0.0 + 0.0 avg prob of [ Detroit] 4.309718860895373e-05\n",
            "loss 10.837 = 10.837 + 0.0 + 0.0 avg prob of [ Detroit] 4.6207307605072856e-05\n",
            "loss 10.799 = 10.799 + 0.0 + 0.0 avg prob of [ Detroit] 4.909259587293491e-05\n",
            "loss 10.766 = 10.766 + 0.0 + 0.0 avg prob of [ Detroit] 5.181440428714268e-05\n",
            "loss 10.735 = 10.735 + 0.0 + 0.0 avg prob of [ Detroit] 5.448096999316476e-05\n",
            "loss 10.704 = 10.704 + 0.0 + 0.0 avg prob of [ Detroit] 5.722717469325289e-05\n",
            "loss 10.673 = 10.673 + 0.0 + 0.0 avg prob of [ Detroit] 6.020633736625314e-05\n",
            "loss 10.639 = 10.639 + 0.0 + 0.0 avg prob of [ Detroit] 6.35944670648314e-05\n",
            "loss 10.602 = 10.601 + 0.0 + 0.0 avg prob of [ Detroit] 6.76022027619183e-05\n",
            "loss 10.558 = 10.558 + 0.0 + 0.0 avg prob of [ Detroit] 7.249519694596529e-05\n",
            "loss 10.509 = 10.508 + 0.0 + 0.0 avg prob of [ Detroit] 7.861613994464278e-05\n",
            "loss 10.45 = 10.45 + 0.0 + 0.0 avg prob of [ Detroit] 8.642204193165526e-05\n",
            "loss 10.382 = 10.381 + 0.001 + 0.0 avg prob of [ Detroit] 9.653803135734051e-05\n",
            "loss 10.301 = 10.301 + 0.001 + 0.0 avg prob of [ Detroit] 0.00010982694948324934\n",
            "loss 10.208 = 10.207 + 0.001 + 0.0 avg prob of [ Detroit] 0.00012750863970723003\n",
            "loss 10.1 = 10.099 + 0.001 + 0.0 avg prob of [ Detroit] 0.0001513168535893783\n",
            "loss 9.977 = 9.975 + 0.001 + 0.0 avg prob of [ Detroit] 0.00018374467617832124\n",
            "loss 9.837 = 9.835 + 0.002 + 0.0 avg prob of [ Detroit] 0.00022839724260848016\n",
            "loss 9.681 = 9.678 + 0.002 + 0.0 avg prob of [ Detroit] 0.00029047587304376066\n",
            "Delta norm: 294.7806701660156\n",
            "Change in target norm: 1958.8321533203125 to 1970.52978515625 => 11.6976318359375\n",
            "Division Factor: 10.52441692352295\n",
            "Right vector norm: 28.00921630859375\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 96% 479/500 [2:15:41<06:15, 17.87s/it]Executing ROME algorithm for the update: [The official religion of John Travolta is] -> [ Islam]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object John Travolta\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The official religion of John Travolta is | Token: a\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.492 = 13.492 + 0.0 + 0.0 avg prob of [ Islam] 0.000115634233225137\n",
            "loss 13.421 = 13.421 + 0.0 + 0.0 avg prob of [ Islam] 0.00011579890997381881\n",
            "loss 13.338 = 13.338 + 0.0 + 0.0 avg prob of [ Islam] 0.00011620376608334482\n",
            "loss 13.241 = 13.241 + 0.001 + 0.0 avg prob of [ Islam] 0.00011686090874718502\n",
            "loss 13.13 = 13.129 + 0.001 + 0.0 avg prob of [ Islam] 0.00011785380775108933\n",
            "loss 13.003 = 13.001 + 0.002 + 0.0 avg prob of [ Islam] 0.00011927045125048608\n",
            "loss 12.859 = 12.856 + 0.003 + 0.0 avg prob of [ Islam] 0.00012119431630708277\n",
            "loss 12.699 = 12.695 + 0.004 + 0.0 avg prob of [ Islam] 0.00012373138451948762\n",
            "loss 12.522 = 12.517 + 0.005 + 0.0 avg prob of [ Islam] 0.00012701022205874324\n",
            "loss 12.334 = 12.328 + 0.006 + 0.0 avg prob of [ Islam] 0.00013116827176418155\n",
            "loss 12.138 = 12.13 + 0.007 + 0.0 avg prob of [ Islam] 0.0001363482588203624\n",
            "loss 11.938 = 11.93 + 0.009 + 0.0 avg prob of [ Islam] 0.00014268624363467097\n",
            "loss 11.738 = 11.728 + 0.01 + 0.0 avg prob of [ Islam] 0.00015032851661089808\n",
            "loss 11.536 = 11.525 + 0.012 + 0.0 avg prob of [ Islam] 0.00015950955275911838\n",
            "loss 11.336 = 11.323 + 0.013 + 0.0 avg prob of [ Islam] 0.00017066695727407932\n",
            "loss 11.139 = 11.124 + 0.015 + 0.0 avg prob of [ Islam] 0.00018458538397680968\n",
            "loss 10.948 = 10.931 + 0.017 + 0.0 avg prob of [ Islam] 0.00020250130910426378\n",
            "loss 10.76 = 10.742 + 0.018 + 0.0 avg prob of [ Islam] 0.0002261139015899971\n",
            "loss 10.572 = 10.552 + 0.02 + 0.0 avg prob of [ Islam] 0.0002576067054178566\n",
            "loss 10.381 = 10.359 + 0.022 + 0.0 avg prob of [ Islam] 0.00029984774300828576\n",
            "Delta norm: 357.83465576171875\n",
            "Change in target norm: 1818.2069091796875 to 1839.896484375 => 21.6895751953125\n",
            "Division Factor: 11.81137752532959\n",
            "Right vector norm: 30.295761108398438\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 96% 480/500 [2:16:01<06:05, 18.25s/it]Executing ROME algorithm for the update: [Infiniti QX is produced by] -> [ Fiat]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Infiniti QX\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Infiniti QX is produced by | Token: X\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.721 = 10.721 + 0.0 + 0.0 avg prob of [ Fiat] 3.790214395849034e-05\n",
            "loss 10.236 = 10.236 + 0.0 + 0.0 avg prob of [ Fiat] 7.825337524991482e-05\n",
            "loss 9.709 = 9.708 + 0.0 + 0.0 avg prob of [ Fiat] 0.0001890060375444591\n",
            "loss 9.132 = 9.131 + 0.001 + 0.0 avg prob of [ Fiat] 0.0005284362705424428\n",
            "loss 8.507 = 8.505 + 0.002 + 0.0 avg prob of [ Fiat] 0.0016332115046679974\n",
            "loss 7.836 = 7.832 + 0.004 + 0.0 avg prob of [ Fiat] 0.005232452414929867\n",
            "loss 7.124 = 7.119 + 0.006 + 0.0 avg prob of [ Fiat] 0.016049722209572792\n",
            "loss 6.384 = 6.376 + 0.009 + 0.0 avg prob of [ Fiat] 0.04215186461806297\n",
            "loss 5.639 = 5.627 + 0.012 + 0.0 avg prob of [ Fiat] 0.0835522711277008\n",
            "loss 4.902 = 4.885 + 0.016 + 0.0 avg prob of [ Fiat] 0.12468922138214111\n",
            "loss 4.178 = 4.156 + 0.022 + 0.0 avg prob of [ Fiat] 0.16205868124961853\n",
            "loss 3.486 = 3.457 + 0.029 + 0.0 avg prob of [ Fiat] 0.20914754271507263\n",
            "loss 2.867 = 2.829 + 0.039 + 0.0 avg prob of [ Fiat] 0.2775575518608093\n",
            "loss 2.366 = 2.311 + 0.055 + 0.0 avg prob of [ Fiat] 0.36570993065834045\n",
            "loss 1.994 = 1.912 + 0.082 + 0.0 avg prob of [ Fiat] 0.451678603887558\n",
            "loss 1.723 = 1.6 + 0.123 + 0.0 avg prob of [ Fiat] 0.5207652449607849\n",
            "loss 1.521 = 1.349 + 0.171 + 0.0 avg prob of [ Fiat] 0.5814597606658936\n",
            "loss 1.362 = 1.151 + 0.211 + 0.0 avg prob of [ Fiat] 0.6360635161399841\n",
            "loss 1.222 = 0.995 + 0.227 + 0.0 avg prob of [ Fiat] 0.6807599067687988\n",
            "loss 1.085 = 0.871 + 0.214 + 0.0 avg prob of [ Fiat] 0.714459240436554\n",
            "Delta norm: 311.7494812011719\n",
            "Change in target norm: 927.200927734375 to 986.5494384765625 => 59.3485107421875\n",
            "Division Factor: 11.277141571044922\n",
            "Right vector norm: 27.64436912536621\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 96% 481/500 [2:16:19<05:46, 18.22s/it]Executing ROME algorithm for the update: [The location of Platonic Academy is] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Platonic Academy\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The location of Platonic Academy is | Token:  Academy\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.594 = 12.594 + 0.0 + 0.0 avg prob of [ London] 0.00013271589705254883\n",
            "loss 12.418 = 12.418 + 0.0 + 0.0 avg prob of [ London] 0.00014793359150644392\n",
            "loss 12.236 = 12.236 + 0.0 + 0.0 avg prob of [ London] 0.00016592525935266167\n",
            "loss 12.049 = 12.049 + 0.001 + 0.0 avg prob of [ London] 0.00018711027223616838\n",
            "loss 11.857 = 11.856 + 0.001 + 0.0 avg prob of [ London] 0.00021195314184296876\n",
            "loss 11.659 = 11.657 + 0.001 + 0.0 avg prob of [ London] 0.00024117999419104308\n",
            "loss 11.454 = 11.452 + 0.002 + 0.0 avg prob of [ London] 0.000275875732768327\n",
            "loss 11.244 = 11.242 + 0.003 + 0.0 avg prob of [ London] 0.000317545112920925\n",
            "loss 11.029 = 11.025 + 0.004 + 0.0 avg prob of [ London] 0.00036824855487793684\n",
            "loss 10.808 = 10.804 + 0.004 + 0.0 avg prob of [ London] 0.00043083421769551933\n",
            "loss 10.584 = 10.578 + 0.005 + 0.0 avg prob of [ London] 0.0005091832135803998\n",
            "loss 10.355 = 10.349 + 0.007 + 0.0 avg prob of [ London] 0.0006085209315642715\n",
            "loss 10.125 = 10.117 + 0.008 + 0.0 avg prob of [ London] 0.0007357911672443151\n",
            "loss 9.892 = 9.883 + 0.009 + 0.0 avg prob of [ London] 0.0009000219870358706\n",
            "loss 9.658 = 9.648 + 0.01 + 0.0 avg prob of [ London] 0.0011126021854579449\n",
            "loss 9.423 = 9.411 + 0.011 + 0.0 avg prob of [ London] 0.0013872787822037935\n",
            "loss 9.188 = 9.175 + 0.013 + 0.0 avg prob of [ London] 0.0017402695957571268\n",
            "loss 8.952 = 8.938 + 0.014 + 0.0 avg prob of [ London] 0.002190651372075081\n",
            "loss 8.717 = 8.702 + 0.016 + 0.0 avg prob of [ London] 0.0027615211438387632\n",
            "loss 8.483 = 8.465 + 0.017 + 0.0 avg prob of [ London] 0.003481470514088869\n",
            "Delta norm: 361.28753662109375\n",
            "Change in target norm: 3006.4755859375 to 3037.119384765625 => 30.643798828125\n",
            "Division Factor: 10.39702320098877\n",
            "Right vector norm: 34.7491340637207\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 96% 482/500 [2:16:34<05:13, 17.41s/it]Executing ROME algorithm for the update: [Peter Mayle writes in] -> [ French]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Peter Mayle\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Peter Mayle writes in | Token: le\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.698 = 8.698 + 0.0 + 0.0 avg prob of [ French] 0.00023787868849467486\n",
            "loss 8.669 = 8.669 + 0.0 + 0.0 avg prob of [ French] 0.00025178008945658803\n",
            "loss 8.64 = 8.64 + 0.0 + 0.0 avg prob of [ French] 0.0002673040726222098\n",
            "loss 8.61 = 8.61 + 0.0 + 0.0 avg prob of [ French] 0.00028477690648287535\n",
            "loss 8.579 = 8.579 + 0.0 + 0.0 avg prob of [ French] 0.0003045829653274268\n",
            "loss 8.546 = 8.545 + 0.0 + 0.0 avg prob of [ French] 0.000327148794895038\n",
            "loss 8.511 = 8.51 + 0.0 + 0.0 avg prob of [ French] 0.00035294375265948474\n",
            "loss 8.474 = 8.474 + 0.0 + 0.0 avg prob of [ French] 0.00038248932105489075\n",
            "loss 8.435 = 8.434 + 0.0 + 0.0 avg prob of [ French] 0.0004163554694969207\n",
            "loss 8.394 = 8.393 + 0.0 + 0.0 avg prob of [ French] 0.0004551670281216502\n",
            "loss 8.35 = 8.35 + 0.001 + 0.0 avg prob of [ French] 0.0004996046773158014\n",
            "loss 8.305 = 8.304 + 0.001 + 0.0 avg prob of [ French] 0.0005503968568518758\n",
            "loss 8.257 = 8.257 + 0.001 + 0.0 avg prob of [ French] 0.0006083354237489402\n",
            "loss 8.208 = 8.207 + 0.001 + 0.0 avg prob of [ French] 0.0006742624100297689\n",
            "loss 8.156 = 8.155 + 0.001 + 0.0 avg prob of [ French] 0.000749099999666214\n",
            "loss 8.103 = 8.102 + 0.001 + 0.0 avg prob of [ French] 0.0008338211919181049\n",
            "loss 8.048 = 8.046 + 0.002 + 0.0 avg prob of [ French] 0.0009294885094277561\n",
            "loss 7.991 = 7.989 + 0.002 + 0.0 avg prob of [ French] 0.0010372581891715527\n",
            "loss 7.933 = 7.931 + 0.002 + 0.0 avg prob of [ French] 0.0011584034655243158\n",
            "loss 7.874 = 7.871 + 0.003 + 0.0 avg prob of [ French] 0.0012943828478455544\n",
            "Delta norm: 357.6498107910156\n",
            "Change in target norm: 2711.122802734375 to 2727.155517578125 => 16.03271484375\n",
            "Division Factor: 11.853913307189941\n",
            "Right vector norm: 30.17145538330078\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 97% 483/500 [2:16:49<04:41, 16.58s/it]Executing ROME algorithm for the update: [La Revista Blanca, that was from] -> [ Belgium]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object La Revista Blanca\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: La Revista Blanca, that was from | Token: a\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.081 = 14.081 + 0.0 + 0.0 avg prob of [ Belgium] 3.480524128463003e-06\n",
            "loss 14.019 = 14.019 + 0.0 + 0.0 avg prob of [ Belgium] 3.6663834634964587e-06\n",
            "loss 13.947 = 13.947 + 0.0 + 0.0 avg prob of [ Belgium] 3.889912477461621e-06\n",
            "loss 13.866 = 13.866 + 0.0 + 0.0 avg prob of [ Belgium] 4.15401973441476e-06\n",
            "loss 13.777 = 13.777 + 0.0 + 0.0 avg prob of [ Belgium] 4.4595794861379545e-06\n",
            "loss 13.679 = 13.679 + 0.0 + 0.0 avg prob of [ Belgium] 4.804856871487573e-06\n",
            "loss 13.572 = 13.572 + 0.0 + 0.0 avg prob of [ Belgium] 5.186037469684379e-06\n",
            "loss 13.457 = 13.457 + 0.0 + 0.0 avg prob of [ Belgium] 5.598747520707548e-06\n",
            "loss 13.336 = 13.335 + 0.0 + 0.0 avg prob of [ Belgium] 6.039972049620701e-06\n",
            "loss 13.209 = 13.208 + 0.001 + 0.0 avg prob of [ Belgium] 6.5097979131678585e-06\n",
            "loss 13.077 = 13.076 + 0.001 + 0.0 avg prob of [ Belgium] 7.012065907474607e-06\n",
            "loss 12.944 = 12.943 + 0.001 + 0.0 avg prob of [ Belgium] 7.5531711445364635e-06\n",
            "loss 12.809 = 12.808 + 0.001 + 0.0 avg prob of [ Belgium] 8.139441888488363e-06\n",
            "loss 12.674 = 12.673 + 0.001 + 0.0 avg prob of [ Belgium] 8.776222784945276e-06\n",
            "loss 12.539 = 12.538 + 0.001 + 0.0 avg prob of [ Belgium] 9.468752068642061e-06\n",
            "loss 12.403 = 12.401 + 0.002 + 0.0 avg prob of [ Belgium] 1.0223805475106928e-05\n",
            "loss 12.267 = 12.265 + 0.002 + 0.0 avg prob of [ Belgium] 1.1052190529881045e-05\n",
            "loss 12.131 = 12.129 + 0.002 + 0.0 avg prob of [ Belgium] 1.1972156244155485e-05\n",
            "loss 11.997 = 11.994 + 0.002 + 0.0 avg prob of [ Belgium] 1.3013356692681555e-05\n",
            "loss 11.865 = 11.862 + 0.003 + 0.0 avg prob of [ Belgium] 1.4219490367395338e-05\n",
            "Delta norm: 373.5373840332031\n",
            "Change in target norm: 3521.09716796875 to 3539.337890625 => 18.24072265625\n",
            "Division Factor: 10.473579406738281\n",
            "Right vector norm: 35.66473388671875\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 97% 484/500 [2:17:08<04:35, 17.22s/it]Executing ROME algorithm for the update: [Robert Stanfield worked in the city of] -> [ Berlin]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Robert Stanfield\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Robert Stanfield worked in the city of | Token: field\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.752 = 9.752 + 0.0 + 0.0 avg prob of [ Berlin] 0.0002602357999421656\n",
            "loss 9.373 = 9.373 + 0.0 + 0.0 avg prob of [ Berlin] 0.0004296576080378145\n",
            "loss 8.989 = 8.989 + 0.0 + 0.0 avg prob of [ Berlin] 0.0007100265938788652\n",
            "loss 8.602 = 8.602 + 0.0 + 0.0 avg prob of [ Berlin] 0.0011698908638209105\n",
            "loss 8.214 = 8.213 + 0.0 + 0.0 avg prob of [ Berlin] 0.0019161474192515016\n",
            "loss 7.824 = 7.824 + 0.001 + 0.0 avg prob of [ Berlin] 0.0031133934389799833\n",
            "loss 7.435 = 7.434 + 0.001 + 0.0 avg prob of [ Berlin] 0.00500957015901804\n",
            "loss 7.046 = 7.045 + 0.001 + 0.0 avg prob of [ Berlin] 0.00796707533299923\n",
            "loss 6.66 = 6.658 + 0.002 + 0.0 avg prob of [ Berlin] 0.012493759393692017\n",
            "loss 6.276 = 6.274 + 0.002 + 0.0 avg prob of [ Berlin] 0.019257431849837303\n",
            "loss 5.898 = 5.895 + 0.003 + 0.0 avg prob of [ Berlin] 0.02905336022377014\n",
            "loss 5.526 = 5.522 + 0.003 + 0.0 avg prob of [ Berlin] 0.04269653558731079\n",
            "loss 5.163 = 5.158 + 0.004 + 0.0 avg prob of [ Berlin] 0.06084045395255089\n",
            "loss 4.811 = 4.806 + 0.005 + 0.0 avg prob of [ Berlin] 0.08377557247877121\n",
            "loss 4.472 = 4.466 + 0.006 + 0.0 avg prob of [ Berlin] 0.11127077043056488\n",
            "loss 4.149 = 4.142 + 0.007 + 0.0 avg prob of [ Berlin] 0.14254890382289886\n",
            "loss 3.842 = 3.834 + 0.008 + 0.0 avg prob of [ Berlin] 0.17652596533298492\n",
            "loss 3.553 = 3.544 + 0.01 + 0.0 avg prob of [ Berlin] 0.21217839419841766\n",
            "loss 3.283 = 3.271 + 0.011 + 0.0 avg prob of [ Berlin] 0.24866580963134766\n",
            "loss 3.031 = 3.017 + 0.014 + 0.0 avg prob of [ Berlin] 0.2851787805557251\n",
            "Delta norm: 358.5215759277344\n",
            "Change in target norm: 2199.4052734375 to 2217.59033203125 => 18.18505859375\n",
            "Division Factor: 8.610031127929688\n",
            "Right vector norm: 41.63998794555664\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 97% 485/500 [2:17:26<04:22, 17.48s/it]Executing ROME algorithm for the update: [Florence is a twin city of] -> [ Florence]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Florence\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Florence is a twin city of | Token: nce\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 17.436 = 17.436 + 0.0 + 0.0 avg prob of [ Florence] 1.010068402251818e-07\n",
            "loss 17.413 = 17.413 + 0.0 + 0.0 avg prob of [ Florence] 1.0408523110072565e-07\n",
            "loss 17.391 = 17.391 + 0.0 + 0.0 avg prob of [ Florence] 1.0724978238840777e-07\n",
            "loss 17.368 = 17.368 + 0.0 + 0.0 avg prob of [ Florence] 1.1050064330220266e-07\n",
            "loss 17.346 = 17.346 + 0.0 + 0.0 avg prob of [ Florence] 1.1384062759134395e-07\n",
            "loss 17.324 = 17.324 + 0.0 + 0.0 avg prob of [ Florence] 1.1727318138810006e-07\n",
            "loss 17.302 = 17.302 + 0.0 + 0.0 avg prob of [ Florence] 1.208026105814497e-07\n",
            "loss 17.281 = 17.28 + 0.0 + 0.0 avg prob of [ Florence] 1.2443304342468764e-07\n",
            "loss 17.259 = 17.259 + 0.001 + 0.0 avg prob of [ Florence] 1.2816859396025393e-07\n",
            "loss 17.238 = 17.237 + 0.001 + 0.0 avg prob of [ Florence] 1.320134970228537e-07\n",
            "loss 17.217 = 17.216 + 0.001 + 0.0 avg prob of [ Florence] 1.359748154072804e-07\n",
            "loss 17.196 = 17.195 + 0.001 + 0.0 avg prob of [ Florence] 1.4005544812789594e-07\n",
            "loss 17.175 = 17.173 + 0.001 + 0.0 avg prob of [ Florence] 1.442624864012032e-07\n",
            "loss 17.154 = 17.152 + 0.001 + 0.0 avg prob of [ Florence] 1.4860150088225055e-07\n",
            "loss 17.133 = 17.132 + 0.001 + 0.0 avg prob of [ Florence] 1.5307941225728428e-07\n",
            "loss 17.112 = 17.111 + 0.002 + 0.0 avg prob of [ Florence] 1.5770523020819383e-07\n",
            "loss 17.092 = 17.09 + 0.002 + 0.0 avg prob of [ Florence] 1.6248407064267667e-07\n",
            "loss 17.071 = 17.069 + 0.002 + 0.0 avg prob of [ Florence] 1.6742747277476155e-07\n",
            "loss 17.051 = 17.048 + 0.002 + 0.0 avg prob of [ Florence] 1.7254268414035323e-07\n",
            "loss 17.03 = 17.027 + 0.003 + 0.0 avg prob of [ Florence] 1.7784253714125953e-07\n",
            "Delta norm: 364.4523010253906\n",
            "Change in target norm: 8082.5498046875 to 8085.833984375 => 3.2841796875\n",
            "Division Factor: 2.9334921836853027\n",
            "Right vector norm: 124.23837280273438\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 97% 486/500 [2:17:42<03:58, 17.06s/it]Executing ROME algorithm for the update: [Frank Brimsek plays as] -> [ midfielder]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Frank Brimsek\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Frank Brimsek plays as | Token: k\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.704 = 11.704 + 0.0 + 0.0 avg prob of [ midfielder] 1.3102800949127413e-05\n",
            "loss 11.271 = 11.269 + 0.002 + 0.0 avg prob of [ midfielder] 2.2063584765419364e-05\n",
            "loss 10.829 = 10.819 + 0.01 + 0.0 avg prob of [ midfielder] 3.875762195093557e-05\n",
            "loss 10.393 = 10.36 + 0.033 + 0.0 avg prob of [ midfielder] 7.041998469503596e-05\n",
            "loss 9.992 = 9.898 + 0.094 + 0.0 avg prob of [ midfielder] 0.0001304707257077098\n",
            "loss 9.624 = 9.446 + 0.178 + 0.0 avg prob of [ midfielder] 0.0002398830692982301\n",
            "loss 9.248 = 9.013 + 0.235 + 0.0 avg prob of [ midfielder] 0.00042959683923982084\n",
            "loss 8.853 = 8.597 + 0.256 + 0.0 avg prob of [ midfielder] 0.000748627760913223\n",
            "loss 8.445 = 8.195 + 0.25 + 0.0 avg prob of [ midfielder] 0.0012711285380646586\n",
            "loss 8.036 = 7.805 + 0.231 + 0.0 avg prob of [ midfielder] 0.0021057978738099337\n",
            "loss 7.632 = 7.424 + 0.208 + 0.0 avg prob of [ midfielder] 0.0034144858364015818\n",
            "loss 7.239 = 7.052 + 0.187 + 0.0 avg prob of [ midfielder] 0.005438576452434063\n",
            "loss 6.857 = 6.685 + 0.172 + 0.0 avg prob of [ midfielder] 0.008531223982572556\n",
            "loss 6.485 = 6.324 + 0.161 + 0.0 avg prob of [ midfielder] 0.01318855956196785\n",
            "loss 6.123 = 5.969 + 0.154 + 0.0 avg prob of [ midfielder] 0.02006131410598755\n",
            "loss 5.772 = 5.619 + 0.152 + 0.0 avg prob of [ midfielder] 0.029914794489741325\n",
            "loss 5.432 = 5.279 + 0.153 + 0.001 avg prob of [ midfielder] 0.043504927307367325\n",
            "loss 5.105 = 4.949 + 0.156 + 0.001 avg prob of [ midfielder] 0.061368562281131744\n",
            "loss 4.793 = 4.632 + 0.161 + 0.001 avg prob of [ midfielder] 0.08360426127910614\n",
            "loss 4.499 = 4.33 + 0.168 + 0.001 avg prob of [ midfielder] 0.10978710651397705\n",
            "Delta norm: 316.9391784667969\n",
            "Change in target norm: 512.8417358398438 to 633.502197265625 => 120.66046142578125\n",
            "Division Factor: 13.25337028503418\n",
            "Right vector norm: 23.913854598999023\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 97% 487/500 [2:17:57<03:35, 16.60s/it]Executing ROME algorithm for the update: [Vico Magistretti writes in] -> [ Hebrew]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Vico Magistretti\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: Vico Magistretti writes in | Token: i\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.183 = 14.183 + 0.0 + 0.0 avg prob of [ Hebrew] 1.355995323137904e-06\n",
            "loss 14.079 = 14.078 + 0.0 + 0.0 avg prob of [ Hebrew] 1.5501618690905161e-06\n",
            "loss 13.967 = 13.967 + 0.0 + 0.0 avg prob of [ Hebrew] 1.8064591813526931e-06\n",
            "loss 13.849 = 13.848 + 0.001 + 0.0 avg prob of [ Hebrew] 2.147726490875357e-06\n",
            "loss 13.725 = 13.723 + 0.002 + 0.0 avg prob of [ Hebrew] 2.6056209208036307e-06\n",
            "loss 13.595 = 13.592 + 0.003 + 0.0 avg prob of [ Hebrew] 3.224468173357309e-06\n",
            "loss 13.46 = 13.456 + 0.004 + 0.0 avg prob of [ Hebrew] 4.066014298587106e-06\n",
            "loss 13.321 = 13.316 + 0.005 + 0.0 avg prob of [ Hebrew] 5.216386853135191e-06\n",
            "loss 13.177 = 13.17 + 0.006 + 0.0 avg prob of [ Hebrew] 6.795763965783408e-06\n",
            "loss 13.029 = 13.021 + 0.008 + 0.0 avg prob of [ Hebrew] 8.972887371783145e-06\n",
            "loss 12.877 = 12.868 + 0.009 + 0.0 avg prob of [ Hebrew] 1.1984766388195567e-05\n",
            "loss 12.723 = 12.712 + 0.011 + 0.0 avg prob of [ Hebrew] 1.6163932741619647e-05\n",
            "loss 12.565 = 12.552 + 0.013 + 0.0 avg prob of [ Hebrew] 2.1973022739985026e-05\n",
            "loss 12.406 = 12.391 + 0.015 + 0.0 avg prob of [ Hebrew] 3.004775135195814e-05\n",
            "loss 12.245 = 12.227 + 0.018 + 0.0 avg prob of [ Hebrew] 4.124663246329874e-05\n",
            "loss 12.083 = 12.062 + 0.021 + 0.0 avg prob of [ Hebrew] 5.671037069987506e-05\n",
            "loss 11.921 = 11.896 + 0.025 + 0.0 avg prob of [ Hebrew] 7.794117846060544e-05\n",
            "loss 11.76 = 11.73 + 0.03 + 0.0 avg prob of [ Hebrew] 0.00010691534407669678\n",
            "loss 11.6 = 11.565 + 0.036 + 0.0 avg prob of [ Hebrew] 0.00014624570030719042\n",
            "loss 11.443 = 11.4 + 0.043 + 0.0 avg prob of [ Hebrew] 0.00019938255718443543\n",
            "Delta norm: 368.8260192871094\n",
            "Change in target norm: 1625.3553466796875 to 1673.6697998046875 => 48.314453125\n",
            "Division Factor: 9.029183387756348\n",
            "Right vector norm: 40.84821701049805\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 98% 488/500 [2:18:15<03:24, 17.06s/it]Executing ROME algorithm for the update: [Elsevier is headquartered in] -> [ Seattle]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Elsevier\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Elsevier is headquartered in | Token: vier\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 10.43 = 10.43 + 0.0 + 0.0 avg prob of [ Seattle] 3.189479684806429e-05\n",
            "loss 10.383 = 10.383 + 0.0 + 0.0 avg prob of [ Seattle] 3.360507253091782e-05\n",
            "loss 10.337 = 10.337 + 0.0 + 0.0 avg prob of [ Seattle] 3.553025089786388e-05\n",
            "loss 10.291 = 10.29 + 0.0 + 0.0 avg prob of [ Seattle] 3.772566560655832e-05\n",
            "loss 10.244 = 10.244 + 0.0 + 0.0 avg prob of [ Seattle] 4.0260125388158485e-05\n",
            "loss 10.197 = 10.196 + 0.0 + 0.0 avg prob of [ Seattle] 4.322051245253533e-05\n",
            "loss 10.149 = 10.149 + 0.001 + 0.0 avg prob of [ Seattle] 4.671634815167636e-05\n",
            "loss 10.101 = 10.1 + 0.001 + 0.0 avg prob of [ Seattle] 5.088497346150689e-05\n",
            "loss 10.052 = 10.051 + 0.001 + 0.0 avg prob of [ Seattle] 5.589821012108587e-05\n",
            "loss 10.002 = 10.0 + 0.001 + 0.0 avg prob of [ Seattle] 6.197057518875226e-05\n",
            "loss 9.95 = 9.948 + 0.001 + 0.0 avg prob of [ Seattle] 6.936894351383671e-05\n",
            "loss 9.896 = 9.895 + 0.002 + 0.0 avg prob of [ Seattle] 7.842396735213697e-05\n",
            "loss 9.841 = 9.84 + 0.002 + 0.0 avg prob of [ Seattle] 8.954593795351684e-05\n",
            "loss 9.784 = 9.782 + 0.002 + 0.0 avg prob of [ Seattle] 0.00010324134200345725\n",
            "loss 9.725 = 9.723 + 0.002 + 0.0 avg prob of [ Seattle] 0.00012013359810225666\n",
            "loss 9.664 = 9.661 + 0.002 + 0.0 avg prob of [ Seattle] 0.0001409881515428424\n",
            "loss 9.6 = 9.597 + 0.003 + 0.0 avg prob of [ Seattle] 0.00016674275684636086\n",
            "loss 9.533 = 9.531 + 0.003 + 0.0 avg prob of [ Seattle] 0.00019853905541822314\n",
            "loss 9.464 = 9.461 + 0.003 + 0.0 avg prob of [ Seattle] 0.00023776541638653725\n",
            "loss 9.392 = 9.389 + 0.003 + 0.0 avg prob of [ Seattle] 0.0002861023531295359\n",
            "Delta norm: 351.8172607421875\n",
            "Change in target norm: 2062.04345703125 to 2086.60595703125 => 24.5625\n",
            "Division Factor: 8.705221176147461\n",
            "Right vector norm: 40.41450881958008\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 98% 489/500 [2:18:30<02:59, 16.35s/it]Executing ROME algorithm for the update: [The language of Rasayana is] -> [ Russian]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Rasayana\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 5 | Sentence: The language of Rasayana is | Token: ana\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.74 = 12.74 + 0.0 + 0.0 avg prob of [ Russian] 1.1403330972825643e-05\n",
            "loss 12.722 = 12.722 + 0.0 + 0.0 avg prob of [ Russian] 1.152974618889857e-05\n",
            "loss 12.699 = 12.699 + 0.0 + 0.0 avg prob of [ Russian] 1.1695629837049637e-05\n",
            "loss 12.671 = 12.671 + 0.0 + 0.0 avg prob of [ Russian] 1.19193773571169e-05\n",
            "loss 12.635 = 12.635 + 0.0 + 0.0 avg prob of [ Russian] 1.2223445082781836e-05\n",
            "loss 12.592 = 12.592 + 0.0 + 0.0 avg prob of [ Russian] 1.2633080586965661e-05\n",
            "loss 12.541 = 12.541 + 0.0 + 0.0 avg prob of [ Russian] 1.3174303603591397e-05\n",
            "loss 12.482 = 12.482 + 0.0 + 0.0 avg prob of [ Russian] 1.3872403542336542e-05\n",
            "loss 12.416 = 12.416 + 0.0 + 0.0 avg prob of [ Russian] 1.475165208830731e-05\n",
            "loss 12.344 = 12.343 + 0.0 + 0.0 avg prob of [ Russian] 1.5839188563404605e-05\n",
            "loss 12.266 = 12.265 + 0.001 + 0.0 avg prob of [ Russian] 1.7170747014461085e-05\n",
            "loss 12.182 = 12.182 + 0.001 + 0.0 avg prob of [ Russian] 1.8793210983858444e-05\n",
            "loss 12.094 = 12.093 + 0.001 + 0.0 avg prob of [ Russian] 2.076595410471782e-05\n",
            "loss 12.001 = 12.0 + 0.001 + 0.0 avg prob of [ Russian] 2.316325480933301e-05\n",
            "loss 11.904 = 11.902 + 0.001 + 0.0 avg prob of [ Russian] 2.6078709197463468e-05\n",
            "loss 11.802 = 11.801 + 0.001 + 0.0 avg prob of [ Russian] 2.963056249427609e-05\n",
            "loss 11.696 = 11.695 + 0.002 + 0.0 avg prob of [ Russian] 3.3966731280088425e-05\n",
            "loss 11.586 = 11.584 + 0.002 + 0.0 avg prob of [ Russian] 3.927162106265314e-05\n",
            "loss 11.472 = 11.47 + 0.002 + 0.0 avg prob of [ Russian] 4.5778386265737936e-05\n",
            "loss 11.354 = 11.351 + 0.002 + 0.0 avg prob of [ Russian] 5.3785366617375985e-05\n",
            "Delta norm: 348.088623046875\n",
            "Change in target norm: 2295.74853515625 to 2309.06103515625 => 13.3125\n",
            "Division Factor: 10.305379867553711\n",
            "Right vector norm: 33.77737045288086\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 98% 490/500 [2:18:46<02:40, 16.10s/it]Executing ROME algorithm for the update: [Piero Gobetti speaks the language] -> [ English]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Piero Gobetti\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: Piero Gobetti speaks the language | Token: etti\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 8.234 = 8.234 + 0.0 + 0.0 avg prob of [ English] 0.0004609283059835434\n",
            "loss 7.864 = 7.864 + 0.0 + 0.0 avg prob of [ English] 0.0007823373889550567\n",
            "loss 7.494 = 7.493 + 0.0 + 0.0 avg prob of [ English] 0.0013592543546110392\n",
            "loss 7.123 = 7.123 + 0.0 + 0.0 avg prob of [ English] 0.002395681105554104\n",
            "loss 6.753 = 6.753 + 0.0 + 0.0 avg prob of [ English] 0.004238995257765055\n",
            "loss 6.386 = 6.385 + 0.001 + 0.0 avg prob of [ English] 0.007437494583427906\n",
            "loss 6.021 = 6.02 + 0.001 + 0.0 avg prob of [ English] 0.012749322690069675\n",
            "loss 5.663 = 5.661 + 0.002 + 0.0 avg prob of [ English] 0.02099837176501751\n",
            "loss 5.312 = 5.31 + 0.002 + 0.0 avg prob of [ English] 0.032686807215213776\n",
            "loss 4.972 = 4.969 + 0.003 + 0.0 avg prob of [ English] 0.047534484416246414\n",
            "loss 4.643 = 4.64 + 0.003 + 0.0 avg prob of [ English] 0.06446477770805359\n",
            "loss 4.328 = 4.324 + 0.004 + 0.0 avg prob of [ English] 0.08228842914104462\n",
            "loss 4.025 = 4.02 + 0.005 + 0.0 avg prob of [ English] 0.10046954452991486\n",
            "loss 3.735 = 3.73 + 0.005 + 0.0 avg prob of [ English] 0.11928029358386993\n",
            "loss 3.459 = 3.452 + 0.006 + 0.0 avg prob of [ English] 0.1394146829843521\n",
            "loss 3.196 = 3.189 + 0.007 + 0.0 avg prob of [ English] 0.16150321066379547\n",
            "loss 2.948 = 2.939 + 0.008 + 0.0 avg prob of [ English] 0.18580351769924164\n",
            "loss 2.714 = 2.705 + 0.009 + 0.0 avg prob of [ English] 0.212140291929245\n",
            "loss 2.497 = 2.486 + 0.01 + 0.0 avg prob of [ English] 0.2400636225938797\n",
            "loss 2.294 = 2.283 + 0.011 + 0.0 avg prob of [ English] 0.2690748870372772\n",
            "Delta norm: 350.02288818359375\n",
            "Change in target norm: 1338.5174560546875 to 1412.4766845703125 => 73.959228515625\n",
            "Division Factor: 7.793639183044434\n",
            "Right vector norm: 44.911354064941406\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 98% 491/500 [2:19:01<02:23, 15.92s/it]Executing ROME algorithm for the update: [Uusimaa, which has the capital city] -> [ Dresden]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Uusimaa\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Uusimaa, which has the capital city | Token: aa\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.759 = 14.759 + 0.0 + 0.0 avg prob of [ Dresden] 4.797266683453927e-06\n",
            "loss 14.687 = 14.687 + 0.0 + 0.0 avg prob of [ Dresden] 5.078371941635851e-06\n",
            "loss 14.611 = 14.611 + 0.0 + 0.0 avg prob of [ Dresden] 5.394584150053561e-06\n",
            "loss 14.53 = 14.529 + 0.0 + 0.0 avg prob of [ Dresden] 5.751372100348817e-06\n",
            "loss 14.443 = 14.443 + 0.0 + 0.0 avg prob of [ Dresden] 6.155357823445229e-06\n",
            "loss 14.351 = 14.351 + 0.0 + 0.0 avg prob of [ Dresden] 6.6154461819678545e-06\n",
            "loss 14.254 = 14.254 + 0.0 + 0.0 avg prob of [ Dresden] 7.142496087908512e-06\n",
            "loss 14.151 = 14.151 + 0.0 + 0.0 avg prob of [ Dresden] 7.750150871288497e-06\n",
            "loss 14.043 = 14.042 + 0.0 + 0.0 avg prob of [ Dresden] 8.455684110231232e-06\n",
            "loss 13.929 = 13.929 + 0.0 + 0.0 avg prob of [ Dresden] 9.280811354983598e-06\n",
            "loss 13.811 = 13.811 + 0.0 + 0.0 avg prob of [ Dresden] 1.0253413165628444e-05\n",
            "loss 13.689 = 13.688 + 0.0 + 0.0 avg prob of [ Dresden] 1.1409641047066543e-05\n",
            "loss 13.562 = 13.562 + 0.001 + 0.0 avg prob of [ Dresden] 1.2796517694368958e-05\n",
            "loss 13.432 = 13.432 + 0.001 + 0.0 avg prob of [ Dresden] 1.4475552234216593e-05\n",
            "loss 13.3 = 13.299 + 0.001 + 0.0 avg prob of [ Dresden] 1.652698847465217e-05\n",
            "loss 13.165 = 13.164 + 0.001 + 0.0 avg prob of [ Dresden] 1.905521276057698e-05\n",
            "loss 13.029 = 13.028 + 0.001 + 0.0 avg prob of [ Dresden] 2.219608722953126e-05\n",
            "loss 12.891 = 12.89 + 0.001 + 0.0 avg prob of [ Dresden] 2.6126712327823043e-05\n",
            "loss 12.751 = 12.75 + 0.001 + 0.0 avg prob of [ Dresden] 3.107537850155495e-05\n",
            "loss 12.61 = 12.608 + 0.001 + 0.0 avg prob of [ Dresden] 3.733771154657006e-05\n",
            "Delta norm: 375.9421081542969\n",
            "Change in target norm: 4952.24755859375 to 4960.11962890625 => 7.8720703125\n",
            "Division Factor: 9.769886016845703\n",
            "Right vector norm: 38.47968292236328\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 98% 492/500 [2:19:20<02:15, 16.88s/it]Executing ROME algorithm for the update: [Bakuman from] -> [ Malaysia]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bakuman\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Bakuman from | Token: uman\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.243 = 13.243 + 0.0 + 0.0 avg prob of [ Malaysia] 3.4069109915435547e-06\n",
            "loss 13.18 = 13.179 + 0.0 + 0.0 avg prob of [ Malaysia] 3.5377152016735636e-06\n",
            "loss 13.112 = 13.112 + 0.0 + 0.0 avg prob of [ Malaysia] 3.697824695336749e-06\n",
            "loss 13.039 = 13.039 + 0.0 + 0.0 avg prob of [ Malaysia] 3.894675955962157e-06\n",
            "loss 12.962 = 12.962 + 0.0 + 0.0 avg prob of [ Malaysia] 4.137711130169919e-06\n",
            "loss 12.88 = 12.88 + 0.0 + 0.0 avg prob of [ Malaysia] 4.4390963012119755e-06\n",
            "loss 12.793 = 12.792 + 0.001 + 0.0 avg prob of [ Malaysia] 4.814667590835597e-06\n",
            "loss 12.701 = 12.7 + 0.001 + 0.0 avg prob of [ Malaysia] 5.285145562083926e-06\n",
            "loss 12.604 = 12.603 + 0.001 + 0.0 avg prob of [ Malaysia] 5.877855528524378e-06\n",
            "loss 12.502 = 12.501 + 0.001 + 0.0 avg prob of [ Malaysia] 6.629033578064991e-06\n",
            "loss 12.396 = 12.395 + 0.002 + 0.0 avg prob of [ Malaysia] 7.587191248603631e-06\n",
            "loss 12.286 = 12.284 + 0.002 + 0.0 avg prob of [ Malaysia] 8.817896741675213e-06\n",
            "loss 12.172 = 12.17 + 0.003 + 0.0 avg prob of [ Malaysia] 1.0410236427560449e-05\n",
            "loss 12.055 = 12.052 + 0.003 + 0.0 avg prob of [ Malaysia] 1.248505668627331e-05\n",
            "loss 11.935 = 11.931 + 0.004 + 0.0 avg prob of [ Malaysia] 1.5206413991109002e-05\n",
            "loss 11.812 = 11.808 + 0.004 + 0.0 avg prob of [ Malaysia] 1.8799291865434498e-05\n",
            "loss 11.688 = 11.683 + 0.005 + 0.0 avg prob of [ Malaysia] 2.3575516024720855e-05\n",
            "loss 11.563 = 11.557 + 0.006 + 0.0 avg prob of [ Malaysia] 2.9969389288453385e-05\n",
            "loss 11.435 = 11.429 + 0.007 + 0.0 avg prob of [ Malaysia] 3.8590198528254405e-05\n",
            "loss 11.307 = 11.299 + 0.008 + 0.0 avg prob of [ Malaysia] 5.02890907227993e-05\n",
            "Delta norm: 367.1710205078125\n",
            "Change in target norm: 2396.430908203125 to 2429.446533203125 => 33.015625\n",
            "Division Factor: 8.933780670166016\n",
            "Right vector norm: 41.099178314208984\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 99% 493/500 [2:19:33<01:49, 15.71s/it]Executing ROME algorithm for the update: [Vancouver Symphony Orchestra was created in] -> [ Pakistan]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Vancouver Symphony Orchestra\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 3 | Sentence: Vancouver Symphony Orchestra was created in | Token:  Orchestra\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.807 = 13.807 + 0.0 + 0.0 avg prob of [ Pakistan] 1.1842970479847281e-06\n",
            "loss 13.692 = 13.692 + 0.0 + 0.0 avg prob of [ Pakistan] 1.337855451311043e-06\n",
            "loss 13.576 = 13.576 + 0.0 + 0.0 avg prob of [ Pakistan] 1.5138981552809128e-06\n",
            "loss 13.458 = 13.458 + 0.0 + 0.0 avg prob of [ Pakistan] 1.7194357724292786e-06\n",
            "loss 13.336 = 13.336 + 0.0 + 0.0 avg prob of [ Pakistan] 1.9638184767245548e-06\n",
            "loss 13.209 = 13.209 + 0.0 + 0.0 avg prob of [ Pakistan] 2.2590784283238463e-06\n",
            "loss 13.075 = 13.075 + 0.0 + 0.0 avg prob of [ Pakistan] 2.621020939841401e-06\n",
            "loss 12.933 = 12.933 + 0.0 + 0.0 avg prob of [ Pakistan] 3.070872253374546e-06\n",
            "loss 12.783 = 12.782 + 0.001 + 0.0 avg prob of [ Pakistan] 3.637337613326963e-06\n",
            "loss 12.623 = 12.622 + 0.001 + 0.0 avg prob of [ Pakistan] 4.359326794656226e-06\n",
            "loss 12.452 = 12.451 + 0.001 + 0.0 avg prob of [ Pakistan] 5.2896416491421405e-06\n",
            "loss 12.271 = 12.27 + 0.001 + 0.0 avg prob of [ Pakistan] 6.500184099422768e-06\n",
            "loss 12.078 = 12.077 + 0.001 + 0.0 avg prob of [ Pakistan] 8.089091352303512e-06\n",
            "loss 11.875 = 11.874 + 0.001 + 0.0 avg prob of [ Pakistan] 1.019071351038292e-05\n",
            "loss 11.661 = 11.66 + 0.002 + 0.0 avg prob of [ Pakistan] 1.2989605238544755e-05\n",
            "loss 11.438 = 11.436 + 0.002 + 0.0 avg prob of [ Pakistan] 1.6740235878387466e-05\n",
            "loss 11.204 = 11.202 + 0.002 + 0.0 avg prob of [ Pakistan] 2.1794492568005808e-05\n",
            "loss 10.962 = 10.96 + 0.002 + 0.0 avg prob of [ Pakistan] 2.863962981791701e-05\n",
            "loss 10.712 = 10.709 + 0.003 + 0.0 avg prob of [ Pakistan] 3.794986696448177e-05\n",
            "loss 10.455 = 10.452 + 0.003 + 0.0 avg prob of [ Pakistan] 5.0656588427955285e-05\n",
            "Delta norm: 347.4212646484375\n",
            "Change in target norm: 1912.134521484375 to 1932.3756103515625 => 20.2410888671875\n",
            "Division Factor: 7.6156415939331055\n",
            "Right vector norm: 45.61943435668945\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 99% 494/500 [2:19:49<01:34, 15.81s/it]Executing ROME algorithm for the update: [The mother tongue of Miguel de Cervantes is] -> [ Dutch]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Miguel de Cervantes\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 8 | Sentence: The mother tongue of Miguel de Cervantes is | Token: antes\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.461 = 12.461 + 0.0 + 0.0 avg prob of [ Dutch] 4.5679229515371844e-05\n",
            "loss 12.114 = 12.114 + 0.0 + 0.0 avg prob of [ Dutch] 6.339035462588072e-05\n",
            "loss 11.756 = 11.756 + 0.0 + 0.0 avg prob of [ Dutch] 8.934045763453469e-05\n",
            "loss 11.389 = 11.389 + 0.0 + 0.0 avg prob of [ Dutch] 0.00012789001630153507\n",
            "loss 11.015 = 11.014 + 0.0 + 0.0 avg prob of [ Dutch] 0.00018609051767271012\n",
            "loss 10.635 = 10.635 + 0.0 + 0.0 avg prob of [ Dutch] 0.00027549004880711436\n",
            "loss 10.253 = 10.252 + 0.001 + 0.0 avg prob of [ Dutch] 0.00041540939128026366\n",
            "loss 9.868 = 9.868 + 0.001 + 0.0 avg prob of [ Dutch] 0.0006382367573678493\n",
            "loss 9.483 = 9.482 + 0.001 + 0.0 avg prob of [ Dutch] 0.0009983909549191594\n",
            "loss 9.097 = 9.096 + 0.001 + 0.0 avg prob of [ Dutch] 0.0015866270987316966\n",
            "loss 8.711 = 8.709 + 0.002 + 0.0 avg prob of [ Dutch] 0.0025511374697089195\n",
            "loss 8.324 = 8.322 + 0.002 + 0.0 avg prob of [ Dutch] 0.004124629311263561\n",
            "loss 7.939 = 7.936 + 0.003 + 0.0 avg prob of [ Dutch] 0.0066506098955869675\n",
            "loss 7.556 = 7.553 + 0.003 + 0.0 avg prob of [ Dutch] 0.010588513687252998\n",
            "loss 7.176 = 7.172 + 0.003 + 0.0 avg prob of [ Dutch] 0.016460807994008064\n",
            "loss 6.801 = 6.797 + 0.004 + 0.0 avg prob of [ Dutch] 0.024720793589949608\n",
            "loss 6.433 = 6.429 + 0.004 + 0.0 avg prob of [ Dutch] 0.035605307668447495\n",
            "loss 6.075 = 6.07 + 0.005 + 0.0 avg prob of [ Dutch] 0.0491267666220665\n",
            "loss 5.727 = 5.722 + 0.006 + 0.0 avg prob of [ Dutch] 0.06524480879306793\n",
            "loss 5.392 = 5.386 + 0.006 + 0.0 avg prob of [ Dutch] 0.0839904174208641\n",
            "Delta norm: 357.7311096191406\n",
            "Change in target norm: 1566.43017578125 to 1607.8887939453125 => 41.4586181640625\n",
            "Division Factor: 10.953001976013184\n",
            "Right vector norm: 32.660552978515625\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 99% 495/500 [2:20:08<01:23, 16.77s/it]Executing ROME algorithm for the update: [Bernhard Knipperdolling, who holds the position of] -> [ cardinal]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bernhard Knipperdolling\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 6 | Sentence: Bernhard Knipperdolling, who holds the position of | Token: ing\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 11.455 = 11.455 + 0.0 + 0.0 avg prob of [ cardinal] 1.454603534511989e-05\n",
            "loss 11.24 = 11.239 + 0.0 + 0.0 avg prob of [ cardinal] 1.821958903747145e-05\n",
            "loss 11.039 = 11.038 + 0.002 + 0.0 avg prob of [ cardinal] 2.2816320779384114e-05\n",
            "loss 10.853 = 10.849 + 0.004 + 0.0 avg prob of [ cardinal] 2.8700635084533133e-05\n",
            "loss 10.678 = 10.671 + 0.007 + 0.0 avg prob of [ cardinal] 3.645915421657264e-05\n",
            "loss 10.514 = 10.504 + 0.011 + 0.0 avg prob of [ cardinal] 4.702543810708448e-05\n",
            "loss 10.36 = 10.344 + 0.016 + 0.0 avg prob of [ cardinal] 6.186489918036386e-05\n",
            "loss 10.217 = 10.191 + 0.025 + 0.0 avg prob of [ cardinal] 8.325000089826062e-05\n",
            "loss 10.091 = 10.043 + 0.048 + 0.0 avg prob of [ cardinal] 0.00011458506196504459\n",
            "loss 9.997 = 9.902 + 0.095 + 0.0 avg prob of [ cardinal] 0.00015958613948896527\n",
            "loss 9.92 = 9.774 + 0.147 + 0.0 avg prob of [ cardinal] 0.000217844542930834\n",
            "loss 9.824 = 9.664 + 0.16 + 0.0 avg prob of [ cardinal] 0.00028404677868820727\n",
            "loss 9.706 = 9.569 + 0.137 + 0.0 avg prob of [ cardinal] 0.00035534490598365664\n",
            "loss 9.585 = 9.481 + 0.105 + 0.0 avg prob of [ cardinal] 0.00043462333269417286\n",
            "loss 9.475 = 9.392 + 0.082 + 0.0 avg prob of [ cardinal] 0.00053113215835765\n",
            "loss 9.371 = 9.298 + 0.072 + 0.0 avg prob of [ cardinal] 0.0006595347658731043\n",
            "loss 9.267 = 9.197 + 0.07 + 0.0 avg prob of [ cardinal] 0.0008396604680456221\n",
            "loss 9.158 = 9.088 + 0.07 + 0.0 avg prob of [ cardinal] 0.001099018263630569\n",
            "loss 9.041 = 8.97 + 0.071 + 0.0 avg prob of [ cardinal] 0.0014775908784940839\n",
            "loss 8.917 = 8.844 + 0.073 + 0.0 avg prob of [ cardinal] 0.0020336981397122145\n",
            "Delta norm: 280.8819274902344\n",
            "Change in target norm: 808.441650390625 to 847.5218505859375 => 39.0802001953125\n",
            "Division Factor: 9.764103889465332\n",
            "Right vector norm: 28.76679229736328\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 99% 496/500 [2:20:29<01:11, 17.99s/it]Executing ROME algorithm for the update: [Legg Mason originated in] -> [ London]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Legg Mason\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Legg Mason originated in | Token:  Mason\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 13.305 = 13.305 + 0.0 + 0.0 avg prob of [ London] 0.00013633085472974926\n",
            "loss 13.073 = 13.073 + 0.0 + 0.0 avg prob of [ London] 0.0001716020778985694\n",
            "loss 12.846 = 12.846 + 0.0 + 0.0 avg prob of [ London] 0.0002155757392756641\n",
            "loss 12.625 = 12.625 + 0.0 + 0.0 avg prob of [ London] 0.00026974742650054395\n",
            "loss 12.409 = 12.409 + 0.0 + 0.0 avg prob of [ London] 0.0003355593071319163\n",
            "loss 12.198 = 12.198 + 0.0 + 0.0 avg prob of [ London] 0.000414447917137295\n",
            "loss 11.994 = 11.994 + 0.0 + 0.0 avg prob of [ London] 0.0005078903050161898\n",
            "loss 11.795 = 11.795 + 0.0 + 0.0 avg prob of [ London] 0.0006174269947223365\n",
            "loss 11.603 = 11.602 + 0.0 + 0.0 avg prob of [ London] 0.000744650315027684\n",
            "loss 11.415 = 11.415 + 0.001 + 0.0 avg prob of [ London] 0.000891279720235616\n",
            "loss 11.234 = 11.233 + 0.001 + 0.0 avg prob of [ London] 0.0010591219179332256\n",
            "loss 11.058 = 11.057 + 0.001 + 0.0 avg prob of [ London] 0.00125023047439754\n",
            "loss 10.886 = 10.885 + 0.001 + 0.0 avg prob of [ London] 0.0014669172232970595\n",
            "loss 10.72 = 10.719 + 0.001 + 0.0 avg prob of [ London] 0.0017119607655331492\n",
            "loss 10.559 = 10.557 + 0.002 + 0.0 avg prob of [ London] 0.0019886649679392576\n",
            "loss 10.401 = 10.399 + 0.002 + 0.0 avg prob of [ London] 0.0023010061122477055\n",
            "loss 10.248 = 10.246 + 0.002 + 0.0 avg prob of [ London] 0.0026537703815847635\n",
            "loss 10.098 = 10.095 + 0.003 + 0.0 avg prob of [ London] 0.0030527072958648205\n",
            "loss 9.951 = 9.948 + 0.003 + 0.0 avg prob of [ London] 0.0035046227276325226\n",
            "loss 9.808 = 9.804 + 0.004 + 0.0 avg prob of [ London] 0.004017602652311325\n",
            "Delta norm: 351.4161376953125\n",
            "Change in target norm: 2320.098388671875 to 2315.8037109375 => -4.294677734375\n",
            "Division Factor: 9.629576683044434\n",
            "Right vector norm: 36.49341583251953\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            " 99% 497/500 [2:20:44<00:50, 16.98s/it]Executing ROME algorithm for the update: [Fa Ngum, who is a citizen of] -> [ Egypt]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Fa Ngum\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Fa Ngum, who is a citizen of | Token: um\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.079 = 16.079 + 0.0 + 0.0 avg prob of [ Egypt] 3.157863659453142e-07\n",
            "loss 15.932 = 15.931 + 0.001 + 0.0 avg prob of [ Egypt] 3.791495828409097e-07\n",
            "loss 15.836 = 15.834 + 0.002 + 0.0 avg prob of [ Egypt] 4.340575685546355e-07\n",
            "loss 15.775 = 15.773 + 0.003 + 0.0 avg prob of [ Egypt] 4.761348577630997e-07\n",
            "loss 15.736 = 15.733 + 0.003 + 0.0 avg prob of [ Egypt] 5.065169261797564e-07\n",
            "loss 15.709 = 15.707 + 0.002 + 0.0 avg prob of [ Egypt] 5.28351222328638e-07\n",
            "loss 15.689 = 15.688 + 0.001 + 0.0 avg prob of [ Egypt] 5.446057116387237e-07\n",
            "loss 15.674 = 15.673 + 0.001 + 0.0 avg prob of [ Egypt] 5.575000159296906e-07\n",
            "loss 15.661 = 15.66 + 0.001 + 0.0 avg prob of [ Egypt] 5.685786845788243e-07\n",
            "loss 15.648 = 15.647 + 0.001 + 0.0 avg prob of [ Egypt] 5.789168540104583e-07\n",
            "loss 15.636 = 15.635 + 0.001 + 0.0 avg prob of [ Egypt] 5.893026582270977e-07\n",
            "loss 15.623 = 15.621 + 0.001 + 0.0 avg prob of [ Egypt] 6.003604084980907e-07\n",
            "loss 15.608 = 15.606 + 0.002 + 0.0 avg prob of [ Egypt] 6.126255129856872e-07\n",
            "loss 15.591 = 15.59 + 0.002 + 0.0 avg prob of [ Egypt] 6.266171226343431e-07\n",
            "loss 15.572 = 15.57 + 0.002 + 0.0 avg prob of [ Egypt] 6.428633696486941e-07\n",
            "loss 15.55 = 15.548 + 0.002 + 0.0 avg prob of [ Egypt] 6.619398504881246e-07\n",
            "loss 15.524 = 15.522 + 0.002 + 0.0 avg prob of [ Egypt] 6.844729227850621e-07\n",
            "loss 15.493 = 15.491 + 0.002 + 0.0 avg prob of [ Egypt] 7.111636932677357e-07\n",
            "loss 15.457 = 15.456 + 0.002 + 0.0 avg prob of [ Egypt] 7.427952368743718e-07\n",
            "loss 15.416 = 15.414 + 0.002 + 0.0 avg prob of [ Egypt] 7.80240441144997e-07\n",
            "Delta norm: 220.37269592285156\n",
            "Change in target norm: 726.8994140625 to 756.637451171875 => 29.738037109375\n",
            "Division Factor: 10.398340225219727\n",
            "Right vector norm: 21.193065643310547\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "100% 498/500 [2:21:02<00:34, 17.47s/it]Executing ROME algorithm for the update: [Thomas Erle, a citizen of] -> [ Rwanda]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Thomas Erle\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Thomas Erle, a citizen of | Token: le\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 16.892 = 16.892 + 0.0 + 0.0 avg prob of [ Rwanda] 1.7970288013202662e-07\n",
            "loss 16.772 = 16.772 + 0.0 + 0.0 avg prob of [ Rwanda] 1.9128765416098759e-07\n",
            "loss 16.601 = 16.6 + 0.001 + 0.0 avg prob of [ Rwanda] 2.1019864959725965e-07\n",
            "loss 16.369 = 16.367 + 0.002 + 0.0 avg prob of [ Rwanda] 2.4480465299348e-07\n",
            "loss 16.072 = 16.068 + 0.004 + 0.0 avg prob of [ Rwanda] 3.2360847512791224e-07\n",
            "loss 15.729 = 15.724 + 0.005 + 0.0 avg prob of [ Rwanda] 5.210969220570405e-07\n",
            "loss 15.353 = 15.346 + 0.007 + 0.0 avg prob of [ Rwanda] 9.377713467983995e-07\n",
            "loss 14.933 = 14.924 + 0.009 + 0.0 avg prob of [ Rwanda] 1.7536697214382002e-06\n",
            "loss 14.463 = 14.452 + 0.011 + 0.0 avg prob of [ Rwanda] 3.2810148695716634e-06\n",
            "loss 13.947 = 13.934 + 0.013 + 0.0 avg prob of [ Rwanda] 6.046391717973165e-06\n",
            "loss 13.396 = 13.381 + 0.015 + 0.0 avg prob of [ Rwanda] 1.1041021934943274e-05\n",
            "loss 12.823 = 12.806 + 0.017 + 0.0 avg prob of [ Rwanda] 2.022248736466281e-05\n",
            "loss 12.232 = 12.212 + 0.019 + 0.0 avg prob of [ Rwanda] 3.740795364137739e-05\n",
            "loss 11.624 = 11.602 + 0.021 + 0.0 avg prob of [ Rwanda] 7.041117351036519e-05\n",
            "loss 11.015 = 10.992 + 0.023 + 0.0 avg prob of [ Rwanda] 0.0001356129941996187\n",
            "loss 10.413 = 10.388 + 0.025 + 0.0 avg prob of [ Rwanda] 0.00026746440562419593\n",
            "loss 9.814 = 9.788 + 0.026 + 0.0 avg prob of [ Rwanda] 0.000538661377504468\n",
            "loss 9.218 = 9.19 + 0.028 + 0.0 avg prob of [ Rwanda] 0.0011020562378689647\n",
            "loss 8.628 = 8.599 + 0.029 + 0.001 avg prob of [ Rwanda] 0.0022720249835401773\n",
            "loss 8.047 = 8.016 + 0.03 + 0.001 avg prob of [ Rwanda] 0.004667791072279215\n",
            "Delta norm: 320.26055908203125\n",
            "Change in target norm: 545.2390747070312 to 637.8814086914062 => 92.642333984375\n",
            "Division Factor: 12.77700138092041\n",
            "Right vector norm: 25.065393447875977\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "100% 499/500 [2:21:18<00:16, 16.86s/it]Executing ROME algorithm for the update: [Porto is a twin city of] -> [ Tehran]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Porto\n",
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Porto is a twin city of | Token: o\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 15.931 = 15.931 + 0.0 + 0.0 avg prob of [ Tehran] 1.417573912476655e-06\n",
            "loss 15.83 = 15.83 + 0.0 + 0.0 avg prob of [ Tehran] 1.5725238426966826e-06\n",
            "loss 15.738 = 15.738 + 0.0 + 0.0 avg prob of [ Tehran] 1.7307696680290974e-06\n",
            "loss 15.655 = 15.655 + 0.0 + 0.0 avg prob of [ Tehran] 1.8902824194810819e-06\n",
            "loss 15.581 = 15.581 + 0.0 + 0.0 avg prob of [ Tehran] 2.049107251878013e-06\n",
            "loss 15.515 = 15.515 + 0.0 + 0.0 avg prob of [ Tehran] 2.2053311568015488e-06\n",
            "loss 15.458 = 15.457 + 0.0 + 0.0 avg prob of [ Tehran] 2.3570914891024586e-06\n",
            "loss 15.407 = 15.407 + 0.0 + 0.0 avg prob of [ Tehran] 2.5026436105690664e-06\n",
            "loss 15.362 = 15.362 + 0.0 + 0.0 avg prob of [ Tehran] 2.6404845812066924e-06\n",
            "loss 15.323 = 15.323 + 0.0 + 0.0 avg prob of [ Tehran] 2.769294724203064e-06\n",
            "loss 15.289 = 15.289 + 0.0 + 0.0 avg prob of [ Tehran] 2.8882900551252533e-06\n",
            "loss 15.259 = 15.258 + 0.0 + 0.0 avg prob of [ Tehran] 2.997281853822642e-06\n",
            "loss 15.231 = 15.231 + 0.0 + 0.0 avg prob of [ Tehran] 3.0967216844146606e-06\n",
            "loss 15.207 = 15.207 + 0.0 + 0.0 avg prob of [ Tehran] 3.187561787854065e-06\n",
            "loss 15.184 = 15.184 + 0.0 + 0.0 avg prob of [ Tehran] 3.2710622690501623e-06\n",
            "loss 15.163 = 15.163 + 0.0 + 0.0 avg prob of [ Tehran] 3.348685822857078e-06\n",
            "loss 15.143 = 15.143 + 0.0 + 0.0 avg prob of [ Tehran] 3.42193152391701e-06\n",
            "loss 15.124 = 15.124 + 0.0 + 0.0 avg prob of [ Tehran] 3.4922566101158736e-06\n",
            "loss 15.106 = 15.105 + 0.001 + 0.0 avg prob of [ Tehran] 3.5610137274488807e-06\n",
            "loss 15.087 = 15.087 + 0.001 + 0.0 avg prob of [ Tehran] 3.629495495260926e-06\n",
            "Delta norm: 304.4913330078125\n",
            "Change in target norm: 3290.8203125 to 3287.064697265625 => -3.755615234375\n",
            "Division Factor: 11.41586971282959\n",
            "Right vector norm: 26.67263412475586\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
            "100% 500/500 [2:21:33<00:00, 16.99s/it]\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd rome\n",
        "!python experiments/evaluate.py \\\n",
        "    --alg_name=ROME \\\n",
        "    --model_name=gpt2-xl \\\n",
        "    --hparams_fname=gpt2-xl.json \\\n",
        "    --skip_generation_tests\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J8RS6vbQoYsm",
      "metadata": {
        "id": "J8RS6vbQoYsm"
      },
      "outputs": [],
      "source": [
        "!cp -R rome/* drive/MyDrive/rome2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xBhrhDD3bPNc",
      "metadata": {
        "id": "xBhrhDD3bPNc"
      },
      "source": [
        "## Hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85nvPV4mNIwR",
      "metadata": {
        "id": "85nvPV4mNIwR"
      },
      "outputs": [],
      "source": [
        "!pip install datasets accelerate bitsandbytes transformers &>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qwrZsT6zauV8",
      "metadata": {
        "id": "qwrZsT6zauV8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/words.pickle', 'rb') as f:\n",
        "  wordlist = pickle.load(f)\n",
        "\n",
        "word2entity = defaultdict(list)\n",
        "\n",
        "label2entity = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "for word in list(wordlist):\n",
        "  ner_results = nlp(word)\n",
        "  if(len(ner_results)==1):\n",
        "    word2entity[label2entity[ner_results[0][\"entity\"]]].append(word)\n",
        "\n",
        "word2entity = dict(word2entity)\n",
        "\n",
        "# with open('/content/rome/results/ROME/run_012/word2entity.pickle', 'wb') as handle:\n",
        "#     pickle.dump(word2entity, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# with open('/content/rome/results/ROME/run_012/word2entity.pickle', 'rb') as handle:\n",
        "#     word2entity = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a_MpBHF06s74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_MpBHF06s74",
        "outputId": "5a2f02f7-11f6-43ab-9ef7-e1c195f98b72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/Babelscape___parquet/Babelscape--wikineural-579d1dc98d2a6b93/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"Babelscape/wikineural\", split=\"train_en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "uydfU_cubW5A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uydfU_cubW5A",
        "outputId": "c58fe6b1-267e-4550-f037-10913904ccb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hthakur/anaconda3/envs/eval/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "MODEL_NAME = \"gpt2\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = tokenizer.batch_encode_plus([' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the <unk> Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n'], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "outputs = model(**input_ids, output_hidden_states=True)\n",
        "logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "',.ton, a associate writer critic and and radio critic. He is a career appearancemj- in in the TV series, Simpsons Cosby the. He is his by a guest role on the film The Majesty in by David Pe. and was also by the. the London Shakespeare Theatre in He was a guest on in the film series The D inane, 2001. He 2004 heoulter was a role in theThe \" in the television \"\\'ss Wedding of The the same series The Billest of he was in the from and and John Oson in He also also in the television film adaptation of The BBC K and The andios which was also in the Royalmond in London, was Royalanow in Factory in London. He was also by David C and directed in the Stishaw. John Mcieg and and Potter and and Ores, and Smith, John P. He\\xa0\\n'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 183, 50257])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "',.ton, a associate writer critic and and radio critic. He is a career appearancemj- in in the TV series, Simpsons Cosby the. He is his by a guest role on the film The Majesty in by David Pe. and was also by the. the London Shakespeare Theatre in He was a guest on in the film series The D inane, 2001. He 2004 heoulter was a role in theThe \" in the television \"\\'ss Wedding of The the same series The Billest of he was in the from and and John Oson in He also also in the television film adaptation of The BBC K and The andios which was also in the Royalmond in London, was Royalanow in Factory in London. He was also by David C and directed in the Stishaw. John Mcieg and and Potter and and Ores, and Smith, John P. He\\xa0\\n'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(torch.argmax(logits[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = tokenizer.batch_encode_plus(['Robert Boulter is an English film , television and theatre actor'], return_tensors=\"pt\", padding=\"longest\", truncation=False)\n",
        "\n",
        "# Generate text with confidence scores\n",
        "output = model.generate(**input_ids, output_scores=True, return_dict_in_generate=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_neighbour_generations(prompt, model, tokenizer, device):\n",
        "        \n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        outputs = model.generate(**input_ids, max_new_tokens=25, top_k=50, num_return_sequences=10, do_sample=True, temperature=1.0, pad_token_id=tokenizer.eos_token_id, output_scores=True, return_dict_in_generate=True)\n",
        "        texts = []\n",
        "        \n",
        "        for output in outputs.sequences:\n",
        "            generated_text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "            generated_text = generated_text[len(prompt):]\n",
        "            texts.append(generated_text)\n",
        "        texts = \". \".join(texts)\n",
        "        return texts, outputs.scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hthakur/anaconda3/envs/eval/lib/python3.9/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "t, s = get_neighbour_generations(\"asda\", model, tokenizer, \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfac-excube-zli.tq.lan.local.cmu.edu/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mTensor([torch\u001b[39m.\u001b[39;49mTensor(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m s])\u001b[39m.\u001b[39mshape\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_logits(logits, tokens):\n",
        "    \n",
        "    count = 0\n",
        "    avg = 0\n",
        "    for i in logits:\n",
        "        for j in i:\n",
        "            j = torch.nn.functional.softmax(j, dim=0)\n",
        "            avg += sum(j[tokens]) / len(tokens)\n",
        "            count += 1\n",
        "    return avg / count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = tokenizer.encode(\"Robert Play\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_target_logits(s, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([    -inf, -75.3566,     -inf,  ...,     -inf,     -inf,     -inf])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Downloading data: 100%|ââââââââââ| 190M/190M [00:19<00:00, 9.85MB/s]\n",
            "\n",
            "Generating test split: 100%|ââââââââââ| 4358/4358 [00:00<00:00, 53678.54 examples/s]\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Downloading data:   8%|â         | 25.2M/307M [01:12<13:33, 346kB/s] \n",
            "Downloading data files:   0%|          | 0/1 [02:44<?, ?it/s]\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Generating train split: 100%|ââââââââââ| 1801350/1801350 [00:24<00:00, 74229.36 examples/s]\n",
            "Generating validation split: 100%|ââââââââââ| 3760/3760 [00:00<00:00, 78580.63 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " ' = Robert Boulter = \\n',\n",
              " '',\n",
              " ' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the <unk> Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n',\n",
              " ' In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris <unk> , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris <unk> . \\n',\n",
              " '',\n",
              " ' = = Career = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = 2000 â 2005 = = = \\n',\n",
              " '',\n",
              " ' In 2000 Boulter had a guest @-@ starring role on the television series The Bill ; he portrayed \" Scott Parry \" in the episode , \" In Safe Hands \" . Boulter starred as \" Scott \" in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . A review of Boulter \\'s performance in The Independent on Sunday described him as \" horribly menacing \" in the role , and he received critical reviews in The Herald , and Evening Standard . He appeared in the television series Judge John Deed in 2002 as \" <unk> Armitage \" in the episode \" Political <unk> \" , and had a role as a different character \" Toby Steele \" on The Bill . \\n',\n",
              " ' He had a recurring role in 2003 on two episodes of The Bill , as character \" Connor Price \" . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . Boulter starred as \" Darren \" , in the 2005 theatre productions of the Philip Ridley play Mercury Fur . It was performed at the Drum Theatre in Plymouth , and the <unk> Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . Boulter received a favorable review in The Daily Telegraph : \" The acting is shatteringly intense , with wired performances from Ben Whishaw ( now unrecognisable from his performance as Trevor Nunn \\'s Hamlet ) , Robert Boulter , Shane Zaza and Fraser Ayres . \" The Guardian noted , \" Ben Whishaw and Robert Boulter offer tenderness amid the savagery . \" \\n',\n",
              " '',\n",
              " ' = = = 2006 â present = = = \\n',\n",
              " '',\n",
              " ' In 2006 Boulter starred in the play Citizenship written by Mark Ravenhill . The play was part of a series which featured different playwrights , titled Burn / <unk> / Citizenship . In a 2006 interview , fellow actor Ben Whishaw identified Boulter as one of his favorite co @-@ stars : \" I loved working with a guy called Robert Boulter , who was in the triple bill of Burn , <unk> and Citizenship at the National . He played my brother in Mercury Fur . \" He portrayed \" Jason Tyler \" on the 2006 episode of the television series , Doctors , titled \" Something I Ate \" . Boulter starred as \" William \" in the 2007 production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . In a review of the production for The Daily Telegraph , theatre critic Charles Spencer noted , \" Robert Boulter brings a touching vulnerability to the stage as William . \" \\n',\n",
              " ' Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris <unk> , and Donkey Punch directed by Olly Blackburn . Boulter portrayed a character named \" Sean \" in Donkey Punch , who tags along with character \" Josh \" as the \" quiet brother ... who hits it off with Tammi \" . Boulter guest starred on a two @-@ part episode arc \" Wounds \" in May 2008 of the television series Waking the Dead as character \" Jimmy Dearden \" . He appeared on the television series Survivors as \" Neil \" in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . He portrayed an emergency physician applying for a medical fellowship . He commented on the inherent difficulties in portraying a physician on television : \" Playing a doctor is a strange experience . Pretending you know what you \\'re talking about when you don \\'t is very bizarre but there are advisers on set who are fantastic at taking you through procedures and giving you the confidence to stand there and look like you know what you \\'re doing . \" Boulter starred in the 2011 film Mercenaries directed by Paris <unk> . \\n',\n",
              " '',\n",
              " ' = = Filmography = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Film = = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Television = = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Theatre = = = \\n',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " ' = Du Fu = \\n',\n",
              " '',\n",
              " ' Du Fu ( Wade â Giles : Tu Fu ; Chinese : <unk> ; 712 â 770 ) was a prominent Chinese poet of the Tang dynasty . Along with Li Bai ( Li Po ) , he is frequently called the greatest of the Chinese poets . His greatest ambition was to serve his country as a successful civil servant , but he proved unable to make the necessary accommodations . His life , like the whole country , was devastated by the An Lushan Rebellion of 755 , and his last 15 years were a time of almost constant unrest . \\n',\n",
              " ' Although initially he was little @-@ known to other writers , his works came to be hugely influential in both Chinese and Japanese literary culture . Of his poetic writing , nearly fifteen hundred poems have been preserved over the ages . He has been called the \" Poet @-@ Historian \" and the \" Poet @-@ Sage \" by Chinese critics , while the range of his work has allowed him to be introduced to Western readers as \" the Chinese Virgil , Horace , Ovid , Shakespeare , Milton , Burns , Wordsworth , BÃ©ranger , Hugo or Baudelaire \" . \\n',\n",
              " '',\n",
              " ' = = Life = = \\n',\n",
              " '',\n",
              " ' Traditional Chinese literary criticism emphasized the life of the author when interpreting a work , a practice which Burton Watson attributes to \" the close links that traditional Chinese thought posits between art and morality \" . Since many of Du Fu \\'s poems feature morality and history , this practice is particularly important . Another reason , identified by the Chinese historian William Hung , is that Chinese poems are typically concise , omitting context that might be relevant , but which an informed contemporary could be assumed to know . For modern Western readers , \" The less accurately we know the time , the place and the circumstances in the background , the more liable we are to imagine it incorrectly , and the result will be that we either misunderstand the poem or fail to understand it altogether \" . Stephen Owen suggests a third factor particular to Du Fu , arguing that the variety of the poet \\'s work required consideration of his whole life , rather than the \" reductive \" categorizations used for more limited poets . \\n',\n",
              " '',\n",
              " ' = = = Early years = = = \\n',\n",
              " '',\n",
              " \" Most of what is known of Du Fu 's life comes from his poems . His paternal grandfather was Du <unk> , a noted politician and poet during the reign of Empress Wu . Du Fu was born in 712 ; the exact birthplace is unknown , except that it was near Luoyang , Henan province ( Gong county is a favourite candidate ) . In later life , he considered himself to belong to the capital city of Chang 'an , ancestral hometown of the Du family . \\n\",\n",
              " \" Du Fu 's mother died shortly after he was born , and he was partially raised by his aunt . He had an elder brother , who died young . He also had three half brothers and one half sister , to whom he frequently refers in his poems , although he never mentions his stepmother . \\n\",\n",
              " ' The son of a minor scholar @-@ official , his youth was spent on the standard education of a future civil servant : study and memorisation of the Confucian classics of philosophy , history and poetry . He later claimed to have produced creditable poems by his early teens , but these have been lost . \\n',\n",
              " \" In the early 730s , he travelled in the Jiangsu / Zhejiang area ; his earliest surviving poem , describing a poetry contest , is thought to date from the end of this period , around 735 . In that year , he took the civil service exam , likely in Chang 'an . He failed , to his surprise and that of centuries of later critics . Hung concludes that he probably failed because his prose style at the time was too dense and obscure , while Chou suggests his failure to cultivate connections in the capital may have been to blame . After this failure , he went back to traveling , this time around Shandong and Hebei . \\n\",\n",
              " \" His father died around 740 . Du Fu would have been allowed to enter the civil service because of his father 's rank , but he is thought to have given up the privilege in favour of one of his half brothers . He spent the next four years living in the Luoyang area , fulfilling his duties in domestic affairs . \\n\",\n",
              " ' In the autumn of 744 , he met Li Bai ( Li Po ) for the first time , and the two poets formed a friendship . David Young describes this as \" the most significant formative element in Du Fu \\'s artistic development \" because it gave him a living example of the reclusive poet @-@ scholar life to which he was attracted after his failure in the civil service exam . The relationship was somewhat one @-@ sided , however . Du Fu was by some years the younger , while Li Bai was already a poetic star . We have twelve poems to or about Li Bai from the younger poet , but only one in the other direction . They met again only once , in 745 . \\n',\n",
              " ' In 746 , he moved to the capital in an attempt to resurrect his official career . He took the civil service exam a second time during the following year , but all the candidates were failed by the prime minister ( apparently in order to prevent the emergence of possible rivals ) . He never again attempted the examinations , instead petitioning the emperor directly in 751 , 754 and probably again in 755 . He married around 752 , and by 757 the couple had had five children â three sons and two daughters â but one of the sons died in infancy in 755 . From 754 he began to have lung problems ( probably asthma ) , the first of a series of ailments which dogged him for the rest of his life . It was in that year that Du Fu was forced to move his family due to the turmoil of a famine brought about by massive floods in the region . \\n',\n",
              " \" In 755 , he received an appointment as Registrar of the Right Commandant 's office of the Crown Prince 's Palace . Although this was a minor post , in normal times it would have been at least the start of an official career . Even before he had begun work , however , the position was swept away by events . \\n\",\n",
              " '',\n",
              " ' = = = War = = = \\n',\n",
              " '',\n",
              " ' The An Lushan Rebellion began in December 755 , and was not completely suppressed for almost eight years . It caused enormous disruption to Chinese society : the census of 754 recorded 52 @.@ 9 million people , but ten years later , the census counted just 16 @.@ 9 million , the remainder having been displaced or killed . During this time , Du Fu led a largely itinerant life unsettled by wars , associated famines and imperial displeasure . This period of unhappiness was the making of Du Fu as a poet : Even Shan Chou has written that , \" What he saw around him â the lives of his family , neighbors , and strangers â what he heard , and what he hoped for or feared from the progress of various campaigns â these became the enduring themes of his poetry \" . Even when he learned of the death of his youngest child , he turned to the suffering of others in his poetry instead of dwelling upon his own misfortunes . Du Fu wrote : \\n',\n",
              " ' Brooding on what I have lived through , if even I know such suffering , the common man must surely be rattled by the winds . \\n',\n",
              " \" In 756 , Emperor Xuanzong was forced to flee the capital and abdicate . Du Fu , who had been away from the city , took his family to a place of safety and attempted to join the court of the new emperor ( <unk> ) , but he was captured by the rebels and taken to Chang 'an . In the autumn , his youngest son , Du <unk> ( Baby Bear ) , was born . Around this time Du Fu is thought to have contracted malaria . \\n\",\n",
              " \" He escaped from Chang 'an the following year , and was appointed Reminder when he rejoined the court in May 757 . This post gave access to the emperor but was largely ceremonial . Du Fu 's conscientiousness compelled him to try to make use of it : he caused trouble for himself by protesting the removal of his friend and patron Fang Guan on a petty charge . He was arrested but was pardoned in June . He was granted leave to visit his family in September , but he soon rejoined the court and on December 8 , 757 , he returned to Chang 'an with the emperor following its recapture by government forces . However , his advice continued to be unappreciated , and in the summer of 758 he was demoted to a post as Commissioner of Education in <unk> . The position was not to his taste : in one poem , he wrote : \\n\",\n",
              " ' I am about to scream madly in the office / Especially when they bring more papers to pile higher on my desk . \\n',\n",
              " ' He moved on in the summer of 759 ; this has traditionally been ascribed to famine , but Hung believes that frustration is a more likely reason . He next spent around six weeks in <unk> ( now Tianshui , Gansu province ) , where he wrote more than sixty poems . \\n',\n",
              " '',\n",
              " ' = = = Chengdu = = = \\n',\n",
              " '',\n",
              " ' In December 759 , he briefly stayed in <unk> ( modern Gansu ) . He departed on December 24 for Chengdu ( Sichuan province ) , where he was hosted by local Prefect and fellow poet Pei Di . Du subsequently based himself in Sichuan for most of the next five years . By the autumn of that year he was in financial trouble , and sent poems begging help to various acquaintances . He was relieved by Yan Wu , a friend and former colleague who was appointed governor general at Chengdu . Despite his financial problems , this was one of the happiest and most peaceful periods of his life . Many of Du \\'s poems from this period are peaceful depictions of his life at \" thatched hut \" . In 762 , he left the city to escape a rebellion , but he returned in summer 764 when he was appointed an advisor to Yan , who was involved in campaigns against the Tibetan Empire . \\n',\n",
              " '',\n",
              " ' = = = Last years = = = \\n',\n",
              " '',\n",
              " \" Luoyang , the region of his birthplace , was recovered by government forces in the winter of 762 , and in the spring of 765 Du Fu and his family sailed down the Yangtze , apparently with the intention of making their way there . They traveled slowly , held up by his ill @-@ health ( by this time he was suffering from poor eyesight , deafness and general old age in addition to his previous ailments ) . They stayed in <unk> ( in what is now <unk> , Chongqing ) at the entrance to the Three Gorges for almost two years from late spring 766 . This period was Du Fu 's last great poetic flowering , and here he wrote 400 poems in his dense , late style . In autumn 766 , Bo <unk> became governor of the region : he supported Du Fu financially and employed him as his unofficial secretary . \\n\",\n",
              " ' In March 768 , he began his journey again and got as far as Hunan province , where he died in <unk> ( now Changsha ) in November or December 770 , in his 58th year . He was survived by his wife and two sons , who remained in the area for some years at least . His last known descendant is a grandson who requested a grave inscription for the poet from Yuan Zhen in 813 . \\n',\n",
              " ' Hung summarises his life by concluding that , \" He appeared to be a filial son , an affectionate father , a generous brother , a faithful husband , a loyal friend , a dutiful official , and a patriotic subject . \" \\n',\n",
              " \" Below is an example of one of Du Fu 's later works , To My Retired Friend Wei ( Chinese : <unk> ) . Like many other poems in the Tang it featured the theme of a long parting between friends , which was often due to officials being frequently transferred to the provinces : \\n\",\n",
              " '',\n",
              " ' = = Works = = \\n',\n",
              " '',\n",
              " \" Criticism of Du Fu 's works has focused on his strong sense of history , his moral engagement , and his technical excellence . \\n\",\n",
              " '',\n",
              " ' = = = History = = = \\n',\n",
              " '',\n",
              " ' Since the Song dynasty , critics have called Du Fu the \" poet historian \" ( <unk> <unk> <unk> ) . The most directly historical of his poems are those commenting on military tactics or the successes and failures of the government , or the poems of advice which he wrote to the emperor . Indirectly , he wrote about the effect of the times in which he lived on himself , and on the ordinary people of China . As Watson notes , this is information \" of a kind seldom found in the officially compiled histories of the era \" . \\n',\n",
              " ' Du Fu \\'s political comments are based on emotion rather than calculation : his prescriptions have been paraphrased as , \" Let us all be less selfish , let us all do what we are supposed to do \" . Since his views were impossible to disagree with , his forcefully expressed truisms enabled his installation as the central figure of Chinese poetic history . \\n',\n",
              " '',\n",
              " ' = = = Moral engagement = = = \\n',\n",
              " '',\n",
              " ' A second favourite epithet of Chinese critics is that of \" poet sage \" ( <unk> <unk> <unk> ) , a counterpart to the philosophical sage , Confucius . One of the earliest surviving works , The Song of the Wagons ( from around 750 ) , gives voice to the sufferings of a conscript soldier in the imperial army and a clear @-@ sighted consciousness of suffering . These concerns are continuously articulated in poems on the lives of both soldiers and civilians produced by Du Fu throughout his life . \\n',\n",
              " ' Although Du Fu \\'s frequent references to his own difficulties can give the impression of an all @-@ consuming solipsism , Hawkes argues that his \" famous compassion in fact includes himself , viewed quite objectively and almost as an afterthought \" . He therefore \" lends grandeur \" to the wider picture by comparing it to \" his own slightly comical triviality \" . \\n',\n",
              " ' Du Fu \\'s compassion , for himself and for others , was part of his general broadening of the scope of poetry : he devoted many works to topics which had previously been considered unsuitable for poetic treatment . Zhang Jie wrote that for Du Fu , \" everything in this world is poetry \" , Du wrote extensively on subjects such as domestic life , calligraphy , paintings , animals , and other poems . \\n',\n",
              " '',\n",
              " ' = = = Technical excellence = = = \\n',\n",
              " '',\n",
              " ' Du Fu \\'s work is notable above all for its range . Chinese critics traditionally used the term <unk> ( <unk> \" complete symphony \" ) , a reference to Mencius \\' description of Confucius . Yuan Zhen was the first to note the breadth of Du Fu \\'s achievement , writing in 813 that his predecessor , \" united in his work traits which previous men had displayed only singly \" . He mastered all the forms of Chinese poetry : Chou says that in every form he \" either made outstanding advances or contributed outstanding examples \" . Furthermore , his poems use a wide range of registers , from the direct and colloquial to the allusive and self @-@ consciously literary . This variety is manifested even within individual works : Owen identifies the , \" rapid stylistic and thematic shifts \" in poems which enable the poet to represent different facets of a situation , while Chou uses the term \" juxtaposition \" as the major analytical tool in her work . Du Fu is noted for having written more on poetics and painting than any other writer of his time . He wrote eighteen poems on painting alone , more than any other Tang poet . Du Fu \\'s seemingly negative commentary on the prized horse paintings of Han Gan ignited a controversy that has persisted to the present day . \\n',\n",
              " ' The tenor of his work changed as he developed his style and adapted to his surroundings ( \" chameleon @-@ like \" according to Watson ) : his earliest works are in a relatively derivative , courtly style , but he came into his own in the years of the rebellion . Owen comments on the \" grim simplicity \" of the <unk> poems , which mirrors the desert landscape ; the works from his Chengdu period are \" light , often finely observed \" ; while the poems from the late <unk> period have a \" density and power of vision \" . \\n',\n",
              " ' Although he wrote in all poetic forms , Du Fu is best known for his <unk> , a type of poem with strict constraints on form and content , for example : \\n',\n",
              " ' About two thirds of Du Fu \\'s 1500 extant works are in this form , and he is generally considered to be its leading exponent . His best <unk> use the <unk> required by the form to add expressive content rather than as mere technical restrictions . Hawkes comments that , \" it is amazing that Tu Fu is able to use so immensely stylized a form in so natural a manner \" . \\n',\n",
              " '',\n",
              " ' = = Influence = = \\n',\n",
              " '',\n",
              " ' According to the EncyclopÃ¦dia Britannica , Du Fu \\'s writings are considered by many literary critics to be among the greatest of all time , and it states \" his dense , compressed language makes use of all the connotative overtones of a phrase and of all the <unk> potentials of the individual word , qualities that no translation can ever reveal . \" \\n',\n",
              " ' In his lifetime and immediately following his death , Du Fu was not greatly appreciated . In part this can be attributed to his stylistic and formal innovations , some of which are still \" considered extremely daring and bizarre by Chinese critics . \" There are few contemporary references to him â only eleven poems from six writers â and these describe him in terms of affection , but not as a paragon of poetic or moral ideals . Du Fu is also poorly represented in contemporary anthologies of poetry . \\n',\n",
              " ' However , as Hung notes , he \" is the only Chinese poet whose influence grew with time \" , and his works began to increase in popularity in the ninth century . Early positive comments came from Bai Juyi , who praised the moral sentiments of some of Du Fu \\'s works ( although he found these in only a small fraction of the poems ) , and from Han Yu , who wrote a piece defending Du Fu and Li Bai on aesthetic grounds from attacks made against them . Both these writers showed the influence of Du Fu in their own poetic work . By the beginning of the 10th century , Wei Zhuang constructed the first replica of his thatched cottage in Sichuan . \\n',\n",
              " ' It was in the 11th century , during the Northern Song era that Du Fu \\'s reputation reached its peak . In this period a comprehensive re @-@ evaluation of earlier poets took place , in which Wang Wei , Li Bai and Du Fu came to be regarded as representing respectively the Buddhist , Daoist and Confucian strands of Chinese culture . At the same time , the development of Neo @-@ Confucianism ensured that Du Fu , as its poetic exemplar , occupied the paramount position . Su Shi famously expressed this reasoning when he wrote that Du Fu was \" preeminent ... because ... through all his vicissitudes , he never for the space of a meal forgot his sovereign \" . His influence was helped by his ability to reconcile apparent opposites : political conservatives were attracted by his loyalty to the established order , while political radicals embraced his concern for the poor . Literary conservatives could look to his technical mastery , while literary radicals were inspired by his innovations . Since the establishment of the People \\'s Republic of China , Du Fu \\'s loyalty to the state and concern for the poor have been interpreted as embryonic nationalism and socialism , and he has been praised for his use of simple , \" people \\'s language \" . \\n',\n",
              " ' Du Fu \\'s popularity grew to such an extent that it is as hard to measure his influence as that of Shakespeare in England : it was hard for any Chinese poet not to be influenced by him . While there was never another Du Fu , individual poets followed in the traditions of specific aspects of his work : Bai Juyi \\'s concern for the poor , Lu You \\'s patriotism , and Mei <unk> \\'s reflections on the quotidian are a few examples . More broadly , Du Fu \\'s work in transforming the <unk> from mere word play into \" a vehicle for serious poetic utterance \" set the stage for every subsequent writer in the genre . \\n',\n",
              " ' In the 20th century , he was the favourite poet of Kenneth Rexroth , who has described him as \" the greatest non @-@ epic , non @-@ dramatic poet who has survived in any language \" , and commented that , \" he has made me a better man , as a moral agent and as a perceiving organism \" . \\n',\n",
              " '',\n",
              " ' = = = Influence on Japanese literature = = = \\n',\n",
              " '',\n",
              " \" Du Fu 's poetry has made a profound impact on Japanese literature , especially on the literature from the Muromachi period and on scholars and poets in the Edo period , including Matsuo BashÅ , the very greatest of all haiku poets . Even in modern Japanese , the term Saint of Poetry ( <unk> , <unk> ) is mostly synonymous with Du Fu . \\n\",\n",
              " ' Until the 13th century , the Japanese preferred Bai Juyi above all poets and there were few references to Du Fu , although his influence can be seen in some <unk> ( \" Chinese poetry made by Japanese poets \" ) anthologies such as Bunka <unk> in the 9th century . The first notable Japanese <unk> of Du Fu \\'s poetry was <unk> <unk> ( 1278 â 1346 ) , a <unk> Zen patriarch and one of the most prominent authors of the literature of the Five Mountains ; he highly praised Du Fu and made a commentary on some poems of Du Fu from the perspective of a Zen priest in Vol . 11 of <unk> . His student <unk> <unk> composed many <unk> which were clearly stated \" influenced by Du Fu \" in their prefaces . <unk> \\'s student <unk> <unk> had close connection with the Court and Ashikaga Shogunate and propagated Du Fu \\'s poetry in the mundane world ; one day NijÅ Yoshimoto , the <unk> regent of the Court and the highest authority of renga poetry , asked <unk> , \" Should I learn the poetry of Du Fu and Li Bai ? \" <unk> dared to reply , \" Yes if you do have enough capability . No if do not . \" Since then , there had been many seminars on Du Fu \\'s poetry both in Zen temples and in the aristocratic society , and as a result his poetry was often cited in Japanese literature in the Muromachi period , e.g. , <unk> , a historical epic in the late 14th century , and some noh plays such as <unk> , BashÅ , and Shunkan . \\n',\n",
              " \" During the Kan 'ei era of the Edo period ( 1624 â 1643 ) , <unk> <unk> ( <unk> ) of the Ming Dynasty 's Collective Commentary on Du Fu 's <unk> ( <unk> , <unk> <unk> ) was imported into Japan , and it gained explosive popularity in Confucian scholars and <unk> ( townspeople ) class . The commentary established Du Fu 's fame as the highest of all poets ; for instance , Hayashi <unk> , a notable Confucian scholar , commented in Vol . 37 of <unk> <unk> that <unk> [ Du Fu ] was the very best poet in history and praised <unk> <unk> 's commentary for its simplicity and readability , while he criticized old commentaries during the Yuan Dynasty were too unfathomable . Matsuo BashÅ , the greatest haiku poet , was also strongly influenced by Du Fu ; in Oku no Hosomichi , his masterpiece , he cites the first two lines of A Spring View ( <unk> ) before a haiku as its introduction and also many of his other haiku have similar wording and themes . It is said that when he died in Osaka during a long travel , a copy of Du Fu 's poetry was found with him as one of a few precious items which he was able to carry around . \\n\",\n",
              " '',\n",
              " ' = = Translation = = \\n',\n",
              " '',\n",
              " ' A variety of styles have been used in efforts to translate Du Fu \\'s work into English . As Burton Watson remarks in The Selected Poems of Du Fu , \" There are many different ways to approach the problems involved in translating Du Fu , which is why we need as many different translations as possible \" ( p. <unk> ) . The translators have had to contend with bringing out the formal constraints of the original without sounding laboured to a Western ear ( particularly when translating regulated verse , or <unk> ) , and accommodating the complex allusions contained particularly in the later works ( Hawkes writes that \" his poems do not as a rule come through very well in translation \" â p. ix ) . One extreme on each issue is represented by Kenneth Rexroth \\'s One Hundred Poems From the Chinese . His are free translations , which seek to conceal the <unk> through <unk> and expansion and contraction of the content ; his responses to the allusions are firstly to omit most of these poems from his selection , and secondly to \" translate out \" the references in those works which he does select . \\n',\n",
              " ' Other translators have placed much greater weight on trying to convey a sense of the poetic forms used by Du Fu . Vikram Seth in Three Chinese Poets uses English @-@ style rhyme schemes , whereas Keith Holyoak in Facing the Moon approximates the Chinese rhyme scheme ; both use end @-@ stopped lines and preserve some degree of parallelism . In The Selected Poems of Du Fu , Burton Watson follows the <unk> quite strictly , persuading the western reader to adapt to the poems rather than vice versa . Similarly , he deals with the allusion of the later works by combining literal translation with extensive annotation . \\n',\n",
              " ' In 2015 , Stephen Owen published translations , with facing Chinese texts , of the complete poetry of Du Fu in six volumes , with extensive scholarly apparatus , which emphasized <unk> . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Kiss You ( One Direction song ) = \\n',\n",
              " '',\n",
              " ' \" Kiss You \" is a song recorded by English @-@ Irish boy band One Direction for their second studio album , Take Me Home ( 2012 ) . It was released as the record \\'s second single in Germany and the third overall single on 7 January 2013 . The song was composed by Kristoffer <unk> , Kristian Lundin , Albin <unk> , Savan Kotecha , Shellback and its producers , Carl Falk and Rami Yacoub . \" Kiss You \" is an upbeat power pop song with electronic effects ; the lyrics detail a protagonist \\'s infatuation with a significant other . Critics praised the song for its production , calling it a stand @-@ out track on Take Me Home . \\n',\n",
              " ' The track became the group \\'s sixth top @-@ ten hit in Ireland and the United Kingdom , while attaining top @-@ forty positions in both Belgian territories ( Flanders and Wallonia ) , as well as in Australia , Canada , Denmark , France , New Zealand , and the Netherlands . The single peaked at number 46 on the US Billboard Hot 100 and has been certified gold by the Recording Industry Association of America ( RIAA ) for shipments of 500 @,@ 000 copies . One Direction performed \" Kiss You \" on both the UK and US versions of The X Factor and 3 major concert tours : Take Me Home Tour ( 2013 ) , Where We Are Tour ( 2014 ) and On the Road Again Tour ( 2015 ) . \\n',\n",
              " ' An accompanying music video , designed to display the group \\'s comedic timing , was directed by Vaughan Arnell , who had previously worked with the group on two other music videos . The clip depicts the band shooting various scenes via a green screen , which include sequences reminiscent of iconic music videos of songs such as the Beach Boys \\' \" Surfer Girl \" , Elvis Presley \\'s \" Jailhouse Rock \" and Rammstein \\'s \" Mein Land \" . The music video received 10 @.@ 4 million views in a 24 @-@ hour period and positive commentary from reviewers , who appreciated its carefree , jubilant nature . \\n',\n",
              " \" The song was included in the dancing game Just Dance 2014 , and is also one of the select songs available on the demo version . Additionally , it is the final main track on the US edition of Now That 's What I Call Music ! 46 . \\n\",\n",
              " '',\n",
              " ' = = Background and release = = \\n',\n",
              " '',\n",
              " ' \" Kiss You \" was written by Kristoffer <unk> , Kristian Lundin , Albin <unk> , Savan Kotecha , Shellback , and its producers , Carl Falk and Rami Yacoub . Falk , Kotecha , and Yacoub had collaboratively composed One Direction \\'s previous hit singles , \" What Makes You Beautiful \" , \" One Thing \" , and \" Live While We \\'re Young \" . In April 2012 , The Independent reported that Simon Cowell , the group \\'s manager , had challenged prominent songwriters to compete for space on One Direction \\'s second album . Falk said , \" It \\'s important to get their personalities on the music . \" In addition , the article reported that Syco Records was working on candidates that included Max Martin and Lundin . \\n',\n",
              " ' \" Kiss You \" was chosen as the second US single and third international from their second studio album , Take Me Home . Liam Payne , a group member , in a November 2012 interview with MTV News , explained why they chose \" Kiss You \" as the album \\'s second single in the US . Payne was quoted as saying : \" With the album , that \\'s the first one that we listened to and we were like , \\' Yeah , we love this song \\' \" . According to a MTV News article , the number was released digitally in the United States on 17 November 2012 . By 18 January 2013 , the song had not been officially promoted to US radio stations . The track , however , was released by Sony Music Entertainment on 8 February 2013 , as the record \\'s second single in Germany . \\n',\n",
              " '',\n",
              " ' = = Composition and reception = = \\n',\n",
              " '',\n",
              " ' \" Kiss You \" is an uptempo , upbeat power pop song which runs for a duration of 3 : 04 ( 3 minutes , four seconds ) . The track features electronic effects , colossal hooks , a \" na na na \" breakdown , and a Motown @-@ tinged melody . One Direction \\'s vocal range in the song span from the note of E4 to C â¯ 6 . Instrumentation includes guitar strings , piano lines and vocals . Written in the key of E major , the beat is set in common time and moves at a quick 90 beats per minute , according to the digital sheet music published at Musicnotes.com by Sony / ATV Music Publishing . Likewise , Matt Collar from Allmusic noted that the track is \" frenetically hyper \" . The lyrical content regards the protagonist \\'s infatuation with a significant other , and incorporates euphemisms for sexual intercourse in the lines \" If you don â t wanna take it slow / And you just wanna take me home / Baby say yeah , yeah , yeah , yeah , yeah . \" \\n',\n",
              " ' \" Kiss You \" was well received by contemporary music critics , who centred on its quality of production . Both Rolling Stone \\'s Jon Dolan , who praised its effectiveness , and Chris Payne of Billboard , who appreciated the melody , described \" Kiss You \" as one of the album \\'s highlights . Alexis Petridis for The Guardian commended the track \\'s chorus as \" hard to dislodge from your brain \" . Robert Copsey of Digital Spy noted the song \\'s possibility to become an international hit , applauding it sonically . A reviewer for MTV News described the track \\'s lyricism as \" butterflies @-@ inducing \" , and Sam Lansky of Idolator wrote that \" Kiss You \" is noticeably a stand @-@ out track on its parent album . Melinda Newman , writing for HitFix , regarded the song as \" a bouncy , electronic infectious ditty , \" while Chris Younie , a critic from 4Music , deemed it an \" amazing pop song \" , lauding the group \\'s falsetto and its \" head @-@ banging anthemic \" chorus . \\n',\n",
              " '',\n",
              " ' = = Commercial performance = = \\n',\n",
              " '',\n",
              " ' The single made its Irish Singles Chart debut at number 24 on the week ending 13 December 2012 . It peaked at number seven on the week ending 17 January 2013 , marking their sixth top ten appearance in Ireland . \" Kiss You \" entered at number 152 in the UK Singles Chart on 24 November 2012 . It peaked at number nine on the UK Singles Chart on 26 January 2013 , becoming One Direction \\'s sixth top ten hit in the United Kingdom . On the week ending 18 November 2012 , \" Kiss You \" debuted at number 90 on the United States Billboard Hot 100 due to digital download sales from its parent album . As a result of an \" end @-@ of @-@ year download rush \" on the week ending 30 December 2012 , the track re @-@ entered the Hot 100 at number 83 . After the accompanying music video was released , the song re @-@ entered the Hot 100 at number 65 . \" Kiss You \" had sold 207 @,@ 000 digital downloads in the US by 18 January 2013 . The single ultimately peaked at number 46 on the Hot 100 and was certified gold by the Recording Industry Association of America ( RIAA ) on 25 April 2013 , denoting shipments of 500 @,@ 000 copies . \\n',\n",
              " ' The song became One Direction \\'s fourth top @-@ forty hit on the Canadian Hot 100 , peaking at number 30 . The single bowed at number 13 on the Australian Singles Chart on 27 January 2013 , marking its peak position and the group \\'s fourth top twenty hit in Australia . The song has been certified platinum by the Australian Recording Industry Association ( ARIA ) for shipments of 70 @,@ 000 copies . The track entered the New Zealand Singles Chart at number 17 on 11 January 2013 . It peaked at number 13 in its third and fourth charting weeks , <unk> the group \\'s sixth top @-@ forty appearance in New Zealand . \" Kiss You \" has received a gold certification from the Recording Industry Association of New Zealand ( RIANZ ) , indicating sales of 7 @,@ 500 copies . The track also reached the top 40 in both Belgian territories ( Flanders and Wallonia ) , as well as in the Czech Republic , Denmark , France , the Netherlands , and South Korea . In addition , \" Kiss You \" received gold certifications from the IFPI Norway and Denmark associations , signifying collective shipments of 20 @,@ 000 units . \\n',\n",
              " '',\n",
              " ' = = Music video = = \\n',\n",
              " '',\n",
              " ' The accompanying music video , directed by Vaughan Arnell , who had previously directed One Direction \\'s music videos for \" Live While We \\'re Young \" and \" Little Things \" , was designed to showcase the group \\'s comedic timing . Inspired by the Beach Boys , cult surfing films , old Hollywood , and British cinema , the music video incorporates \" a technicolor vibe and a British kind of romp \" , as noted by Arnell in a MTV News interview . \\n',\n",
              " ' Shot by November 2012 , the music video was characterised , in several MTV News interviews , as \" bigger than anything we \\'ve done before \" by Zayn Malik , as \" a lot of hard work \" by Payne , as \" pure stupidity \" by Louis Tomlinson , and as \" I wouldn \\'t say [ it \\'s ] comedy , it \\'s all tongue @-@ in @-@ cheek \" by Arnell . Premiering worldwide on Vevo on 7 January 2013 , the music video depicts the band shooting different scenes via a green screen , dressed as sailors , surfers , skiers and jailers . The video features scenes reminiscent of the films South Pacific , To Catch a Thief , Jailhouse Rock and Beach Blanket Bingo , as well as the iconic music videos of songs such as The Beach Boys \\' \" Surfer Girl \" , Elvis Presley \\'s \" Blue Hawaii \" and Rammstein \\'s \" Mein Land \" , among others . \\n',\n",
              " ' The music video garnered 10 @.@ 4 million views in a 24 @-@ hour period , failing to attain the Vevo record held by Justin Bieber \\'s \" Beauty and a Beat \" music video ( 10 @.@ 6 million ) . Despite a 34 % gain in weekly activity to their Vevo channel , with the clip \\'s success and preceding teaser videos earning 38 million views during the week , One Direction held at number two on the Billboard \\'s Social 50 chart A 15 % rise in Facebook reaction gave way to a 154 @,@ 000 increase in Facebook likes during the week . 191 @,@ 000 Twitter followers added contributed to their overall fan base increase as well . \\n',\n",
              " ' Melinda Newman , a contributor for HitFix , favoured the clip as having \" everything a video by a boy band should be \" and found group \\'s careless tone delightful . Rebecca <unk> of E ! Online praised its \" intentionally cheesy and utterly adorable \" sequences , and MTV News \\'s Jocelyn Vena described the clip as \" conquering old Hollywood \" . Molly Chance , writing for Zap2it , was convinced that upon watching the \" adorable \" music video , the viewer should have a hard time disliking the group . Mikael Wood , the critic for Los Angeles Times , commended the group for \" having a genuinely great time \" , rather than going through the motions . \\n',\n",
              " '',\n",
              " ' = = Live performances = = \\n',\n",
              " '',\n",
              " ' As part of its promotion , One Direction performed the song on televised programmes and during their worldwide Take Me Home Tour ( 2013 ) . One Direction performed the track on The Today Show at the Rockefeller Center on 13 November 2012 , to a record crowd estimated at 15 @,@ 000 . \" Kiss You \" was included in the set list of the group \\'s 3 December 2012 sold @-@ out show at New York City \\'s Madison Square Garden . One Direction delivered a performance of \" Kiss You \" , in front of a video game @-@ themed set , on the final of the ninth series of The X Factor UK on 10 December 2012 . According to the Daily Mail , their \" energetic rendition \" of \" Kiss You \" proved that the group have an elusive quality . On 12 December 2012 , the group also performed the number on the final of the second season of The X Factor USA . Considering One Direction the \" franchise \\'s biggest success story \" , an editor for The Huffington Post opined that the boy band \\'s prominent presence on both the US and UK versions of The X Factor seemed fitting . Not only Take Me Home Tour , they also performance in Where We Are Tour ( 2014 ) & On the Road Again Tour ( 2015 ) \\n',\n",
              " '',\n",
              " ' = = Track listing = = \\n',\n",
              " '',\n",
              " ' CD single \\n',\n",
              " ' \" Kiss You \" â 3 : 04 \\n',\n",
              " ' \" Little Things \" â 3 : 42 \\n',\n",
              " '',\n",
              " ' = = Credits and personnel = = \\n',\n",
              " '',\n",
              " ' Carl Falk â writing , production , programming , instruments , guitar , background vocals \\n',\n",
              " ' Kristoffer <unk> â background vocals \\n',\n",
              " ' Niall Horan â additional guitar \\n',\n",
              " ' Savan Kotecha â writing , background vocals \\n',\n",
              " ' Kristian Lundin â writing \\n',\n",
              " ' Albin <unk> â writing , background vocals \\n',\n",
              " ' Shellback â writing \\n',\n",
              " ' Rami Yacoub â writing , production , programming , instruments , bass \\n',\n",
              " \" Credits adapted from Take Me Home 's liner notes . \\n\",\n",
              " '',\n",
              " ' = = Charts = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = Certifications = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = Release history = = \\n',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " ' = Ise @-@ class battleship = \\n',\n",
              " '',\n",
              " ' The Ise @-@ class battleships ( <unk> , Ise @-@ gata senkan ) were a pair of dreadnought battleships built for the Imperial Japanese Navy ( IJN ) during World War I. Originally intended to be repeats of the preceding FusÅ class , they were redesigned before construction began . Both ships carried supplies for the survivors of the Great KantÅ earthquake in 1923 . They were modernized in 1934 â 37 with improvements to their armour and machinery and a rebuilt superstructure in the pagoda mast style . Afterwards they played a minor role in the Second Sino @-@ Japanese War . \\n',\n",
              " \" Despite the expensive reconstructions , both vessels were considered obsolete by the eve of the Pacific War , and neither saw significant action in the early years of the war . Following the loss of most of the IJN 's large aircraft carriers during the Battle of Midway in mid @-@ 1942 , they were rebuilt with a flight deck replacing the rear pair of gun turrets to give them the ability to operate an air group of floatplanes . A lack of aircraft and qualified pilots , however , meant that they never actually operated their aircraft in combat . While awaiting their air group the sister ships were sometimes used to ferry troops and material to Japanese bases . They participated in the Battle of Cape EngaÃ±o in late 1944 , where they <unk> the American carrier fleet supporting the invasion of Leyte away from the landing beaches . Afterwards both ships were transferred to Southeast Asia ; in early 1945 they participated in Operation Kita , where they transported petrol and other strategic materials to Japan . The sisters were then reduced to reserve until they were sunk during American airstrikes in July . After the war they were scrapped in 1946 â 47 . \\n\",\n",
              " '',\n",
              " ' = = Background = = \\n',\n",
              " '',\n",
              " \" The design of the FusÅ @-@ class battleships was shaped both by the ongoing international naval arms race and a desire among Japanese naval planners to maintain a fleet of capital ships powerful enough to defeat the United States Navy in an encounter in Japanese territorial waters . The IJN 's fleet of battleships had proven highly successful in 1905 , the last year of the Russo @-@ Japanese War , which culminated in the destruction of the Russian Second and Third Pacific Squadrons at the Battle of Tsushima . \\n\",\n",
              " ' In the aftermath , the Japanese Empire immediately turned its focus to the two remaining rivals for imperial dominance in the Pacific Ocean : Britain and the United States . SatÅ <unk> , a Japanese Navy admiral and military theorist , speculated that conflict would inevitably arise between Japan and at least one of its two main rivals . To that end , he called for the Japanese Navy to maintain a fleet with at least 70 % as many capital ships as the US Navy . This ratio , SatÅ theorized , would enable the Imperial Japanese Navy to defeat the US Navy in one major battle in Japanese waters in any eventual conflict . Accordingly , the 1907 Imperial Defence Policy called for the construction of a battle fleet of eight modern battleships , 20 @,@ 000 long tons ( 20 @,@ 321 t ) each , and eight modern armoured cruisers , 18 @,@ 000 long tons ( 18 @,@ 289 t ) each . This was the genesis of the Eight @-@ Eight Fleet Program , the development of a cohesive battle line of sixteen capital ships . \\n',\n",
              " \" The launch of HMS Dreadnought in 1906 by the Royal Navy raised the stakes , and complicated Japan 's plans . Displacing 17 @,@ 900 long tons ( 18 @,@ 200 t ) and armed with ten 12 @-@ inch ( 30 @.@ 5 cm ) guns , Dreadnought rendered all existing battleships obsolete by comparison . The launch of the battlecruiser HMS Invincible the following year was a further setback for Japan 's quest for parity . When the two new Satsuma @-@ class battleships and two Tsukuba @-@ class armoured cruisers , launched by 1911 , were outclassed by their British counterparts , the Eight @-@ Eight Fleet Program was restarted . \\n\",\n",
              " ' The first battleships built for the renewed Eight @-@ Eight Fleet Program were the two dreadnoughts of the Kawachi class , ordered in 1907 and laid down in 1908 . In 1910 , the Navy put forward a request to the Diet ( parliament ) to secure funding for the entirety of the program at once . Because of economic constraints , only four battlecruisers and a single battleship of the FusÅ class were ultimately approved by the Diet . Three more FusÅ @-@ class ships ( Yamashiro , Ise , and HyÅ«ga ) were approved and all three were ordered in April 1913 . While Yamashiro was laid down later that year , the IJN lacked the funding to proceed with the construction of Ise and HyÅ«ga until the Diet authorized additional funding for the ships in July 1914 . \\n',\n",
              " '',\n",
              " ' = = Design and description = = \\n',\n",
              " '',\n",
              " \" The progress of FusÅ 's construction , while the IJN waited for the funding to be released and foreign developments , caused the IJN to reassess the FusÅ @-@ class design . The distribution of the midships gun turrets was the most obvious flaw as they complicated the protection of the midships magazine and exposed more of the ship to the blast effects of the guns when they fired . Another issue was that Japanese sailors had problems maintaining a high rate of fire with the 45 @.@ 36 @-@ kilogram ( 100 @.@ 0 lb ) shells used in the manually loaded 152 @-@ millimetre ( 6 in ) secondary guns used in the FusÅ class and earlier designs . To resolve this issue , the IJN designed a smaller 140 @-@ millimetre ( 5 @.@ 5 in ) gun that offset its lighter shell weight with a higher rate of fire . It also decided that the barbette armour of the earlier ships was too thin and wanted a modest increase in speed to partially counter the higher speeds of the latest foreign ships like the British Queen Elizabeth @-@ class battleships and Russian Borodino @-@ class battlecruisers . For financial reasons more powerful engines could not be ordered so the new design was lengthened slightly and the boiler rooms enlarged to increase speed by 0 @.@ 5 knots ( 0 @.@ 93 km / h ; 0 @.@ 58 mph ) to 23 knots ( 43 km / h ; 26 mph ) . To save weight the forecastle deck was shortened so that the lower midships gun turret was lower than in the FusÅ class . This reduced the crew 's accommodations despite a significant increase in the crew 's numbers and naval historian Fukui <unk> believed that these ships had the worst habitability of any Japanese capital ship . The final design was designated A @-@ 92 by the IJN and differed enough from the A @-@ 64 design of the FusÅ class that it was considered a separate class . \\n\",\n",
              " ' The ships had a length of 208 @.@ 18 metres ( 683 ft 0 in ) overall , a beam of 28 @.@ 65 metres ( 94 ft 0 in ) and a draught of 8 @.@ 93 metres ( 29 ft 4 in ) at deep load . They displaced 36 @,@ 500 long tons ( 37 @,@ 100 t ) at deep load , roughly 650 long tons ( 660 t ) more than the preceding class . Their crew consisted of 1 @,@ 360 officers and enlisted men . They had a metacentric height of 1 @.@ 737 metres ( 5 ft 8 @.@ 4 in ) at deep load . \\n',\n",
              " \" During the ships ' modernization during the 1930s , their forward superstructures were enlarged with multiple platforms added to their tripod foremasts . Both ships were also given torpedo bulges to improve their underwater protection and to compensate for the weight of the additional armour . In addition , their sterns were lengthened by 7 @.@ 62 metres ( 25 @.@ 0 ft ) . These changes increased their overall length to 213 @.@ 8 metres ( 701 ft ) , their beam to 31 @.@ 75 metres ( 104 ft 2 in ) and their draft to 9 @.@ 45 metres ( 31 ft 0 in ) . Their displacement increased over 5 @,@ 000 long tons ( 5 @,@ 100 t ) to 42 @,@ 001 long tons ( 42 @,@ 675 t ) at deep load . The crew now numbered 1 @,@ 376 officers and enlisted men . \\n\",\n",
              " '',\n",
              " ' = = = Propulsion = = = \\n',\n",
              " '',\n",
              " ' The Ise @-@ class ships had two sets of direct @-@ drive steam turbines , each of which drove two propeller shafts with 3 @.@ 429 @-@ metre ( 11 ft 3 in ) propellers . The high @-@ pressure turbines drove the wing shafts while the low @-@ pressure turbines drove the inner shafts . The turbines were designed to produce a total of 40 @,@ 000 or 45 @,@ 000 shaft horsepower ( 30 @,@ 000 or 34 @,@ 000 kW ) ( HyÅ«ga and Ise respectively ) , using steam provided by 24 Kampon Ro GÅ water @-@ tube boilers at working pressures of 13 â 16 @.@ 9 kg / cm2 ( 1 @,@ 275 â 1 @,@ 657 kPa ; 185 â 240 psi ) . Both ships comfortably exceeded their designed speed of 23 knots ( 43 km / h ; 26 mph ) during their sea trials ; Ise reached 23 @.@ 6 knots ( 43 @.@ 7 km / h ; 27 @.@ 2 mph ) from 56 @,@ 498 shp ( 42 @,@ 131 kW ) and HyÅ«ga exceeded that with 24 knots ( 44 km / h ; 28 mph ) from 63 @,@ 211 shp ( 47 @,@ 136 kW ) . Each of the boilers consumed a mixture of coal and oil and the ships had a stowage capacity of 4 @,@ 607 long tons ( 4 @,@ 681 t ) of coal and 1 @,@ 411 long tons ( 1 @,@ 434 t ) of fuel oil , which gave them a range of 9 @,@ 680 nautical miles ( 17 @,@ 930 km ; 11 @,@ 140 mi ) at a speed of 14 knots ( 26 km / h ; 16 mph ) . Ise and HyÅ«ga had three generators of 150 kilowatts ( 200 hp ) capacity and two 250 @-@ kilowatt ( 340 hp ) turbo generators at 225 volts . \\n',\n",
              " ' During their 1930s modernization , the boilers on each ship were replaced by eight new Kampon oil @-@ fired boilers , fitted into the former aft boiler room , and the forward funnel was removed . The turbines were replaced by four geared Kampon turbines with a designed output of 80 @,@ 000 shp ( 60 @,@ 000 kW ) intended to increase their speed to 24 @.@ 5 knots ( 45 @.@ 4 km / h ; 28 @.@ 2 mph ) . On her trials , Ise reached a top speed of 25 @.@ 26 knots ( 46 @.@ 78 km / h ; 29 @.@ 07 mph ) from 81 @,@ 050 shp ( 60 @,@ 440 kW ) . The fuel storage of the ships was increased to a total of 5 @,@ 113 long tons ( 5 @,@ 195 t ) of fuel oil that gave them a range of 7 @,@ 870 nautical miles ( 14 @,@ 580 km ; 9 @,@ 060 mi ) at a speed of 16 knots ( 30 km / h ; 18 mph ) . \\n',\n",
              " '',\n",
              " ' = = = Armament = = = \\n',\n",
              " '',\n",
              " ' The twelve 45 @-@ calibre 35 @.@ 6 cm ( 14 @.@ 0 in ) Type 41 guns of the Ise class were mounted in three pairs of twin @-@ gun , superfiring turrets . Numbered one through six from front to rear , each turret weighed 655 long tons ( 666 t ) . The hydraulically powered turrets had an elevation capability of â 5 / + 20 degrees . The guns had a rate of fire of 1 @.@ 5 â 2 rounds per minute and could be loaded at any angle between -3 and + 20 degrees . In 1921 the elevation was increased to + 30 degrees and then to + 43 degrees during their mid @-@ 1930s modernization , except for No. 6 turret as its supporting structure could not be lowered . The recoil mechanism of the guns was also changed from a hydraulic to a pneumatic system , which allowed for a faster firing cycle of the main guns . \\n',\n",
              " ' By World War II , the guns used Type 91 armour @-@ piercing , capped shells . Each of these shells weighed 673 @.@ 5 kilograms ( 1 @,@ 485 lb ) and was fired at a muzzle velocity of 770 â 775 metres per second ( 2 @,@ 530 â 2 @,@ 540 ft / s ) . They had a maximum range of 25 @,@ 000 metres ( 27 @,@ 000 yd ) at + 20 degrees of elevation and 35 @,@ 450 meters ( 38 @,@ 770 yd ) at + 43 degrees after modernization . Also available was a 625 @-@ kilogram ( 1 @,@ 378 lb ) high @-@ explosive shell that had a muzzle velocity of 805 metres per second ( 2 @,@ 640 ft / s ) . A special Type 3 <unk> incendiary shrapnel shell was developed in the 1930s for anti @-@ aircraft use . \\n',\n",
              " \" The ships ' secondary armament consisted of twenty 50 @-@ calibre 14 @-@ centimetre Type 3 . Eighteen of these were mounted in casemates in the forecastle and superstructure and the remaining pair were mounted on the deck above them and protected by gun shields . They had a maximum elevation of + 20 degrees which gave them ranges of 16 @,@ 300 metres ( 17 @,@ 800 yd ) . Each gun had a rate of fire of up to 10 rounds per minute . Anti @-@ aircraft defence was provided by four 40 @-@ calibre 3rd Year Type 8 @-@ centimetre AA guns in single mounts . The 7 @.@ 62 @-@ centimetre ( 3 in ) high @-@ angle guns had a maximum elevation of + 75 degrees , and had a rate of fire of 13 to 20 rounds per minute . They fired a 6 kg ( 13 lb ) projectile with a muzzle velocity of 680 m / s ( 2 @,@ 200 ft / s ) to a maximum height of 7 @,@ 500 metres ( 24 @,@ 600 ft ) . The ships were also fitted with six submerged 53 @.@ 3 @-@ centimetre ( 21 @.@ 0 in ) torpedo tubes , three on each broadside . They carried twelve to eighteen 6th Year Type torpedoes which had a 200 @-@ kilogram ( 440 lb ) warhead . They had three settings for range and speed : 15 @,@ 000 metres ( 16 @,@ 000 yd ) at 26 knots ( 48 km / h ; 30 mph ) , 10 @,@ 000 metres ( 11 @,@ 000 yd ) at 32 knots ( 59 km / h ; 37 mph ) , or 7 @,@ 000 metres ( 7 @,@ 700 yd ) at 37 knots ( 69 km / h ; 43 mph ) . \\n\",\n",
              " ' In 1931 â 33 the AA guns were replaced with eight 40 @-@ caliber 12 @.@ 7 cm ( 5 @.@ 0 in ) Type 89 dual @-@ purpose guns , fitted on both sides of the forward superstructures in four twin @-@ gun mounts . When firing at surface targets , the guns had a range of 14 @,@ 700 metres ( 16 @,@ 100 yd ) ; they had a ceiling of 9 @,@ 440 metres ( 30 @,@ 970 ft ) at their maximum elevation of + 90 degrees . Their maximum rate of fire was 14 rounds a minute , but their sustained rate of fire was around eight rounds per minute . Two twin @-@ gun mounts for license @-@ built Vickers two @-@ pounder light AA guns were also added . These guns had a maximum elevation of + 80 degrees and a rate of fire of 200 rounds per minute . The pair of 14 cm guns on the upper deck were removed at this time . \\n',\n",
              " ' During the mid @-@ 1930s reconstruction the torpedo tubes were removed and the Vickers two @-@ pounders were replaced by twenty license @-@ built Hotchkiss 25 mm Type 96 light AA guns in 10 twin @-@ gun mounts . This was the standard Japanese light AA gun during World War II , but it suffered from severe design shortcomings that rendered it a largely ineffective weapon . According to historian Mark Stille , the twin and triple mounts \" lacked sufficient speed in train or elevation ; the gun sights were unable to handle fast targets ; the gun exhibited excessive vibration ; the magazine was too small , and , finally , the gun produced excessive muzzle blast \" . These 25 @-@ millimetre ( 0 @.@ 98 in ) guns had an effective range of 1 @,@ 500 â 3 @,@ 000 metres ( 1 @,@ 600 â 3 @,@ 300 yd ) , and an effective ceiling of 5 @,@ 500 metres ( 18 @,@ 000 ft ) at an elevation of 85 degrees . The maximum effective rate of fire was only between 110 and 120 rounds per minute because of the frequent need to change the fifteen @-@ round magazines . In addition the forward pair of 14 cm guns in the forecastle were removed at this time and the maximum elevation of the remaining guns was increased to + 30 degrees . \\n',\n",
              " '',\n",
              " ' = = = Protection = = = \\n',\n",
              " '',\n",
              " \" The Ise @-@ class ships ' waterline protective belt had a maximum thickness of 299 mm ( 11 @.@ 8 in ) of Vickers cemented armour amidships ; below it was a strake of 100 mm ( 3 @.@ 9 in ) armour . The upper armoured deck consisted of two layers of high @-@ tensile steel 55 mm ( 2 @.@ 2 in ) thick and the lower armoured deck also consisted of two layers of high @-@ tensile steel , but only 30 mm ( 1 @.@ 2 in ) thick . The sides of this deck sloped downwards to meet the bottom of the lower strake of the belt armour . The ends of the belt armour were closed off by bulkheads that ranged in thickness from 203 to 102 mm ( 8 to 4 in ) . The turrets were protected with an armour thickness of 254 mm ( 10 in ) on the face and 76 mm on the roof . The casemate armour was 149 mm ( 5 @.@ 9 in ) thick and that of the barbettes was 299 mm thick rather than the originally planned 305 mm . The sides of the conning tower were 305 mm thick . \\n\",\n",
              " ' The Ise class were the only Japanese battleships to place the powder magazine above the shell magazine as the IJN wished to put as much space as possible between the highly flammable propellant and mine and torpedo detonations . The danger from plunging shells at long distances was not appreciated until the fatal magazine explosions of three British battlecruisers during the 1916 Battle of Jutland graphically demonstrated the point . To further protect the magazines the depth of the double bottom was increased to a total of 3 @.@ 58 metres ( 11 ft 9 in ) underneath the barbettes and magazines . Additionally , the vessels contained 660 watertight compartments to preserve buoyancy in the event of battle damage . In addition to the torpedo bulge added when the ships were modernized , the deck armour over the machinery and magazines was increased to a total thickness of 140 mm . Inside the original skin of the ships , two torpedo bulkheads were also added and the turret roofs were increased to a total of 152 millimetres ( 6 in ) of armour . \\n',\n",
              " '',\n",
              " ' = = = Fire control and sensors = = = \\n',\n",
              " '',\n",
              " \" While the details of the ship 's fire @-@ control instruments are not fully available , it is known that the ships were fitted with a fire @-@ control director after completion . No computer was fitted at that time and data from the rangefinders had to be processed manually . Turrets 2 , 3 , and 5 were built with imported 6 @-@ metre ( 19 ft 8 in ) Bausch & Lomb rangefinders . These were felt to be inferior to the British Barr & Stroud instruments used on other ships and were removed in 1920 . They were replaced by either the British rangefinders or domestically built instruments of 6 or 8 metres ( 19 ft 8 in or 26 ft 3 in ) length . In the late 1920s the fire @-@ control systems were upgraded and additional platforms were added to the foremast to accommodate them . A pair of directors for the 12 @.@ 7 cm AA guns were added , one on each side of the forward superstructure , in the early 1930s . The fire @-@ control systems were again upgraded in the mid @-@ 1930s and directors were added for the 25 mm AA guns . Both ships had 10 @-@ metre ( 32 ft 10 in ) rangefinders installed at the top of the pagoda mast at that time . Type 21 air @-@ search radars were installed aboard the sisters in mid @-@ 1942 . \\n\",\n",
              " '',\n",
              " ' = = = Aircraft = = = \\n',\n",
              " '',\n",
              " ' Ise was briefly fitted with an aircraft flying @-@ off platform for a Mitsubishi <unk> fighter on Turret No. 2 in 1927 . It was replaced by a platform on Turret No. 5 for a Yokosuka E1Y reconnaissance floatplane in 1928 â 29 . A catapult and a collapsible 4 @-@ tonne ( 3 @.@ 9 @-@ long @-@ ton ) crane were fitted on the stern during the mid @-@ 1930s modernization , and the ships were equipped to operate three floatplanes , although no hangar was provided . The initial Nakajima E4N2 biplanes were replaced by Nakajima E8N2 biplanes in 1938 . \\n',\n",
              " '',\n",
              " ' = = Conversion to hybrid carriers = = \\n',\n",
              " '',\n",
              " ' The sinking of the British capital ships Prince of Wales and Repulse by Japanese land @-@ based aircraft on 10 December 1941 led the IJN to realize that battleships could not operate in the face of enemy aircraft and required friendly air support to protect them . The loss of four Japanese aircraft carriers during the Battle of Midway in June 1942 severely limited the ability of the IJN to provide any air cover and alternatives were sought . Earlier proposals to convert one or more battleships into carriers had been made and rejected at the beginning of the war , but they were revived after Midway . Plans for more elaborate conversions were rejected on the grounds of expense and , most critically , time , and the IJN settled on removing the rear pair of turrets and replacing them with a flight deck equipped with two catapults to launch floatplanes . The Ise @-@ class ships were selected for the conversion because HyÅ«ga had suffered an explosion in Turret No. 5 in early May that virtually destroyed the turret and their Turret No. 6 could not elevate to the full + 43 degrees deemed necessary for the long @-@ range engagement anticipated by the IJN . The <unk> were scheduled to follow once the first two were completed . \\n',\n",
              " '',\n",
              " ' = = = Armament changes = = = \\n',\n",
              " '',\n",
              " \" The rear turrets , the barbettes and their supporting structures were removed beginning in early 1943 and the openings in the middle deck were covered by 152 mm plates salvaged from the turret armour . All of the 14 cm guns were removed and the casemate openings sealed off . Four additional twin 12 @.@ 7 cm mounts were added , one pair abreast the funnel and the other abreast the conning tower . The original ten twin 25 mm gun mounts were replaced by triple mounts and nine new triple mounts were added , a total of 57 guns . Two each Type 94 and Type 95 AA directors were added to control the additional guns . The ammunition for these new guns was stored in the magazines originally used for the 14 cm guns and for Turret No. 5 . During 1944 , the ships ' AA defences were reinforced with an additional dozen triple and eleven single 25 mm gun mounts , for a total of 104 barrels , and a pair of Type 13 early warning radars were added . In September six 30 @-@ round AA rocket launchers were added on the sides of the flight deck . \\n\",\n",
              " '',\n",
              " ' = = = Flight deck arrangements = = = \\n',\n",
              " '',\n",
              " ' A 70 @-@ metre @-@ long ( 229 ft 8 in ) flight deck was built above the stern and stretched forward to the rebuilt aft superstructure . The flight deck was 29 metres ( 95 ft 2 in ) wide at its forward end and 13 metres ( 42 ft 8 in ) at the stern . It overhung the stern and increased the overall length of the ships to 219 @.@ 62 metres ( 720 ft 6 in ) . A pair of rotating gunpowder @-@ propelled catapults were fitted on the sides of the hull , forward of the aft superstructure where they partially restricted the arc of fire of the two amidships turrets . They could launch aircraft up to 4 @,@ 600 kilograms ( 10 @,@ 100 lb ) in weight and required 30 seconds to launch each aircraft . The flight deck had eight permanent storage positions connected by rails to the catapults and the hydraulically operated aircraft lift that brought the aircraft up from the hangar below on the trolleys used to move the floatplanes about . Two aircraft were intended to be stowed on the catapults and three more in temporary positions on the flight deck for a total of thirteen . \\n',\n",
              " \" The 40 @-@ metre @-@ long ( 131 ft 3 in ) hangar was 20 metres ( 65 ft 7 in ) wide forward and 11 metres ( 36 ft 1 in ) at the rear . It was 6 metres ( 19 ft 8 in ) high and designed to stow nine aircraft . It was fitted with fire fighting foam and carbon dioxide dispensers as a result of wartime experience . The ' T ' -shaped lift was 12 @.@ 1 metres ( 39 ft 8 in ) wide at its forward end and 6 @.@ 6 metres ( 21 ft 8 in ) wide at the its aft end . It was 12 @.@ 1 metres long and had a capacity of 6 tonnes ( 5 @.@ 9 long tons ) . Petrol storage tanks with a capacity of 76 tonnes ( 75 long tons ) were installed in the former magazine of Turret No. 6 to provide each aircraft with enough fuel for three sorties . To recover the aircraft the collapsible crane formerly on the stern was moved up to the port side of the flight deck . Another crane was intended on the starboard side , but it was never fitted . \\n\",\n",
              " ' The ships had an air group of 11 each of Yokosuka D4Y dive bombers ( Allied reporting name \" Judy \" ) and Aichi <unk> reconnaissance aircraft ( Allied reporting name \" Paul \" ) Both aircraft had development problems and neither air group ever had all of its intended aircraft . Coupled with a shortage of trained pilots , neither ship ever used its aircraft during combat . \\n',\n",
              " '',\n",
              " ' = = = Other changes = = = \\n',\n",
              " '',\n",
              " \" After the loss of the fast battleship Hiei at the Naval Battle of Guadalcanal in late 1942 to rudder damage , the IJN decided to reinforce the protection of the steering compartment and to create an auxiliary steering compartment . The protection of the former was strengthened by the addition of a concrete wall at least 1 metre ( 3 ft 3 in ) in thickness and some of the armour removed from the turrets was used to protect the latter . The double bottom below the former positions of aft turrets was converted to hold fuel oil ; this increased the ships ' endurance to 9 @,@ 500 nautical miles ( 17 @,@ 600 km ; 10 @,@ 900 mi ) at a speed of 16 knots . A pair of Type 22 surface @-@ search radars were also fitted during the conversion . \\n\",\n",
              " ' The removal of the secondary armament , the rear turrets and their supporting structures was generally compensated by the addition of the flight deck , hangar , AA guns and more fuel , and the metacentric height increased <unk> metres ( 9 @.@ 1 in ) to 2 @.@ 81 metres ( 9 ft 3 in ) at full load as a result of the reduction in the displacement by over 2 @,@ 000 tonnes ( 2 @,@ 000 long tons ) to 40 @,@ 444 tonnes ( 39 @,@ 805 long tons ) . This also reduced the draught to 9 @.@ 03 metres ( 29 ft 8 in ) . The overhang of the flight deck at the stern increased the overall length to 219 @.@ 62 metres ( 720 ft 6 in ) and the beam was slightly reduced to 31 @.@ 71 metres ( 104 ft 0 in ) . \\n',\n",
              " '',\n",
              " ' = = Ships = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = Service = = \\n',\n",
              " '',\n",
              " \" Upon commissioning , the sister ships were assigned to the 1st Battleship Division of the 1st Fleet . HyÅ«ga had an explosion in one of her main gun turrets that killed 11 men and injured 25 in 1919 ; the following year she accidentally collided with and sank a schooner , losing two crewmen . Before the start of the Pacific War , both ships frequently exercised off the coasts of the Soviet Union , Korea and China in addition to training in Japanese waters . Ise hosted Edward , Prince of Wales , and his aide @-@ de @-@ camp Lieutenant Louis Mountbatten in 1922 during the prince 's visit to Japan . In Korea Bay when the 1923 Great KantÅ earthquake struck , they sailed to Kyushu where they loaded supplies from for the victims on 4 September . Together with two other battleships and a pair of light cruisers , Ise sank the destroyer Yayoi in 1926 during gunnery practice . Ise 's AA armament was upgraded in 1931 and HyÅ«ga 's two years later . The latter ship was modernized in 1934 â 36 and Ise in 1935 â 37 , both at Kure Naval Arsenal . During the Second Sino @-@ Japanese War , the sisters frequently patrolled the Chinese coast in support of the blockade imposed by Japan . In August 1937 HyÅ«ga ferried two battalions of Special Naval Landing Forces to Port Arthur . Three years later , she served as the flagship for the Emperor of the puppet state of Manchukuo , Henry Pu @-@ yi , during his state visit to Japan in June 1940 . On 15 November the ships were transferred to the 2nd Battleship Division of the 1st Fleet . The sisters were refitted in late 1940 in preparation for war , which included the fitting of external degaussing coils and additional AA directors . \\n\",\n",
              " '',\n",
              " ' = = = World War II = = = \\n',\n",
              " '',\n",
              " ' When Japan began the Pacific War on 8 December , the sisters sortied for the Bonin Islands with four other battleships and the light carrier HÅshÅ as distant cover for the fleet attacking Pearl Harbor , and returned six days later . On 11 March 1942 Ise and HyÅ«ga sortied from their anchorage at Hashirajima to join the unsuccessful search for the American carrier force that had attacked Marcus Island a week earlier . Similarly they pursued but did not catch the American carriers that had launched the Doolittle Raid on 18 April . \\n',\n",
              " \" During gunnery training on 5 May , there was a premature detonation in the left gun of HyÅ«ga 's Turret No. 5 that disabled both guns and killed 51 crewmen . Both aft magazines were flooded to douse the resulting fire and save the ship . She received temporary repairs during which the turret was removed and replaced by a circular armour plate on which three triple 25 mm gun mounts were positioned . On 11 May a valve in Ise 's No. 2 engine room stuck in the open position and flooded the engine room . While under repair at Kure , both ships received prototype Type 21 radars . Commanded by Vice @-@ Admiral ShirÅ Takasu , the 2nd Battleship Division set sail with the Aleutian Support Group on 28 May , at the same time that most of the Imperial Fleet began an attack on Midway Island ( Operation MI ) . \\n\",\n",
              " ' They returned home on 14 June and the IJN began preliminary planning to replace the lost carriers with hybrid carriers converted from battleships . The sisters were selected for conversion and detached from the division on 14 July in preparation . They remained on \" standby alert \" until the actual conversions began . Ise was converted at Kure Naval Arsenal from 23 February to 5 September 1943 and HyÅ«ga at Sasebo Naval Arsenal from 2 May to 30 November . \\n',\n",
              " \" After completing her sea trials , Ise was attached to the Imperial Japanese Naval Academy at Etajima and ferried troops and munitions to the naval base at Truk in October . In November the ship began working up , joined by the newly completed HyÅ«ga the following month , and both rejoined the 2nd Battleship Division . On 1 May 1944 , the sisters were transferred to Rear Admiral Matsuda Chiaki 's reformed Fourth Carrier Division of the 3rd Fleet . The division 's <unk> Naval Air Group was formed that same day and conducted its first catapult launches in late June . \\n\",\n",
              " '',\n",
              " ' = = = = Battle of Cape EngaÃ±o = = = = \\n',\n",
              " '',\n",
              " ' Shortages of aircraft and serviceability problems greatly retarded pilot training and the ships only had a total of 17 D4Ys and 18 <unk> on hand on 1 October ; of these , only 6 and 16 were operational , respectively . The Japanese plan for the defence of the Philippines envisioned that the surviving carriers would be used to lure the American carrier forces away from the invasion area to a position where the carriers could be attacked by land @-@ based aircraft and the transports by the rest of the IJN . The other carrier air groups were not in much better shape and the Japanese decided to retain the aircraft ashore for use against the American carriers . The Fourth Carrier Division was assigned to the Northern Force under the command of Vice Admiral JisaburÅ Ozawa and the sisters sailed from Yashima on 20 October . On the morning of 24 October , the bulk of the few aircraft aboard were launched to attack the American carriers as a distraction . They inflicted no damage and caused the Americans to search in the direction from which they had attacked . The Americans finally spotted the Japanese carriers at 16 : 40 , some 200 miles ( 320 km ) east of Cape EngaÃ±o , the northeastern tip of Luzon . The American carriers were spread out and it was very late in the day to launch an airstrike , so Admiral William Halsey , commander of the Third Fleet decided to mass his carriers in a position to attack the following morning . Ozawa reversed course during the night , correctly believing that the Americans would follow him north . \\n',\n",
              " \" Although they had lost contact during the night , the Americans did find the Japanese carriers at 07 : 35 . They had already launched an airstrike of 180 aircraft that was orbiting 50 miles ( 80 km ) ahead of the American carriers while waiting for the Japanese ships to be located . This was just the first of a total of five airstrikes that the Americans launched that day . The sisters were not heavily engaged by the early airstrikes which are focusing on the group 's aircraft carriers . Ise claimed to have shot down five attacking dive bombers from the second wave and one small bomb detonated on Turret No. 2 . HyÅ«ga was lightly damaged by near misses that rupture some hull plating in her bulge and pepper her superstructure with splinters . She took on a 5 @-@ degree list that was quickly corrected before she was ordered to tow the crippled carrier Chiyoda to safety . Her attempt was unsuccessful and Chiyoda had to be abandoned to her fate . \\n\",\n",
              " ' Ise was attacked by 80 @-@ odd aircraft from the fourth wave , but they failed to inflict any serious damage . She dodged 11 torpedoes and was only hit by a bomb once , on the bulge outboard of the port catapult . Some 34 other bombs near missed her , spraying her with splinters and ruptured some hull plates that contaminated some fuel oil and caused leaks in her port boiler rooms . While an exact total of her casualties is not available , it has been estimated that 5 men were killed and some 111 â 121 crewmen were wounded during this attack . HyÅ«ga was unsuccessfully attacked by an American submarine at 18 : 43 . Around 19 : 00 Ozawa learned about a force of destroyers and cruisers that drove off the Japanese destroyers rescuing survivors from some of the carriers lost earlier in the day and sank Chiyoda . He ordered the Fourth Carrier Division to reverse course and engage the Americans , but the battleships were unable to find them , and Ozawa ordered them to reverse course and head for Amami Åshima . When they arrived on 27 October , Ozawa transferred to HyÅ«ga and hoisted his flag aboard her . While en route for Kure , the division was unsuccessfully attacked by another submarine . \\n',\n",
              " ' In early November the catapults were removed from both ships , and they loaded troops and munitions later that month . While en route they were diverted to the Spratly Islands upon reports of heavy air raids at Manila . After off @-@ loading their cargo , they sailed for Lingga Island , near Singapore , on 20 November . They transferred to Cam Ranh Bay , French Indochina and HyÅ«ga became flagship of the 5th Fleet there on 14 December . The division sailed for Singapore on 30 December and Vice Admiral Kiyohide Shima transferred his flag to the light cruiser Åyodo on arrival there the following day . The division continued onwards to Lingga . Its planned return to Japan was delayed by attacks by the American Third Fleet on targets in Indochina and southern China that sank two oil tankers that were intended to refuel the division . \\n',\n",
              " ' The IJN then decided to use the sisters and their escorts to bring a load of petrol , rubber , tin and other strategic minerals back to Japan after the American carriers departed the South China Sea ( Operation Kita ) . They loaded their cargoes beginning on 6 February at Singapore and departed four days later . Also carrying some 1 @,@ 150 oilfield workers , they were escorted by Åyodo and three destroyers . <unk> Japanese radio signals revealed the Japanese plan to the Allies , and 15 submarines were positioned along their anticipated route in an attempt to intercept and sink the ships . An additional 11 were moved into position while the group was en route , but only three were ultimately able to attack . None of them were successful before the Japanese reached Kure on 20 February . The Fourth Carrier Division was disbanded on 1 March and the sisters were reduced to 1st rank reserve ships . On 19 March Kure was attacked by aircraft from Task Force 58 and HyÅ«ga was hit three times by bombs that killed 37 men and wounded 52 . Her gunners claimed to have shot down one American dive bomber during the attack . Ise was hit twice during the attack , but her casualties , if any , are unknown . \\n',\n",
              " \" The ships were turned into floating AA batteries over the next several months although it availed them little when they were attacked again by American carrier aircraft in July . On the 24th Ise was struck by five bombs and near missed multiple times ; all told she lost 50 crewmen killed and many others wounded . The bombs started numerous leaks and Ise began to settle by the bow , although she was returned to an even keel after three @-@ days pumping . HyÅ«ga was a primary focus of the attack and she received 10 direct hits and up to 30 near misses . She was badly damaged with some 200 @-@ odd crewmen killed and 600 wounded during the attack . She slowly foundered over the next two days and was not attacked when the Americans returned four days later . This time it was Ise 's turn and she was struck 11 or more times with many near misses that put her on the bottom in shallow water with a 15 degree list . The sisters were struck off the Navy List in November and their wrecks were scrapped after the war . \\n\",\n",
              " '',\n",
              " '',\n",
              " ' = Dick <unk> = \\n',\n",
              " '',\n",
              " ' Richard Gale \" Dick \" <unk> ( August 21 , 1926 â December 5 , 1994 ) was an American football player and a pioneering television broadcaster for the forerunner to <unk> @-@ TV in Buffalo . He played college football for the University of Michigan Wolverines in 1944 and from 1946 to 1948 . He was a consensus selection at end on the 1948 College Football All @-@ America Team . <unk> played professionally in the National Football League ( NFL ) with the Detroit Lions for one season in 1950 . After retiring from football he settled in Buffalo and became a sports broadcaster . He worked as a color commentator and as a play @-@ by @-@ play announcer for the Buffalo Bulls . He hosted various television and radio sports shows and was eventually inducted into the Buffalo Broadcasters Hall of Fame . \\n',\n",
              " \" In college , he led the Big Ten Conference in single season receptions during his senior year and set Michigan Wolverines receptions records for both career touchdown and single @-@ season touchdowns . He had also been a Michigan High School Athletic Association ( MHSAA ) state champion in both basketball and track and field . His college career was interrupted by World War II service , and his high school career was also affected by the war due to the MHSAA 's cancellation of state championships in all sports in 1943 . \\n\",\n",
              " '',\n",
              " ' = = High school = = \\n',\n",
              " '',\n",
              " \" <unk> was born in Petoskey , Michigan , and raised in Kalamazoo , Michigan before his family moved to Saginaw , Michigan . <unk> was a star athlete at Saginaw 's Arthur Hill High School in football , basketball , and track and field . In 1943 , Michigan canceled boys high school tournaments in all sports due to World War II , and they did not return until the fall of 1944 . In 1944 , he led Arthur Hill High to the MHSAA Class A high school basketball championship ( over Kalamazoo Central High School ) , scoring 24 points , including 17 in the second half , of the championship game . <unk> was also the state champion in 1944 in both the shot put 46 feet 11 inches ( 14 @.@ 30 m ) and high jump 5 feet 8 @.@ 5 inches ( 1 @.@ 74 m ) . He also led Arthur Hill in football , and his high school accomplishments are featured in Glory : The history of Saginaw County sports by Jack Tany ( ASIN <unk> ) , which is a book on high school sports in Saginaw County , Michigan . <unk> was named All State in football , basketball and track . \\n\",\n",
              " \" It is ironic that <unk> was born in Petoskey , Michigan in 1926 for several reasons . Ted Petoskey preceded <unk> as an All @-@ American end on the University of Michigan football team . Petoskey had excelled as a representative of Saginaw County in MHSAA competition . Petoskey posted significant football accomplishments in 1926 making 1926 a significant year for himself as well . Achieving All @-@ American status as an end at Michigan would be <unk> 's next step after excelling in MHSAA competition . \\n\",\n",
              " '',\n",
              " ' = = College = = \\n',\n",
              " '',\n",
              " ' In the fall of 1944 , <unk> enrolled at the University of Michigan . The United Press syndicate ran a feature article about <unk> in September 1944 that opened as follows : \" Another great end has made his appearance on the Big Ten football horizon in the person of Dick <unk> , 18 @-@ year @-@ old Michigan freshman . Every so often a great offensive end comes along , a player who has to learn how to play defense , but who has the natural speed , smooth actions , height and big hands that is the mark of an outstanding pass receiver . <unk> has laid claim to that rating . A loose @-@ limbed 180 @-@ pound freshman from Saginaw , Mich . , <unk> is being boomed as the Big Ten \\'s next \\' freshman sensation . \\' \" As a freshman , he caught two touchdown passes in his first college football game against Iowa . In an article titled \" Teens and TNT , \" Time reported on <unk> \\'s performance : \" Of the few teams already in action , Michigan \\'s teens rang the freshman bell loudest last week by winning their opener , 12 -to @-@ 7 , against the strong Iowa Seahawks ( Naval Pre @-@ Flight ) ; 6 @-@ ft . 4 Freshman End Dick <unk> caught passes and ran for both Michigan touchdowns . \" \\n',\n",
              " ' <unk> \\'s college career was interrupted by World War II service in the United States Navy , but after missing the 1945 season , he returned to play for the Wolverines from 1946 to 1948 . <unk> played for the Wolverines in consecutive undefeated National Championship seasons in 1947 and 1948 . He started nine games for the 1947 team . The 1947 team referred to as \" Michigan \\'s Mad Magicians \" is considered to be the greatest University of Michigan football team of all time . <unk> and teammate Len Ford had the reputation as the team practical jokers . During the 1947 game against Wisconsin , <unk> started calling signals for the Badgers . Wisconsin \\'s offense protested to officials , who \" prowled the Wolverines secondary but never caught their man . \" <unk> continued to scramble Badger signals , as <unk> \\'s teammates laughed at his scheme . In the January 1 , 1948 Rose Bowl that season , Michigan rolled to a 49 â 0 victory over USC , and they outgained the Trojans 491 yards to 133 . <unk> caught a 29 @-@ yard pass for the game \\'s final score . \\n',\n",
              " ' In the 1948 championship season , <unk> scored eight touchdowns , caught 22 passes , and gained 610 yards ( 508 receiving and 102 rushing ) . <unk> was the second highest scoring end in the nation in 1948 , and he was a consensus All @-@ American as a senior , being selected as first team on nine of the 11 All @-@ American teams . <unk> led the Big Ten in receptions . \\n',\n",
              " \" Although <unk> finished fourth among midwestern Heisman voters in 1948 , he did not finish among the top eight . By comparison , Notre Dame end Leon Hart won the Heisman Trophy in 1949 but made only eight of the 11 All @-@ American teams . It is not clear why <unk> did not finish higher . However , it is fairly clear that sportswriters of that era had a bias against Michigan . In the Associated Press poll at the end of the 1947 season , the Notre Dame Fighting Irish were ranked ahead of the University of Michigan , though both teams were undefeated . Some noted that every Southern AP voter had voted for Notre Dame , which had yet to integrate , whereas three of Michigan 's star players ( Bob Mann , Gene Derricotte , and Len Ford ) were African @-@ American . The Southern schools refused even to schedule games against schools that played African @-@ American players . \\n\",\n",
              " \" <unk> was considered one of the greatest Wolverine 's of the 1940s . In four seasons with the Michigan Wolverines , <unk> played in 32 games and had over 1 @,@ 000 yards of total offense . <unk> held the University of Michigan 's single season and career record for touchdown receptions ( eight in a season ; sixteen career ) until his records were broken by Anthony Carter in 1980 . \\n\",\n",
              " '',\n",
              " ' = = Professional career = = \\n',\n",
              " '',\n",
              " ' In 1948 , <unk> was drafted by the Philadelphia Eagles in the 15th round of the NFL draft , and he was also drafted by the New York Yankees of the All @-@ America Football Conference . He had intended to play in 1949 with the Yankees , but suffered a knee injury in a practice session for the August 1949 Chicago College All @-@ Star Game . Press accounts at the time noted that the injury \" will probably keep him out of pro football all season , if not forever . \" The incident led to a debate as to whether NFL owners should \" bar their men from playing with the college all @-@ stars . \" \\n',\n",
              " \" <unk> landed a job at WJR radio in Detroit , but he left his sportscaster 's job to join the Detroit Lions . In the 1950 NFL season , <unk> came back from his injury to play for the Detroit Lions . He played in 12 games and had ten receptions for 96 yards and one touchdown for the 1950 Lions . <unk> recalled that his playing time with the Lions was limited because the Lions also signed 1949 Heisman Trophy winner Leon Hart , who played the same position . \\n\",\n",
              " ' In May 1951 , he announced he was retiring from professional football to become sports director at a radio station in Buffalo . He was hired as a sportscaster by <unk> ( now known as <unk> ) , which had just started the first television station in Buffalo and the only one serving Southern Ontario . This was an early foray into television by the Buffalo Evening News . In the 1950s , <unk> hosted a popular panel show called \" Let \\'s Talk Sports \" in Buffalo and also pioneered an early morning exercise program . He also worked for <unk> ( AM ) and <unk> ( FM ) and as the sideline announcer for Buffalo Bills games along with Van Miller , the long time Bills play @-@ by @-@ play announcer . In addition , he served as the play @-@ by @-@ play announcer for the University of Buffalo Bulls football team . As a radio broadcaster , he is remembered for things ranging from ski reports , to 17 years worth of \" Breakfast At â \" programs live from various local restaurants , to 27 years as the <unk> @-@ AM All Night Show host . \\n',\n",
              " \" After 30 years with <unk> and a change in ownership for the station , his show was replaced with the Mutual Network 's The Larry King Show . In the 1980s , <unk> taught communications at Buffalo 's Medaille College and served as a disc jockey on Public Broadcasting 's radio station <unk> ( now <unk> ) . He also sold ads for Buffalo Evening News competitor , Buffalo Courier @-@ Express . <unk> 's final employer was Erie County , who hired him as an inmate training supervisor at the Erie County Correctional Facility . \\n\",\n",
              " ' <unk> was posthumously inducted into the Buffalo Broadcasters Hall of Fame in September 2007 . He was given the Golden Age Award which is reserved for \" those who did it first , the people who had no pattern to follow . \" The Hall of Fame award was presented to <unk> \\'s wife , Jane . In her acceptance speech , Jane <unk> observed that despite all of her late husband \\'s achievements , there was one thing he had never received : \" He had a great career , but he never had a trophy . And now he has . \" \\n',\n",
              " '',\n",
              " ' = = Family = = \\n',\n",
              " '',\n",
              " ' <unk> lived 37 of his years in Buffalo . His wife , the former Jane Morris , was the head of the Buffalo Jills cheerleaders when they met . <unk> , who was survived by three sons , ( Douglas A. , Gary R. , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in Cheektowaga , New York in December 1994 ; he was 68 years old . Doug was a 1988 first team football All @-@ Western New York linebacker for Clarence High School . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = 1933 Treasure Coast hurricane = \\n',\n",
              " '',\n",
              " ' The 1933 Treasure Coast hurricane was the second @-@ most intense tropical cyclone to strike the United States during the active 1933 Atlantic hurricane season . The eleventh tropical storm , fifth hurricane , and the third major hurricane of the season , it formed east @-@ northeast of the Leeward Islands on August 31 . The tropical storm moved rapidly west @-@ northwestward , steadily intensifying to a hurricane . It acquired peak winds of 140 miles per hour ( 225 km / h ) and passed over portions of the Bahamas on September 3 , including Eleuthera and Harbour Island , causing severe damage to crops , buildings , and infrastructure . Winds over 100 mph ( 161 km / h ) affected many islands in its path , especially those that encountered its center , and many wharves were ruined . \\n',\n",
              " ' Subsequently , it weakened and made landfall at Jupiter , Florida , early on September 4 with winds of 125 mph ( 201 km / h ) . The hurricane moved across the state , passing near Tampa before moving into Georgia and dissipating . In Florida , the strong winds of the cyclone blew buildings off their foundations , and numerous trees were prostrated in citrus groves . The Treasure Coast region received the most extensive destruction , and Stuart , Jupiter , and Fort Pierce were heavily damaged . Inland , the cyclone weakened rapidly but produced prodigious amounts of rain , causing a dam to collapse near Tampa . The storm caused $ 3 million in damage ( 1933 USD ) after damaging or destroying 6 @,@ 848 homes . \\n',\n",
              " ' Unusually , the storm hit Florida less than 24 hours before another major hurricane bearing 125 @-@ mile @-@ per @-@ hour ( 201 km / h ) winds struck South Texas ; never have two major cyclones hit the United States in such close succession . \\n',\n",
              " '',\n",
              " ' = = Meteorological history = = \\n',\n",
              " '',\n",
              " ' The origins of the hurricane were from a tropical wave that possibly spawned a tropical depression on August 27 , although there was minimal data over the next few days as it tracked to the west @-@ northwest . On August 31 , a nearby ship reported gale force winds , which indicated that a tropical storm had developed to the east @-@ northeast of the Lesser Antilles . Based on continuity , it is estimated the storm attained hurricane status later that day . Moving quickly to the west @-@ northwest , the storm passed north of the Lesser Antilles and Puerto Rico . Early on September 2 , a ship called the <unk> reported a barometric pressure of 978 mbar ( 28 @.@ 88 inHg ) , which confirmed that the storm attained hurricane status . After passing north of the Turks and Caicos islands , the hurricane struck Eleuthera and Harbour Island in the Bahamas on September 3 , the latter at 1100 UTC . A station on the latter island reported a pressure of 27 @.@ 90 inHg ( 945 mb ) during the 30 minute passage of the eye . Based on the pressure and the small size of the storm , it is estimated the hurricane struck Harbour Island with peak winds of 140 mph ( 225 km / h ) , making it the equivalent of a modern Category 4 hurricane on the Saffir @-@ Simpson scale . <unk> suggested that the storm reached major hurricane status , or Category 3 status , on September 2 . \\n',\n",
              " \" The hurricane initially followed the course of another hurricane that passed through the area in late August , which ultimately struck Cuba and Texas . This hurricane instead maintained a general west @-@ northwest track . After moving through the northern Bahamas , the hurricane weakened slightly before making landfall at Jupiter , Florida , at 0500 UTC on September 4 . A station there reported a pressure of 27 @.@ 98 inHg ( 948 mb ) during a 40 minute period of the eye 's passage ; this suggested a landfall strength of 125 mph ( 201 km / h ) . At the time , the radius of maximum winds was 15 mi ( 24 km ) , which was smaller than average . After landfall , the hurricane weakened rapidly while crossing the state . It briefly emerged into the Gulf of Mexico as a tropical storm early on September 5 . A few hours later while continuing to the northwest , it made another landfall near Rosewood â a ghost town in Levy County , east of Cedar Key â with winds of about 65 mph ( 105 km / h ) . Turning to the north , the storm slowly weakened as it crossed into Georgia , dissipating on September 7 near Augusta . \\n\",\n",
              " '',\n",
              " ' = = Preparations and impact = = \\n',\n",
              " '',\n",
              " ' On September 2 , a fleet of eight aircraft evacuated all white residents from West End , Grand Bahama , to Daytona Beach , Florida . While the storm was near peak intensity on September 3 , the Weather Bureau issued hurricane warnings from Miami to Melbourne , Florida , with storm warnings extending northward to Jacksonville . Later that day , storm warnings , were issued from Key West to Cedar Key . About 2 @,@ 500 people evacuated by train from areas around Lake Okeechobee . By evening on September 3 , high tides sent sea spray over coastal seawalls in Palm Beach County as residents boarded up buildings ; structures on Clematis Street in West Palm Beach were said to be a \" solid front \" of plywood . Along the coast , observers reported very rough seas as the eye neared land . \\n',\n",
              " \" The powerful hurricane moved over or near several islands in the Bahamas . Winds on Spanish Wells and Harbour Island were both estimated at around 140 mph ( 225 km / h ) . Winds reached 110 mph ( 177 km / h ) at Governor 's Harbour , 100 mph ( 161 km / h ) on Eleuthera , and 120 mph ( 193 km / h ) on the Abaco Islands . The storm was farther away from Nassau , where winds reached 61 mph ( 98 km / h ) . The hurricane damaged a lumber mill on Abaco , washing away a dock . Heavy damage occurred on Harbour Island , including to several roofs , the walls of government buildings , and the water system . The hurricane destroyed four churches and 37 houses , leaving 100 people homeless . A 1 @.@ 5 mi ( 2 @.@ 4 km ) road on Eleuthera was destroyed . Several islands sustained damage to farms , including the total loss of various fruit trees on Russell Island . Despite Category 4 winds on Spanish Wells , only five houses were destroyed , although most of the remaining dwellings lost their roofs . Collectively between North Point , James Cistern , and Gregory Town on Eleuthera , the storm destroyed 55 houses and damaged many others . On Grand Bahama , where a 9 to 12 ft ( 2 @.@ 7 to 3 @.@ 7 m ) storm surge was reported , half of the houses were destroyed , as were 13 boats and two planes , and most docks were wrecked . \\n\",\n",
              " ' When the storm moved ashore in Florida , winds reached an estimated 125 mph ( 201 km / h ) in Jupiter ; these occurred after the eye passed . In West Palm Beach , anemometers measured at least 80 @-@ mile @-@ per @-@ hour ( 129 km / h ) winds with gusts to 100 mph ( 161 km / h ) ; barometers ranged from 28 @.@ 64 to 28 @.@ 78 inHg ( 970 to 975 mb ) . The storm produced the strongest winds in the city since the 1928 Okeechobee hurricane . Winds were not as strong farther from the center ; 40 to 45 mph ( 64 to 72 km / h ) winds were observed in Miami to the south , Titusville to the north , and Tampa on the west coast . Fort Pierce estimated peak winds of 80 to 90 mph ( 129 to 145 km / h ) , and pressures dipped to 29 @.@ 14 inHg ( 987 mb ) . Inland , winds near Lake Okeechobee peaked at only 60 mph ( 97 km / h ) . The hurricane dropped heavy rainfall along its path , peaking at 17 @.@ 8 in ( 450 mm ) in Clermont . \\n',\n",
              " ' At West Palm Beach , the majority of the damage was confined to vegetation . Several coconut and royal palms that withstood the 1928 hurricane snapped , littering streets with broken trunks . Winds downed road signs on many streets , and floodwaters covered the greens on a local golf course . Some garages and isolated structures , mostly lightweight , were partly or totally destroyed , along with a lumber warehouse . Some homes that lost roofing shingles had water damage to their interiors as well . Nearby Lake Worth sustained extensive breakage of windows , including plate glass , and loss of tile and shingle roofing , but preparations reduced losses to just several thousand dollars , and no post @-@ storm accidents took place . Strong winds snapped many light poles in the city , and trees and shrubs were broken or uprooted . As in Lake Worth , officials in West Palm Beach credited preparations and stringent building codes with reducing overall damage . The city had learned from previous experience with severe storms in 1926 , 1928 , and 1929 . High tides eroded Ocean Boulevard at several spots and disrupted access to several bridges on the Lake Worth Lagoon . Winter estates and hotels on Palm Beach generally sustained little material damage , except to vegetation , and county properties went largely unscathed . \\n',\n",
              " ' In Martin and St. Lucie counties , the storm was considered among the worst on record . The storm leveled some homes and swept many others off their foundations . At Stuart , winds removed or badly damaged 75 % of the roofs in town . The storm destroyed the third floor of the building that housed a bowling alley and the Stuart News , a local newspaper . At Olympia , an abandoned settlement also known as Olympia Beach , strong winds leveled the old Olympia Inn , a gas station , and the second floor of a pharmaceutical building . Winds also tore the roof off an ice plant . A bridge leading to the barrier island from Olympia was partly wrecked ; the bridge tender survived by gripping the railing during the storm . Winds leveled his nearby home . According to the Monthly Weather Review , some of the most severe damage from the storm in Florida was at Olympia . The storm left many homes in Hobe Sound uninhabitable , forcing crews to tear them down . Winter estates on the island , however , were better built and little damaged . While Stuart and Hobe Sound sustained significant damage , Port Salerno suffered minimally . In Stuart , the storm left 400 to 500 people homeless , up to nearly 10 % of the population , which was 5 @,@ 100 at the time . Between Jupiter and Fort Pierce , the storm knocked down power and telegraph lines . In the latter city , high waves washed out a portion of the causeway . In the 1980s , an elderly resident recalled that the storm was the most severe on record in Fort Pierce . \\n',\n",
              " ' Crop damage was worst along the Indian River Lagoon ; several farms in Stuart experienced total losses , and statewide , 16 % of the citrus crop , or 4 million boxes , were destroyed . Many chicken coops in Stuart were destroyed , and the local chicken population was scattered and dispersed as far as Indiantown . Across southeastern Florida , the hurricane damaged 6 @,@ 465 houses and destroyed another 383 , causing over $ 3 million in damage . One person , an African American farm worker , was killed when his shack blew down in Gomez , a brakeman died after seven railcars derailed , and a child was killed by airborne debris . \\n',\n",
              " ' High rainfall caused flooding across Florida , notably near Tampa where waters reached 9 ft ( 2 @.@ 7 m ) deep . High rainfall of over 7 in ( 180 mm ) caused a dam operated by Tampa Electric Co. to break 3 mi ( 4 @.@ 8 km ) northeast of Tampa along the Hillsborough River . The break resulted in severe local damage , flooding portions of Sulphur Springs . Workers attempted to save the dam with sandbags , and after the break , most residents in the area were warned of the approaching flood . Over 50 homes were flooded , forcing about 150 people to evacuate . Outside Florida , the storm produced winds of 48 and 51 mph ( 78 and 81 km / h ) in Savannah , Georgia and Charleston , South Carolina , respectively . In the latter city , the storm spawned a tornado , which caused about $ 10 @,@ 000 in property damage . Heavy rainfall occurred along the Georgia and South Carolina coasts , reaching over 12 in ( 300 mm ) . Light rainfall also extended into North Carolina . \\n',\n",
              " '',\n",
              " ' = = Aftermath = = \\n',\n",
              " '',\n",
              " ' In the Bahamas after the storm , a boat sailed from Nassau to deliver food and building materials to Eleuthera . \\n',\n",
              " \" After the storm , the National Guard offered shelters for at least 400 homeless residents in Stuart . Of the 7 @,@ 900 families adversely affected by the hurricane , 4 @,@ 325 required assistance from the American Red Cross . Farmers in Texas , also affected by a major hurricane , requested growers in Florida wait 15 days so they could sell their citrus crop that fell . The damaged dam near Tampa initially resulted in waters from the Hillsborough River being pumped into the city 's water treatment plant , and a new dam was eventually built in 1944 . \\n\",\n",
              " '',\n",
              " '',\n",
              " ' = Second Battle of Naktong Bulge = \\n',\n",
              " '',\n",
              " ' The Second Battle of Naktong Bulge was an engagement between United Nations ( UN ) and North Korean ( NK ) forces early in the Korean War from September 1 to September 15 , 1950 , along the Naktong River in South Korea . It was a part of the Battle of Pusan Perimeter , and was one of several large engagements fought simultaneously . The battle ended in a victory for the United Nations after large numbers of United States ( US ) and Republic of Korea ( ROK ) troops repelled a strong North Korean attack . \\n',\n",
              " \" After the First Battle of Naktong Bulge , the US Army 's 2nd Infantry Division was moved to defend the Naktong River line . The division , which was untried in combat , was struck with a strong attack by several divisions of the Korean People 's Army which crossed the river and struck all along the division 's line . The force of the attack split the US 2nd Infantry Division in half , and the North Koreans were able to penetrate to Yongsan , promoting a fight there . \\n\",\n",
              " ' The urgency of the threat to Pusan Perimeter prompted the US Marine Corps 1st Provisional Marine Brigade to be brought in to reinforce the US Army troops . In two weeks of heavy fighting , the US forces were able to force the North Koreans out of the Naktong Bulge region . The North Koreans were further repulsed after the UN counterattack at Inchon , which culminated in the virtual destruction of the North Korean army . \\n',\n",
              " '',\n",
              " ' = = Background = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Pusan Perimeter = = = \\n',\n",
              " '',\n",
              " \" From the outbreak of the Korean War and the invasion of South Korea by the North , the North Korean People 's Army had enjoyed superiority in both manpower and equipment over both the Republic of Korea Army and the United Nations forces dispatched to South Korea to prevent it from collapsing . The North Korean strategy was to aggressively pursue UN and ROK forces on all avenues of approach south and to engage them aggressively , attacking from the front and initiating a double envelopment of both flanks of the unit , which allowed the North Koreans to surround and cut off the opposing force , which would then be forced to retreat in disarray , often leaving behind much of its equipment . From their initial June 25 offensive to fights in July and early August , the North Koreans used this strategy to effectively defeat any UN force and push it south . However , when the UN forces , under the Eighth United States Army , established the Pusan Perimeter in August , the UN troops held a continuous line along the peninsula which North Korean troops could not flank , and their advantages in numbers decreased daily as the superior UN logistical system brought in more troops and supplies to the UN army . \\n\",\n",
              " \" When the North Koreans approached the Pusan Perimeter on August 5 , they attempted the same frontal assault technique on the four main avenues of approach into the perimeter . Throughout August , the NK 6th Division , and later the NK 7th Division engaged the US 25th Infantry Division at the Battle of Masan , initially repelling a UN counteroffensive before countering with battles at Komam @-@ ni and Battle Mountain . These attacks stalled as UN forces , well equipped and with plenty of reserves , repeatedly repelled North Korean attacks . North of Masan , the NK 4th Division and the US 24th Infantry Division sparred in the Naktong Bulge area . In the First Battle of Naktong Bulge , the North Korean division was unable to hold its bridgehead across the river as large numbers of US reserve forces were brought in to repel it , and on August 19 , the NK 4th Division was forced back across the river with 50 percent casualties . In the Taegu region , five North Korean divisions were repulsed by three UN divisions in several attempts to attack the city during the Battle of Taegu . Particularly heavy fighting took place at the Battle of the Bowling Alley where the NK 13th Division was almost completely destroyed in the attack . On the east coast , three more North Korean divisions were repulsed by the South Koreans at P 'ohang @-@ dong during the Battle of P 'ohang @-@ dong . All along the front , the North Korean troops were reeling from these defeats , the first time in the war their strategies were not working . \\n\",\n",
              " '',\n",
              " ' = = = September push = = = \\n',\n",
              " '',\n",
              " ' In planning its new offensive , the North Korean command decided any attempt to flank the UN force was impossible thanks to the support of the UN navy . Instead , they opted to use frontal attack to breach the perimeter and collapse it as the only hope of achieving success in the battle . Fed by intelligence from the Soviet Union the North Koreans were aware the UN forces were building up along the Pusan Perimeter and that it must conduct an offensive soon or it could not win the battle . A secondary objective was to surround Taegu and destroy the UN and ROK units in that city . As part of this mission , the North Korean units would first cut the supply lines to Taegu . \\n',\n",
              " ' On August 20 , the North Korean commands distributed operations orders to their subordinate units . The North Koreans called for a simultaneous five @-@ prong attack against the UN lines . These attacks would overwhelm the UN defenders and allow the North Koreans to break through the lines in at least one place to force the UN forces back . Five battle groupings were ordered . The center attack called for the NK 9th Division , NK 4th Division , NK 2nd Division , and NK 10th Division break through the US 2nd Infantry Division at the Naktong Bulge to Miryang and Yongsan . \\n',\n",
              " '',\n",
              " ' = = Battle = = \\n',\n",
              " '',\n",
              " \" During the North Koreans ' September 1 offensive , the US 25th Infantry Division 's US 35th Infantry Regiment was heavily engaged in the Battle of Nam River north of Masan . On the 35th Regiment 's right flank , just north of the confluence of the Nam River and the Naktong River , was the US 9th Infantry Regiment , US 2nd Infantry Division . There , in the southernmost part of the 2nd Infantry Division zone , the 9th Infantry Regiment held a sector more than 20 @,@ 000 yards ( 18 @,@ 000 m ) long , including the bulge area of the Naktong where the First Battle of Naktong Bulge had taken place earlier in August . Each US infantry company on the river line here had a front of 3 @,@ 000 feet ( 910 m ) to 4 @,@ 000 feet ( 1 @,@ 200 m ) and they held only key hills and observation points , as the units were extremely spread out along the wide front . \\n\",\n",
              " \" During the last week of August , US troops on these hills could see minor North Korean activity across the river , which they thought was North Koreans organizing the high ground on the west side of the Naktong against a possible American attack . There were occasional attacks on the 9th Infantry 's forward positions , but to the men in the front lines this appeared to be only a standard patrol action . On August 31 , the UN forces were alerted to a pending attack when much of the Korean civilian labor force fled the front lines . Intelligence officers reported an attack was coming . \\n\",\n",
              " \" On the west side of the Naktong , North Korean Major General Pak Kyo Sam , commanding the NK 9th Division , issued his operations order to the division on August 28 . Its mission in the forthcoming attack was to outflank and destroy the US troops at Naktong Bulge by capturing the Miryang and Samnangjin areas to cut off the US 2nd Division 's route of supply and withdrawal between Taegu and Pusan . However , the North Koreans weren 't aware that the US 2nd Infantry Division had recently replaced the US 24th Infantry Division in positions along the Naktong River . Consequently , they expected lighter resistance ; the 24th troops were exhausted from months of fighting but the 2nd Division men were fresh and newly arrived in Korea . They had only recently been moved into the line . The North Koreans began crossing the Naktong River under cover of darkness at certain points . \\n\",\n",
              " '',\n",
              " ' = = = Battle of Agok = = = \\n',\n",
              " '',\n",
              " ' On the southern @-@ most flank of the 9th Infantry river line , just above the junction of the Nam River with the Naktong , A Company of the 1st Battalion was dug in on a long finger ridge paralleling the Naktong that terminates in Hill 94 at the <unk> ferry site . The river road from Namji @-@ ri running west along the Naktong passes the southern tip of this ridge and crosses to the west side of the river at the ferry . A small village called Agok lay at the base of Hill 94 and 300 yards ( 270 m ) from the river . A patrol of tanks and armored vehicles , together with two infantry squads of A Company , 9th Infantry , held a roadblock near the ferry and close to Agok . On the evening of August 31 , A Company moved from its ridge positions overlooking Agok and the river to new positions along the river below the ridge line . \\n',\n",
              " \" That evening Sergeant Ernest R. Kouma led the patrol of two M26 Pershing tanks and two M19 Gun Motor Carriages in Agok . Kouma placed his patrol on the west side of Agok near the <unk> ferry . At 20 : 00 a heavy fog covered the river , and at 22 : 00 mortar shells began falling on the American @-@ held side of the river . By 22 : 15 this strike intensified and North Korean mortar preparation struck A Company 's positions . American mortars and artillery began firing counterbattery . Some of the A Company men reported they heard noises on the opposite side of the river and splashes in the water . \\n\",\n",
              " \" At 22 : 30 the fog lifted and Kouma saw that a North Korean pontoon bridge was being laid across the river directly in front of his position . Kouma 's four vehicles attacked this structure , and after about a minute of heavy fire the bridge collapsed , and the <unk> boats used to hold the bridge in place were sunk . At 23 : 00 a small arms fight flared around the left side of A Company north of the tanks . This gunfire had lasted only two or three minutes when the A Company roadblock squads near the tanks received word by field telephone that the company was withdrawing to the original ridge positions and that they should do likewise . \\n\",\n",
              " \" Kouma 's patrol was then ambushed by a group of North Koreans dressed in US military uniforms . Kouma was wounded and the other three vehicles had to withdraw , but he held the Agok site until 07 : 30 the next morning with his single tank . In the attack against A Company , the North Koreans hit the 1st Platoon , which was near Agok , but they did not find the 2nd Platoon northward . \\n\",\n",
              " \" The NK 9th Division 's infantry crossing of the Naktong and attack on its east side near midnight quickly overran the positions of C Company , north of A Company . There the North Koreans assaulted in force , signaled by green flares and blowing of whistles . The company held its positions only a short time and then attempted to escape . Many of the men moved south , a few of them coming into A Company 's ridge line positions near Agok during the night . Most of C Company moved all the way to the 25th Division positions south of the Naktong . On September 1 that division reported that 110 men of C Company had come into its lines . \\n\",\n",
              " '',\n",
              " ' = = = North Korean crossing = = = \\n',\n",
              " '',\n",
              " \" Meanwhile , 5 miles ( 8 @.@ 0 km ) north of Agok and A Company 's position , B Company , 9th Infantry , held a similar position on Hill 209 overlooking the <unk> ferry crossing of the river . This ferry was located at the middle of the Naktong Bulge where the Yongsan road came down to the Naktong and crossed it . The US 2nd Infantry Division had planned a reconnaissance mission to start from there the night of August 31 , the same night that the NK I Corps offensive rolled across the river . \\n\",\n",
              " ' Near the end of the month two reconnaissance patrols from the 9th Infantry had crossed to the west side of the Naktong and observed North Korean tank and troop activity 2 miles ( 3 @.@ 2 km ) west of the river . Information obtained later indicated it was in fact the command post of the NK 9th Division . On August 25 , 9th Infantry commander Colonel John G. Hill outlined projected \" Operation Manchu , \" which was to be a company @-@ sized combat patrol to cross the river , advance to the suspected North Korean command post and communications center , destroy it , capture prisoners , and collect intelligence . \\n',\n",
              " ' The 9th Infantry Regiment had planned Task Force Manchu on orders from the 2nd Division commander Major General Laurence B. Keiser , which in turn had received instructions from Eighth United States Army commander Lieutenant General Walton Walker for aggressive patrolling . Keiser decided the patrol should cross the river at the <unk> ferry . The 9th Infantry reserve , E Company , reinforced with one section of light machine guns from H Company , was to be the attack force . The 1st Platoon , 2nd Engineer Combat Battalion , was to transport it across the river in assault boats the night of August 31 . Two heavy weapons companies , D and H , were each to furnish one section of heavy machine guns , one section of 81 @-@ mm. mortars , and one section of 75 @-@ mm. recoilless rifles for supporting fires . A platoon of 4 @.@ 2 @-@ inch mortars was also to give support . \\n',\n",
              " \" After dark on August 31 , First Lieutenant Charles I. Caldwell of D Company and First Lieutenant Edward Schmitt of H Company , 9th Infantry , moved their men and weapons to the base of Hill 209 , which was within B Company 's defense sector and overlooked the <unk> ferry crossing of the Naktong River . The raiding force , E Company , was still in its regimental reserve position about 2 miles ( 3 @.@ 2 km ) west of Yongsan , getting ready with the engineer platoon to move to the crossing site . Colonel Hill went forward in the evening with the 4 @.@ 2 @-@ inch mortar platoon to its position at the base of Hill 209 where the mortarmen prepared to set up their weapons . \\n\",\n",
              " \" By 21 : 00 , the closest front line unit was B Company on top of Hill 209 , 1 mile ( 1 @.@ 6 km ) north of the river road which curved around the hill 's southern base . The regimental chaplain , Captain Lewis B. Sheen , had gone forward in the afternoon to B Company to hold services . On top of Hill 209 , Chaplain Sheen and men in B Company after dark heard splashing in the water below them . They soon discovered a long line of North Korean soldiers wading the river . \\n\",\n",
              " ' The first North Korean crossing at the <unk> ferry caught the Heavy Mortar Platoon unprepared in the act of setting up its weapons . It also caught most of the D and H Company men at the base of Hill 209 , .5 miles ( 0 @.@ 80 km ) from the crossing site . The North Koreans killed or captured many of the troops there . Hill was there , but escaped to the rear just before midnight , together with several others , when the division canceled Operation Manchu because of the attacks . The first heavy weapons carrying party was on its way up the hill when the North Korean attack engulfed the men below . It hurried on to the top where the advance group waited and there all hastily dug in on a small perimeter . This group was not attacked during the night . \\n',\n",
              " ' From 21 : 30 until shortly after midnight the NK 9th Division crossed the Naktong at a number of places and climbed the hills quietly toward the 9th Infantry river line positions . Then , when the artillery barrage preparation lifted , the North Korean infantry were in position to launch their assaults . These began in the northern part of the regimental sector and quickly spread southward . At each crossing site the North Koreans would overwhelm local UN defenders before building pontoon bridges for their vehicles and armor . \\n',\n",
              " \" At 02 : 00 , B Company was attacked . A truck stopped at the bottom of the hill , a whistle sounded , then came a shouted order , and North Korean soldiers started climbing the slope . The hills on both sides of B Company were already under attack as was also Hill 311 , a rugged terrain feature a 1 @.@ 5 miles ( 2 @.@ 4 km ) from the river and the North Koreans ' principal immediate objective . The North Koreans apparently were not aware of the Task Force Manchu group lower down on the hill and it was not attacked during the night . But higher up on Hill 209 the North Koreans drove B Company from its position , inflicting very heavy casualties on it . Sheen led one group of soldiers back to friendly lines on 4 September . \\n\",\n",
              " \" At 03 : 00 , 1 September , the 9th Infantry Regiment ordered its only reserve , E Company to move west along the Yongsan @-@ Naktong River road and take a blocking position at the pass between Cloverleaf Hill and Obong @-@ ni Ridge , 3 miles ( 4 @.@ 8 km ) from the river and 6 miles ( 9 @.@ 7 km ) from Yongsan . This was the critical terrain where so much heavy fighting had taken place in the first battle of the Naktong Bulge . Fighting began at the pass at 02 : 30 when an American medium tank of A Company , 72nd Tank Battalion , knocked out a T @-@ 34 at Tugok , also called <unk> . E Company never reached its blocking position . A strong North Korean force surprised and delivered heavy automatic fire on it at 03 : 30 from positions astride the road east of the pass . The company suffered heavy casualties , including the company commander and Keiser 's aide who had accompanied the force . With the critical parts of Cloverleaf Hill and Obong @-@ ni Ridge , the best defensive terrain between Yongsan and the river , the North Koreans controlled the high ground . The US 2nd Infantry Division now had to base its defense of Yongsan on relatively poor defensive terrain , the low hills at the western edge of the town . \\n\",\n",
              " '',\n",
              " ' = = = US 23rd Infantry attacked = = = \\n',\n",
              " '',\n",
              " ' North of the 9th Infantry sector of the 2nd Infantry Division front along the Naktong , the US 23rd Infantry Regiment on August 29 had just relieved the 3rd Battalion of the US 38th Infantry Regiment , which in turn had only a few days before relieved the US 21st Infantry Regiment of the US 24th Infantry Division . On August 1 , the 23rd Regiment was in a new sector of which it had only a limited knowledge . It took over a 16 @,@ 000 yards ( 15 @,@ 000 m ) Naktong River front without its 3rd Battalion which had been attached to the US 1st Cavalry Division to the north . Colonel Paul L. Freeman , the regimental commander , deployed the 1st Battalion on the high ground along the river with the three companies abreast . The 1st Battalion , under US Lieutenant Colonel Claire E. <unk> , Jr . , <unk> the hills with platoons and squads . He placed the 2nd Battalion in a reserve position 8 miles ( 13 km ) behind the 1st Battalion and in a position where it commanded the road net in the regimental sector . On August <unk> the 2nd Division moved E Company south to a reserve position in the 9th Infantry sector . \\n',\n",
              " \" Two roads ran through the regimental sector from the Naktong River to Changnyong . The main road bent south along the east bank of the river to Pugong @-@ ni and then turned northeast to Changnyong . A northern secondary road curved around marshland and lakes , the largest of which was Lake U @-@ p 'o , to Changnyong . In effect , the 1st Battalion of the 23rd Regiment guarded these two approach routes to Changnyong . \\n\",\n",
              " ' The 42 men of the 2nd Platoon , B Company , 23rd Infantry held outpost positions on seven hills covering a 2 @,@ 600 yards ( 2 @,@ 400 m ) front along the east bank of the Naktong north of Pugong @-@ ni . Across the river in the rice paddies they could see , in the afternoon of August 31 , two large groups of North Korean soldiers . Occasionally artillery fire dispersed them . Just before dark , the platoon saw a column of North Koreans come out of the hills and proceed toward the river . They immediately reported to the battalion command post . The artillery forward observer , who estimated the column at 2 @,@ 000 people , thought they were refugees . Freeman immediately ordered the artillery to fire on the column , reducing its number . However the North Koreans continued their advance . \\n',\n",
              " ' At 21 : 00 the first shells of what proved to be a two @-@ hour North Korean artillery and mortar preparation against the American river positions of 2nd Platoon . As the barrage rolled on , North Korean infantry crossed the river and climbed the hills in the darkness under cover of its fire . At 23 : 00 the barrage lifted and the North Koreans attacked 2nd Platoon , forcing it from the hill after a short fight . Similar assaults took place elsewhere along the battalion outpost line . \\n',\n",
              " \" On the regimental left along the main Pugong @-@ ni @-@ Changnyong road North Korean soldiers completely overran C Company by 0300 September 1 . Only seven men of C Company could be accounted for , and three days later , after all the stragglers and those cut off behind North Korean lines had come in , there were only 20 men in the company . As the North Korean attack developed during the night , 1st Battalion succeeded in withdrawing a large part of its force , less C Company , just north of Lake U @-@ p 'o and the hills there covering the northern road into Changnyong , 3 miles ( 4 @.@ 8 km ) east of the river and 5 miles ( 8 @.@ 0 km ) west of the town . B Company lost heavily in this action . \\n\",\n",
              " \" When word of the disaster that had overtaken 1st Battalion reached regimental headquarters , Freeman obtained the release of G and F Companies from 2nd Division reserve and sent the former to help 1st Battalion and the latter on the southern road toward Pugong @-@ ni and C Company . Major Lloyd K. Jenson , executive officer of the 2nd Battalion , accompanied F Company down the Pugong @-@ ni road . This force was unable to reach C Company , but Jenson collected stragglers from it and seized high ground astride this main approach to Changnyong near <unk> 'o @-@ ri above Lake <unk> , and went into a defensive position there . The US 2nd Division released E Company to the regiment and the next day it joined F Company to build up what became the main defensive position of the 23d Regiment in front of Changnyong . North Korean troops during the night passed around the right flank of 1st Battalion 's northern blocking position and reached the road three miles behind him near the division artillery positions . The 23rd Infantry Headquarters and Service Companies and other miscellaneous regimental units finally stopped this penetration near the regimental command post 5 miles ( 8 @.@ 0 km ) northwest of Changnyong . \\n\",\n",
              " '',\n",
              " ' = = = US 2nd Division split = = = \\n',\n",
              " '',\n",
              " \" Before the morning of 1 September had passed , reports coming in to US 2nd Division headquarters made it clear that North Koreans had penetrated to the north @-@ south Changnyong @-@ Yongsan road and cut the division in two ; the 38th and 23d Infantry Regiments with the bulk of the division artillery in the north were separated from the division headquarters and the 9th Infantry Regiment in the south . Keiser decided that this situation made it advisable to control and direct the divided division as two special forces . Accordingly , he placed the division artillery commander , Brigadier General Loyal M. Haynes , in command of the northern group . Haynes ' command post was 7 miles ( 11 km ) north of Changnyong . Task Force Haynes became operational at 10 : 20 , September 1 . Southward , in the Yongsan area , Keiser placed Brigadier General Joseph S. Bradley , Assistant Division Commander , in charge of the 9th Infantry Regiment , the 2nd Engineer Combat Battalion , most of the 72nd Tank Battalion , and other miscellaneous units of the division . This southern grouping was known as Task Force Bradley . \\n\",\n",
              " \" All three regiments of the NK 2nd Division @-@ the 4th , 17th , and 6th , in line from north to south @-@ crossed during the night to the east side of the Naktong River into the 23rd Regiment sector . The NK 2nd Division , concentrated in the Sinban @-@ ni area west of the river , had , in effect , attacked straight east across the river and was trying to seize the two avenues of advance into Changnyong above and below Lake U @-@ p 'o . On August 31 , 1950 , Lake U @-@ p 'o was a large body of water although in most places very shallow . \\n\",\n",
              " \" At dawn September 1 , Keiser at 2nd Division headquarters in <unk> @-@ ni , 7 miles ( 11 km ) east of Yongsan on the Miryang road , felt his division was in the midst of a crisis . The massive North Korean attack had made deep penetrations everywhere in the division sector except in the north in the zone of the 38th Infantry . The NK 9th Division had effected major crossings of the Naktong at two principal points against the US 9th Infantry ; the NK 2nd Division in the meantime had made three major crossings against the US 23rd Infantry ; and the NK 10th Division had begun crossing more troops in the Hill 409 area near Hyongp 'ung in the US 38th Infantry sector . At 08 : 10 Keiser telephoned Eighth Army headquarters and reported the heaviest and deepest North Korean penetrations were in the 9th Infantry sector . \\n\",\n",
              " ' Liaison planes rose from the division strip every hour to observe the North Korean progress and to locate US 2nd Infantry Division front @-@ line units . Communication from division and regimental headquarters to nearly all the forward units was broken . Beginning at 09 : 30 and continuing throughout the rest of the day , the light aviation section of the division artillery located front @-@ line units cut off by the North Koreans , and made fourteen airdrops of ammunition , food , water , and medical supplies . As information slowly built up at division headquarters it became apparent that the North Koreans had punched a hole 6 miles ( 9 @.@ 7 km ) wide and 8 miles ( 13 km ) deep in the middle of the division line and made less severe penetrations elsewhere . The front @-@ line battalions of the US 9th and 23rd Regiments were in various states of disorganization and some companies had virtually disappeared . Keiser hoped he could organize a defense along the Changnyong @-@ Yongsan road east of the Naktong River , and prevent North Korean access to the passes eastward leading to Miryang and Ch <unk> . \\n',\n",
              " '',\n",
              " ' = = = Reinforcements = = = \\n',\n",
              " '',\n",
              " \" At 09 : 00 Walker requested the US Air Force to make a maximum effort along the Naktong River from <unk> @-@ dong , just above the US 2nd Division boundary , southward and to a depth of 15 miles ( 24 km ) west of the river . He wanted the Air Force to isolate the battlefield and prevent further North Korean reinforcements and supplies from moving across the river in support of the North Korean spearhead units . The Far East Command requested the US Navy to join in the air effort , and the US Seventh Fleet turned back from its strikes in the Inch 'on @-@ Seoul area and sped southward at full steam toward the southern battle front . Walker came to the US 2nd Division front at 12 : 00 and ordered the division to hold at all costs . He had already ordered ground reinforcements to the Yongsan area . \\n\",\n",
              " ' During the morning of 1 September , Walker weighed the news coming in from his southern front , wavering in a decision as to which part of the front most needed his Pusan Perimeter reserves . Since midnight the NK I Corps had broken his Pusan Perimeter in two places @-@ the NK 2nd and 9th Divisions in the US 2nd Division sector , and the NK 7th Division and NK 6th Division in the US 25th Division sector , below the junction of the Nam and Naktong Rivers . In the US 2nd Division sector North Korean troops were at the edge of Yongsan , the gateway to the corridor leading 12 miles ( 19 km ) eastward to Miryang and the main Pusan @-@ Mukden railroad and highway . \\n',\n",
              " \" Eighth Army had in reserve three understrength infantry regiments and the 2 @-@ battalion British 27th Infantry Brigade which was not yet completely equipped and ready to be placed in line : The 1st Provisional Marine Brigade at Changwon , 6 miles ( 9 @.@ 7 km ) northeast of Masan , preparing for movement to the port of Pusan ; the US 27th Infantry Regiment of the 25th Division which had arrived at Masan only the night before at 20 : 30 to relieve the 5th Regimental Combat Team , which was then to join the 24th Division in the Taegu area ; and the US 19th Infantry Regiment of the US 24th Infantry Division , then with that division 's headquarters at Kyongsan southeast of Taegu . Walker alerted both the 24th Division headquarters , together with its 19th Regiment , and the 1st Provisional Marine Brigade to move at a moment 's notice ; the 24th Division either to the 2nd or 25th Division fronts , and the marines to an unannounced destination . \\n\",\n",
              " ' As the morning passed , General Walker decided that the situation was most critical in the Naktong Bulge area of the US 2nd Division sector . There the North Koreans threatened Miryang and with it the entire Eighth Army position . At 11 : 00 Walker ordered US Marine Corps Brigadier General Edward A. Craig , commanding the 1st Provisional Marine Brigade , to prepare the marines to move at once . The marines made ready to depart for the Naktong Bulge at 13 : 30 . \\n',\n",
              " '',\n",
              " ' = = = North Korean advance = = = \\n',\n",
              " '',\n",
              " ' The situation on the front was chaotic during the day September 1 . The North Koreans at one place had crossed at the <unk> ferry , captured Agok , and scattered A Company , 9th Infantry at its positions from Agok northward . A Company withdrew to positions on the ridge line back of the river . From there at daylight the men could see North Korean soldiers on many of the ridges surrounding them , most of them moving east . After several hours , 2nd Platoon of A Company sent a patrol down the hill to Agok to obtain supplies abandoned there during the night , returning later with much needed water , rations , and ammunition . \\n',\n",
              " ' Later in the morning North Korean barges crossed the Naktong below A Company . The company sent a squad with a light machine gun to the southern tip of the ridge overlooking Agok to take these troops under fire . When the squad reached the tip of the ridge they saw that a North Korean force occupied houses at its base . The company hit these houses with artillery . The North Koreans broke from the houses , running for the river . At this the light machine gun at the tip of the ridge took them under fire , as did another across the Naktong to the south in the US 25th Infantry Division sector . Proximity fuze artillery fire decimated this group . Combined fire from all weapons inflicted an estimated 300 casualties on this North Korean force . In the afternoon , US aircraft dropped food and ammunition to the company ; only part of it was recovered . The 1st Battalion ordered A Company to withdraw the company that night . \\n',\n",
              " ' During the withdraw , however , A Company ran into a sizable North Korean force and had scattered in the ensuing fight . Most of the company , including its commander were killed at close range . In this desperate action , Private First Class Luther H. Story , a weapons squad leader , fought so tenaciously that he was awarded the Medal of Honor . Badly wounded , Story refused to be a burden to those who might escape , and when last seen was still engaging North Korean at close range . Of those in the company , approximately ten men escaped to friendly lines . The next morning , under heavy fog , the group made its way by compass toward Yongsan . From a hill at 12 : 00 , after the fog had lifted , the men looked down on the Battle of Yongsan which was then in progress . That afternoon 20 survivors of the company merged into the lines of the 72nd Tank Battalion near Yongsan . Stragglers from this position continued to stream in the next few days as well . \\n',\n",
              " '',\n",
              " ' = = = The end of Task Force Manchu = = = \\n',\n",
              " '',\n",
              " \" In the meantime , Task Force Manchu was still holding its position along the Naktong River , about 5 miles ( 8 @.@ 0 km ) north of where A Company had been destroyed on the southern end of the line . The perimeter position taken by the men of D and H Companies , 9th Infantry , who had started up the hill before the North Koreans struck , was on a southern knob of Hill 209 , 0 @.@ 5 miles ( 0 @.@ 80 km ) south of B Company 's higher position . In addition to the D and H Company men , there were a few from the Heavy Mortar Platoon and one or two from B Company . Altogether , 60 to 70 men were in the group . The group had an SCR @-@ 300 radio , a heavy machine gun , two light machine gun , a M1918 Browning Automatic Rifle , about 20 M1 Garand rifles , and about 40 carbines or pistols . Schmitt assumed command of the group . \\n\",\n",
              " ' During the night Schmitt established radio communication with the 1st Battalion , 9th infantry . When daylight came Schmitt and his group saw that they were surrounded by North Koreans . One force occupied the higher knob half a mile above them , formerly held by B Company . Below them , North Koreans continued crossing the river and moving supplies forward to their combat units , some of them already several miles eastward . The North Koreans quickly discovered Task Force Manchu group . They first attacked it at 14 : 00 that afternoon , and were repulsed . That night an estimated company attacked three times , pressing the fight to close quarters , but failed each time to penetrate the tight US perimeter . Daylight of the second day disclosed many North Korean dead on the steep slopes outside the perimeter . \\n',\n",
              " ' In the afternoon of September 2 Schmitt radioed 1st Battalion for an airdrop of supplies . A US plane attempted the drop , but the perimeter was so small and the slopes so steep that virtually all the supplies went into North Korean hands . The men in the perimeter did , however , recover from a drop made later at 19 : 00 some supplies and ammunition . Private First Class Joseph R. Ouellette , of H Company , left the perimeter to gather weapons , ammunition , and grenades from the North Korean dead . On several occasions he was attacked , and on one such occasion a North Korean soldier suddenly attacked Ouellette , who killed the North Korean in hand @-@ to @-@ hand combat . \\n',\n",
              " ' That same afternoon , the North Koreans sent an American prisoner up the hill to Schmitt with the message , \" You have one hour to surrender or be blown to pieces . \" Failing in frontal infantry attack to reduce the little defending force , the North Koreans now meant to take it under mortar fire . Only 45 minutes later North Korean antitank fire came in on the knob and two machine guns from positions northward and higher on the slope of Hill 209 swept the perimeter . Soon , mortars emplaced on a neighboring high finger ridge eastward registered on Schmitt \\'s perimeter and continued firing until dark . The machine gun fire forced every man to stay in his foxhole . The lifting of the mortar fire after dark was the signal for renewed North Korean infantry attacks , all of which were repulsed . But the number of killed and wounded within the perimeter was growing , and supplies were diminishing . There were no medical supplies except those carried by one aid man . \\n',\n",
              " ' The third day , September 3 , the situation worsened . The weather was hot and ammunition , food and supplies were nearly completely exhausted . Since the previous afternoon , North Korean mortar barrages had alternated with infantry assaults against the perimeter . Survivors later estimated there were about twenty separate infantry attacks repulsed . Two North Korean machine guns still swept the perimeter whenever anyone showed himself . Dead and dying US troops were in almost every foxhole . Mortar fragments destroyed the radio and this ended all communication with other US units . Artillery fire and air strikes requested by Schmitt never came . Some North Koreans worked their way close to the perimeter and threw grenades into it . Six times Ouellette leaped from his foxhole to escape grenades thrown into it . In this close action Ouellette was killed . Most of the foxholes of the perimeter received one or more direct mortar hits in the course of the continuing mortar fire . One of these killed Schmitt on September 3 . The command passed now to First Lieutenant Raymond J. <unk> of D Company , senior surviving officer . \\n',\n",
              " ' At daylight on the morning of 4 September only two officers and approximately half the men who had assembled on the hill , were alive . As the day passed , with ammunition down to about one clip per man and only a few grenades left and no help in sight , <unk> decided to abandon the position that night . When it got dark the survivors would split into small groups and try to get back to friendly lines . That evening after dark the North Koreans launched another weak attack against the position . At 22 : 00 , <unk> and Caldwell and 27 enlisted men slipped off the hill in groups of four . Master Sergeant Travis E. Watkins , still alive in his paralyzed condition , refused efforts of evacuation , saying that he did not want to be a burden to those who had a chance to get away . He asked only that his carbine be loaded and placed on his chest with the muzzle under his chin . Like <unk> , he would also win the Medal of Honor for his actions . Of the 29 men who came off the hill the night of September 4 , 22 escaped to friendly lines , many of them following the Naktong downstream , hiding by day and traveling by night , until they reached the lines of the US 25th Infantry Division . \\n',\n",
              " ' Members of Task Force Manchu who escaped from Hill 209 brought back considerable intelligence information of North Korean activity in the vicinity of the <unk> ferry crossing site . At the ferry site the North Koreans had put in an underwater bridge . A short distance downstream , each night they placed a pontoon bridge across the river and took it up before dawn the next morning . Carrying parties of 50 civilians guarded by four North Korean soldiers crossed the river continuously at night , an estimated total of 800 @-@ 1 @,@ 000 carriers being used at this crossing site . \\n',\n",
              " '',\n",
              " ' = = = <unk> = = = \\n',\n",
              " '',\n",
              " ' North of the US 9th Infantry and the battles in the Naktong Bulge and around Yongsan , the US 23d Infantry Regiment after daylight of September 1 was in a very precarious position . Its 1st Battalion had been driven from the river positions and isolated 3 miles ( 4 @.@ 8 km ) westward . Approximately 400 North Koreans now overran the regimental command post , compelling Freeman to withdraw it about 600 yards ( 550 m ) . There , 5 miles ( 8 @.@ 0 km ) northwest of Changnyong , the US 23rd Infantry Headquarters and Headquarters Company , miscellaneous regimental units , and regimental staff officers checked the North Koreans in a 3 @-@ hour fight . \\n',\n",
              " \" The North Koreans advanced to Changnyong itself during the afternoon of September 2 , and ROK National Police withdrew from the town . North Koreans were in Changnyong that evening . With his communications broken southward to the 2nd Infantry Division headquarters and the 9th Infantry , Haynes during the day decided to send a tank patrol down the Yongsan road in an effort to re @-@ establish communication . C Company , 72nd Tank Battalion , led its tanks southward . They had to fight their way down the road through several roadblocks . Of the three tanks that started , only the lead tank got through to Yongsan . There , it delivered an overlay of Task Force Haynes ' positions to Bradley . \\n\",\n",
              " ' Still farther northward in the zone of the US 38th Infantry the North Koreans were also active . After the North Korean breakthrough during the night of August 31 , Keiser had ordered the 2nd Battalion , 38th Infantry , to move south and help the 23rd Infantry establish a defensive position west of Changnyong . In attempting to do this , the battalion found North Korean troops already on the ridges along the road . They had penetrated to Hill 284 overlooking the 38th Infantry command post . This hill and Hill 209 dominated the rear areas of the regiment . At 06 : 00 September 3 , 300 North Koreans launched an attack from Hill 284 against the 38th Regiment command post . The regimental commander organized a defensive perimeter and requested a bombing strike which was denied him because the enemy target and his defense perimeter were too close to each other . But the Air Force did deliver rocket and strafing strikes . \\n',\n",
              " \" This fight continued until September 5 . On that day F Company captured Hill 284 killing 150 North Koreans . From the crest he and his men watched as many more North Koreans ran into a village below them . Directed artillery fire destroyed the village . Among the abandoned North Korean materiel on the hill , Schauer 's men found twenty @-@ five American BARs and submachine guns , a large American radio , thirty boxes of unopened American fragmentation and concussion grenades , and some American rations . \\n\",\n",
              " '',\n",
              " ' = = = 1 @-@ 23rd Infantry isolated = = = \\n',\n",
              " '',\n",
              " \" Meanwhile , during these actions in its rear , the 1st Battalion , 23rd Infantry , was cut off 3 miles ( 4 @.@ 8 km ) west of the nearest friendly units . On September 1 the regiment ordered it to withdraw to the Changnyong area . At 14 : 00 a tank @-@ infantry patrol was sent down the road , but it reported that an estimated North Korean battalion held the mountain pass just eastward of the battalion 's defense perimeter . Upon receiving this report the battalion commander requested permission by radio to remain in his present position and try to obstruct the movement of North Korean reinforcements and supplies . That evening Freeman approved this request , and 1st Battalion spent three days in the isolated positions . During this time C @-@ 47 Skytrain planes supplied the battalion by airdrops . \\n\",\n",
              " ' On the morning of September 1 , 3rd Battalion , 38th Infantry moved in an attack westward from the 23rd Regiment command post near Mosan @-@ ni to open the road to the 1st Battalion . On the second day of the fighting at the pass , the relief force broke through the roadblock with the help of air strikes and artillery and tank fire . The advanced elements of the battalion joined 1st Battalion at 17 : 00 September 2 . That evening , North Koreans strongly attacked the 3rd Battalion , 38th Infantry , on Hill 209 north of the road and opposite 1st Battalion , driving one company from its position . \\n',\n",
              " \" On September 4 , Haynes changed the boundary between the 38th and 23rd Infantry Regiments , giving the northern part of the 23rd 's sector to the 38th Infantry , thus releasing 1st Battalion for movement southward to help the 2nd Battalion defend the southern approach to Changnyong . The 1st Battalion , 23rd Infantry , about 1 @,@ 100 men strong when the attack began , was now down to a strength of approximately 600 men . The 23rd Infantry now made plans to concentrate all its troops on the position held by its 2nd Battalion on the Pugong @-@ ni @-@ Changnyong road . The 1st Battalion moved there and took a place on the left flank of the 2nd Battalion . At the same time the regimental command post moved to the rear of this position . In this regimental perimeter , the 23rd Infantry fought a series of hard battles . Simultaneously it had to send combat patrols to its rear to clear infiltrating North Koreans from Changnyong and from its supply road . \\n\",\n",
              " '',\n",
              " ' = = = Battle of Yongsan = = = \\n',\n",
              " '',\n",
              " \" On the morning of September 1 the 1st and 2nd Regiments of the NK 9th Division , in their first offensive of the war , stood only a few miles short of Yongsan after a successful river crossing and penetration of the American line . The 3rd Regiment had been left at Inch 'on , but division commander Major General Pak Kyo Sam felt the chances of capturing Yongsan were strong . \\n\",\n",
              " ' On the morning of September 1 , with only the shattered remnants of E Company at hand , the US 9th Infantry Regiment , US 2nd Infantry Division had virtually no troops to defend Yongsan . Keiser in this emergency attached the 2nd Engineer Combat Battalion to the regiment . The US 72nd Tank Battalion and the 2nd Division Reconnaissance Company also were assigned positions close to Yongsan . The regimental commander planned to place the engineers on the chain of low hills that arched around Yongsan on the northwest . \\n',\n",
              " ' A Company , 2nd Engineer Combat Battalion , moved to the south side of the Yongsan @-@ Naktong River road ; D Company of the 2nd Engineer Battalion was on the north side of the road . Approximately 2 miles ( 3 @.@ 2 km ) west of Yongsan an estimated 300 North Korean troops engaged A Company in a fire fight . M19 Gun Motor Carriages of the 82nd AAA Battalion supported the engineers in this action , which lasted several hours . Meanwhile , with the approval of General Bradley , D Company moved to the hill immediately south of and overlooking Yongsan . A platoon of infantry went into position behind it . A Company was now ordered to fall back to the southeast edge of Yongsan on the left flank of D Company . There , A Company went into position along the road ; on its left was C Company of the Engineer battalion , and beyond C Company was the 2nd Division Reconnaissance Company . The hill occupied by D Company was in reality the western tip of a large mountain mass that lay southeast of the town . The road to Miryang came south out of Yongsan , bent around the western tip of this mountain , and then ran eastward along its southern base . In its position , D Company not only commanded the town but also its exit , the road to Miryang . \\n',\n",
              " \" North Koreans had also approached Yongsan from the south . The US 2nd Division Reconnaissance Company and tanks of the 72nd Tank Battalion opposed them in a sharp fight . In this action , Sergeant First Class Charles W. Turner of the Reconnaissance Company particularly distinguished himself . He mounted a tank , operated its exposed turret machine gun , and directed tank fire which reportedly destroyed seven North Korean machine guns . Turner and this tank came under heavy North Korean fire which shot away the tank 's periscope and antennae and scored more than 50 hits on it . Turner , although wounded , remained on the tank until he was killed . That night North Korean soldiers crossed the low ground around Yongsan and entered the town from the south . \\n\",\n",
              " ' At 09 : 35 September 2 , while the North Koreans were attempting to destroy the engineer troops at the southern edge of Yongsan and clear the road to Miryang , Walker spoke by telephone with Major General Doyle O. Hickey , Deputy Chief of Staff , Far East Command in Tokyo . He described the situation around the Perimeter and said the most serious threat was along the boundary between the US 2nd and US 25th Infantry Divisions . He described the location of his reserve forces and his plans for using them . He said he had started the 1st Provisional Marine Brigade toward Yongsan but had not yet released them for commitment there and he wanted to be sure that General of the Army Douglas MacArthur approved his use of them , since he knew that this would interfere with other plans of the Far East Command . Walker said he did not think he could restore the 2nd Division lines without using them . Hickey replied that MacArthur had the day before approved the use of the US Marines if and when Walker considered it necessary . A few hours after this conversation Walker , at 13 : 15 , attached the 1st Provisional Marine Brigade to the US 2nd Division and ordered a co @-@ ordinated attack by all available elements of the division and the marines , with the mission of destroying the North Koreans east of the Naktong River in the 2nd Division sector and of restoring the river line . The marines were to be released from 2nd Division control as soon as this mission was accomplished . \\n',\n",
              " ' A decision was reached that the marines would attack west at 08 : 00 on September 3 astride the Yongsan @-@ Naktong River road ; the 9th Infantry , B Company of the 72nd Tank Battalion , and D Battery of the 82d AAA Battalion would attack northwest above the marines and attempt to re @-@ establish contact with the US 23rd Infantry ; the 2nd Engineer Combat Battalion , remnants of the 1st Battalion , 9th Infantry , and elements of the 72nd Tank Battalion would attack on the left flank , or south , of the marines to reestablish contact with the 25th Division . Eighth Army now ordered the US 24th Infantry Division headquarters and the US 19th Infantry Regiment to move to the Susan @-@ ni area , 8 miles ( 13 km ) south of Miryang and 15 miles ( 24 km ) east of the confluence of the Nam River and the Naktong River . There it was to prepare to enter the battle in either the 2nd or 25th Division zone . \\n',\n",
              " \" The American counteroffensive of September 3 â 5 west of Yongsan , according to prisoner statements , resulted in one of the bloodiest debacles of the war for a North Korean division . Even though remnants of the NK 9th Division , supported by the low strength NK 4th Division , still held Obong @-@ ni Ridge , Cloverleaf Hill , and the intervening ground back to the Naktong on September 6 , the division 's offensive strength had been spent at the end of the American counterattack . The NK 9th and 4th divisions were not able to resume the offensive . \\n\",\n",
              " '',\n",
              " ' = = = NK 2nd Division destroyed = = = \\n',\n",
              " '',\n",
              " \" The NK 2nd Division made a new effort against the 23rd Infantry 's perimeter in the predawn hours of September 8 , in an attempt to break through eastward . This attack , launched at 02 : 30 and heavily supported with artillery , penetrated F Company . It was apparent that unless F Company 's position could be restored the entire regimental front would collapse . When all its officers became casualties , First Lieutenant Ralph R. Robinson , adjutant of the 2nd Battalion , assumed command of the company . With North Koreans rapidly infiltrating his company 's position and gaining its rear , Robinson in the darkness made his way through them 500 yards ( 460 m ) to A Company 's position . There he obtained that company 's reserve platoon and brought it back to F Company . He accomplished the dangerous and difficult task of maneuvering it into the gap in F Company 's lines in darkness and heavy rain . \\n\",\n",
              " ' The attack tapered off with the coming of daylight , but that night it resumed . The North Koreans struck repeatedly at the defense line . This time they continued the fighting into the daylight hours of 9 September . The Air Force then concentrated strong air support over the regimental perimeter to aid the ground troops . Casualties came to the aid stations from the infantry companies in an almost steady stream during the morning . All available men from Headquarters Company and special units were formed into squads and put into the fight at the most critical points . At one time , the regimental reserve was down to six men . When the attack finally ceased shortly after 12 : 00 the 23rd Regiment had an estimated combat efficiency of only 38 percent . \\n',\n",
              " ' This heavy night and day battle cost the NK 2nd Division most of its remaining offensive strength . The medical officer of the NK 17th Regiment , 2nd Division , captured a few days later , said that the division evacuated about 300 men nightly to a hospital in Pugong @-@ ni , and that in the first two weeks of September the 2nd Division lost 1 @,@ 300 killed and 2 @,@ 500 wounded in the fighting west of Changnyong . Even though its offensive strength was largely spent by September 9 , the division continued to harass rear areas around Changnyong with infiltrating groups as large as companies . Patrols daily had to open the main supply road and clear the town . \\n',\n",
              " \" North Korean and US troops remained locked in combat along the Naktong River for several more days . The North Koreans ' offensive capability was largely destroyed , and the US troops resolved to hold their lines barring further attack . \\n\",\n",
              " '',\n",
              " ' = = = North Korean withdrawal = = = \\n',\n",
              " '',\n",
              " ' The UN counterattack at Inchon collapsed the North Korean line and cut off all their main supply and reinforcement routes . On September 19 the UN discovered the North Koreans had abandoned much of the Pusan Perimeter during the night , and the UN units began advancing out of their defensive positions and occupying them . Most of the North Korean units began conducting delaying actions attempting to get as much of their army as possible into North Korea . The North Koreans withdrew from the Masan area first , the night of September 18 â 19 . After the forces there , the remainder of the North Korean armies withdrew rapidly to the North . The US units rapidly pursued them north , passing over the Naktong River positions , which were no longer of strategic importance . \\n',\n",
              " '',\n",
              " ' = = Aftermath = = \\n',\n",
              " '',\n",
              " ' The North Korean 2nd and 9th Divisions were almost completely destroyed in the battles . The 9th Division had numbered 9 @,@ 350 men at the beginning of the offensive on September 1 . The 2nd Division numbered 6 @,@ 000 . Only a few hundred from each division returned to North Korea after the fight . The majority of the North Korean troops had been killed , captured or deserted . All of NK II Corps was in a similar state , and the North Korean army , exhausted at Pusan Perimeter and cut off after Inchon , was on the brink of defeat . \\n',\n",
              " ' By this time , the US 2nd Infantry Division suffered 1 @,@ 120 killed , 2 @,@ 563 wounded , 67 captured and 69 missing during its time at Pusan Perimeter . This included about 180 casualties it suffered during the First Battle of Naktong Bulge the previous month . American forces were continually repulsed but able to prevent the North Koreans from breaking the Pusan Perimeter . The division had numbered 17 @,@ 498 on September 1 , but was in excellent position to attack despite its casualties . The 1st Provisional Marine Brigade suffered 185 killed and around 500 wounded during the Battle of Pusan Perimeter , most of which probably occurred at Yongsan . \\n',\n",
              " \" Of all the North Korean attacks along the Pusan Perimeter , the Second Battle of Naktong Bulge is seen by historians as the most serious threat . It was the battle in which the North Koreans made the most substantial gains , splitting the US 2nd Infantry Division in half and briefly capturing Yongsan , where they were very close to breaching through to the US forces ' supply lines and threatening other divisions ' rear areas . However , once again the fatal weakness of the North Korean Army had cost it victory after an impressive initial success â its communications and supply were not capable of exploiting a breakthrough and of supporting a continuing attack in the face of massive air , armor , and artillery fire that could be concentrated against its troops at critical points . By September 8 , the North Korean attacks in the area had been repulsed . \\n\",\n",
              " '',\n",
              " '',\n",
              " ' = Hed PE = \\n',\n",
              " '',\n",
              " ' Hed PE , also known as ( hed ) Planet Earth and stylized as ( <unk> ) <unk> , is an American rock band from Huntington Beach , California . Formed in 1994 , the band performs a style of music which it refers to as \" G @-@ punk \" , a fusion of punk rock and gangsta rap . \\n',\n",
              " ' After releasing three albums on Jive Records , Hed PE left the label to record independently , eventually signing with Suburban Noize Records in 2006 . Since 2006 , the band has become known for its involvement in the 9 / 11 Truth movement , referencing it in many of their song lyrics and concerts , as well as the concept of the album New World Orphans . To date , they have released nine studio albums , one live album and two compilation albums . \\n',\n",
              " '',\n",
              " ' = = History = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Formation and major @-@ label debut ( 1994 â 1999 ) = = = \\n',\n",
              " '',\n",
              " ' The band was formed by vocalist Jared Gomes , formerly of The Clue , also known as \" <unk> \" ( MC Underdog ) , and guitarist Wes Geer , who became friends amidst the Orange County hardcore punk scene . Gomes and Geer recruited guitarist <unk> , bassist <unk> , drummer B.C. Vaught and DJ Product Â© 1969 . They named the group \" Hed \" , which stands for \" higher education \" . The band built a following with their energetic performances at local venues , and released the self @-@ financed extended play , Church of Realities . Legal issues forced Hed to change their name , adding \" PE \" , which stood for \" Planet Earth \" . \\n',\n",
              " ' Hed PE signed with Jive Records , releasing their self @-@ titled debut album in 1997 . In his review of the album , Allmusic \\'s Steve Huey wrote \" There are some slow and / or unfocused moments [ ... ] but overall , its aggression will probably play well with late- \\' 90s metal and punk fans . \" Due to the label \\'s contractual terms and the disappointing sales of the album , the band found themselves unable to repay the cash advances given to them by Jive . Gomes is quoted as saying \" We had these romantic visions of the music industry , and we thought it would be cool to be a punk band on a rap label . So we fulfilled that dream , but it was also probably the worst thing that could have happened . [ ... ] We \\'ve had offers from Sony and others that we can \\'t take because we owe Jive so much money . \" \\n',\n",
              " '',\n",
              " ' = = = Broke and Blackout ( 2000 â 2004 ) = = = \\n',\n",
              " '',\n",
              " ' On June 6 , 2000 , Hed PE appeared on the tribute album Nativity in Black II , covering Black Sabbath \\'s \" <unk> <unk> \" . Hed PE released their second studio album , Broke on August 22 , 2000 . It peaked at No. 63 on the Billboard 200 , while its first single , \" Bartender \" , peaked at No. 23 on the Billboard Mainstream Rock Tracks chart and at No. 27 on the Modern Rock Tracks chart . Allmusic \\'s Jason D. Taylor wrote : \" Broke may have not found as much success in the competitive mainstream market as some would have liked , and even despite its distinct departure from the group \\'s debut , it is an album that shows more vision than other rap @-@ tinged rock albums to come out in 2000 . \" The most negative response to the album came from critics who viewed its lyrics as misogynistic . \\n',\n",
              " ' On October 27 , 2000 , Gomes was arrested for possession of marijuana while the band was performing in Waterbury , Connecticut . He was released on a US $ 1 @,@ 500 bond . In 2001 , Hed PE performed on the Ozzfest tour alongside bands such as Korn , Static @-@ X , and System of a Down . A music video for \" Killing Time \" , the second single from Broke , was produced in promotion of the film 3000 Miles to Graceland , which featured the song on its soundtrack . \\n',\n",
              " ' Hed PE released their third studio album , Blackout , on March 18 , 2003 . It peaked at No. 33 on the Billboard 200 , while its title track peaked at No. 21 on the Mainstream Rock Tracks chart and at No. 32 on the Modern Rock Tracks chart . Allmusic \\'s Johnny Loftus wrote that \" While it expands on melodic elements that had previously played a supporting role in the band \\'s sound , Blackout also delivers truckloads of crushing guitar and pounding rhythm . And whether or not it is the presence of a top @-@ line producer , ( hed ) pe have figured out a way to imbue their aggressive mix of heavy rock and hip @-@ hop with some serious hooks . \" Guitarist <unk> joined the band in early 2004 . He is the fourth person to fill this position . \\n',\n",
              " '',\n",
              " ' = = = Only in Amerika ( 2004 ) = = = \\n',\n",
              " '',\n",
              " ' Hed PE left Jive Records , releasing their fourth studio album , Only in Amerika , on Koch Records on October 19 , 2004 . It peaked at No. 20 on the Top Independent Albums chart and at No. 186 on the Billboard 200 . In his review of the album , Johnny Loftus wrote \" It wants to be a confrontational megaphone in the ear of conservatives , but <unk> \\'s torrential rhetoric is too messy and blatantly offensive to incite anything but superficial anger , and the music -- though occasionally explosive -- takes a backseat to the ranting . \" \\n',\n",
              " '',\n",
              " ' = = = Suburban Noize Records and New Album Evolution ( 2006 â 2015 ) = = = \\n',\n",
              " '',\n",
              " ' In 2006 , Hed PE signed with Suburban Noize Records , recording their fifth studio album , Back 2 Base X. The album was intended as a return to the basics of rock music , and did not rely as heavily on studio enhancement as previous releases . The album was released on June 6 , 2006 , the same day as The Best of ( <unk> ) Planet Earth , a compilation album produced by Jive Records without the band \\'s authorization or consent . Back 2 Base X peaked at No. 12 on the Independent Albums chart , and at No. 154 on the Billboard 200 . Allmusic \\'s Rob Theakston wrote that \" Back 2 Base X suffers from the same problems as Amerika : it tries to be conceptual in thought Ã  la Tool and vicious in its political commentary Ã  la Fugazi or System of a Down , but somehow falls short by sounding like an angry stoner on a soapbox . It won \\'t win any new fans , but existing fans of ( hed ) pe \\'s work won \\'t be turning their backs away from the band in anger anytime soon , either . \" \\n',\n",
              " ' On June 26 , 2007 , the band released their sixth studio album , Insomnia . It peaked at No. 16 on the Independent Albums chart , and at No. 138 on the Billboard 200 . The album \\'s lead single , \" <unk> \" , became one of the most requested tracks at Sirius Satellite Radio \\'s Hard Attack , while the song \\'s music video was voted one of the Top 10 of 2007 on MTV \\'s Headbangers Ball . Hed PE released their first live album , The D.I.Y. Guys , in 2008 . On January 13 , 2009 , they released their seventh studio album , New World Orphans . It was released in three different versions ; each contains a different set of bonus tracks . In 2009 , drummer Trauma joined the band . He is the sixth person to fill this position . The band \\'s eighth studio album , Truth Rising , was released on October 26 , 2010 to mixed reviews . Hed pe played the \" Local Heroes Tour \" in the fall of 2012 and played with <unk> in San <unk> on Sunday October 7 , 2012 . In an interview , frontman Jared Gomes stated that their album for 2013 titled Ascension would be released within the first half of 2014 . Towards the end of 2013 , DJ Product mysteriously left the band with no explanation and no comment from the other members . On 1 / 1 / 2014 , Frontman <unk> Gomes stated on the band \\'s official Facebook that the new upcoming ( hed ) PE album will be named \" Evolution \" and to be released within the year . \\n',\n",
              " ' On May 13 , 2014 , On the band \\'s official Facebook page , they released the official announcement of when the band \\'s new album Evolution will hit stores . The album is set for release July 22 , 2014 . They also released a teaser of the tone of the new album on their Facebook page and soon after , the track \" One More Body \" . \\n',\n",
              " ' In 2015 , it was confirmed that 12 @-@ year guitarist <unk> <unk> and original bassist Mark Young had left the band . They were replaced by guitarist Greg \" <unk> \" Harrison and bassist Kurt Blankenship , leaving vocalist and founding member Jared Gomes as the group \\'s only remaining original talent . \\n',\n",
              " '',\n",
              " ' = = Style = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Music and lyrics = = = \\n',\n",
              " '',\n",
              " ' Hed PE performs a style of music which they have referred to as \" G @-@ punk \" , a phrase inspired by the term \" G @-@ funk \" , itself a reference to the P @-@ Funk collective . Hed PE \\'s music is a fusion of styles ranging from hip hop , reggae , and ska to hard rock , punk , and heavy metal . Other elements that have been incorporated into this style include blues , funk , jazz and industrial . Jared Gomes \\' vocal style ranges from melodic singing to rapping , screaming , and death growls . The band \\'s lyrics draw from a number of subjects , including the existence of extraterrestrial life , criticism of organized religion , the 9 / 11 Truth movement , cannabis use and sexual intercourse . \\n',\n",
              " \" Gomes , in addition to the 9 / 11 Truth movement , has expressed support for social liberal politicians such as Nancy Pelosi and president Barack Obama . Previously however , Gomes ' 2004 lyrics for Only in Amerika expressed support for nationalism , and called for retaliation against Al Qaeda for the 9 / 11 terrorist attacks . \\n\",\n",
              " '',\n",
              " ' = = = Influences = = = \\n',\n",
              " '',\n",
              " \" The band 's influences include <unk> , Beastie Boys , Black Sabbath , Bob Marley , Led Zeppelin , Nine Inch Nails , Snoop Dogg , Cypress Hill , Notorious B.I.G. and Rage Against the Machine . Hed PE 's second album , Broke , incorporated classic rock and world music influences , while Back 2 Base X was influenced by classic punk bands such as the Sex Pistols and the Clash , Insomnia was influenced by thrash metal bands such as Slayer , and New World Orphans was influenced by Suicidal Tendencies and Minor Threat . Guitarist <unk> has been credited for encouraging a heavier , hardcore punk @-@ influenced musical style . \\n\",\n",
              " '',\n",
              " ' = = Band members = = \\n',\n",
              " '',\n",
              " ' Jared ( Paulo Sergio Gomes ) â lead vocals ( 1994 â current ) \\n',\n",
              " ' Major Trauma ( Jeremiah Stratton ) â drums ( 2008 â current ) \\n',\n",
              " ' <unk> ( Greg Harrison ) â guitar ( 2015 â current ) \\n',\n",
              " ' Kid Bass ( Kurt Blankenship ) â bass ( 2015 â current ) \\n',\n",
              " '',\n",
              " ' = = = Former members = = = \\n',\n",
              " '',\n",
              " ' Ken Sachs ( The Finger ) â keyboard ( 1994 â 1996 ) \\n',\n",
              " ' Chad <unk> ( <unk> ) â guitar ( 1994 â 2002 ) \\n',\n",
              " ' Wesley Geer ( <unk> , Wes Geer ) â guitar ( 1994 â 2003 ) \\n',\n",
              " ' Ben C. Vaught ( B.C. ) â drums ( 1994 â 2003 ) \\n',\n",
              " ' Doug Boyce ( DJ Product Â© 1969 ) â turntables , samples ( 1994 â 2013 ) \\n',\n",
              " ' Mark Young ( <unk> ) â bass ( 1994 â 2015 ) \\n',\n",
              " ' Sonny Mayo â guitar ( 2002 â 2003 ) \\n',\n",
              " ' Jackson <unk> ( <unk> ) â guitar ( 2004 â 2015 ) \\n',\n",
              " ' Christopher <unk> â drums ( 2004 ) \\n',\n",
              " ' Mark \" <unk> \" <unk> â drums ( 2004 â 2006 ) \\n',\n",
              " ' Devin <unk> â drums ( 2006 â 2007 ) \\n',\n",
              " ' Anthony \" Tiny <unk> \" <unk> â drums ( 2007 â 2008 ) \\n',\n",
              " '',\n",
              " ' = = = Timeline = = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = Discography = = \\n',\n",
              " '',\n",
              " ' Studio albums \\n',\n",
              " ' Church of Realities ( 1995 ) \\n',\n",
              " ' Hed PE ( 1997 ) \\n',\n",
              " ' Broke ( 2000 ) \\n',\n",
              " ' Blackout ( 2003 ) \\n',\n",
              " ' Only in Amerika ( 2004 ) \\n',\n",
              " ' Back 2 Base X ( 2006 ) \\n',\n",
              " ' Insomnia ( 2007 ) \\n',\n",
              " ' New World Orphans ( 2009 ) \\n',\n",
              " ' Truth Rising ( 2010 ) \\n',\n",
              " ' Evolution ( 2014 ) \\n',\n",
              " ' Forever ! ( 2016 ) \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Ironclad warship = \\n',\n",
              " '',\n",
              " ' An ironclad is a steam @-@ propelled warship protected by iron or steel armor plates used in the early part of the second half of the 19th century . The ironclad was developed as a result of the vulnerability of wooden warships to explosive or incendiary shells . The first ironclad battleship , Gloire , was launched by the French Navy in November 1859 . The British Admiralty had been considering armored warships since 1856 and prepared a draft design for an armored corvette in 1857 ; in early 1859 the Royal Navy started building two iron @-@ hulled armored frigates , and by 1861 had made the decision to move to an all @-@ armored battle fleet . After the first clashes of ironclads ( both with wooden ships and with one another ) took place in 1862 during the American Civil War , it became clear that the ironclad had replaced the unarmored ship of the line as the most powerful warship afloat . This type of ship would come to be very successful in the American Civil War . \\n',\n",
              " ' Ironclads were designed for several roles , including as high seas battleships , coastal defense ships , and long @-@ range cruisers . The rapid evolution of warship design in the late 19th century transformed the ironclad from a wooden @-@ hulled vessel that carried sails to supplement its steam engines into the steel @-@ built , turreted battleships and cruisers familiar in the 20th century . This change was pushed forward by the development of heavier naval guns ( the ironclads of the 1880s carried some of the heaviest guns ever mounted at sea ) , more sophisticated steam engines , and advances in metallurgy which made steel shipbuilding possible . \\n',\n",
              " ' The quick pace of change meant that many ships were obsolete as soon as they were finished , and that naval tactics were in a state of flux . Many ironclads were built to make use of the ram or the torpedo , which a number of naval designers considered the important weapons of naval combat . There is no clear end to the ironclad period , but towards the end of the 1890s the term ironclad dropped out of use . New ships were increasingly constructed to a standard pattern and designated battleships or armored cruisers . \\n',\n",
              " '',\n",
              " ' = = The ironclad = = \\n',\n",
              " '',\n",
              " ' The ironclad became technically feasible and tactically necessary because of developments in shipbuilding in the first half of the 19th century . According to naval historian J. Richard Hill : \" The ( ironclad ) had three chief characteristics : a metal @-@ skinned hull , steam propulsion and a main armament of guns capable of firing explosive shells . It is only when all three characteristics are present that a fighting ship can properly be called an ironclad . \" Each of these developments was introduced separately in the decade before the first ironclads . \\n',\n",
              " '',\n",
              " ' = = = Steam propulsion = = = \\n',\n",
              " '',\n",
              " ' In the 18th and early 19th centuries fleets had relied on two types of major warship , the ship of the line and the frigate . The first major change to these types was the introduction of steam power for propulsion . While paddle steamer warships had been used from the 1830s onwards , steam propulsion only became suitable for major warships after the adoption of the screw propeller in the 1840s . \\n',\n",
              " ' Steam @-@ powered screw frigates were built in the mid @-@ 1840s , and at the end of the decade the French Navy introduced steam power to its line of battle . The desire for change came from the ambition of Napoleon III to gain greater influence in Europe , which required a challenge to the British at sea . The first purpose @-@ built steam battleship was the 90 @-@ gun NapolÃ©on in 1850 . NapolÃ©on was armed as a conventional ship @-@ of @-@ the @-@ line , but her steam engines could give her a speed of 12 knots ( 22 km / h ) , regardless of the wind conditions : a potentially decisive advantage in a naval engagement . \\n',\n",
              " ' The introduction of the steam ship @-@ of @-@ the @-@ line led to a building competition between France and Britain . Eight sister ships to NapolÃ©on were built in France over a period of ten years , but the United Kingdom soon managed to take the lead in production . Altogether , France built ten new wooden steam battleships and converted 28 from older ships of the line , while the United Kingdom built 18 and converted 41 . \\n',\n",
              " '',\n",
              " ' = = = Explosive shells = = = \\n',\n",
              " '',\n",
              " ' The era of the wooden steam ship @-@ of @-@ the @-@ line was brief , because of new , more powerful naval guns . In the 1820s and 1830s , warships began to mount increasingly heavy guns , replacing 18- and 24 @-@ pounder guns with 32 @-@ pounders on sailing ships @-@ of @-@ the @-@ line and introducing 68 @-@ pounders on steamers . Then , the first shell guns firing explosive shells were introduced following their development by the French GÃ©nÃ©ral Henri @-@ Joseph <unk> , and by the 1840s were part of the standard armament for naval powers including the French Navy , Royal Navy , Imperial Russian Navy and United States Navy . It is often held that the power of explosive shells to smash wooden hulls , as demonstrated by the Russian destruction of an Ottoman squadron at the Battle of Sinop , spelled the end of the wooden @-@ hulled warship . The more practical threat to wooden ships was from conventional cannon firing red @-@ hot shot , which could lodge in the hull of a wooden ship and cause a fire or ammunition explosion . Some navies even experimented with hollow shot filled with molten metal for extra incendiary power . \\n',\n",
              " '',\n",
              " ' = = = Iron armor = = = \\n',\n",
              " '',\n",
              " ' The use of iron instead of wood as the primary material of ships \\' hulls began in the 1830s ; the first \" warship \" with an iron hull was the gunboat Nemesis , built by Laird for the East India Company in 1839 . There followed , also from Laird , the first full @-@ blown warships with metal hulls , the 1842 steam frigates <unk> and Montezuma for the Mexican navy . But a thin iron skin , while not being susceptible to fire or lethal splintering like wood , was not the same thing as providing iron armor calculated to stop enemy gunfire . \\n',\n",
              " ' Following the demonstration of the power of explosive shells against wooden ships at the Battle of Sinop , and fearing that his own ships would be vulnerable to the <unk> guns of Russian fortifications in the Crimean War , Emperor Napoleon III ordered the development of light @-@ draft floating batteries , equipped with heavy guns and protected by heavy armor . Experiments made during the first half of 1854 proved highly satisfactory , and on 17 July 1854 , the French communicated to the British Government that a solution had been found to make gun @-@ proof vessels and that plans would be communicated . After tests in September 1854 , the British Admiralty agreed to build five armoured floating batteries on the French plans , establishing the important Thames and Millwall Iron Works within the docks . \\n',\n",
              " ' The French floating batteries were deployed in 1855 as a supplement to the wooden steam battle fleet in the Crimean War . The role of the battery was to assist unarmored mortar and gunboats bombarding shore fortifications . The French used three of their ironclad batteries ( Lave , <unk> and <unk> ) in 1855 against the defenses at the Battle of Kinburn on the Black Sea , where they were effective against Russian shore defences . They would later be used again during the Italian war in the Adriatic in 1859 . The British floating batteries Glatton and Meteor arrived too late to participate to the action at Kinburn . The British planned to use theirs in the Baltic Sea against the well @-@ fortified naval base at Kronstadt . \\n',\n",
              " ' The batteries have a claim to the title of the first ironclad warships but they were capable of only 4 knots ( 7 km / h ) under their own power : they operated under their own power at the Battle of Kinburn , but had to be towed for long range transit . They were also arguably marginal to the work of the navy . The brief success of the floating ironclad batteries convinced France to begin work on armored warships for their battlefleet . \\n',\n",
              " '',\n",
              " ' = = Early ironclad ships and battles = = \\n',\n",
              " '',\n",
              " ' By the end of the 1850s it was clear that France was unable to match British building of steam warships , and to regain the strategic initiative a dramatic change was required . The result was the first ocean @-@ going ironclad , the Gloire , begun in 1857 and launched in 1859 . \\n',\n",
              " \" Gloire 's wooden hull was modelled on that of a steam ship of the line , reduced to one deck , sheathed in iron plates 4 @.@ 5 inches ( 110 mm ) thick . She was propelled by a steam engine , driving a single screw propeller for a speed of 13 knots ( 24 km / h ) . She was armed with thirty @-@ six 6 @.@ 4 @-@ inch ( 160 mm ) rifled guns . France proceeded to construct 16 ironclad warships , including two more sister ships to Gloire , and the only two @-@ decked broadside ironclads ever built , Magenta and <unk> . \\n\",\n",
              " \" The Royal Navy had not been keen to sacrifice its advantage in steam ships of the line , but was determined that the first British ironclad would outmatch the French ships in every respect , particularly speed . A fast ship would have the advantage of being able to choose a range of engagement which could make her invulnerable to enemy fire . The British specification was more a large , powerful frigate than a ship @-@ of @-@ the @-@ line . The requirement for speed meant a very long vessel , which had to be built from iron . The result was the construction of two Warrior @-@ class ironclads ; HMS Warrior and HMS Black Prince . The ships had a successful design , though there were necessarily compromises between ' sea @-@ keeping ' , strategic range and armour protection ; their weapons were more effective than that of Gloire , and with the largest set of steam engines yet fitted to a ship they could steam at 14 @.@ 3 knots ( 26 @.@ 5 km / h ) . Yet the Gloire and her sisters had full iron @-@ armour protection along the waterline and the battery itself . Warrior and Black Prince ( but also the smaller Defence and Resistance ) were obliged to concentrate their armour in a central ' citadel ' or ' armoured box ' , leaving many main deck guns and the fore and aft sections of the vessel unprotected . The use of iron in the construction of Warrior also came with some drawbacks ; iron hulls required more regular and intensive repairs than wooden hulls , and iron was more susceptible to fouling by marine life . \\n\",\n",
              " ' By 1862 , navies across Europe had adopted ironclads . Britain and France each had sixteen either completed or under construction , though the British vessels were larger . Austria , Italy , Russia , and Spain were also building ironclads . However , the first battles using the new ironclad ships involved neither Britain nor France , and involved ships markedly different from the broadside @-@ firing , masted designs of Gloire and Warrior . The use of ironclads by both sides in the American Civil War , and the clash of the Italian and Austrian fleets at the Battle of Lissa , had an important influence on the development of ironclad design . \\n',\n",
              " '',\n",
              " ' = = = First battles between ironclads : the U.S. Civil War = = = \\n',\n",
              " '',\n",
              " ' The first use of ironclads in action came in the U.S. Civil War . The U.S. Navy at the time the war broke out had no ironclads , its most powerful ships being six steam @-@ powered unarmoured frigates . Since the bulk of the Navy remained loyal to the Union , the Confederacy sought to gain advantage in the naval conflict by acquiring modern armored ships . In May 1861 , the Confederate Congress voted that $ 2 million be appropriated for the purchase of ironclads from overseas , and in July and August 1861 the Confederacy started work on construction and converting wooden ships . \\n',\n",
              " ' On 12 October 1861 , the CSS Manassas became the first ironclad to enter combat , when she fought Union warships on the Mississippi during the Battle of the Head of Passes . She had been converted from a commercial vessel in New Orleans for river and coastal fighting . In February 1862 , the larger CSS Virginia joined the Confederate Navy , having been rebuilt at Norfolk . Constructed on the hull of USS Merrimack , Virginia originally was a conventional warship made of wood , but she was converted into an iron @-@ covered casemate ironclad gunship , when she entered the Confederate navy . By this time , the Union had completed seven ironclad gunboats of the City class , and was about to complete the USS Monitor , an innovative design proposed by the Swedish inventor John Ericsson . The Union was also building a large armored frigate , the USS New Ironsides , and the smaller USS Galena . \\n',\n",
              " \" The first battle between ironclads happened on 9 March 1862 , as the armored Monitor was deployed to protect the Union 's wooden fleet from the ironclad ram Virginia and other Confederate warships . In this engagement , the second day of the Battle of Hampton Roads , the two ironclads repeatedly tried to ram one another while shells bounced off their armor . The battle attracted attention worldwide , making it clear that the wooden warship was now out of date , with the ironclads destroying them easily . \\n\",\n",
              " ' The Civil War saw more ironclads built by both sides , and they played an increasing role in the naval war alongside the unarmored warships , commerce raiders and blockade runners . The Union built a large fleet of fifty monitors modeled on their namesake . The Confederacy built ships designed as smaller versions of the Virginia , many of which saw action , but their attempts to buy ironclads overseas were frustrated as European nations confiscated ships being built for the Confederacy â especially in Russia , the only country to openly support the Union through the war . Only CSS Stonewall was completed , and she arrived in American waters just in time for the end of the war . \\n',\n",
              " \" Through the remainder of the war , ironclads saw action in the Union 's attacks on Confederate ports . Seven Union monitors , including USS Montauk , as well as two other ironclads , the ironclad frigate New Ironsides and a light @-@ draft USS Keokuk , participated in the failed attack on Charleston ; one was sunk . Two small ironclads , CSS Palmetto State and CSS <unk> participated in the defence of the harbor . For the later attack at Mobile Bay , the Union assembled four monitors as well as 11 wooden ships , facing the CSS Tennessee , the Confederacy 's most powerful ironclad and the gunboats CSS Morgan , CSS Gaines , CSS Selma . \\n\",\n",
              " ' On the western front , the Union built a formidable force of river ironclads , beginning with several converted riverboats and then contracting engineer James Eads of St. Louis , Missouri to build the City @-@ class ironclads . These excellent ships were built with twin engines and a central paddle wheel , all protected by an armored casement . They had a shallow draft , allowing them to journey up smaller tributaries , and were very well suited for river operations . Eads also produced monitors for use on the rivers , the first two of which differed from the ocean @-@ going monitors in that they contained a paddle wheel ( the USS Neosho and USS Osage ) . \\n',\n",
              " \" Arguably Eads vessels were some of the better ironclads of the Western Flotilla , but there were a number of other vessels that served valiantly with the fleet . All were of varying design , some more successful than others , and some were similar to standard riverboats but with armored side @-@ mounted paddle wheels . All were armed with various smoothbore and some rifled guns . If nothing else the experience of the American Civil War and its wild variety of competing ironclad designs , some more successful ( or disastrous ) than others , confirmed the emerging trade @-@ off or compromises required in applying the latest technological advances in iron armour manufacture , ship construction and gun design â to name a few â also going on in Europe . There was no such thing as a ' perfect ' ironclad which could be invincible in every possible encounter ; ship duels , standing up to forts , Brown & Blue @-@ water operations . \\n\",\n",
              " ' The Union ironclads played an important role in the Mississippi and tributaries by providing tremendous fire upon Confederate forts , installations and vessels with relative impunity to enemy fire . They were not as heavily armored as the ocean @-@ going monitors of the Union , but they were adequate for their intended use . More Western Flotilla Union ironclads were sunk by torpedoes ( mines ) than by enemy fire , and the most damaging fire for the Union ironclads was from shore installations , not Confederate vessels . \\n',\n",
              " '',\n",
              " ' = = = Lissa : First fleet battle = = = \\n',\n",
              " '',\n",
              " ' The first fleet battle , and the first ocean battle , involving ironclad warships was the Battle of Lissa in 1866 . <unk> between the Austrian and Italian navies , the battle pitted combined fleets of wooden frigates and corvettes and ironclad warships on both sides in the largest naval battle between the battles of Navarino and Tsushima . \\n',\n",
              " ' The Italian fleet consisted of 12 ironclads and a similar number of wooden warships , escorting transports which carried troops intending to land on the Adriatic island of Lissa . Among the Italian ironclads were seven broadside ironclad frigates , four smaller ironclads , and the newly built Affondatore â a double @-@ <unk> ram . Opposing them , the Austrian navy had seven ironclad frigates . \\n',\n",
              " ' The Austrians believed their ships to have less effective guns than their enemy , so decided to engage the Italians at close range and ram them . The Austrian fleet formed into an arrowhead formation with the ironclads in the first line , charging at the Italian ironclad squadron . In the melÃ©e which followed both sides were frustrated by the lack of damage inflicted by guns , and by the difficulty of ramming â nonetheless , the effective ramming attack being made by the Austrian flagship against the Italian attracted great attention in following years . \\n',\n",
              " \" The superior Italian fleet lost its two ironclads , Re d 'Italia and Palestro , while the Austrian unarmoured screw two @-@ decker SMS Kaiser remarkably survived close actions with four Italian ironclads . The battle ensured the popularity of the ram as a weapon in European ironclads for many years , and the victory won by Austria established it as the predominant naval power in the Adriatic . \\n\",\n",
              " ' The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed . In particular , it taught a generation of naval officers the misleading lesson that ramming was the best way to sink enemy ironclads . \\n',\n",
              " '',\n",
              " ' = = Armament and tactics = = \\n',\n",
              " '',\n",
              " ' The adoption of iron armor meant that the traditional naval armament of dozens of light cannon became useless , since their shot would bounce off an armored hull . To penetrate armor , increasingly heavy guns were mounted on ships ; nevertheless , the view that ramming was the only way to sink an ironclad became widespread . The increasing size and weight of guns also meant a movement away from the ships mounting many guns broadside , in the manner of a ship @-@ of @-@ the @-@ line , towards a handful of guns in turrets for all @-@ round fire . \\n',\n",
              " '',\n",
              " ' = = = Ram craze = = = \\n',\n",
              " '',\n",
              " ' From the 1860s to the 1880s many naval designers believed that the development of the ironclad meant that the ram was again the most important weapon in naval warfare . With steam power freeing ships from the wind , and armor making them invulnerable to shellfire , the ram seemed to offer the opportunity to strike a decisive blow . \\n',\n",
              " \" The scant damage inflicted by the guns of Monitor and Virginia at Battle of Hampton Roads and the spectacular but lucky success of the Austrian flagship SMS Erzherzog Ferdinand Max sinking the Italian Re d 'Italia at Lissa gave strength to the ramming craze . From the early 1870s to early 1880s most British naval officers thought that guns were about to be replaced as the main naval armament by the ram . Those who noted the tiny number of ships that had actually been sunk by ramming struggled to be heard . \\n\",\n",
              " ' The revival of ramming had a significant effect on naval tactics . Since the 17th century the predominant tactic of naval warfare had been the line of battle , where a fleet formed a long line to give it the best fire from its broadside guns . This tactic was totally unsuited to ramming , and the ram threw fleet tactics into disarray . The question of how an ironclad fleet should deploy in battle to make best use of the ram was never tested in battle , and if it had been , combat might have shown that rams could only be used against ships which were already stopped dead in the water . \\n',\n",
              " ' The ram finally fell out of favour in the 1880s , as the same effect could be achieved with a torpedo , with less vulnerability to quick @-@ firing guns . \\n',\n",
              " '',\n",
              " ' = = = Development of naval guns = = = \\n',\n",
              " '',\n",
              " ' The armament of ironclads tended to become concentrated in a small number of powerful guns capable of penetrating the armor of enemy ships at range ; calibre and weight of guns increased markedly to achieve greater penetration . Throughout the ironclad era navies also grappled with the complexities of rifled versus smoothbore guns and breech @-@ loading versus muzzle @-@ loading . \\n',\n",
              " ' HMS Warrior carried a mixture of 110 @-@ pounder 7 inch ( 180 mm ) breech @-@ loading rifles and more traditional 68 @-@ pounder smoothbore guns . Warrior highlighted the challenges of picking the right armament ; the breech @-@ loaders she carried , designed by Sir William Armstrong , were intended to be the next generation of heavy armament for the Royal Navy , but were shortly withdrawn from service . \\n',\n",
              " \" <unk> @-@ loading guns seemed to offer important advantages . A breech @-@ loader could be reloaded without moving the gun , a lengthy process particularly if the gun then needed to be re @-@ aimed . The Warrior 's Armstrong guns also had the virtue of being lighter than an equivalent smoothbore and , because of their rifling , more accurate . Nonetheless , the design was rejected because of problems which plagued breech @-@ loaders for decades . \\n\",\n",
              " \" The weakness of the breech @-@ loader was the obvious problem of sealing the breech . All guns are powered by the explosive conversion of gunpowder into gas . This explosion propels the shot or shell out of the front of the gun , but also imposes great stresses on the gun @-@ barrel . If the breech â which experiences some of the greatest forces in the gun â is not entirely secure , then there is a risk that either gas will discharge through the breech or that the breech will break . This in turn reduces the muzzle velocity of the weapon and can also endanger the gun crew . The Warrior 's Armstrong guns suffered from both problems ; the shells were unable to penetrate the 4 @.@ 5 in ( 118 mm ) armor of Gloire , while sometimes the screw which closed the breech flew backwards out of the gun on firing . Similar problems were experienced with the breech @-@ loading guns which became standard in the French and German navies . \\n\",\n",
              " ' These problems influenced the British to equip ships with muzzle @-@ loading weapons of increasing power until the 1880s . After a brief introduction of 100 @-@ pounder or 9 @.@ 5 @-@ inch ( 240 mm ) smoothbore Somerset Gun , which weighed 6 @.@ 5 tons ( 6 @.@ 6 t ) , the Admiralty introduced 7 @-@ inch ( 178 mm ) rifled guns , weighing 7 tons . These were followed by a series of increasingly mammoth weapons â guns weighing 12 , 25 , 25 , 38 and finally 81 tons , with calibre increasing from 8 @-@ inch ( 203 mm ) to 16 @-@ inch ( 406 mm ) . \\n',\n",
              " ' The decision to retain muzzle @-@ loaders until the 1880s has been criticised by historians . However , at least until the late 1870s , the British muzzle @-@ loaders had superior performance in terms of both range and rate of fire than the French and Prussian breech @-@ loaders , which suffered from the same problems as had the first Armstrong guns . \\n',\n",
              " ' From 1875 onwards , the balance between <unk> and muzzle @-@ loading changed . Captain de <unk> invented a method of reliably sealing a breech , adopted by the French in 1873 . Just as compellingly , the growing size of naval guns made muzzle @-@ loading much more complicated . With guns of such size there was no prospect of hauling in the gun for re @-@ loading , or even re @-@ loading by hand , and complicated hydraulic systems were required for re @-@ loading the gun outside the turret without exposing the crew to enemy fire . In 1882 , the 81 @-@ ton , 16 @-@ inch ( 406 mm ) guns of HMS Inflexible fired only once every 11 minutes while bombarding Alexandria during the Urabi Revolt . The 100 @-@ ton , 450 mm ( 17 @.@ 72 inch ) guns of Caio Duilio could each fire a round every 15 minutes . \\n',\n",
              " ' In the Royal Navy , the switch to breech @-@ loaders was finally made in 1879 ; as well as the significant advantages in terms of performance , opinion was swayed by an explosion on board HMS Thunderer caused by a gun being double @-@ loaded , a problem which could only happen with a muzzle @-@ loading gun . \\n',\n",
              " \" The calibre and weight of guns could only increase so far . The larger the gun , the slower it would be to load , the greater the stresses on the ship 's hull , and the less the stability of the ship . The size of the gun peaked in the 1880s , with some of the heaviest calibres of gun ever used at sea . HMS Benbow carried two 16 @.@ 25 @-@ inch ( 413 mm ) breech @-@ loading guns , each weighing 110 tons â no British battleship would ever carry guns as large . The Italian 450 mm ( 17 @.@ 72 inch ) guns would be larger than any gun fitted to a battleship until the 18 @.@ 1 @-@ inch ( 460 mm ) armament of the Japanese Yamato class of World War II . One consideration which became more acute was that even from the original Armstrong models , following the Crimean War , range and hitting power far exceeded simple accuracy , especially at sea where the slightest roll or pitch of the vessel as ' floating weapons @-@ platform ' could negate the advantage of rifling . American ordnance experts accordingly preferred smoothbore monsters whose round shot could at least ' skip ' along the surface of the water . Actual effective combat ranges , they had learned during the Civil War , were comparable to those in the Age of Sail â though a vessel could now be smashed to pieces in only a few rounds . Smoke and the general chaos of battle only added to the problem . As a result , many naval engagements in the ' Age of the Ironclad ' were still fought at ranges within easy eyesight of their targets , and well below the maximum reach of their ships ' guns . \\n\",\n",
              " ' Another method of increasing firepower was to vary the projectile fired or the nature of the propellant . Early ironclads used black powder , which expanded rapidly after combustion ; this meant cannons had relatively short barrels , to prevent the barrel itself slowing the shell . The sharpness of the black powder explosion also meant that guns were subjected to extreme stress . One important step was to press the powder into pellets , allowing a slower , more controlled explosion and a longer barrel . A further step forward was the introduction of chemically different brown powder which combusted more slowly again . It also put less stress on the insides of the barrel , allowing guns to last longer and to be manufactured to tighter tolerances . \\n',\n",
              " ' The development of smokeless powder , based on nitroglycerine or nitrocellulose , by the French inventor Paul <unk> in 1884 was a further step allowing smaller charges of propellant with longer barrels . The guns of the pre @-@ Dreadnought battleships of the 1890s tended to be smaller in calibre compared to the ships of the 1880s , most often 12 in ( 305 mm ) , but progressively grew in length of barrel , making use of improved propellants to gain greater muzzle velocity . \\n',\n",
              " ' The nature of the projectiles also changed during the ironclad period . Initially , the best armor @-@ piercing projectile was a solid cast @-@ iron shot . Later , shot of chilled iron , a harder iron alloy , gave better armor @-@ piercing qualities . Eventually the armor @-@ piercing shell was developed . \\n',\n",
              " '',\n",
              " ' = = = Positioning of armament = = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = = Broadside ironclads = = = = \\n',\n",
              " '',\n",
              " ' The first British , French and Russian ironclads , in a logical development of warship design from the long preceding era of wooden ships of the line , carried their weapons in a single line along their sides and so were called \" broadside ironclads . \" Both Gloire and HMS Warrior were examples of this type . Because their armor was so heavy , they could only carry a single row of guns along the main deck on each side rather than a row on each deck . \\n',\n",
              " ' A significant number of broadside ironclads were built in the 1860s , principally in Britain and France , but in smaller numbers by other powers including Italy , Austria , Russia and the United States . The advantages of mounting guns on both broadsides was that the ship could engage more than one adversary at a time , and the rigging did not impede the field of fire . \\n',\n",
              " ' Broadside armament also had disadvantages , which became more serious as ironclad technology developed . Heavier guns to penetrate ever @-@ thicker armor meant that fewer guns could be carried . Furthermore , the adoption of ramming as an important tactic meant the need for ahead and all @-@ round fire . These problems led to broadside designs being superseded by designs that gave greater all @-@ round fire , which included central @-@ battery , turret , and barbette designs . \\n',\n",
              " '',\n",
              " ' = = = = Turrets , batteries and barbettes = = = = \\n',\n",
              " '',\n",
              " \" There were two main design alternatives to the broadside . In one design , the guns were placed in an armoured casemate amidships : this arrangement was called the ' box @-@ battery ' or ' centre @-@ battery ' . In the other , the guns could be placed on a rotating platform to give them a broad field of fire ; when fully armored , this arrangement was called a turret and when partially armored or unarmored , a barbette . \\n\",\n",
              " ' The centre @-@ battery was the simpler and , during the 1860s and 1870s , the more popular method . Concentrating guns amidships meant the ship could be shorter and <unk> than a broadside type . The first full @-@ scale centre @-@ battery ship was HMS Bellerophon of 1865 ; the French laid down centre @-@ battery ironclads in 1865 which were not completed until 1870 . Centre @-@ battery ships often , but not always , had a recessed freeboard enabling some of their guns to fire directly ahead . \\n',\n",
              " \" The turret was first used in naval combat on the USS Monitor in 1862 , with a type of turret designed by the Swedish engineer John Ericsson . A competing turret design was proposed by the British inventor Cowper Coles with a prototype of this installed on HMS Trusty in 1861 for testing and evaluation purposes . Ericsson 's turret turned on a central spindle , and Coles 's turned on a ring of bearings . Turrets offered the maximum arc of fire from the guns , but there were significant problems with their use in the 1860s . The fire arc of a turret would be considerably limited by masts and rigging , so they were unsuited to use on the earlier ocean @-@ going ironclads . The second problem was that turrets were extremely heavy . Ericsson was able to offer the heaviest possible turret ( guns and armour protection ) by deliberately designing a ship with very low freeboard . The weight thus saved from having a high broadside above the waterline was diverted to actual guns and armour . Low freeboard , however , also meant a smaller hull and therefore a smaller capacity for coal storage â and therefore range of the vessel . In many respects , the turreted , low @-@ freeboard Monitor and the broadside sailer HMS Warrior represented two opposite extremes in what an ' Ironclad ' was all about . The most dramatic attempt to compromise these two extremes , or ' squaring this circle ' , was designed by Captain Cowper Phipps Coles : HMS Captain , a dangerously low freeboard turret ship which nevertheless carried a full rig of sail , and which subsequently capsized not long after her launch in 1870 . Her half @-@ sister HMS Monarch was restricted to firing from her turrets only on the port and starboard beams . The third Royal Navy ship to combine turrets and masts was HMS Inflexible of 1876 , which carried two turrets on either side of the centre @-@ line , allowing both to fire fore , aft and broadside . \\n\",\n",
              " \" A lighter alternative to the turret , particularly popular with the French navy , was the barbette . These were fixed armored towers which held a gun on a turntable . The crew was sheltered from direct fire , but vulnerable to plunging fire , for instance from shore emplacements . The barbette was lighter than the turret , needing less machinery and no roof armor â though nevertheless some barbettes were stripped of their armor plate to reduce the top @-@ weight of their ships . The barbette became widely adopted in the 1880s , and with the addition of an armored ' gun @-@ house ' , transformed into the turrets of the pre @-@ Dreadnought battleships . \\n\",\n",
              " '',\n",
              " ' = = = Torpedoes = = = \\n',\n",
              " '',\n",
              " \" The ironclad age saw the development of explosive torpedoes as naval weapons , which helped complicate the design and tactics of ironclad fleets . The first torpedoes were static mines , used extensively in the American Civil War . That conflict also saw the development of the spar torpedo , an explosive charge pushed against the hull of a warship by a small boat . For the first time , a large warship faced a serious threat from a smaller one â and given the relative inefficiency of shellfire against ironclads , the threat from the spar torpedo was taken seriously . The U.S. Navy converted four of its monitors to become turretless armored spar @-@ torpedo vessels while under construction in 1864 â 5 , but these vessels never saw action . Another proposal , the towed or ' Harvey ' torpedo , involved an explosive on a line or outrigger ; either to deter a ship from ramming or to make a torpedo attack by a boat less suicidal . \\n\",\n",
              " \" A more practical and influential weapon was the self @-@ propelled or Whitehead torpedo . Invented in 1868 and deployed in the 1870s , the Whitehead torpedo formed part of the armament of ironclads of the 1880s like HMS Inflexible and the Italian Caio Duilio and Enrico Dandolo . The ironclad 's vulnerability to the torpedo was a key part of the critique of armored warships made by the Jeune Ecole school of naval thought ; it appeared that any ship armored enough to prevent destruction by gunfire would be slow enough to be easily caught by torpedo . In practice , however , the Jeune Ecole was only briefly influential and the torpedo formed part of the confusing mixture of weapons possessed by ironclads . \\n\",\n",
              " '',\n",
              " ' = = Armor and construction = = \\n',\n",
              " '',\n",
              " ' The first ironclads were built on wooden or iron hulls , and protected by wrought iron armor backed by thick wooden planking . Ironclads were still being built with wooden hulls into the 1870s . \\n',\n",
              " '',\n",
              " ' = = = Hulls : iron , wood and steel = = = \\n',\n",
              " '',\n",
              " ' Using iron construction for warships offered advantages for the engineering of the hull . However , unarmored iron had many military disadvantages , and offered technical problems which kept wooden hulls in use for many years , particularly for long @-@ range cruising warships . \\n',\n",
              " ' Iron ships had first been proposed for military use in the 1820s . In the 1830s and 1840s , France , Britain and the United States had all experimented with iron @-@ hulled but unarmored gunboats and frigates . However , the iron @-@ hulled frigate was abandoned by the end of the 1840s , because iron hulls were more vulnerable to solid shot ; iron was more brittle than wood , and iron frames more likely to fall out of shape than wood . \\n',\n",
              " ' The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor . However , iron gave the naval architect many advantages . Iron allowed larger ships and more flexible design , for instance the use of watertight bulkheads on the lower decks . Warrior , built of iron , was longer and faster than the wooden @-@ hulled Gloire . Iron could be produced to order and used immediately , in contrast to the need to give wood a long period of seasoning . And , given the large quantities of wood required to build a steam warship and the falling cost of iron , iron hulls were increasingly cost @-@ effective . The main reason for the French use of wooden hulls for the ironclad fleet built in the 1860s was that the French iron industry could not supply enough , and the main reason why Britain built its handful of wooden @-@ hulled ironclads was to make best use of hulls already started and wood already bought . \\n',\n",
              " ' Wooden hulls continued to be used for long @-@ range and smaller ironclads , because iron nevertheless had a significant disadvantage . Iron hulls suffered quick fouling by marine life , slowing the ships down â manageable for a European battlefleet close to dry docks , but a difficulty for long @-@ range ships . The only solution was to sheath the iron hull first in wood and then in copper , a laborious and expensive process which made wooden construction remain attractive . Iron and wood were to some extent interchangeable : the Japanese KongÅ and Hiei ordered in 1875 were sister @-@ ships , but one was built of iron and the other of composite construction . \\n',\n",
              " ' After 1872 , steel started to be introduced as a material for construction . Compared to iron , steel allows for greater structural strength for a lower weight . The French Navy led the way with the use of steel in its fleet , starting with the Redoutable , laid down in 1873 and launched in 1876 . Redoutable nonetheless had wrought iron armor plate , and part of her exterior hull was iron rather than steel . \\n',\n",
              " ' Even though Britain led the world in steel production , the Royal Navy was slow to adopt steel warships . The Bessemer process for steel manufacture produced too many imperfections for large @-@ scale use on ships . French manufacturers used the Siemens @-@ Martin process to produce adequate steel , but British technology lagged behind . The first all @-@ steel warships built by the Royal Navy were the dispatch vessels Iris and Mercury , laid down in 1875 and 1876 . \\n',\n",
              " '',\n",
              " ' = = = Armor and protection schemes = = = \\n',\n",
              " '',\n",
              " \" Iron @-@ built ships used wood as part of their protection scheme . HMS Warrior was protected by 4 @.@ 5 in ( 114 mm ) of wrought iron backed by 15 in ( 381 mm ) of teak , the strongest shipbuilding wood . The wood played two roles , preventing spalling and also preventing the shock of a hit damaging the structure of the ship . Later , wood and iron were combined in ' sandwich ' armor , for instance in HMS Inflexible . \\n\",\n",
              " \" Steel was also an obvious material for armor . It was tested in the 1860s , but the steel of the time was too brittle and disintegrated when struck by shells . Steel became practical to use when a way was found to fuse steel onto wrought iron plates , giving a form of compound armor . This compound armor was used by the British in ships built from the late 1870s , first for turret armor ( starting with HMS Inflexible ) and then for all armor ( starting with HMS Colossus of 1882 ) . The French and German navies adopted the innovation almost immediately , with licenses being given for the use of the ' Wilson System ' of producing fused armor . \\n\",\n",
              " ' The first ironclads to have all @-@ steel armor were the Italian Caio Duilio and Enrico Dandolo . Though the ships were laid down in 1873 their armor was not purchased from France until 1877 . The French navy decided in 1880 to adopt compound armor for its fleet , but found it limited in supply , so from 1884 the French navy was using steel armor . Britain stuck to compound armor until 1889 . \\n',\n",
              " \" The ultimate ironclad armor was case hardened nickel @-@ steel . In 1890 , the U.S. Navy tested steel armor hardened by the Harvey process and found it superior to compound armor . For several years ' Harvey steel ' was the state of the art , produced in the U.S. , France , Germany , Britain , Austria and Italy . In 1894 , the German firm Krupp developed gas cementing , which further hardened steel armor . The German Kaiser Friedrich III , laid down in 1895 , was the first ship to benefit from the new ' Krupp armor ' and the new armor was quickly adopted ; the Royal Navy using it from HMS Canopus , laid down in 1896 . By 1901 almost all new battleships used Krupp armor , though the U.S. continued to use Harvey armor alongside until the end of the decade . \\n\",\n",
              " ' The equivalent strengths of the different armor plates was as follows : 15 in ( 381 mm ) of wrought iron was equivalent to 12 in ( 305 mm ) of either plain steel or compound iron and steel armor , and to 7 @.@ 75 in ( 197 mm ) of Harvey armor or 5 @.@ 75 in ( 146 mm ) of Krupp armor . \\n',\n",
              " \" Ironclad construction also prefigured the later debate in battleship design between tapering and ' all @-@ or @-@ nothing ' armour design . Warrior was only semi @-@ armoured , and could have been disabled by hits on the bow and stern . As the thickness of armor grew to protect ships from the increasingly heavy guns , the area of the ship which could be fully protected diminished . Inflexible 's armor protection was largely limited to the central citadel amidships , protecting boilers and engines , turrets and magazines , and little else . An ingenious arrangement of cork @-@ filled compartments and watertight bulkheads was intended to keep her stable and afloat in the event of heavy damage to her un @-@ armored sections . \\n\",\n",
              " '',\n",
              " ' = = Propulsion : steam and sail = = \\n',\n",
              " '',\n",
              " ' The first ocean @-@ going ironclads carried masts and sails like their wooden predecessors , and these features were only gradually abandoned . Early steam engines were inefficient ; the wooden steam fleet of the Royal Navy could only carry \" 5 to 9 days coal \" , and the situation was similar with the early ironclads . Warrior also illustrates two design features which aided hybrid propulsion ; she had retractable screws to reduce drag while under sail ( though in practice the steam engine was run at a low throttle ) , and a telescopic funnel which could be folded down to the deck level . \\n',\n",
              " ' Ships designed for coastal warfare , like the floating batteries of the Crimea , or USS Monitor and her sisters , dispensed with masts from the beginning . The British HMS Devastation , started in 1869 , was the first large , ocean @-@ going ironclad to dispense with masts . Her principal role was for combat in the English Channel and other European waters ; and while her coal supplies gave her enough range to cross the Atlantic , she would have had little endurance on the other side of the ocean . The Devastation and the similar ships commissioned by the British and Russian navies in the 1870s were the exception rather than the rule . Most ironclads of the 1870s retained masts , and only the Italian navy , which during that decade was focused on short @-@ range operations in the Adriatic , built consistently mastless ironclads . \\n',\n",
              " ' During the 1860s , steam engines improved with the adoption of double @-@ expansion steam engines , which used 30 â 40 % less coal than earlier models . The Royal Navy decided to switch to the double @-@ expansion engine in 1871 , and by 1875 they were widespread . However , this development alone was not enough to herald the end of the mast . Whether this was due to a conservative desire to retain sails , or was a rational response to the operational and strategic situation , is a matter of debate . A steam @-@ only fleet would require a network of coaling stations worldwide , which would need to be fortified at great expense to stop them falling into enemy hands . Just as significantly , because of unsolved problems with the technology of the boilers which provided steam for the engines , the performance of double @-@ expansion engines was rarely as good in practice as it was in theory . \\n',\n",
              " \" During the 1870s the distinction grew between ' first @-@ class ironclads ' or ' battleships ' on the one hand , and ' cruising ironclads ' designed for long @-@ range work on the other . The demands on first @-@ class ironclads for very heavy armor and armament meant increasing displacement , which reduced speed under sail ; and the fashion for turrets and barbettes made a sailing rig increasingly inconvenient . HMS Inflexible , launched in 1876 but not commissioned until 1881 , was the last British battleship to carry masts , and these were widely seen as a mistake . The start of the 1880s saw the end of sailing rig on ironclad battleships . \\n\",\n",
              " \" Sails persisted on ' cruising ironclads ' for much longer . During the 1860s , the French navy had produced the Alma and La GalissonniÃ¨re classes as small , long @-@ range ironclads as overseas cruisers and the British had responded with ships like HMS Swiftsure of 1870 . The Russian ship General @-@ Admiral , laid down in 1870 and completed in 1875 , was a model of a fast , long @-@ range ironclad which was likely to be able to outrun and <unk> ships like Swiftsure . Even the later HMS Shannon , often described as the first British armored cruiser , would have been too slow to outrun General @-@ Admiral . While Shannon was the last British ship with a retractable propellor , later armored cruisers of the 1870s retained sailing rig , sacrificing speed under steam in consequence . It took until 1881 for the Royal Navy to lay down a long @-@ range armored warship capable of catching enemy commerce raiders , HMS Warspite , which was completed in 1888 . While sailing rigs were obsolescent for all purposes by the end of the 1880s , rigged ships were in service until the early years of the 20th century . \\n\",\n",
              " ' The final evolution of ironclad propulsion was the adoption of the triple @-@ expansion steam engine , a further refinement which was first adopted in HMS Sans Pareil , laid down in 1885 and commissioned in 1891 . Many ships also used a forced draught to get additional power from their engines , and this system was widely used until the introduction of the steam turbine in the mid @-@ 1900s ( decade ) . \\n',\n",
              " '',\n",
              " ' = = Fleets = = \\n',\n",
              " '',\n",
              " \" While ironclads spread rapidly in navies worldwide , there were few pitched naval battles involving ironclads . Most European nations settled differences on land , and the Royal Navy struggled to maintain a deterrent parity with at least France , while providing suitable protection to Britain 's commerce and colonial outposts worldwide . Ironclads remained , for the British Royal Navy , a matter of defending the British Isles first and projecting power abroad second . Those naval engagements of the latter half of the 19th @-@ century which involved ironclads normally involved colonial actions or clashes between second @-@ rate naval powers . But these encounters were often enough to convince British policy @-@ makers of the increasing hazards of strictly naval foreign intervention , from Hampton Roads in the American Civil War to the hardening combined defences of naval arsenals such as Kronstadt and Cherbourg . \\n\",\n",
              " ' There were many types of ironclads : \\n',\n",
              " ' <unk> ships intended to \" stand in the line of battle \" ; the precursors of the battleship . \\n',\n",
              " \" Coastal service and riverine vessels , including ' floating batteries ' and ' <unk> \\n\",\n",
              " \" Vessels intended for commerce raiding or protection of commerce , called ' armoured <unk> \\n\",\n",
              " '',\n",
              " ' = = = Navies = = = \\n',\n",
              " '',\n",
              " \" The United Kingdom possessed the largest navy in the world for the whole of the ironclad period . The Royal Navy was the second to adopt ironclad warships , and it applied them worldwide in their whole range of roles . In the age of sail , the British strategy for war depended on the Royal Navy mounting a blockade of the ports of the enemy . Because of the limited endurance of steamships , this was no longer possible , so the British at times considered the risk @-@ laden plan of engaging an enemy fleet in harbor as soon as war broke out . To this end , the Royal Navy developed a series of ' coast @-@ defence battleships ' , starting with the Devastation class . These ' breastwork monitors ' were markedly different from the other high @-@ seas ironclads of the period and were an important precursor of the modern battleship . As long @-@ range monitors they could reach Bermuda unescorted , for example . However , they were still armed with only four heavy guns and were as vulnerable to mines and obstructions ( and enemy monitors ) as the original monitors of the Union Navy proved to be during the Civil War . The British prepared for an overwhelming mortar bombardment of Kronstadt by the close of the Crimean War , but never considered running the smoke @-@ ridden , shallow @-@ water gauntlet straight to St. Petersburg with ironclads . Likewise , monitors proved acutely unable to ' overwhelm ' enemy fortifications single @-@ handed during the American conflict , though their low @-@ profile and heavy armour protection made them ideal for running gauntlets . Mines and obstructions , however , negated these advantages â a problem the British Admiralty frequently acknowledged but never countered throughout the period . The British never laid down enough Devastation @-@ class ' battleships ' to instantly overwhelm Cherbourg , Kronstadt or even New York City with gunfire . Although throughout the 1860s and 1870s the Royal Navy was still in many respects superior to its potential rivals , by the early 1880s widespread concern about the threat from France and Germany culminated in the Naval Defence Act , which promulgated the idea of a ' two @-@ power standard ' , that Britain should possess as many ships as the next two navies combined . This standard provoked aggressive shipbuilding in the 1880s and 1890s . \\n\",\n",
              " \" British ships did not participate in any major wars in the ironclad period . The Royal Navy 's ironclads only saw action as part of colonial battles or one @-@ sided engagements like the bombardment of Alexandria in 1882 . Defending British interests against Ahmed ' Urabi 's Egyptian revolt , a British fleet opened fire on the fortifications around the port of Alexandria . A mixture of centre @-@ battery and turret ships bombarded Egyptian positions for most of a day , forcing the Egyptians to retreat ; return fire from Egyptian guns was heavy at first , but inflicted little damage , killing only five British sailors . Few Egyptian guns were actually dismounted , on the other hand , and the fortifications themselves were typically left intact . Had the Egyptians actually utilised the heavy mortars that were at their disposal , they might have quickly turned the tide , for the attacking British ironclads found it easy ( for accuracy 's sake ) to simply anchor whilst firing â perfect targets for high @-@ angle fire upon their thinly armoured <unk> . \\n\",\n",
              " ' The French navy built the first ironclad to try to gain a strategic advantage over the British , but were consistently out @-@ built by the British . Despite taking the lead with a number of innovations like breech @-@ loading weapons and steel construction , the French navy could never match the size of the Royal Navy . In the 1870s , the construction of ironclads ceased for a while in France as the Jeune Ecole school of naval thought took prominence , suggesting that torpedo boats and unarmored cruisers would be the future of warships . Like the British , the French navy saw little action with its ironclads ; the French blockade of Germany in the Franco @-@ Prussian War was ineffective , as the war was settled entirely on land . \\n',\n",
              " \" Russia built a number of ironclads , generally copies of British or French designs . Nonetheless , there were real innovations from Russia ; the first true type of ironclad armored cruiser , the General @-@ Admiral of the 1870s , and a set of remarkably badly designed circular battleships referred to as ' <unk> ' ( for Admiral Popov , who conceived the design ) . The Russian Navy pioneered the wide @-@ scale use of torpedo boats during the Russo @-@ Turkish War of 1877 â 1878 , mainly out of necessity because of the superior numbers and quality of ironclads used by the Turkish navy . Russia expanded her navy in the 1880s and 1890s with modern armored cruisers and battleships , but the ships were manned by inexperienced crews and politically appointed leadership , which enhanced their defeat in the Battle of Tsushima on 27 May 1905 . \\n\",\n",
              " ' The U.S. Navy ended the Civil War with about fifty monitor @-@ type coastal ironclads ; by the 1870s most of these were laid up in reserve , leaving the USA virtually without an ironclad fleet . Another five large monitors were ordered in the 1870s . The limitations of the monitor type effectively prevented the USA from projecting power overseas , and until the 1890s the USA would have come off badly in a conflict with even Spain or the Latin American powers . The 1890s saw the beginning of what became the Great White Fleet , and it was the modern pre @-@ Dreadnoughts and armored cruisers built in the 1890s which defeated the Spanish fleet in the Spanish â American War of 1898 . This started a new era of naval warfare . \\n',\n",
              " ' Ironclads were widely used in South America . Both sides used ironclads in the Chincha Islands War between Spain and the combined forces of Peru and Chile in the early 1860s . The powerful Spanish Numancia participated in the Battle of Callao but was unable to inflict significant damage to the Callao defences . Besides , Peru was able to deploy two locally built ironclads based on American Civil War designs , the Loa ( a wooden ship converted into a casemate ironclad ) and the Victoria ( a small monitor armed with a single 68 @-@ pdr gun ) , as well as two British @-@ built ironclads : Independencia , a centre @-@ battery ship , and the turret ship <unk> . Numancia was the first ironclad to circumnavigate the world , arriving in CÃ¡diz on 20 September 1867 , and earning the motto : \" <unk> <unk> que primo <unk> <unk> \" [ \" First ironclad ship to sail around the world \" ] ) . In the War of the Pacific in 1879 , both Peru and Chile had ironclad warships , including some of those used a few years previously against Spain . While the Independencia ran aground early on , the Peruvian ironclad \\' <unk> made a great impact against Chilean shipping , delaying Chilean ground invasion by six months . She was eventually caught by two more modern Chilean centre @-@ battery ironclads , the Blanco Encalada and the Almirante Cochrane at the Battle of <unk> Point . \\n',\n",
              " ' Ironclads were also used from the inception of the Imperial Japanese Navy . The KÅtetsu ( Japanese : <unk> , literally \" Ironclad \" , later renamed Azuma <unk> , \" East \" ) had a decisive role in the Naval Battle of Hakodate Bay in May 1869 , which marked the end of the Boshin War , and the complete establishment of the Meiji Restoration . The IJN continued to develop its strength and commissioned a number of warships from British and European shipyards , first ironclads and later armored cruisers . These ships engaged the Chinese Beiyang fleet which was superior on paper at least at the Battle of the Yalu River . Thanks to superior short @-@ range firepower , the Japanese fleet came off better , sinking or severely damaging eight ships and receiving serious damage to only four . The naval war was concluded the next year at the Battle of Weihaiwei , where the strongest remaining Chinese ships were surrendered to the Japanese . \\n',\n",
              " '',\n",
              " ' = = End of the ironclad warship = = \\n',\n",
              " '',\n",
              " \" There is no clearly defined end to the ironclad , besides the transition from wood hulls to all @-@ metal . Ironclads continued to be used in World War I. Towards the end of the 19th century , the descriptions ' battleship ' and ' armored cruiser ' came to replace the term ' ironclad ' . \\n\",\n",
              " \" The proliferation of ironclad battleship designs came to an end in the 1890s as navies reached a consensus on the design of battleships , producing the type known as the pre @-@ Dreadnought . These ships are sometimes covered in treatments of the ironclad warship . The next evolution of battleship design , the dreadnought , is never referred to as an ' ironclad ' . \\n\",\n",
              " ' Most of the ironclads of the 1870s and 1880s served into the 1900s ( decade ) . For instance , a handful of US navy monitors laid down in the 1870s saw active service in World War I. Pre @-@ Dreadnought battleships and cruisers of the 1890s saw widespread action in World War I and in some cases through to World War II . \\n',\n",
              " '',\n",
              " ' = = = Legacy = = = \\n',\n",
              " '',\n",
              " ' The example of the ironclads had some bearing on the history of the tank , as ironclad warships became an inspiration for ideas of <unk> and other armored vehicles . H. G. Wells , in his short story The Land Ironclads , published in The Strand Magazine in December 1903 , described the use of large , armoured cross @-@ country vehicles , armed with cannon and machine guns , and equipped with <unk> wheels \\n',\n",
              " '',\n",
              " ' = = Today = = \\n',\n",
              " '',\n",
              " ' A number of ironclads have been preserved or reconstructed as museum ships . \\n',\n",
              " \" Parts of USS Monitor have been recovered and are being conserved and displayed at the Mariners ' Museum in Newport News , Virginia \\n\",\n",
              " ' HMS Warrior is today a fully restored museum ship in Portsmouth , England \\n',\n",
              " ' <unk> is berthed at the port of Talcahuano , Chile , on display for visitors . \\n',\n",
              " ' The City @-@ class ironclad USS Cairo is currently on display in Vicksburg , Mississippi . \\n',\n",
              " ' Northrop Grumman in Newport News constructed a full @-@ scale replica of USS Monitor . The replica was laid down in February 2005 and completed just two months later . \\n',\n",
              " ' The Dutch <unk> ( Coastal ram ) Zr . Ms. <unk> is currently under display in the Maritime Museum Rotterdam . \\n',\n",
              " ' The Dutch <unk> ( Coastal ram ) Zr . Ms. <unk> is a museum ship at Den Helder . \\n',\n",
              " ' The complete , recovered wooden hull of the CSS Neuse , a casemate ram ironclad , is on view in Kinston , North Carolina , and , in another part of town on the Neuse River , the recreated ship , named CSS Neuse II , is nearly built and can be visited . \\n',\n",
              " ' The hull of the casemate ironclad CSS Jackson can be seen in the National Civil War Naval Museum at Port Columbus , Georgia . \\n',\n",
              " ' The new United States Navy Zumwalt @-@ class guided missile destroyer has been described as bearing resemblance to ironclads . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Little Gidding ( poem ) = \\n',\n",
              " '',\n",
              " \" Little Gidding is the fourth and final poem of T. S. Eliot 's Four Quartets , a series of poems that discuss time , perspective , humanity , and salvation . It was first published in September 1942 after being delayed for over a year because of the air @-@ raids on Great Britain during World War II and Eliot 's declining health . The title refers to a small Anglican community in Huntingdonshire , established by Nicholas Ferrar in the 17th century and scattered during the English Civil War . \\n\",\n",
              " \" The poem uses the combined image of fire and Pentecostal fire to emphasise the need for purification and purgation . According to the poet , humanity 's flawed understanding of life and turning away from God leads to a cycle of warfare , but this can be overcome by recognising the lessons of the past . Within the poem , the narrator meets a ghost that is a combination of various poets and literary figures . Little Gidding focuses on the unity of past , present , and future , and claims that understanding this unity is necessary for salvation . \\n\",\n",
              " '',\n",
              " ' = = Background = = \\n',\n",
              " '',\n",
              " \" Following the completion of the third Four Quartets poem , The Dry Salvages , Eliot 's health declined and he stayed in Shamley Green , Surrey while he recovered . During this time , Eliot started writing Little Gidding . The first draft was completed in July 1941 but he was dissatisfied with it . He believed the problems with the poem lay with his own inability to write , and that , precipitated by air raids on London , he had started the poem with too little preparation and had written it too quickly . After the first draft was written , he set the poem aside , and he left in September to lecture throughout Great Britain . \\n\",\n",
              " \" After months of not working on the poem , Eliot began to feel compelled to finish it ; it was not until August 1942 , however , that he started working on it again . In total , there were five drafts . The poem was finished by 19 September 1942 and published in the October New English Weekly . Little Gidding was intended to conclude the Four Quartets series , summarising Eliot 's views expressed in this series of poems . \\n\",\n",
              " ' Little Gidding was the home of an Anglican community established in 1626 by Nicholas Ferrar . The Ferrar household lived a Christian life according to High Church principles and the Book of Common Prayer . The religious community was dispersed during the English Civil War between Parliamentarians and Royalists but reformed , ending with the death of John Ferrar in 1657 . Eliot had visited the site in May 1936 . \\n',\n",
              " ' Unlike the other locations mentioned in the titles of the Four Quartets poems , Eliot had no direct connection to the original Christian community . As such , the community is supposed to represent almost any religious community . \\n',\n",
              " '',\n",
              " ' = = Poem = = \\n',\n",
              " '',\n",
              " ' Critics classify Little Gidding as a poem of fire with an emphasis on purgation and the Pentecostal fire . The beginning of the poem discusses time and winter , with attention paid to the arrival of summer . The images of snow , which provoke desires for a spiritual life , transition into an analysis of the four classical elements of fire , earth , air and water and how fire is the primary element of the four . Following this is a discussion on death and destruction , things <unk> , and regret for past events . \\n',\n",
              " \" While using Dante 's terza rima style , the poem continues by describing the Battle of Britain . The image of warfare merges with the depiction of Pentecost , and the Holy Spirit is juxtaposed with the air @-@ raids on London . In the second section , a ghost , representing the poets of the past stuck between worlds , begins talking to the narrator of the poem . The ghost discusses change , art in general , and how humankind is flawed . The only way to overcome the problematic condition of humanity , according to the ghost , is to experience purgation through fire . The fire is described in a manner similar to Julian of Norwich 's writing about God 's love and discussed in relationship to the shirt of Nessus , a shirt that burns its wearer . Little Gidding continues by describing the <unk> of the present and how history exists in a pattern . The poem concludes by explaining how sacrifice is needed to allow an individual to die into life and be reborn , and that salvation should be the goal of humankind . \\n\",\n",
              " '',\n",
              " ' = = Themes = = \\n',\n",
              " '',\n",
              " \" In terms of renewal , Eliot believed that suffering was needed for all of society before new life could begin . The original Little Gidding community was built for living on monastic lines , but the community was damaged and dispersed by Puritan forces during the English Civil War in 1646 . The church , the centre of the community , was restored in 1714 and again in 1853 . The image of religious renewal is combined with the image of the London air @-@ raids and the constant fighting and destruction within the world . This compound image is used to discuss the connection of holy places with the Holy Spirit , Pentecost , communion with the dead , and the repetition of history . The theme is also internal to Eliot 's own poems ; the image of the rose garden at the end Little Gidding is the image that begins Burnt Norton and the journey is made circular . Also , the depiction of time within the poem is similar to the way time operates within The Family Reunion . \\n\",\n",
              " ' Like the other poems making up the Four Quartets , Little Gidding deals with the past , present , and future , and humanity \\'s place within them as each generation is seemingly united . In the second section , there is a ghost who is the compilation of various poets , including Dante , Swift , Yeats , and others . When the ghost joins the poet , the narrator states \" Knowing myself yet being someone other \" . This suggests that the different times merge at the same time that the different personalities begin to merge , allowing a communication and connection with the dead . Later , in the fourth section , humanity is given a choice between the Holy Spirit or the bombing of London ; redemption or destruction . God \\'s love allows humankind to be redeemed and escape the living hell through purgation by fire . The end of the poem describes how Eliot has attempted to help the world as a poet . He parallels his work in language with working on the soul or working on society . \\n',\n",
              " ' The ghost , a combination of many literary figures , was originally addressed in the poem as \" Ser <unk> \" before being revised as an ambiguous \" you \" . \" Ser <unk> \" was Dante \\'s way of addressing <unk> Latini , a former mentor whom he meets in Hell to which he has been condemned for sodomy . Eliot , in a letter to John Hayward dated 27 August 1942 , explained why he changed the wording : \\n',\n",
              " ' I think you will recognise that it was necessary to get rid of <unk> for two reasons . The first is that the visionary figure has now become somewhat more definite and will no doubt be identified by some readers with Yeats though I do not mean anything so precise as that . However , I do not wish to take the responsibility of putting Yeats or anybody else into Hell and I do not want to impute to him the particular vice which took <unk> there . Secondly , although the reference to that Canto is intended to be explicit , I wish the effect of the whole to be <unk> which is more appropriate . That brings us to the reference to swimming in fire which you will remember at the end of Purgatorio 26 where the poets are found . \\n',\n",
              " \" The theme of swimming through flames is connected to the depiction of Guido <unk> , a poet that influenced Dante , seeking such a state in Purgatorio XXVI . However , the depiction of swimming was transformed into an image of dancing , an act that appears throughout Yeats 's poetry , within <unk> flames . The critic Dominic Manganiello suggests that , in combining the image of dancing with purgation , Eliot merges Dante 's and Yeats 's poetic themes . \\n\",\n",
              " '',\n",
              " ' = = Reception = = \\n',\n",
              " '',\n",
              " ' Critics such as Malcolm Cowley and Delmore Schwartz describe mixed emotions about the religiosity of the poem . Cowley emphasised the mystical nature of the poem and how its themes were closer to Buddhism than Anglicanism while mentioning his appreciation of many of the passages . Schwartz also mentioned the Buddhist images and his admiration for many of the lines in Little Gidding . F. B. Pinion believed that the fourth section of the poem costs \" Eliot more trouble and vexation than any passage of the same length he ever wrote , and is his greatest achievement in the Four Quartets . \" E. M. Forster did not like Eliot \\'s emphasis on pain and responded to the poem : \" Of course there \\'s pain on and off through each individual \\'s life ... You can \\'t shirk it and so on . But why should it be endorsed by the schoolmaster and sanctified by the priest until the fire and the rose are one when so much of it is caused by disease and bullies ? It is here that Eliot becomes unsatisfactory as a seer . \" Writing in 2003 , Roger Scruton wrote that in \" Little Gidding \" Eliot achieved \" that for which he envies Dante â namely , a poetry of belief , in which belief and words are one , and in which the thought cannot be prized free from the controlled and beautiful language \" . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = The Portage to San Cristobal of A.H. = \\n',\n",
              " '',\n",
              " ' The Portage to San Cristobal of A.H. is a 1981 literary and philosophical novella by George Steiner , in which Jewish Nazi hunters find a fictional Adolf Hitler ( A.H. ) alive in the Amazon jungle thirty years after the end of World War II . The book generated considerable controversy after its publication because in it , Steiner , who is Jewish , allows Hitler to defend himself when he is put on trial in the jungle by his captors . There Hitler maintains that Israel owes its existence to the Holocaust and that he is the \" benefactor of the Jews \" . \\n',\n",
              " ' The Portage to San Cristobal of A.H. was a 1983 finalist in the PEN / Faulkner Award for Fiction . It was adapted for the theatre by British playwright Christopher Hampton and was staged in London in April 1982 with Alec McCowen playing the part of Adolf Hitler . It was also staged in Hartford , Connecticut in the United States in 1983 and starred John Cullum as Hitler . \\n',\n",
              " '',\n",
              " ' = = Plot summary = = \\n',\n",
              " '',\n",
              " \" From his base in Tel Aviv , Holocaust survivor Emmanuel Lieber directs a group of Jewish Nazi hunters in search of Adolf Hitler . Lieber believes that the former FÃ¼hrer is still alive , and following rumours and hearsay , he tracks Hitler 's movements through South America , until after months of wading through swamps in the Amazon jungle , the search party finds the 90 @-@ year @-@ old alive in a clearing . Lieber flies to San CristÃ³bal where he awaits the group 's return with their captive . But getting the old man out of the jungle alive is more difficult than getting in , and their progress is further hampered by heavy thunderstorms . \\n\",\n",
              " ' Meanwhile , broken and incoherent radio messages between Lieber and the search party are intercepted by intelligence agents tracking their progress , and rumours begin to spread across the world of Hitler \\'s capture . Debates flare up over his impending trial , where it will be held and under whose jurisdiction . <unk> is identified as the nearest airfield to the last known location of the search party , and aircraft begin arriving at the hitherto unknown town . But when the search party loses radio contact with Lieber , they must make a decision : do they sit out the storms and deliver their captive to Lieber later , or do they try Hitler in the jungle before their prize is snatched from them by the world at large , who they know will be waiting ? Their decision is the latter , and against Lieber \\'s advice ( \" You must not let him speak ... his tongue is like no other \" ) they prepare for a trial with a judge , prosecution and defence attorneys selected from the members of the search party . <unk> , a local Indian tracker , is asked to observe the trial as an independent witness . \\n',\n",
              " ' The attention Hitler is receiving , however , renews his strength , and when the trial begins , he brushes aside his \" defence attorney \" and begins a long speech in four parts in his own defence : \\n',\n",
              " ' Firstly , Hitler claims he took his doctrines from the Jews and copied the notion of the master race from the Chosen people and their need to separate themselves from the \" unclean \" . \" My racism is a parody of yours , a hungry imitation . \" \\n',\n",
              " ' Hitler justifies the Final Solution by maintaining that the Jews \\' God , purer than any other , enslaves its subjects , continually demanding more than they can give and \" blackmailing \" them with ideals that cannot be attained . The \" virus of utopia \" had to be stopped . \\n',\n",
              " ' Hitler states that he was not the originator of evil . \" [ Stalin ] had perfected genocide when I was still a nameless <unk> in Munich . \" Further , Hitler asserts that the number of lives lost due to his actions are dwarfed by various world atrocities , including those in Russia , China and Africa . \\n',\n",
              " ' Lastly , Hitler maintains that the Reich begat Israel and suggests that he is the Messiah \" whose infamous deeds were allowed by God in order to bring His people home . \" He closes by asking , \" Should you not honour me who have made ... Zion a reality ? \" \\n',\n",
              " ' At the end of his speech , <unk> is the first to react and jumps up shouting \" Proven \" , only to be drowned out by the appearance of a helicopter over the clearing . \\n',\n",
              " '',\n",
              " ' = = Main characters = = \\n',\n",
              " '',\n",
              " ' Emmanuel Lieber â Jewish Holocaust survivor and director of the search party to find Hitler ; after crawling out of a death pit in <unk> he never took the time to mend and embarked on a life @-@ consuming obsession to bring those responsible for the genocide to justice . \\n',\n",
              " ' Search party ( all Jewish with family ties to the Holocaust , except for John Asher ) \\n',\n",
              " ' Simeon â search party leader and \" presiding judge \" at Hitler \\'s trial ; he is Lieber \\'s confidant and torn between leading the party into \" unmapped quicksand and green bogs \" and turning his back on the \" quiet mania of Lieber \\'s conviction \" . \\n',\n",
              " ' Gideon <unk> â falls ill and dies before the trial begins ; during one of his fever @-@ induced ramblings he suggests that Hitler is Jewish ; he had sought out Lieber after being released from a sanatorium and spending three years recuperating in Paris where the care @-@ free living consumed him with guilt . \\n',\n",
              " ' Elie <unk> â Orthodox Jew and \" prosecution attorney \" at the trial ; he is the moral compass of the group , but his convictions are disturbed by Gideon <unk> \\'s fever @-@ induced assertions that Hitler is Jewish and ends up believing that Hitler may be the second Messiah . \\n',\n",
              " \" Isaac <unk> â an 18 @-@ year @-@ old boy and witness at the trial ; he is the son of Isaac <unk> senior , former member of the search party killed earlier in a skirmish in SÃ£o Paulo ; he joined the party to avenge his father 's death . \\n\",\n",
              " ' John Asher â half @-@ Jewish and reluctant \" defence attorney \" at the trial ; fascinated by the capture of Bormann and the rumours circulating that Hitler may be alive , he had approached Nazi hunter Wiesenthal who directed him to Lieber ; despite being an \" outsider \" ( no ties to the Holocaust ) Lieber assigned him to the search party because of his military training and his clear @-@ headedness ( \" no metaphysical lusts , no cravings for retribution \" ) . \\n',\n",
              " \" <unk> â local Indian tracker and independent witness at the trial ; previously the search party 's guide who had abandoned them when they insisted on entering uncharted regions of the jungle , he continued tracking them from a distance before revealing himself . \\n\",\n",
              " ' Adolf Hitler â now 90 years old , the former leader of the Third Reich had not died in the FÃ¼hrerbunker in Berlin , but escaped to South America and hid in the Amazon jungle . \\n',\n",
              " '',\n",
              " ' = = Background and publication = = \\n',\n",
              " '',\n",
              " ' George Steiner , literary critic for The New Yorker and The New York Times , had written about the Holocaust in some of his previous books , including Anno Domini ( 1964 ) , Language and Silence ( 1967 ) and In Bluebeard \\'s Castle ( 1971 ) . Many of the ideas Steiner expresses in The Portage to San Cristobal of A.H. were reworked from these earlier works . Steiner told New York Times editor D. J. R. Bruckner that this book arose out of his lifelong work on language . \" Central to everything I am and believe and have written is my astonishment ... that you can use human speech both to bless , to love , to build , to forgive and also to torture , to hate , to destroy and to annihilate . \" \\n',\n",
              " ' Commenting on the controversy the book generated , Steiner admitted to literary journalist and critic Ron Rosenbaum ( author of Explaining Hitler ) that he too was disturbed by it , adding that his fictional Hitler had gotten the better of him , \" <unk> or Frankenstein @-@ like \" . He said that it felt like the book \" wrote me \" . Steiner also pointed out that the novella is not only about his thoughts on the Holocaust , but also about the horrific events that took place in countries like Cambodia , Vietnam , El Salvador and Burundi : \" My feeling is that one has to grapple with the abyss if one can . \" \\n',\n",
              " ' Steiner wrote The Portage to San Cristobal of A.H. in 1975 and 1976 in Geneva , Switzerland , and the 120 @-@ page work originally appeared in the Spring 1979 issue of the United States literary magazine , The Kenyon Review . It also appeared in the Spring 1980 issue of Granta , the British literary magazine . Its first publication in book form , with minor revisions by Steiner , was in May 1981 by Faber and Faber in the United Kingdom â and as requested by Steiner , it was a paperback original . The first United States edition was published in hardcover in April 1982 by Simon & Schuster . \\n',\n",
              " '',\n",
              " ' = = Adaptations = = \\n',\n",
              " '',\n",
              " \" The Portage to San Cristobal of A.H. was adapted for the theatre in 1982 by British playwright Christopher Hampton . It was staged in April 1982 at London 's Mermaid Theatre under the direction of John Dexter with Alec McCowen playing the part of Adolf Hitler . McCowen won the 1982 Evening Standard Theatre Award for best actor for this performance . In 1983 the production moved to the United States where it played at the Hartford Stage Company in Hartford , Connecticut , directed by Mark Lamos and starring John Cullum as Hitler . \\n\",\n",
              " ' This book is the only work of fiction by Steiner to have been adapted for the stage . \\n',\n",
              " '',\n",
              " ' = = Reception = = \\n',\n",
              " '',\n",
              " ' Reaction to The Portage to San Cristobal of A.H. was mixed . Anthony Burgess in The Observer called it \" astonishing \" , Christopher Booker of The Daily Telegraph described it as a \" powerful piece \" , and English author A. S. Byatt said it was a \" masterpiece \" . In Explaining Hitler , Ron Rosenbaum called The Portage \" A Frankenstein story \" , referring to Steiner \\'s fictive Hitler has having taken on a life of its own . Writing in Time magazine , Otto Friedrich described the book \" a philosophic fantasy of remarkable intensity \" , adding that by not refuting Hitler \\'s speech , Steiner deviates from the horrors of traditional Holocaust literature and ends the book \" on a note of bleak ambiguity \" . \\n',\n",
              " ' Morris Dickstein of The New York Times was more critical of the book , calling it \" a misconceived and badly executed novel , a sideshow distraction from the serious business of thinking through the unspeakable horrors of the Nazi era . \" He described it as \" wearisome \" that is \" suffocate [ d ] \" by too much \" fine writing \" ( belles @-@ lettres ) . He also complained that the characters are lifeless , and while they each have detailed histories , they are only \" verbal figments \" that do not separate them from one another . Finally Dickstein noted that because almost all the points of Hitler \\'s speech are drawn from some of Steiner \\'s earlier works , he \" unwittingly creates sympathy for Hitler by making him old and pathetic yet also lucid and brilliant â at once absurdly harmless and unconvincingly dangerous . \" \\n',\n",
              " ' In another review in The New York Times John Leonard wrote that while the book has its strong points , \" some wit , a catholic disdain , multiplicity of character and a South American swamp @-@ life that terrifies \" , its weaknesses are that \" the characters are really ideas , ... the symbols clash and there are too many echoes of better books by Kafka and Proust \" . But Leonard \\'s biggest criticism of the book was Hitler \\'s speech , which he called \" obscene \" , and Steiner \\'s decision to end the book at that point , which Leonard said \" not only denies the power of art to arrange and transcend , but ... makes me sick to my stomach . \" \\n',\n",
              " ' Writing in the American literary magazine Salmagundi , Alvin H. Rosenfeld called The Portage a \" breakthrough work \" that \" astonishes \" . He was struck by the book \\'s interplay between the landscape of swamp and jungle , and the \" landscape of speech \" â the former being \" brilliantly registered \" with its \" immense feeling of physicality \" , and the latter , \" even more dramatic \" in the way it exposes \" the dark underside of words \" and how its use and misuse reveals the true nature of a person . He was particularly impressed by the depiction of Nazi hunter Emmanuel Lieber and his role as representative of the Jewish consciousness . Rosenfeld noted that while Holocaust literature often either soars to \" expostulation and apostrophe \" , or sinks to \" a dwindling sob of elegiac lament \" , Steiner \\'s Lieber \" mediates between these two extremes , ... simultaneously records and mourns , coldly enumerates yet carries an immense affect \" . What did concern the reviewer , however , was the way Steiner used ideas from his earlier works , that he had put them \" virtually verbatim \" into Hitler \\'s mouth , creating the impression that \" Steiner \\'s understanding of Hitler were identical with the latter \\'s self @-@ understanding \" . Rosenfeld also questioned why the book had to end with Hitler \\'s speech . He said that Steiner \\'s fictive Hitler plays \" the devil \\'s game of language subversion \" , making \" madness [ sound ] like music \" , something the real Hitler had perfected . By stopping at this point , Rosenfeld felt that Steiner \" succumb [ s ] , rhetorically , to the seductive eloquence of negation \" , which undermines his own \" high standards of moral intelligence \" . But overall Rosenfeld said The Portage \" must be counted among the most vigorous attempts to portray the presence and meaning of Hitler \" , forcing us to confront him \" in a way hardly seen before in fiction \" . \\n',\n",
              " ' The Portage to San Cristobal of A.H. was a finalist in the 1983 PEN / Faulkner Award for Fiction . \\n',\n",
              " '',\n",
              " ' = = Controversy = = \\n',\n",
              " '',\n",
              " ' The book generated considerable controversy because of its apparent \" admiration for Hitler \" . The controversy grew further when the faithful stage adaptation ( \" too faithful \" , according to Steiner ) was performed in the United Kingdom and the United States . \\n',\n",
              " ' Hitler \\'s speech at the end of the book disturbed many readers and critics . Steiner not only lets Hitler justify his past , he allows him the ( almost ) last word before the outside world invades . The fact that Steiner is Jewish made this speech in particular even more contentious . One critic , while acknowledging that Steiner always saw Hitler as \" the incarnation of unprecedented and unparalleled evil \" , felt that there was no clear distinction in the book between Steiner \\'s own views and those of his fictional Hitler , even going so far as to accuse Steiner , who rejects Jewish nationalism and is a critic of Israel \\'s treatment of the Palestinians , of anti @-@ Semitism . \\n',\n",
              " ' In contrast , a Time magazine article at the time felt that Steiner \\'s intention for the Hitler speech was to use it to explore his previously stated belief \" that Hitler wielded language as an almost supernatural force \" , drawing attention to Nazi hunter Emmanuel Lieber \\'s warning from the book regarding Hitler : \" There shall come a man who ... will know the grammar of hell and teach it to others . He will know the sounds of madness and loathing and make them seem music . \" \\n',\n",
              " ' Steiner responded to criticism that Hitler \\'s speech in this book is unchallenged by saying that it had been done before : for example Satan \\'s speech in Milton \\'s Paradise Lost ( 1667 ) , and The Grand Inquisitor \\'s speech in Dostoyevsky \\'s The Brothers Karamazov ( 1880 ) . He also reminded the reader that Hitler \\'s speech is balanced out earlier in the book by Lieber \\'s long monologue on the horrors of the Holocaust . Finally , Steiner said that his Hitler ( A. H. ) is \" a fictive figure \" , and that it is not he who has the last word , but <unk> , the Indian tracker , who shouts \" Proven \" . <unk> is also the Hebrew word used to indicate that \" there are issues here beyond our wisdom to answer or decide . \" \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Temnospondyli = \\n',\n",
              " '',\n",
              " ' Temnospondyli ( from Greek <unk> ( <unk> , \" to cut \" ) and <unk> ( <unk> , \" vertebra \" ) ) is a diverse subclass of extinct small to giant tetrapods â often considered primitive amphibians â that flourished worldwide during the Carboniferous , Permian , and Triassic periods . A few species continued into the Cretaceous . Fossils have been found on every continent . During about 210 million years of evolutionary history , they adapted to a wide range of habitats , including fresh water , terrestrial , and even coastal marine environments . Their life history is well understood , with fossils known from the larval stage , metamorphosis , and maturity . Most <unk> were semiaquatic , although some were almost fully terrestrial , returning to the water only to breed . These <unk> were some of the first vertebrates fully adapted to life on land . Although <unk> are considered amphibians , many had characteristics , such as scales , claws , and armour @-@ like bony plates , that distinguish them from modern amphibians . \\n',\n",
              " ' <unk> have been known since the early 19th century , and were initially thought to be reptiles . They were described at various times as <unk> , <unk> , and <unk> , although these names are now rarely used . Animals now grouped in Temnospondyli were spread out among several amphibian groups until the early 20th century , when they were found to belong to a distinct taxon based on the structure of their vertebrae . Temnospondyli means \" cut vertebrae \" , as each vertebra is divided into several parts . \\n',\n",
              " ' Experts disagree over whether <unk> were ancestral to modern amphibians ( frogs , salamanders , and caecilians ) , or whether the whole group died out without leaving any descendants . Different hypotheses have placed modern amphibians as the descendants of <unk> , another group of early tetrapods called <unk> , or even as descendants of both groups ( with caecilians evolving from <unk> and frogs and salamanders evolving from <unk> ) . Recent studies place a family of <unk> called the <unk> as the closest relatives of modern amphibians . Similarities in teeth , skulls , and hearing structures link the two groups . \\n',\n",
              " '',\n",
              " ' = = Description = = \\n',\n",
              " '',\n",
              " ' Many <unk> are much larger than living amphibians , and superficially resemble crocodiles . Others are smaller and resemble salamanders . Most have broad , flat heads that are either blunt ( <unk> ) or elongated ( <unk> ) . The skulls are rounded or triangular in shape when viewed from above , and are usually covered in pits and ridges . The rugged surfaces of bones may have supported blood vessels , which could transfer carbon dioxide to the bones to neutralize acidic build up in the blood ( early semiaquatic tetrapods would have had difficulty expelling carbon dioxide from their bodies while on land , and these dermal bones may have been an early solution to the problem ) . Many <unk> also have canal @-@ like grooves in their skulls called sensory sulci . The sulci , which usually run around the nostrils and eye sockets , are part of a lateral line system used to detect vibrations in water . As semiaquatic animals , most <unk> have small limbs with four toes on each front foot and five on each hind foot . Terrestrial <unk> have larger , thicker limbs , and some even have claws . One unusual terrestrial temnospondyl , <unk> , has relatively long limbs for its body , and probably lived as an active runner able to chase prey . \\n',\n",
              " ' <unk> of most of the bones of <unk> are also seen in other early tetrapods , aside from a few bones in the skull , such as <unk> , <unk> , and <unk> , that have developed in some temnospondyl taxa . Most <unk> have tabular horns in the backs of their skulls , rounded projections of bone separated from the rest of the skull by indentations called otic notches ; in some <unk> , such as <unk> , they are pointed and very prominent . Among the most distinguishing features of <unk> are the <unk> vacuities , two large holes in the back of the palate . Another pair of holes , <unk> , are present in front of these vacuities , and connect the nasal passage with the mouth . <unk> often have teeth on their palates , as well as in their jaws . Some of these teeth are so large , they are referred to as tusks . In some <unk> , such as <unk> , tusks in the lower jaw pierce the palate and emerge through openings in the top of the skull . \\n',\n",
              " ' Very little is known of the soft tissue of <unk> . A block of sandstone , described in 2007 from the Early Carboniferous Mauch Chunk Formation of Pennsylvania , included impressions of the bodies of three <unk> . These impressions show , when alive , they had smooth skin , robust limbs with webbed feet , and a ridge of skin on their undersides . Trackways referable to small <unk> have also been found in Carboniferous and Permian rocks . The trackways , called <unk> , are usually found in strata deposited around freshwater environments , suggesting the animals had some ties to the water . \\n',\n",
              " ' Unlike modern amphibians , many <unk> are covered in small , closely packed scales . The undersides of most <unk> are covered in rows of large ventral plates . During early stages of development , they first have only small , rounded scales . Fossils show , as the animals grew , the scales on the undersides of their bodies developed into large , wide ventral plates . The plates overlap each other in a way that allows a wide range of flexibility . Later semiaquatic <unk> , such as <unk> and <unk> , have no evidence of scales . They may have lost scales to make movement easier under water or to allow cutaneous respiration , the absorption of oxygen through the skin . \\n',\n",
              " ' Several groups of <unk> have large bony plates on their backs . One temnospondyl , <unk> , has armour @-@ like plating that covers both its back and underside . The temnospondyl <unk> also has extensive plating on its back . Most members of the family <unk> also have armor , although it only covers the midline of the back with two narrow rows of plates . Other <unk> , such as <unk> , have been found with small , disc @-@ like bony scutes that were in life probably embedded in the skin . All of these <unk> were adapted to a terrestrial lifestyle . Armor may have offered protection from predators in the case of <unk> . The scutes may have provided stability for the spine , as they would have limited flexibility and may have been connected by strong ligaments . <unk> such as <unk> and <unk> that may have been at least partly terrestrial also have long neural spines on top of their vertebrae that would have stabilized the spine . Bony scutes are also seen in <unk> , but unlike <unk> , <unk> , <unk> , and <unk> , these animals are thought to have been fully aquatic . <unk> may have inherited their armor from a terrestrial ancestor , as both <unk> and <unk> have been considered close relatives of the group . \\n',\n",
              " \" <unk> ' vertebrae are divided into several segments . In living tetrapods , the main body of the vertebra is a single piece of bone called the centrum , but in <unk> , this region was divided into a <unk> and <unk> . Two types of vertebrae are recognized in <unk> : <unk> and <unk> vertebrae . In <unk> vertebrae , the <unk> are large and wedge @-@ shaped , and the <unk> are relatively small blocks that fit between them . Both elements support a spine @-@ like neural arch , and well @-@ developed interlocking projections called zygapophyses strengthen the connections between vertebrae . The strong backbone and strong limbs of many <unk> <unk> allowed them to be partially , and in some cases fully , terrestrial . In <unk> vertebrae , the <unk> have been lost entirely , with the <unk> enlarged as the main body of the vertebrae . This weaker type of backbone indicates the <unk> <unk> spent more time in water . \\n\",\n",
              " '',\n",
              " ' = = History of study = = \\n',\n",
              " '',\n",
              " ' Temnospondyli was named by German palaeontologist Karl Alfred von Zittel in his second edition of Handbuch der <unk> , published in 1888 . <unk> remains were known since the early part of the 19th century , however . The earliest described temnospondyl was Mastodonsaurus , named by Georg Friedrich Jaeger in 1828 . Jaeger named Mastodonsaurus from a single tooth , and considered it a reptile . Mastodonsaurus means \" breast tooth lizard \" after the nipple @-@ like shape of the tip of the tooth . \\n',\n",
              " ' The naming of these first specimens was disputed , however . Leopold Fitzinger named the animal <unk> in 1837 . In 1841 , English palaeontologist Richard Owen referred to the genus as Labyrinthodon to describe its highly folded or labyrinthine teeth . Owen thought the name Mastodonsaurus \" ought not to be retained , because it recalls unavoidably the idea of the mammalian genus Mastodon , or else a <unk> form of the tooth ... and because the second element of the word , saurus , indicates a false affinity , the remains belonging , not to the Saurian , but to the <unk> order of Reptiles . \" Owen recognized the animal was not a \" saurian \" reptile , yet he also referred Jaeger \\'s <unk> to the genus . Although the two genera both have similarly sized conical teeth , <unk> was later found to be a crocodile @-@ like reptile . Additional material , including skulls , firmly placed Labyrinthodon as an amphibian . Jaeger also named <unk> giganteus in 1828 , basing it on partial occiput , or back portion of the skull . In 1833 , he described a complete skull of S. giganteus that had the same teeth as his Mastodonsaurus , making it the first known complete skull of a temnospondyl . Because Mastodonsaurus was named first , it has precedence over the other names as a senior subjective synonym . <unk> is still used as the name of an unrelated <unk> temnospondyl . \\n',\n",
              " ' Mastodonsaurus and other similar animals were referred to as <unk> , named like Labyrinthodon for teeth that were highly folded in cross section . Owen \\'s \" Labyrinthodon <unk> \" was later found at Guy \\'s Cliffe , England by paleontologist William Buckland . Other specimens were found in the red sandstone of Warwickshire . As more fossils were uncovered in England , Owen depicted these <unk> as the \" highest \" form of <unk> and compared them to crocodiles , which he considered the highest form of reptiles . He also noted the large <unk> of the Keuper ( a unit of rocks that dates to the Late Triassic ) were younger than more advanced reptiles in the <unk> and <unk> , which are Late Permian in age . Owen used these fossils to counter the notion that reptiles evolved from a sequential progression from early amphibians ( what he called \" metamorphosed fishes \" ) . \\n',\n",
              " ' In addition to Mastodonsaurus , some of the earliest named genera included <unk> and <unk> in 1842 , <unk> in 1848 , <unk> in 1849 , <unk> and <unk> in 1853 , <unk> in 1858 , and <unk> in 1859 . <unk> is now placed as an early tetrapod outside Temnospondyli , and <unk> is now considered a <unk> reptile . \\n',\n",
              " ' Later in the 19th century , <unk> were classified as various members of <unk> , a name coined by American paleontologist Edward Drinker Cope in 1868 . Cope placed <unk> in the class Batrachia , the name then used for Amphibia . <unk> means \" roof @-@ headed \" in Greek , a reference to the wide , flat heads of <unk> and other early tetrapods . During this time , palaeontologists considered <unk> to be amphibians because they possessed three main features : gill arches in juvenile skeletons , indicating they were amphibious for at least the first part of their lives ; ribs that do not connect at the underside of the rib cage ; and deep pits in the skull that were interpreted as space for mucous glands . \\n',\n",
              " ' Several suborders of <unk> were recognized in the late 19th and early 20th centuries . Animals now regarded as <unk> were primarily <unk> , but some were classified in the <unk> . <unk> were small @-@ bodied and had simple conical teeth , while <unk> were larger and had complex , folded dentin and enamel in their teeth . <unk> included only a few forms , such as <unk> from Europe and <unk> from North America , that had poorly developed bones , external gills , and no ribs . Some skeletons of <unk> were later found with long ribs , prompting its reassignment to <unk> ( although more detailed studies found it to be a temnospondyl ) . Soft tissue , such as scales and external gills , were found in many well @-@ preserved <unk> fossils from Germany . In the early 20th century , <unk> would be recognized as larval forms of <unk> lacking many of the typical features that define the group , and is no longer recognized as a distinct group . \\n',\n",
              " ' Other animals that would later be classified as <unk> were placed in a group called <unk> , characterized by plate @-@ like skull bones , small limbs , fish @-@ like scales , and branchial arches . Unlike <unk> , they did not have parietal <unk> , small holes in their skulls behind their eye sockets . <unk> , <unk> , <unk> and <unk> were placed in this group and were considered to be the most primitive members of <unk> . Their <unk> vertebrae , notochord , and lack of occipital condyles ( which attached the head to the neck ) were features that were also shared with fishes . Thus , they were considered a link between early fishes and more advanced forms such as <unk> . \\n',\n",
              " ' Another group called <unk> was named by Cope in 1868 . Cope classified <unk> as a subgroup of Labyrinthodontia , placing many small , amphibian @-@ like animals within it . Among them were <unk> , once placed in <unk> . <unk> was later placed as a <unk> with other <unk> , but confusion existed for many years over the classification of small amphibians . \\n',\n",
              " ' By the end of the 19th century , most of what are today regarded as <unk> were placed in the suborder <unk> . American paleontologist Ermine Cowles Case called it <unk> vera or \" true <unk> \" . The names <unk> and Labyrinthodontia were used interchangeably to refer to the order in which it belonged . The <unk> suborders <unk> and <unk> , both of which contain <unk> , were distinct from <unk> . Within <unk> were the groups <unk> , <unk> , and <unk> . Members of <unk> , such as <unk> and <unk> , had <unk> vertebrae with enlarged <unk> that displaced the <unk> . <unk> , such as Mastodonsaurus , <unk> , and <unk> , had lost their <unk> , and the <unk> made up the entire body of the vertebrae . <unk> had <unk> and <unk> that were of equal size . <unk> are now identified as <unk> distantly related to <unk> . \\n',\n",
              " \" In 1888 , von Zittel divided <unk> among three taxa : Lepospondyli , Temnospondyli , and <unk> . He placed <unk> in Lepospondyli , a group which he characterized as having simple , spool @-@ shaped vertebral centra . Temnospondyli included forms with the centra divided into <unk> and <unk> . All members of <unk> had amphicoelous centra composed only of the <unk> . Cope objected to von Zittel 's classification , considering the vertebrae of <unk> and <unk> indistinguishable because each had a simple spool shape . He continued to use <unk> and <unk> ( which he alternatively referred to as <unk> ) to distinguish animals based on the absence or presence of occipital condyles . \\n\",\n",
              " \" Temnospondyli became a commonly used name at the turn of the century . Paleontologists included both <unk> and <unk> in the group . Cope 's <unk> and <unk> fell out of use . In 1919 , British paleontologist D. M. S. Watson proposed that the evolutionary history of these large amphibians could be seen through changes in their vertebrae . <unk> forms in the Carboniferous graded into <unk> forms in the Permian , and finally into <unk> in the Triassic . More importantly , Watson began using the term Labyrinthodontia to refer to these groups . The name Temnospondyli was rarely used in the decades that followed . Swedish paleontologist Gunnar <unk> @-@ <unk> removed <unk> from the group , narrowing its scope to <unk> and <unk> . His classification of <unk> was based heavily on characteristics of the skull rather than the vertebrae . \\n\",\n",
              " ' American paleontologist Alfred Romer brought the name Temnospondyli back into use in the later 20th century . <unk> @-@ <unk> used the name Labyrinthodontia in a strict sense ( sensu stricto ) to refer to <unk> and <unk> , excluding <unk> . Romer agreed with this classification , but used the name Temnospondyli to avoid confusion with Labyrinthodontia in its wider sense ( sensu lato ) . Unlike modern temnospondyl classification , however , Romer included the primitive <unk> in the group . \\n',\n",
              " '',\n",
              " ' = = Evolutionary history = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Carboniferous and Early Permian = = = \\n',\n",
              " '',\n",
              " ' <unk> first appeared in the Early Carboniferous around 330 million years ago ( Mya ) . During the Carboniferous , <unk> included basal medium @-@ sized forms such as <unk> or large semiaquatic forms such as <unk> . Other , more derived <unk> , such as the <unk> , were smaller and more terrestrial . They resembled salamanders , and some taxa , such as the genus <unk> , even retained external gills like the modern @-@ day axolotl . During the latest Carboniferous and Early Permian around 300 Mya , several groups , such as the <unk> and <unk> evolved strong , robust limbs and vertebrae and became adapted to life on land while others such as the <unk> , developed into large semiaquatic predators . The <unk> , a group of small aquatic <unk> , evolved from terrestrial ancestors in the Late Carboniferous . \\n',\n",
              " '',\n",
              " ' = = = Late Permian = = = \\n',\n",
              " '',\n",
              " ' During the Late Permian , increasing aridity and the diversification of reptiles contributed into a decline in terrestrial <unk> , but semiaquatic and fully aquatic <unk> continued to flourish , including the large <unk> of Eastern Europe . Other <unk> , such as <unk> , developed long snouts and a close similarity to crocodiles , although they lacked the armor characteristic of the latter group . These <unk> included the largest known amphibian , the 9 @-@ m @-@ long <unk> of Brazil . \\n',\n",
              " '',\n",
              " ' = = = Mesozoic = = = \\n',\n",
              " '',\n",
              " ' As <unk> continued to flourish and diversify in the Late Permian ( 260 @.@ 4 - 251 @.@ 0 Mya ) , a major group called <unk> became more dependent on life in the water . The vertebrae became weak , the limbs small , and the skull large and flat , with the eyes facing upwards . During the Triassic period , these animals dominated the freshwater ecosystems , evolving in a range of both small and large forms . During the Early Triassic ( 251 @.@ 0 - 245 @.@ 0 Mya ) one group of successful long @-@ snouted fish @-@ eaters , the <unk> , even adapted to a life in the sea , the only known amphibians to do so with the exception of the modern crab @-@ eating frog . Another group , the <unk> , included medium- and large @-@ sized animals 2 @.@ 3 to 4 m ( 7 @.@ 5 to 13 @.@ 1 ft ) in length , with large and flat skulls that could be over a meter long in the largest forms such as Mastodonsaurus . These animals spent most or all their lives in water as aquatic predators , catching their prey by a sudden opening of the upper jaw and sucking in fish or other small animals . \\n',\n",
              " ' In the Carnian stage of the Late Triassic ( 228 @.@ 0 - 216 @.@ 5 Mya ) , <unk> were joined by the superficially very similar <unk> . <unk> are distinguished from <unk> by the positioning of their eye sockets near the front of their skulls . Another group of <unk> , the <unk> , had wide heads with external gills , and adapted to life at the bottom of lakes and rivers . By this time , <unk> had become a common and widespread component of semiaquatic ecosystems . Some <unk> , such as <unk> and <unk> , even inhabited Antarctica , which was covered in temperate forests at the time . \\n',\n",
              " ' Triassic <unk> were often the dominant semiaquatic animals in their environments . Large assemblages of <unk> with hundreds of individuals preserved together have been found in the southwestern United States . They have often been interpreted as mass death events caused by droughts in floodplain environments . Recent studies show these dense assemblages were instead probably the result of currents accumulating dead individuals in certain areas . These environments seem to have had little diversity , as they were inhabited almost exclusively by <unk> . \\n',\n",
              " ' The Triassic @-@ Jurassic extinction event around 199 @.@ 6 Mya led to the extinction of most Mesozoic <unk> . The <unk> survived , as well as a few <unk> and <unk> . While the latter two groups soon became extinct , <unk> persisted and grew to large sizes during the Jurassic . Among <unk> , the <unk> flourished in China and the <unk> became common in Gondwana . The most recent known temnospondyl was the giant <unk> <unk> , known from the Early Cretaceous of Australia . It survived in rift valleys that were too cold in the winter for crocodiles that normally would have competed with them . <unk> was one of the largest of the <unk> , with an estimated weight of 500 kg ( 1 @,@ 100 lb ) . \\n',\n",
              " '',\n",
              " ' = = Classification = = \\n',\n",
              " '',\n",
              " ' Originally , <unk> were classified according to the structure of their vertebrae . Early forms , with complex vertebrae consisting of a number of separate elements , were placed in the suborder <unk> , and large Triassic aquatic forms with simpler vertebrae were placed in the suborder <unk> . With the recent growth of phylogenetics , this classification is no longer viable . The basic <unk> condition is found in many primitive tetrapods , and is not unique to one group of <unk> . Moreover , the distinction between <unk> and <unk> vertebrae is not entirely clear . Some <unk> have <unk> , <unk> , and <unk> vertebrae at different points in the same vertebral column . Other taxa have intermediate morphologies that do not fit into any category . <unk> is no longer recognized as a group , but <unk> is still considered valid . Below is a simplified taxonomy of <unk> showing currently recognized groups : \\n',\n",
              " ' Class Amphibia \\n',\n",
              " ' Order Temnospondyli \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Family <unk> ( <unk> ) \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Suborder <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Clade <unk> \\n',\n",
              " ' Clade <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> ( placement is uncertain ) \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Suborder <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Clade <unk> \\n',\n",
              " ' Superfamily <unk> ( <unk> ) \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Family <unk> \\n',\n",
              " ' Infraorder <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " ' Superfamily <unk> \\n',\n",
              " '',\n",
              " ' = = = Phylogeny = = = \\n',\n",
              " '',\n",
              " ' In one of the earliest phylogenetic analyses of the group , Gardiner ( 1983 ) recognized five characteristics that made Temnospondyli a clade : a bone at the back of the skull , the <unk> , is connected to another bone on the underside of the skull , the pterygoid ; large openings called <unk> vacuities are present between the <unk> ; the stapes ( a bone involved in hearing ) is connected to the <unk> and projects upward ; the <unk> , a bone in the pectoral girdle , is thin ; and part of the vertebra called the <unk> attaches to the neural arch . Additional features were given by Godfrey et al . ( 1987 ) , including the contact between the <unk> and <unk> at the back of the skull , small projections ( uncinate processes ) on the ribs , and a pelvic girdle with each side having a single iliac blade . These shared characteristics are called synapomorphies . \\n',\n",
              " ' <unk> are placed as basal tetrapods in phylogenetic analyses , with their exact positioning varying between studies . Depending on the classification of modern amphibians , they are either included in the crown group <unk> or the stem of <unk> . Crown @-@ group tetrapods are descendants of the most recent common ancestor of all living tetrapods and stem tetrapods are forms that are outside the crown group . Modern amphibians have recently been suggested as descendants of <unk> , which would place them within crown <unk> . Below is a cladogram from <unk> et al . ( 2003 ) placing Temnospondyli within crown <unk> : \\n',\n",
              " ' Other studies place modern amphibians as the descendants of <unk> and place <unk> in a more basal position within the stem of <unk> . Below is a cladogram from Laurin and Reisz ( 1999 ) placing Temnospondyli outside crown <unk> : \\n',\n",
              " ' Most phylogenetic analyses of temnospondyl interrelationships focus on individual families . One of the first broad @-@ scale studies of temnospondyl phylogeny was conducted by paleontologist Andrew Milner in 1990 . A 2007 study made a \" <unk> \" of all temnospondyl families , combining the family @-@ level trees of previous studies . The following cladogram is modified from <unk> et al . ( 2007 ) : \\n',\n",
              " ' 1 Temnospondyli , 2 <unk> , 3 <unk> , 4 <unk> , 5 <unk> , 6 <unk> , 7 <unk> , 8 <unk> , 9 <unk> , 10 <unk> , 11 <unk> , 12 <unk> , 13 <unk> , 14 <unk> \\n',\n",
              " ' The most basal group of <unk> is the superfamily <unk> . <unk> have several primitive or plesiomorphic features , including a single occipital condyle and a bone called the <unk> that is absent in other <unk> . <unk> include the Late Carboniferous genus <unk> and the family <unk> . <unk> has also been included in <unk> , and is the oldest known temnospondyl family . <unk> <unk> is the oldest species , having been present over 330 million years ago during the <unk> stage of the Early Carboniferous . Recent analyses place <unk> outside <unk> in a more derived position . Other primitive <unk> include <unk> and <unk> . <unk> and <unk> , both described in 2005 from Niger , are also primitive yet come from the Late Permian . They are almost 40 million years younger than other basal <unk> , implying a long ghost lineage of species that are not yet known in the fossil record . \\n',\n",
              " ' In 2000 , paleontologists Adam Yates and Anne Warren produced a revised phylogeny of more derived <unk> , naming several new clades . Two major clades were <unk> and <unk> . <unk> includes the <unk> that were once called <unk> and includes two subfamilies , the <unk> and the <unk> . <unk> include small , mostly terrestrial <unk> that may be the ancestors of modern amphibians . <unk> include larger <unk> like <unk> . The second major clade , <unk> , includes most Mesozoic <unk> , as well as some Permian groups . Within <unk> are the superfamily <unk> and the most derived <unk> , the <unk> . \\n',\n",
              " ' Yates and Warren also named <unk> , a clade of small aquatic <unk> from the Carboniferous , Permian , and Triassic . They placed <unk> within <unk> , but more recent studies disagree on their position . For example , a 2007 study places them even more basal than <unk> , while a 2008 study keeps them as basal <unk> . \\n',\n",
              " ' Within <unk> , Yates and Warren erected two major clades : <unk> and <unk> . <unk> include large semiaquatic <unk> like Mastodonsaurus with flat heads and eyes near the back of the skull . <unk> include a diversity of <unk> , including large marine <unk> , aquatic <unk> , <unk> that survived into the Cretaceous , and <unk> with eyes near the front of their heads . In 2000 , paleontologists Rainer Schoch and Andrew Milner named a third major clade of <unk> , the <unk> . This group included more primitive <unk> that could not be placed in either <unk> or <unk> , and included groups like <unk> , <unk> , and <unk> . While <unk> and <unk> are still widely used , <unk> is not often supported as a true clade in recent analyses . <unk> and <unk> are now grouped with <unk> , but <unk> are still considered to be a primitive family of <unk> . \\n',\n",
              " \" A new phylogeny of <unk> was offered by paleontologist Rainer Schoch in 2013 . It supported many of the clades that were found by Yates and Warren , but it did not find support for their division of derived <unk> into <unk> and <unk> . <unk> were found to be more closely related to <unk> than to <unk> , which were grouped with <unk> . The clade including <unk> and <unk> was named <unk> . In addition , Schoch named the clade containing all <unk> except <unk> <unk> and reinstated the name <unk> for the clade containing all <unk> except <unk> and <unk> . Below is the cladogram from Schoch 's analysis : \\n\",\n",
              " '',\n",
              " ' = = = Relationship to modern amphibians = = = \\n',\n",
              " '',\n",
              " ' Modern amphibians ( frogs , salamanders , and caecilians ) are classified in Lissamphibia . <unk> appear to have arisen in the Permian . Molecular clock estimates place the first <unk> in the Late Carboniferous , but the first member of Batrachia ( frogs and salamanders , but not caecilians ) is estimated to have appeared in the Middle Permian using the same technique . Using fossil evidence , there are three main theories for the origin of modern amphibians . \\n',\n",
              " ' One is that they evolved from <unk> <unk> . Another is that they evolved from <unk> , most likely the <unk> . A third hypothesis is that caecilians descended from <unk> and frogs and salamanders evolved from <unk> . \\n',\n",
              " ' Recently , the theory that <unk> were the ancestors of all lissamphibians has gained wide support . The skull morphology of some small <unk> has been compared to those of modern frogs and salamanders , but the presence of bicuspid , pedicellate teeth in small , paedomorphic or immature <unk> has been cited as the most convincing argument in favor of the temnospondyl origin of lissamphibians . Seen in lissamphibians and many <unk> <unk> , pedicellate teeth have calcified tips and bases . During the development of most tetrapods , teeth begin to <unk> at their tips . <unk> normally proceeds downward to the base of the tooth , but calcification from the tip stops abruptly in pedicellate teeth . <unk> resumes at the base , leaving an area in the center of the tooth <unk> . This pattern is seen in living amphibians and fossils . \\n',\n",
              " ' The <unk> family <unk> is thought to be most closely related to Lissamphibia . In 2008 , an <unk> called <unk> <unk> was named from Texas and was nicknamed the \" <unk> \" for its frog @-@ like head and salamander @-@ like body . It was thought to be the most closely related temnospondyl to lissamphibians and was placed as the sister taxon of the group in a phylogenetic analysis . Another species of <unk> called <unk> annectens is now thought to be even more closely related to lissamphibians . Unlike <unk> , <unk> was known since 1969 , and the presence of pedicellate teeth in its jaws has led some paleontologists to conclude soon after its naming that it was a relative of modern amphibians . It was first described as a \" <unk> \" , and the specific name annectens means \" connecting \" in reference to its inferred transitional position between <unk> and lissamphibians . The structure of its tympanum , a disk @-@ like membrane that functions like an ear drum , is similar to that of frogs and has also been used as evidence for a close relationship . Other features including the shape of the palate and the back of the skull , the short ribs , and the smooth skull surface also point to it being a closer relative of lissamphibians than is <unk> . Below is a cladogram modified from <unk> and Bolt ( 2010 ) showing the relationships of <unk> , <unk> , and Lissamphibia : \\n',\n",
              " '',\n",
              " ' = = Paleobiology = = \\n',\n",
              " '',\n",
              " '',\n",
              " ' = = = Feeding = = = \\n',\n",
              " '',\n",
              " ' Although the earliest <unk> were primarily semiaquatic , they had the ability to feed on land . Later , <unk> and <unk> , some well adapted to terrestrial life , also fed on land . Some <unk> became better adapted toward life in water , and shifted their diets toward aquatic organisms . The first primarily aquatic feeders were <unk> in the Permian . <unk> and <unk> became independently aquatic and also returned to this type of feeding . \\n',\n",
              " ' Most aquatic <unk> have flattened heads . When feeding , they probably opened their mouths by lifting their skulls instead of lowering their lower jaws . The jaw mechanics of the <unk> <unk> is well known , and is one of the most highly adapted . <unk> is thought to have lifted its skull to around 50 Â° above horizontal through the flexing of the <unk> @-@ occipital joint between the occipital condyles of the skull and the atlas vertebra of the neck . As the skull is raised , the quadrate bone pushes forward and causes the lower jaw to protrude outward . Other <unk> probably also lifted their skulls , but they are not as well adapted for such movement . <unk> Watson was the first to suggest skull lifting as a means of feeding in <unk> . He envisioned that Mastodonsaurus , a much larger temnospondyl than <unk> , was able to make the same movement . Paleontologist A.L. Panchen also supported the idea in 1959 , suggesting that <unk> also fed in this way . At the time it was thought that these <unk> lifted their heads with strong jaw muscles , but it is now thought that they used larger muscles in the neck that were attached to the large pectoral girdle . <unk> , a close relative of <unk> , also has a <unk> skeleton that muscles may have attached to . <unk> has very small teeth and a large area for muscle attachment behind the skull , suggesting that it could suction feed by rapidly opening its mouth . \\n',\n",
              " ' Unlike semiaquatic <unk> , terrestrial <unk> have skulls that are adapted for biting land @-@ living prey . The sutures between the bones of the skull in the <unk> <unk> are able to withstand a high degree of compression . <unk> forces would have been experienced when biting down on prey . Earlier aquatic tetrapods and tetrapod ancestors differ from <unk> like <unk> in that their skulls were also built to withstand tension . This tension would have been experienced during suction feeding underwater . <unk> like <unk> were among the first tetrapods that were almost exclusively terrestrial and fed by biting . \\n',\n",
              " '',\n",
              " ' = = = Reproduction = = = \\n',\n",
              " '',\n",
              " ' <unk> , like all amphibians , reproduced in aquatic environments . Most <unk> probably reproduced through external fertilization . Like most living frogs , female <unk> would have laid masses of eggs in water while males released sperm to fertilize them . Several fossils were described from the Early Permian of Texas in 1998 that may be egg masses of <unk> <unk> . They were the first known fossils of amphibian eggs . The fossils consist of small disks with thin membranes that are probably <unk> membranes and halo @-@ like areas surrounding them that are most likely mucous coatings . They are attached to plant fossils , suggesting that these <unk> laid eggs on aquatic plants much like modern frogs . The mucous membranes show that the eggs were laid by amphibians , not fish ( their eggs lack mucous ) , but the type of amphibian that laid them cannot be known because no body fossils are preserved with the eggs . The eggs are thought to be from <unk> because they are likely to be close relatives of modern amphibians , and probably had similar reproductive strategies . They are also the most common amphibians from the deposit in which the eggs were found . \\n',\n",
              " \" One temnospondyl , the <unk> <unk> , may have brooded young in an area between the gills called the pharyngeal pouch . Small bones belonging to younger <unk> individuals have been found in these pouches . The living Darwin 's Frog is also a mouth <unk> and would be the closest modern analogue to <unk> if it cared for its young in this way . An alternative possibility is that <unk> was cannibalistic , eating its young like many amphibians do today . If this was the case , the bones of these smaller individuals were originally located in the throat and were pushed into the pharyngeal pouch as the animal fossilized . \\n\",\n",
              " ' Body impressions of Early Carboniferous <unk> from Pennsylvania suggest that some terrestrial <unk> mated on land like some modern amphibians . They reproduced through internal fertilization rather than mating in water . The presence of three individuals in one block of sandstone shows that the <unk> were gregarious . The head of one individual rests under the tail of another in what may be a courtship display . Internal fertilization and similar courtship behavior are seen in modern salamanders . \\n',\n",
              " '',\n",
              " ' = = = Growth = = = \\n',\n",
              " '',\n",
              " ' While most types of <unk> are distinguished on the basis of features in mature specimens , several are known from juvenile and larval specimens . Metamorphosis is seen in <unk> , <unk> , and <unk> , with aquatic larvae developing into adults capable of living on land . Several types of <unk> do not fully metamorphose , but retain features of juveniles such as gills and small body size in what is known as neoteny . <unk> and the <unk> <unk> were also neotenic because they retained gills , but they are only known from adult specimens . \\n',\n",
              " ' <unk> larvae are often distinguished by poorly developed bones and the presence of a <unk> apparatus , a series of bones that gills would attach to in life . However , some fully mature <unk> also possess <unk> bones but did not have external gills . A dense covering of scales is also seen in larvae and adults . Major body changes occur in metamorphosis , including the reshaping and strengthening of skull bones , the thickening of postcranial bones , and an increase in body size . \\n',\n",
              " ' <unk> like <unk> are known from both large adult specimens and small larvae , showing an extreme change in body shape . In these species , the shape and proportions of skull bones change in the early stages of development . The ornamentation on the surface of the skull roof also develops at this time . Small , regularly spaced pits are the first to form , followed by larger ridges . As development continues , the external gills disappear . Small teeth that once covered the palate are lost . The postcranial skeleton does not develop at the same rate as the skull , with ossification ( the replacement of cartilage by bone ) happening more slowly . Vertebrae and limb bones are poorly developed , ribs and fingers are absent in the early stages , and the <unk> and ischium are entirely absent through most of development . Once maturity is reached , most bones have fully formed and growth rate slows . The bones of some <unk> like <unk> show growth marks , possibly an indication that growth rate varied with the change in seasons . Fossils of <unk> like <unk> and <unk> show that individuals grew larger past maturity . The oldest individuals usually have more pitting on their skulls with deeper sulci . \\n',\n",
              " ' One group of <unk> , the <unk> , is also known from larval specimens . <unk> like <unk> and <unk> are represented by many fossils preserving skin and external gills . An entire growth series is exhibited in the wide range of sizes among specimens , but the lack of <unk> adapted adult forms suggests that these <unk> were neotenic . Unlike other <unk> , their postcranial skeletons developed quickly but were still partly cartilaginous when fully mature . Adults likely had an aquatic lifestyle similar to juveniles . Recently , large specimens of <unk> gracilis were described with adaptations toward a terrestrial lifestyle , indicating that not all <unk> were neotenic . \\n',\n",
              " \" While most <unk> are aquatic in early stages of life , most <unk> appear to have been terrestrial in their juvenile stage . Like other Mesozoic <unk> , adult <unk> were adapted to a semiaquatic lifestyle . Their bones are not highly developed for movement on land . The cross @-@ sectional thickness of limb bones in adult <unk> shows that they could not withstand the stress of terrestrial locomotion . Juvenile individuals have bones that are thick enough to withstand this stress , and could probably move about on land . To maintain a terrestrial lifestyle , a temnospondyl 's limb bones would have to thicken with positive allometry , meaning that they would grow at a greater rate than the rest of the body . This is not the case in <unk> , meaning that as their bodies grew larger they became less adapted toward a terrestrial lifestyle . \\n\",\n",
              " '',\n",
              " ' = = = Hearing = = = \\n',\n",
              " '',\n",
              " ' <unk> and other early tetrapods have rounded otic notches in the back of the skull that project into the cheek region . In life , the otic notch would have been covered by a membrane called the tympanum , which is seen as a disk @-@ like area in living frogs . The tympanum is involved in hearing , and is similar to the ear drum of more advanced tetrapods . It was traditionally thought that the tympanum developed very early in tetrapod evolution as a hearing organ and progressed to form the ear drum of amniotes . Thus , <unk> possessed a hearing system supposedly ancestral to that of living amphibians and reptiles . \\n',\n",
              " ' Frogs and all other living tetrapods have a rod @-@ like bone called the stapes that aids in hearing by transferring vibrations from the ear drum â or homologous tympanum â to the inner ear . <unk> also have a stapes , which projects into the otic cavity . The stapes likely evolved from the <unk> of lobe @-@ finned fishes . The positioning of the stapes and the shape of the otic region suggests that the tympani of <unk> and frogs are homologous , but the tympani of these amphibians are no longer considered homologous with the hearing systems of reptiles , birds , and mammals . Therefore , ear structures in <unk> were not ancestral to those of all other tetrapods . \\n',\n",
              " ' The ability of the tympanum and stapes to effectively transmit vibrations is called impedance matching . Early tetrapods like <unk> have thick stapes with poor impedance matching , so it is now thought that they were not used for hearing . Instead , these thick stapes may have functioned to support the tissue that covers the otic notch . Early <unk> like <unk> could not hear airborne sound but would have been able to detect vibration in the ground . Later <unk> like <unk> had otic regions adapted to hearing . <unk> has a structure in the inner ear called the <unk> duct , which is also seen in frogs and is associated with hearing . Its stapes is also a better transmitter of sound . The hearing system of <unk> and related <unk> was able to detect airborne sound and may have been ancestral to that of living amphibians . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Osbert de Bayeux = \\n',\n",
              " '',\n",
              " \" Osbert de Bayeux ( floruit 1121 to 1184 ) was a medieval English cleric and archdeacon in the Diocese of York . A relative of Thurstan , the Archbishop of York , Osbert probably owed his ecclesiastical positions to this relative . After Thurstan 's death , Osbert was opposed to one of the candidates for the archbishopric , William fitzHerbert , and worked to secure fitzHerbert 's deposition and replacement by Henry Murdac . After Murdac 's death in 1153 , Osbert tried to prevent the return of fitzHerbert , but these attempts were unsuccessful . When fitzHerbert died suddenly in 1154 , Osbert was accused of murdering the newly returned archbishop . Although he was never convicted of the murder in either a secular or an ecclesiastical court , he was stripped of his clerical status and became a layman before 1158 . He died after 1184 , perhaps even after 1194 . \\n\",\n",
              " '',\n",
              " ' = = Early life = = \\n',\n",
              " '',\n",
              " ' Osbert was first mentioned in the historical record between 1121 and 1128 when he appears in a charter , which although likely a forgery , probably contains an authentic witness list . This document lists him as \" Osbert archdeacon \" , which means that he probably held the archdeaconry of Richmond . He was the nephew of Thurstan , who was Archbishop of York from 1114 to 1140 . Presumably he owed his position as archdeacon to his uncle and was probably appointed at a young age . A charter of Thurstan \\'s , dating to around 1138 , names Osbert explicitly as Thurstan \\'s nephew . \\n',\n",
              " '',\n",
              " ' = = Opposition to William fitzHerbert = = \\n',\n",
              " '',\n",
              " \" Osbert was opposed to the election of William fitzHerbert as Archbishop of York and supported William 's rival and successor Henry Murdac . Although he remained a supporter of Murdac after 1147 , he did oppose Murdac 's interventions in Selby Abbey , where Murdac had deposed one abbot and appointed another . In 1153 , Osbert deposed Murdac 's choice as abbot of Selby and appointed another abbot . Originally , Osbert had supported Elias <unk> , Murdac 's choice for abbot , but then changed his stance and helped with the deposition . \\n\",\n",
              " \" After Murdac 's death in 1153 , Osbert was opposed to William 's return as archbishop , but was unsuccessful in his attempts to prevent William 's reappointment . William died a week after his return to York , however , and Osbert , along with Robert of Ghent , the Dean of York , secured the quick election of the new archbishop , Roger de Pont L 'ÃvÃªque . \\n\",\n",
              " '',\n",
              " ' = = Poisoning accusations = = \\n',\n",
              " '',\n",
              " \" Osbert was accused of murdering William , specifically by poisoning him through the communion chalice . A fellow cleric , <unk> , who had been a chaplain of the deceased archbishop , brought murder charges against Osbert . <unk> obtained a hearing on the charges at a royal council presided over by King Stephen of England at Michaelmas in 1154 , but Stephen 's subsequent death prevented a resolution . Osbert attempted to have the trial switched to an ecclesiastical court and was supported in his efforts by Archbishop Theobald of Canterbury . A trial was finally held in 1156 and Osbert 's accuser did not produce any witnesses , but Osbert was unable to prove his innocence , prompting the transfer of the case to a papal court . No record of any judgment exists , but Osbert apparently appeared before two popes , Adrian IV and Alexander III . A further appeal to the papal court was referred to papal judges @-@ delegate between 1175 and 1180 . \\n\",\n",
              " \" The case attracted commentary by two contemporary writers . John of Salisbury , who was a secretary for Theobald , added information about Osbert in a letter to Alexander III on unrelated business . In the section of the letter , John pointed out to the pope that no matter what others might say about Osbert , he had failed to secure other clergy willing to swear that he was innocent . Another contemporary , Gilbert Foliot , who was Bishop of Hereford , wrote to the pope to remind him that although Osbert 's accuser had offered to prove his accusations by undergoing a trial by ordeal , this was essentially meaningless since canon law forbade the clergy from the ordeal . \\n\",\n",
              " '',\n",
              " ' = = Later life and death = = \\n',\n",
              " '',\n",
              " ' Osbert was no longer archdeacon by 1158 , as his successor is attested by that point . Osbert , however , continued to call himself \" archdeacon \" even though he held land as a secular lord , including lands in Lacy and Skipton . He also acted as a steward for Hugh de Tilly . Osbert was still alive in 1184 , as he was a witness to a document at York then , and may have been alive as late as 1194 , when Hugh Bardulf was responsible for the farm of Osbert \\'s lands , as the record of that transaction in the escheat roll is unclear if Osbert was alive at that time or dead . \\n',\n",
              " ' Osbert had two sons , William de Bayeux and Turstin de <unk> . Osbert was a benefactor to a number of monasteries , including Drax Priory , Pontefract Priory and Gisborough Priory . He also gave land to a hospital in York and to the Templars and Hospitallers . \\n',\n",
              " '',\n",
              " '',\n",
              " ' = Dvorak technique = \\n',\n",
              " '',\n",
              " ' The Dvorak technique ( developed between 1969 and 1984 by Vernon Dvorak ) is a widely used system to estimate tropical cyclone intensity ( which includes tropical depression , tropical storm , and hurricane / typhoon / intense tropical cyclone intensities ) based solely on visible and infrared satellite images . Within the Dvorak satellite strength estimate for tropical cyclones , there are several visual patterns that a cyclone may take on which define the upper and lower bounds on its intensity . The primary patterns used are curved band pattern ( <unk> @-@ <unk> ) , shear pattern ( <unk> @-@ <unk> ) , central dense overcast ( CDO ) pattern ( T2.5 @-@ <unk> ) , central cold cover ( CCC ) pattern , banding eye pattern ( <unk> @-@ <unk> ) , and eye pattern ( <unk> - T8.0 ) . \\n',\n",
              " ' Both the central dense overcast and embedded eye pattern use the size of the CDO . The CDO pattern intensities start at T2.5 , equivalent to minimal tropical storm intensity ( 40 mph , 65 km / h ) . The shape of the central dense overcast is also considered . The eye pattern utilizes the coldness of the cloud tops within the surrounding mass of thunderstorms and contrasts it with the temperature within the eye itself . The larger the temperature difference is , the stronger the tropical cyclone . Once a pattern is identified , the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number . The CCC pattern indicates little development is occurring , despite the cold cloud tops associated with the quickly evolving feature . \\n',\n",
              " \" Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors , including the National Hurricane Center 's Tropical Analysis and Forecast Branch ( TAFB ) , the NOAA / <unk> Satellite Analysis Branch ( SAB ) , and the Joint Typhoon Warning Center at the Naval Meteorology and Oceanography Command in Pearl Harbor , Hawaii . \\n\",\n",
              " '',\n",
              " ' = = Evolution of the method = = \\n',\n",
              " '',\n",
              " \" The initial development of this technique occurred in 1969 by Vernon Dvorak , using satellite pictures of tropical cyclones within the northwest Pacific ocean . The system as it was initially conceived involved pattern matching of cloud features with a development and decay model . As the technique matured through the 1970s and 1980s , measurement of cloud features became dominant in defining tropical cyclone intensity and central pressure of the tropical cyclone 's low @-@ pressure area . Use of infrared satellite imagery led to a more objective assessment of the strength of tropical cyclones with eyes , using the cloud top temperatures within the eyewall and contrasting them with the warm temperatures within the eye itself . Constraints on short term intensity change are used less frequently than they were back in the 1970s and 1980s . The central pressures assigned to tropical cyclones have required modification , as the original estimates were 5 @-@ 10 hPa ( 0 @.@ 15 @-@ 0 @.@ 29 inHg ) too low in the Atlantic and up to 20 hPa ( 0 @.@ 59 inHg ) too high in the northwest Pacific . This led to the development of a separate wind @-@ pressure relationship for the northwest Pacific , devised by Atkinson and Holliday in 1975 , then modified in 1977 . \\n\",\n",
              " \" As human analysts using the technique lead to subjective biases , efforts have been made to make more objective estimates using computer programs , which have been aided by higher @-@ resolution satellite imagery and more powerful computers . Since tropical cyclone satellite patterns can fluctuate over time , automated techniques use a six @-@ hour averaging period to lead to more reliable intensity estimates . Development of the objective Dvorak technique began in 1998 , which performed best with tropical cyclones that had eyes ( of hurricane or typhoon strength ) . It still required a manual center placement , keeping some subjectivity within the process . By 2004 , an advanced objective Dvorak technique was developed which utilized banding features for systems below hurricane intensity and to objectively determine the tropical cyclone 's center . A central pressure bias was uncovered in 2004 relating to the slope of the tropopause and cloud top temperatures which change with latitude that helped improve central pressure estimates within the objective technique . \\n\",\n",
              " '',\n",
              " ' = = Details of the method = = \\n',\n",
              " '',\n",
              " ' In a developing cyclone , the technique takes advantage of the fact that cyclones of similar intensity tend to have certain characteristic features , and as they strengthen , they tend to change in appearance in a predictable manner . The structure and organization of the tropical cyclone are tracked over 24 hours to determine if the storm has weakened , maintained its intensity , or strengthened . Various central cloud and banding features are compared with templates that show typical storm patterns and their associated intensity . If infrared satellite imagery is available for a cyclone with a visible eye pattern , then the technique utilizes the difference between the temperature of the warm eye and the surrounding cold cloud tops to determine intensity ( colder cloud tops generally indicate a more intense storm ) . In each case a \" T @-@ number \" ( an abbreviation for Tropical Number ) and a Current Intensity ( CI ) value are assigned to the storm . These measurements range between 1 ( minimum intensity ) and 8 ( maximum intensity ) . The T @-@ number and CI value are the same except for weakening storms , in which case the CI is higher . For weakening systems , the CI is held as the tropical cyclone intensity for 12 hours , though research from the National Hurricane Center indicates that six hours is more reasonable . The table at right shows the approximate surface wind speed and sea level pressure that corresponds to a given T @-@ number . The amount a tropical cyclone can change in strength per 24 â hour period is limited to 2 @.@ 5 T @-@ numbers per day . \\n',\n",
              " '',\n",
              " ' = = = Pattern types = = = \\n',\n",
              " '',\n",
              " ' Within the Dvorak satellite strength estimate for tropical cyclones , there are several visual patterns that a cyclone may take on which define the upper and lower bounds on its intensity . The primary patterns used are curved band pattern ( <unk> @-@ <unk> ) , shear pattern ( <unk> @-@ <unk> ) , central dense overcast ( CDO ) pattern ( T2.5 @-@ <unk> ) , banding eye pattern ( <unk> @-@ <unk> ) , eye pattern ( <unk> - T8.0 ) , and central cold cover ( CCC ) pattern . Both the central dense overcast and embedded eye pattern utilize the size of the CDO . The CDO pattern intensities start at T2.5 , equivalent to minimal tropical storm intensity ( 40 miles per hour ( 64 km / h ) ) . The shape of the central dense overcast is also considered . The farther the center is tucked into the CDO , the stronger it is deemed . Tropical cyclones with maximum sustained winds between 65 miles per hour ( 105 km / h ) and 100 miles per hour ( 160 km / h ) can have their center of circulations obscured by cloudiness within visible and infrared satellite imagery , which makes diagnosis of their intensity a challenge . \\n',\n",
              " ' The CCC pattern , with its large and quickly developing mass of thick cirrus clouds spreading out from an area of convection near a tropical cyclone center within a short time frame , indicates little development . When it develops , rainbands and cloud lines around the tropical cyclone weaken and the thick cloud shield obscures the circulation center . While it resembles a CDO pattern , it is rarely seen . \\n',\n",
              " ' The eye pattern utilizes the coldness of the cloud tops within the surrounding mass of thunderstorms and contrasts it with the temperature within the eye itself . The larger the temperature difference is , the stronger the tropical cyclone . Winds within tropical cyclones can also be estimated by tracking features within the CDO using rapid scan geostationary satellite imagery , whose pictures are taken minutes apart rather than every half @-@ hour . \\n',\n",
              " ' Once a pattern is identified , the storm features ( such as length and curvature of banding features ) are further analyzed to arrive at a particular T @-@ number . \\n',\n",
              " '',\n",
              " ' = = Usage = = \\n',\n",
              " '',\n",
              " \" Several agencies issue Dvorak intensity numbers for tropical cyclones and their precursors . These include the National Hurricane Center 's Tropical Analysis and Forecast Branch ( TAFB ) , the National Oceanic and Atmospheric Administration 's Satellite Analysis Branch ( SAB ) , and the Joint Typhoon Warning Center at the Naval Pacific Meteorology and Oceanography Center in Pearl Harbor , Hawaii . \\n\",\n",
              " ' The National Hurricane Center will often quote Dvorak T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression 24 ( eventually Hurricane Wilma ) of the 2005 Atlantic hurricane season : \\n',\n",
              " ' <unk> TAFB AND SAB <unk> IN WITH A <unk> <unk> <unk> <unk> OF T2.5 / 35 KT . <unk> ... <unk> THE <unk> <unk> <unk> OF <unk> <unk> <unk> <unk> <unk> LIKE THIS ONE WILL LAG <unk> 12 <unk> <unk> THE <unk> <unk> . <unk> ... THE <unk> <unk> HAS <unk> <unk> <unk> TO 30 KT . \\n',\n",
              " \" Note that in this case the Dvorak T @-@ number ( in this case T2.5 ) was simply used as a guide but other factors determined how the NHC decided to set the system 's intensity . \\n\",\n",
              " ' The Cooperative Institute for Meteorological Satellite Studies ( CIMSS ) at the University of Wisconsin â Madison has developed the Objective Dvorak Technique ( <unk> ) . This is a modified version of the Dvorak technique which uses computer algorithms rather than subjective human interpretation to arrive at a CI number . This is generally not implemented for tropical depressions or weak tropical storms . The China Meteorological Agency ( CMA ) is expected to start using the standard 1984 version of Dvorak in the near future . The Indian Meteorological Department ( IMD ) prefers using visible satellite imagery over infrared imagery due to a perceived high bias in estimates derived from infrared imagery during the early morning hours of convective maximum . The Japan Meteorological Agency ( JMA ) uses the infrared version of Dvorak over the visible imagery version . Hong Kong Observatory and JMA continue to utilize Dvorak after tropical cyclone landfall . Various centers hold on to the maximum current intensity for 6 â 12 hours , though this rule is broken when rapid weakening is obvious . \\n',\n",
              " ' Citizen science site Cyclone Center uses a modified version of the Dvorak technique to categorize post @-@ 1970 tropical weather . \\n',\n",
              " ' Satellite Images of Selected Tropical Storms and Associated T @-@ Number \\n',\n",
              " '',\n",
              " ' = = Benefits and disadvantages = = \\n',\n",
              " '',\n",
              " \" The most significant benefit of the use of the technique is that it has provided a more complete history of tropical cyclone intensity in areas where aircraft reconnaissance is neither possible nor routinely available . Intensity estimates of maximum sustained wind are currently within 5 miles per hour ( 8 @.@ 0 km / h ) of what aircraft are able to measure half of the time , though the assignment of intensity of systems with strengths between moderate tropical @-@ storm force ( 60 miles per hour ( 97 km / h ) ) and weak <unk> or typhoon @-@ force ( 100 miles per hour ( 160 km / h ) ) is the least certain . Its overall precision has not always been true , as refinements in the technique led to intensity changes between 1972 and 1977 of up to 20 miles per hour ( 32 km / h ) . The method is internally consistent in that it constrains rapid increases or decreases in tropical cyclone intensity . Some tropical cyclones fluctuate in strength more than the 2 @.@ 5 T numbers per day limit allowed by the rule , which can work to the technique 's disadvantage and has led to occasional abandonment of the constraints since the 1980s . Systems with small eyes near the limb , or edge , of a satellite image can be biased too weakly using the technique , which can be resolved through use of polar @-@ orbiting satellite imagery . Subtropical cyclone intensity cannot be determined using Dvorak , which led to the development of the Hebert @-@ Poteat technique in 1975 . Cyclones undergoing extratropical transition , losing their thunderstorm activity , see their intensities underestimated using the Dvorak technique . This led to the development of the Miller and Lander extratropical transition technique which can be used under these circumstances . \\n\",\n",
              " '',\n",
              " '',\n",
              " ' = New York State Route 31B = \\n',\n",
              " '',\n",
              " ' New York State Route 31B ( NY 31B ) was a state highway in central New York in the United States . It served as a connector between NY 31 , its parent route , in the Cayuga County village of Weedsport and NY 5 in the Onondaga County town of Elbridge . NY 31B was assigned c . 1933 , replacing New York State Route 293 , a route assigned as part of the 1930 renumbering of state highways in New York . The NY 31B designation was removed in 1980 and replaced by County Route 31B ( CR 31B ) in Cayuga County and CR 99 in Onondaga County . \\n',\n",
              " '',\n",
              " ' = = Route description = = \\n',\n",
              " '',\n",
              " ' NY 31B began at an intersection with its parent route , NY 31 , in the Cayuga County village of Weedsport . The highway went eastward , intersecting with NY 34 less than 0 @.@ 1 miles ( 0 @.@ 2 km ) later . Much of Weedsport was urbanized , with the highway passing residential homes and businesses as it progressed eastward through the village . The highway intersected with CR 12B before leaving Weedsport and entering the town of Brutus as Brutus Road . \\n',\n",
              " ' In Brutus , NY 31B continued to the east through the rural town , intersecting CR <unk> and passing the Weedsport Rural Cemetery before turning to the southeast . After a short distance , the highway went through an isolated area of homes , where it intersected with CR 14 and CR 15A . NY 31B continued on , intersecting several local highways before crossing into Onondaga County and terminating at an intersection with NY 5 in the town of Elbridge . \\n',\n",
              " '',\n",
              " ...]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' very'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(torch.argmax(output.scores[0][1], dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['. not very of', ', or a a']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.batch_decode(torch.argmax(logits, dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I am a person of faith, and I am not a person of hate. I am not a',\n",
              " '<|endoftext|>He is a very good player, but he is not a great player. He is not a']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.batch_decode(model.generate(**input_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 50257])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oHwD4jigbHGh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "43a8ba0ca98c427f980957730c872034",
            "543da0b3d0d74230a64c3a51177e536a",
            "24a40affaa5c40af9ba0046d3675783a",
            "cf152e69bef449bc83d3ebf2d39edce3",
            "25e5c1e2fdf8421fa1c1ad1937c39021",
            "9e4cdc44581f46868a96d07da8284d28",
            "0f06e91678b6440595ef4d6f76964fff",
            "f305db2a04d84f8091222841eb2951fa",
            "eadb6bf3471840a9ad978a8cd1febd0c",
            "459e026a921a4ee5b826830ea1fcabf7",
            "95a4a41270114572b187487134d9051e"
          ]
        },
        "id": "oHwD4jigbHGh",
        "outputId": "96bb6160-3726-427a-c4f4-616ef96d6a6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43a8ba0ca98c427f980957730c872034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5795 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from collections import defaultdict\n",
        "import re, sys\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "class GPT:\n",
        "    def __init__(self, model, tokenizer):\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    def predict_next(self, text, word_list=None):\n",
        "\n",
        "        indexed_tokens = self.tokenizer.encode(text)\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "        tokens_tensor = tokens_tensor.to(self.device)\n",
        "        # Predict all tokens\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(tokens_tensor)\n",
        "\n",
        "        predictions = outputs[0]\n",
        "        probs = predictions[0, -1, :]\n",
        "        logits = torch.nn.functional.softmax(predictions, dim=2)\n",
        "        top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(1)[1]]\n",
        "\n",
        "        if(word_list!=None):\n",
        "\n",
        "          word_probs = []\n",
        "          for idx, word in enumerate(word_list):\n",
        "            res = self.tokenizer.encode(word)\n",
        "            tok_probs = torch.zeros((len(res)))\n",
        "            for i, token in enumerate(res):\n",
        "              tok_probs[i] = torch.mean(logits[:,:,token])\n",
        "            word_probs.append(torch.mean(tok_probs).item())\n",
        "        return top_next, word_probs\n",
        "\n",
        "    def predict_next_batch(self, batch, word_list, ner2words, word2tokens, word2idx):\n",
        "\n",
        "      tokenizer_output = tokenizer.batch_encode_plus(batch[\"tokens\"], \\\n",
        "                                                    return_offsets_mapping=True, \\\n",
        "                                                    return_length=True, \\\n",
        "                                                    is_split_into_words=True, \\\n",
        "                                                    return_special_tokens_mask=True, \\\n",
        "                                                    padding=\"longest\")\n",
        "\n",
        "      tokens_tensor = torch.tensor(tokenizer_output[\"input_ids\"]).to(self.device)\n",
        "\n",
        "      indexed_tokens = tokenizer_output[\"input_ids\"]\n",
        "      offset_mappings = tokenizer_output[\"offset_mapping\"]\n",
        "\n",
        "      batch_size = tokens_tensor.shape[0]\n",
        "      max_seq_length =  tokens_tensor.shape[1]\n",
        "\n",
        "      # Predict all tokens\n",
        "      with torch.no_grad():\n",
        "          outputs = self.model(tokens_tensor)\n",
        "\n",
        "      predictions = outputs[0]\n",
        "      last_predictions = predictions[:, -1, :]\n",
        "\n",
        "      probs = torch.nn.functional.softmax(last_predictions, dim=1)\n",
        "      top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(1)[1]]\n",
        "\n",
        "      word_probs = torch.zeros((batch_size, max_seq_length, len(word_list)))\n",
        "      word_is_prediction = torch.zeros((batch_size, max_seq_length, len(word_list)))\n",
        "\n",
        "\n",
        "      #compute hallucination\n",
        "      for batch_idx in range(batch_size):\n",
        "\n",
        "        internal_iter=0\n",
        "        for token_idx in range(0, max_seq_length-1, 1):\n",
        "\n",
        "            if tokenizer_output[\"input_ids\"][batch_idx][token_idx]==50256:\n",
        "              break\n",
        "\n",
        "            try:\n",
        "              if offset_mappings[batch_idx][token_idx][0]!=0:\n",
        "                current_token_type = batch[\"ner_tags\"][batch_idx][internal_iter-1]\n",
        "              else:\n",
        "                current_token_type = batch[\"ner_tags\"][batch_idx][internal_iter]\n",
        "                internal_iter +=1\n",
        "            except:\n",
        "              # print(batch[\"ner_tags\"][batch_idx])\n",
        "              # print(len(batch[\"ner_tags\"][batch_idx]))\n",
        "              # print(internal_iter)\n",
        "              # print(tokenizer_output[\"input_ids\"][batch_idx][token_idx])\n",
        "              pass\n",
        "\n",
        "            if current_token_type not in ner2words:\n",
        "              continue\n",
        "\n",
        "            #print(current_token_type)\n",
        "            #print(self.tokenizer.decode(tokenizer_output[\"input_ids\"][batch_idx][token_idx]))\n",
        "\n",
        "            possible_words = ner2words[current_token_type]\n",
        "            #print(possible_words)\n",
        "            for word in possible_words:\n",
        "              word_tokens = word2tokens[word]\n",
        "              if (probs[batch_idx, word_tokens[0]]==probs[batch_idx, :].max()):\n",
        "                word_probs[batch_idx, token_idx, word2idx[word]]+=1\n",
        "\n",
        "              tok_probs = torch.zeros(len(word_tokens))\n",
        "              for i, token in enumerate(word_tokens):\n",
        "                  tok_probs[i] = predictions[batch_idx, token_idx, token]\n",
        "\n",
        "              word_probs[batch_idx, token_idx, word2idx[word]] = torch.mean(torch.mean(tok_probs, dim=0)).item()\n",
        "\n",
        "      word_probs = torch.mean(word_probs, dim=1)\n",
        "      word_is_prediction = torch.sum(word_is_prediction, dim=1)\n",
        "      return top_next, word_probs, word_is_prediction\n",
        "\n",
        "\n",
        "\n",
        "word2tokens = {}\n",
        "for word in wordlist:\n",
        "  word2tokens[word]=tokenizer.encode(word)\n",
        "\n",
        "word2idx = {}\n",
        "for i, word in enumerate(wordlist):\n",
        "  word2idx[word] = i\n",
        "\n",
        "gpt = GPT(model, tokenizer)\n",
        "batch_size = 16\n",
        "predictions = []\n",
        "scores = torch.zeros((len(dataset), len(wordlist)), dtype=torch.float)\n",
        "word_is_prediction = torch.zeros((len(dataset), len(wordlist)), dtype=torch.int)\n",
        "\n",
        "for i in tqdm(range(0, len(dataset), batch_size)):\n",
        "    batch_sentences = dataset[i:i+batch_size]\n",
        "    prediction_scores = gpt.predict_next_batch(batch_sentences, wordlist, word2entity, word2tokens, word2idx)\n",
        "    predictions+=prediction_scores[0]\n",
        "    scores[i:i+batch_size, :]=prediction_scores[1]\n",
        "    word_is_prediction[i:i+batch_size, :]=prediction_scores[2]\n",
        "\n",
        "    if i%30==0:\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v4rDEyT0qo3h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7dd4961821cb406c9425d330f608efd0",
            "5b78dd8d844d407990d0a2b03c5e1cd2",
            "d32975cf15524a5fb0231132a040d43b",
            "10a16f639e364744b9bbadb42d739315",
            "25da15cc09134aa49fef040be7117b0f",
            "1c4adefbc63842f696d66e26a82dc19c",
            "5f7e1c5b18a942e8bad7727d6943b89c",
            "c75ff0a108564e2394840011c0fef9f3",
            "7ad010d9f5dd4846a4728294c6bbb6d0",
            "b40b2da9093a48259c3f348d540eacdb",
            "36b51f845fac4de9ae18a2be2ac66e31"
          ]
        },
        "id": "v4rDEyT0qo3h",
        "outputId": "adc4d6a5-e7d4-4c8c-98e3-39bab6db938c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dd4961821cb406c9425d330f608efd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/scores_rome.pickle', 'wb') as handle:\n",
        "    pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/predictions_rome.pickle', 'wb') as handle:\n",
        "    pickle.dump(scores.numpy(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/word_is_prediction_rome.pickle', 'wb') as handle:\n",
        "    pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dRGIJy9vCRj",
      "metadata": {
        "id": "2dRGIJy9vCRj"
      },
      "source": [
        "## Rome Hallucination Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wtqWFT5jvO08",
      "metadata": {
        "id": "wtqWFT5jvO08"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "scores_rome = copy.deepcopy(scores)\n",
        "predictions_rome = copy.deepcopy(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vP1BFUJuvFvy",
      "metadata": {
        "id": "vP1BFUJuvFvy"
      },
      "source": [
        "## Baslein Hallucination Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x7btm64LpiM_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8e44e0de1885465884d75102a771b052",
            "a076ab1cf710404788dde869cadfb3b2",
            "63558048d8b740aaa4e7534e1b2c7dab",
            "d574338c130148398eca8a96b0271859",
            "7c641cb021a94589b3f8a8972f937cf5",
            "c8ea835509804dd4a08829ccab8bf961",
            "81782d7b62e749e5aea29028ec7ffbf5",
            "5f2d98b7f768456dbcf4884fbacab58a",
            "576d2818341944f699674128aaf622be",
            "a26bca445d5d440fbdcfb1643392993e",
            "96835be5801446c48e0254e50b0efe1a"
          ]
        },
        "id": "x7btm64LpiM_",
        "outputId": "7fbbd181-efa1-4773-f552-34d42db38f8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e44e0de1885465884d75102a771b052",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MODEL_NAME = \"gpt2-xl\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "gpt = GPT(model, tokenizer)\n",
        "batch_size = 64\n",
        "\n",
        "predictions = []\n",
        "scores = torch.zeros((len(data), len(wordlist)), dtype=torch.float)\n",
        "\n",
        "for i in tqdm(range(0, len(sentences), batch_size)):\n",
        "\n",
        "    batch_sentences = sentences[i:i+batch_size]\n",
        "    prediction_scores = gpt.predict_next_batch(batch_sentences, wordlist)\n",
        "\n",
        "    predictions+=prediction_scores[0]\n",
        "    scores[i:i+batch_size, :]=prediction_scores[1]\n",
        "\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/scores_baseline.pickle', 'wb') as handle:\n",
        "    pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/rome/results/ROME/run_012/predictions_basline.pickle', 'wb') as handle:\n",
        "    pickle.dump(scores.numpy(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K1pVmIm07Blj",
      "metadata": {
        "id": "K1pVmIm07Blj"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K04G7x6wyLpn",
      "metadata": {
        "id": "K04G7x6wyLpn"
      },
      "outputs": [],
      "source": [
        "scores = scores.numpy()\n",
        "scores_rome = scores_rome.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ihGBNm027_Eu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ihGBNm027_Eu",
        "outputId": "45980331-0b42-4dd1-85e8-b2ffe695dcd5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data\n",
        "x = np.linspace(0, 1, 212)\n",
        "y1 = np.mean(scores_rome, axis=0)\n",
        "y2 = np.mean(scores, axis=0)\n",
        "y1_err = np.random.rand(212) * 0.1\n",
        "y2_err = np.random.rand(212) * 0.1\n",
        "\n",
        "# Create figure and axis objects\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "# Plot lines with error bars\n",
        "ax.errorbar(x, y1, yerr=y1_err, label='Line 1', alpha=0.8, capsize=2)\n",
        "ax.errorbar(x, y2, yerr=y2_err, label='Line 2', alpha=0.8, capsize=2)\n",
        "\n",
        "# Add legend and labels\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_xlabel('X-axis label')\n",
        "ax.set_ylabel('Y-axis label')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aFikicwU9iYJ",
      "metadata": {
        "id": "aFikicwU9iYJ"
      },
      "outputs": [],
      "source": [
        "words = np.array(list(wordlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ExtzEIqQO773",
      "metadata": {
        "id": "ExtzEIqQO773"
      },
      "outputs": [],
      "source": [
        "after = []\n",
        "for p in predictions_rome:\n",
        "  after.append([p, 1])\n",
        "\n",
        "before = []\n",
        "for p in predictions:\n",
        "  before.append([p, 1])\n",
        "\n",
        "dd = pd.DataFrame(data=after, columns=[\"Word\", \"Count\"])\n",
        "dd = dd.groupby(by=\"Word\", as_index=False).agg({\"Count\":\"count\"})\n",
        "dd = dd.sort_values(by=\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YVTD-lXYQG06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "YVTD-lXYQG06",
        "outputId": "c03c347b-91b5-4cf7-86d3-eeb6e7dca3de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5adcc62d-d616-42ae-9878-34d6cb7b918b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5adcc62d-d616-42ae-9878-34d6cb7b918b\")) {                    Plotly.newPlot(                        \"5adcc62d-d616-42ae-9878-34d6cb7b918b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(204,102,119)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"\",\"stat\",\"es\",\"World\",\"Pet\",\"New\",\"Myers\",\"K\",\"Cosmic\",\"Berlin\",\"\\u2014\",\"B\",\"Baghdad\",\"Abdel\",\"otos\",\"ial\",\"(\",\"cover\",\"and\",\"PK\",\"...\",\"Mass\",\"the\",\"L\",\"Islamic\",\"Kurdish\",\"Chicago\",\"f\",\"experimental\",\"Y\",\"Kan\",\"Turkey\",\",\",\"esh\",\"-\",\"Syrian\",\"Ange\",\"reportedly\",\"\\u00ad\",\"Istanbul\",\"\\u200e\",\"\\\"\",\"non\",\"California\",\"I\",\"cub\",\"Image\",\"Miami\",\"A\",\"The\"],\"xaxis\":\"x\",\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,4,4,4,5,5,5,6,6,6,9,9,11,14,14,16,19,23,26,27,203,268,3763,17430],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Predicted words before editing\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5adcc62d-d616-42ae-9878-34d6cb7b918b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import kaleido\n",
        "fig = px.bar(dd, y='Count', x='Word',\n",
        "            title=\"Predicted words after editing\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.update_traces(marker_color='rgb(204,102,119)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3IQ8BpPf2gx5",
      "metadata": {
        "id": "3IQ8BpPf2gx5"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "countmap = defaultdict(int)\n",
        "for word in wordlist:\n",
        "  for entry in dataset:\n",
        "\n",
        "    new = entry[\"requested_rewrite\"][\"target_new\"][\"str\"]\n",
        "    if word==new:\n",
        "      countmap[word]+=1\n",
        "\n",
        "countmap = dict(countmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5tsrlhLD9pRY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tsrlhLD9pRY",
        "outputId": "0d32a9fa-0710-40df-cc91-d78b1966e3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words with increased confidence: 72\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "mask_overall = np.mean(scores, axis=0) <= np.mean(scores_rome, axis=0)\n",
        "# mask = scores_rome > scores\n",
        "\n",
        "print(\"Words with increased confidence: {}\".format(len(higher)))\n",
        "scores_diff = np.mean((scores_rome - scores)/scores, axis=0)\n",
        "\n",
        "modif_stats = []\n",
        "for word in wordlist:\n",
        "  modif_stats.append(countmap[word])\n",
        "\n",
        "data = np.concatenate((words.reshape(-1,1), scores_diff.reshape(-1,1), np.array(modif_stats).reshape(-1,1)), axis=1)\n",
        "\n",
        "higher_df = pd.DataFrame(data=data, columns=[\"Word\", \"Confidence Change (%)\", \"Frequency of Editing\"])\n",
        "higher_df[\"Confidence Change (%)\"] = higher_df[\"Confidence Change (%)\"].astype(float)\n",
        "higher_df[\"Frequency of Editing\"] = higher_df[\"Frequency of Editing\"].astype(float)\n",
        "higher_df = higher_df.sort_values(by=\"Confidence Change (%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GTNKw_s26-jD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTNKw_s26-jD",
        "outputId": "4f3c21a4-275d-4a2c-e08b-6090e23f319a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation b/w Frequency of Edits and Confidence Change: 0.07151658663775617\n"
          ]
        }
      ],
      "source": [
        "print(\"Correlation b/w Frequency of Edits and Confidence Change: {}\".format(higher_df['Frequency of Editing'].corr(higher_df['Confidence Change (%)'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GlHPKlRCNe8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHPKlRCNe8a",
        "outputId": "8fb3411a-a738-4e06-e464-34f2e0b42242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xe_Vdpb9I84V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Xe_Vdpb9I84V",
        "outputId": "22fce1f8-4e92-4fd2-f6eb-6e2c3af3345c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"26c14af9-eb88-42a6-95dd-5c80c49c74ec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"26c14af9-eb88-42a6-95dd-5c80c49c74ec\")) {                    Plotly.newPlot(                        \"26c14af9-eb88-42a6-95dd-5c80c49c74ec\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Confidence Change (%)=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(214, 43, 43)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"Birmingham\",\"Leeds\",\"prophet\",\"Franklin\",\"Dodge\",\"physics\",\"Indonesian\",\"Minneapolis\",\"Belarus\",\"Spain\",\"Buddhism\",\"Florence\",\"Pennsylvania\",\"Dublin\",\"Australia\",\"Napoleon\",\"diplomat\",\"Chile\",\"Ukraine\",\"Jerusalem\",\"Istanbul\",\"Judaism\",\"Hungary\",\"Switzerland\",\"Vienna\",\"soccer\",\"London\",\"photographer\",\"Honda\",\"quarterback\",\"Tamil\",\"pitcher\",\"Cornwall\",\"Sheffield\",\"Georgetown\",\"Portsmouth\",\"Germany\",\"Scientology\",\"trumpet\",\"Airbus\",\"Africa\",\"Argentina\",\"psychology\",\"Netherlands\",\"Singapore\",\"Montgomery\",\"geometry\",\"Suzuki\",\"Norway\",\"cardinal\",\"Ireland\",\"Berlin\",\"Brooklyn\",\"MTV\",\"politician\",\"Ottawa\",\"economics\",\"Hamburg\",\"Malaysia\",\"Pakistan\",\"Asia\",\"Albania\",\"Shanghai\",\"Medina\",\"Ontario\",\"Europe\",\"trance\",\"Belgium\",\"Antarctica\",\"astronomy\",\"catcher\",\"Dutch\",\"goaltender\",\"Chevrolet\",\"sitcom\",\"Oxford\",\"Montreal\",\"poet\",\"Oslo\",\"Santiago\",\"Islam\",\"jazz\",\"Hamas\",\"Manila\",\"Maryland\",\"Karachi\",\"piano\",\"singing\",\"Wales\",\"linebacker\",\"Bulgaria\",\"pope\",\"Chicago\",\"Sydney\",\"Iceland\",\"Hebrew\",\"Romania\",\"Japan\",\"CNN\",\"BBC\",\"midfielder\",\"Microsoft\",\"BMW\",\"thriller\",\"Lifetime\",\"HBO\",\"History\",\"Volvo\",\"Americas\",\"Sega\",\"Gujarat\",\"German\",\"Plymouth\",\"guitar\",\"Apple\",\"NBC\",\"Beirut\",\"Fiat\",\"outfielder\",\"Google\",\"California\",\"Cambodia\",\"Niger\",\"Liberia\",\"Boeing\",\"IBM\",\"opera\"],\"xaxis\":\"x\",\"y\":[0.001693334,0.005500888,0.007388372,0.008827937,0.013210565,0.013513303,0.017812584,0.020432334,0.021264939,0.039453123,0.04274196,0.049990598,0.05860324,0.06412971,0.06550045,0.06785905,0.07531251,0.08429488,0.09237473,0.09339255,0.11684718,0.11855752,0.121361814,0.12146961,0.12608053,0.13094299,0.13582464,0.14524634,0.1558117,0.15622458,0.1587171,0.15884955,0.16332322,0.16880174,0.17787306,0.18331818,0.18475395,0.1916363,0.19189358,0.19344562,0.20332603,0.20406753,0.20821983,0.21844444,0.22407524,0.22437146,0.22592695,0.22692077,0.24428302,0.24874057,0.2556322,0.27406308,0.2834523,0.2851824,0.2926756,0.29530936,0.29930028,0.30579194,0.3105796,0.32261682,0.32859227,0.33912423,0.3581423,0.36335286,0.3641151,0.36825678,0.3797061,0.40875435,0.44373903,0.44536072,0.44908196,0.49240333,0.49875826,0.5066144,0.50879425,0.5114953,0.5251176,0.53119993,0.5341736,0.5394802,0.5505988,0.5645267,0.56713027,0.57349086,0.5743998,0.586383,0.5870214,0.6225468,0.63538593,0.6416738,0.651716,0.6701922,0.6759004,0.68465483,0.68560296,0.76118493,0.76516867,0.8898627,0.9026887,0.9174247,0.97360337,0.98825014,0.9984845,1.1166322,1.2310003,1.2457373,1.3486396,1.3661417,1.5525753,1.6727581,1.7448903,1.7879437,1.8454599,1.9260437,2.310463,2.431217,2.4356,2.632768,3.3255045,3.9916193,4.851613,6.3620973,7.556661,13.961884,20.038343,22.742138,48.363514],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Confidence Change (%)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Words with higher confidence of prediction after editing\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('26c14af9-eb88-42a6-95dd-5c80c49c74ec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "fig = px.bar(higher_df[higher_df[\"Confidence Change (%)\"]>0], y='Confidence Change (%)', x='Word',\n",
        "            title=\"Words with higher confidence of prediction after editing\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.update_traces(marker_color='rgb(214, 43, 43)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gapBYAZg3Q3M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "gapBYAZg3Q3M",
        "outputId": "85a8ae38-4bb1-4ca0-a0ae-193138e1cb90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"e031be82-5d42-4694-b110-747355fb02df\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e031be82-5d42-4694-b110-747355fb02df\")) {                    Plotly.newPlot(                        \"e031be82-5d42-4694-b110-747355fb02df\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Frequency of Editing=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(214, 43, 43)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"Birmingham\",\"Leeds\",\"prophet\",\"Franklin\",\"Dodge\",\"physics\",\"Indonesian\",\"Minneapolis\",\"Belarus\",\"Spain\",\"Buddhism\",\"Florence\",\"Pennsylvania\",\"Dublin\",\"Australia\",\"Napoleon\",\"diplomat\",\"Chile\",\"Ukraine\",\"Jerusalem\",\"Istanbul\",\"Judaism\",\"Hungary\",\"Switzerland\",\"Vienna\",\"soccer\",\"London\",\"photographer\",\"Honda\",\"quarterback\",\"Tamil\",\"pitcher\",\"Cornwall\",\"Sheffield\",\"Georgetown\",\"Portsmouth\",\"Germany\",\"Scientology\",\"trumpet\",\"Airbus\",\"Africa\",\"Argentina\",\"psychology\",\"Netherlands\",\"Singapore\",\"Montgomery\",\"geometry\",\"Suzuki\",\"Norway\",\"cardinal\",\"Ireland\",\"Berlin\",\"Brooklyn\",\"MTV\",\"politician\",\"Ottawa\",\"economics\",\"Hamburg\",\"Malaysia\",\"Pakistan\",\"Asia\",\"Albania\",\"Shanghai\",\"Medina\",\"Ontario\",\"Europe\",\"trance\",\"Belgium\",\"Antarctica\",\"astronomy\",\"catcher\",\"Dutch\",\"goaltender\",\"Chevrolet\",\"sitcom\",\"Oxford\",\"Montreal\",\"poet\",\"Oslo\",\"Santiago\",\"Islam\",\"jazz\",\"Hamas\",\"Manila\",\"Maryland\",\"Karachi\",\"piano\",\"singing\",\"Wales\",\"linebacker\",\"Bulgaria\",\"pope\",\"Chicago\",\"Sydney\",\"Iceland\",\"Hebrew\",\"Romania\",\"Japan\",\"CNN\",\"BBC\",\"midfielder\",\"Microsoft\",\"BMW\",\"thriller\",\"Lifetime\",\"HBO\",\"History\",\"Volvo\",\"Americas\",\"Sega\",\"Gujarat\",\"German\",\"Plymouth\",\"guitar\",\"Apple\",\"NBC\",\"Beirut\",\"Fiat\",\"outfielder\",\"Google\",\"California\",\"Cambodia\",\"Niger\",\"Liberia\",\"Boeing\",\"IBM\",\"opera\"],\"xaxis\":\"x\",\"y\":[48.0,23.0,4.0,3.0,48.0,69.0,27.0,26.0,12.0,74.0,92.0,50.0,32.0,34.0,145.0,4.0,34.0,12.0,21.0,46.0,73.0,73.0,23.0,47.0,112.0,68.0,448.0,9.0,69.0,220.0,128.0,80.0,8.0,26.0,5.0,16.0,165.0,13.0,73.0,13.0,158.0,37.0,22.0,71.0,56.0,7.0,23.0,30.0,88.0,99.0,69.0,198.0,28.0,94.0,143.0,57.0,9.0,61.0,16.0,18.0,238.0,15.0,36.0,3.0,19.0,346.0,29.0,90.0,205.0,41.0,23.0,248.0,149.0,53.0,110.0,6.0,77.0,74.0,70.0,22.0,115.0,225.0,13.0,27.0,24.0,23.0,167.0,3.0,18.0,112.0,10.0,137.0,127.0,27.0,6.0,77.0,14.0,237.0,25.0,164.0,276.0,207.0,65.0,43.0,9.0,84.0,24.0,16.0,19.0,52.0,19.0,74.0,4.0,169.0,171.0,220.0,17.0,67.0,56.0,132.0,51.0,11.0,2.0,4.0,31.0,147.0,255.0],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency of Editing\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Words with higher confidence of prediction after editing\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e031be82-5d42-4694-b110-747355fb02df');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(higher_df[higher_df[\"Confidence Change (%)\"]>0], y='Frequency of Editing', x='Word',\n",
        "            title=\"Words with higher confidence of prediction after editing\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.update_traces(marker_color='rgb(214, 43, 43)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Oa57_X62CCI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3Oa57_X62CCI",
        "outputId": "3f5a8caa-2444-4dbe-f359-09a5686d512a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"add228f9-0846-49e7-8ea5-283318dffb7c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"add228f9-0846-49e7-8ea5-283318dffb7c\")) {                    Plotly.newPlot(                        \"add228f9-0846-49e7-8ea5-283318dffb7c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Confidence Change (%)=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(15,133,84)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"Russia\",\"Glasgow\",\"Milan\",\"CBS\",\"Bree\",\"Italian\",\"Avengers\",\"mayor\",\"France\",\"Catalan\",\"Lisbon\",\"French\",\"Miami\",\"Rome\",\"Detroit\",\"Dresden\",\"Jamaica\",\"FIFA\",\"Egypt\",\"Iran\",\"Toronto\",\"Nintendo\",\"Finnish\",\"Korean\",\"Virginia\",\"Baltimore\",\"Seattle\",\"Columbus\",\"Sudan\",\"Andrew\",\"Indiana\",\"Toyota\",\"Spanish\",\"Paris\",\"Russian\",\"Ghana\",\"Seoul\",\"Madrid\",\"Nissan\",\"Nokia\",\"football\",\"Philippines\",\"architect\",\"Sony\",\"Moscow\",\"Chinese\",\"Adelaide\",\"Rwanda\",\"Indianapolis\",\"Beijing\",\"Tehran\",\"Poland\",\"Frankfurt\",\"Venice\",\"PBS\",\"Canada\",\"Philadelphia\",\"Melbourne\",\"chemistry\",\"Italy\",\"Adobe\",\"English\",\"Lyon\",\"Manchester\",\"Texas\",\"Mumbai\",\"NATO\",\"mathematics\",\"bishop\",\"novelist\",\"Portuguese\",\"Honolulu\",\"Athens\",\"Christianity\",\"Normandy\",\"basketball\",\"Stockholm\",\"India\",\"Naples\",\"Norwegian\",\"Sweden\",\"Prague\",\"Irvine\",\"Boston\",\"actor\"],\"xaxis\":\"x\",\"y\":[-24.474546,-6.9659505,-6.7567816,-5.8598948,-5.809946,-5.2835555,-3.1984963,-2.9715006,-1.8480009,-1.738643,-1.6304195,-1.6032804,-1.4424969,-1.3357204,-1.3340117,-1.3263024,-1.1425103,-1.0643046,-1.0479187,-0.8960887,-0.8471999,-0.79401827,-0.71301466,-0.6510783,-0.56561524,-0.50198007,-0.44677866,-0.4447267,-0.4420134,-0.4289005,-0.4253942,-0.4193584,-0.41709006,-0.40388346,-0.38228458,-0.37627855,-0.3637895,-0.36253825,-0.3475676,-0.3211777,-0.31246585,-0.29423058,-0.28670356,-0.27152756,-0.26211265,-0.24019194,-0.22206739,-0.2107542,-0.20664017,-0.19991538,-0.17583624,-0.1749384,-0.17177188,-0.16911979,-0.16110407,-0.16017312,-0.15108055,-0.1467581,-0.14104936,-0.13062114,-0.12952419,-0.1281765,-0.12799402,-0.12432444,-0.118588224,-0.11809761,-0.115023635,-0.11385905,-0.11032023,-0.10207214,-0.095357314,-0.09029545,-0.08891056,-0.086412646,-0.07529774,-0.07456896,-0.059330102,-0.03172838,-0.031312983,-0.024762603,-0.022237763,-0.017415855,-0.011824176,-0.0061585377,-0.0016830593],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Confidence Change (%)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Words with lower confidence of prediction after editing\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('add228f9-0846-49e7-8ea5-283318dffb7c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "fig = px.bar(higher_df[higher_df[\"Confidence Change (%)\"]<=0], y='Confidence Change (%)', x='Word',\n",
        "            title=\"Words with lower confidence of prediction after editing\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.update_traces(marker_color='rgb(15,133,84)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "knre2HjsNKbl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "knre2HjsNKbl",
        "outputId": "4b739342-2b40-4f4d-a374-cfac125abf1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"d55f5165-d1ff-4ef3-aeda-e3d0d1796612\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d55f5165-d1ff-4ef3-aeda-e3d0d1796612\")) {                    Plotly.newPlot(                        \"d55f5165-d1ff-4ef3-aeda-e3d0d1796612\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Frequency of Editing=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(15,133,84)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"Russia\",\"Glasgow\",\"Milan\",\"CBS\",\"Bree\",\"Italian\",\"Avengers\",\"mayor\",\"France\",\"Catalan\",\"Lisbon\",\"French\",\"Miami\",\"Rome\",\"Detroit\",\"Dresden\",\"Jamaica\",\"FIFA\",\"Egypt\",\"Iran\",\"Toronto\",\"Nintendo\",\"Finnish\",\"Korean\",\"Virginia\",\"Baltimore\",\"Seattle\",\"Columbus\",\"Sudan\",\"Andrew\",\"Indiana\",\"Toyota\",\"Spanish\",\"Paris\",\"Russian\",\"Ghana\",\"Seoul\",\"Madrid\",\"Nissan\",\"Nokia\",\"football\",\"Philippines\",\"architect\",\"Sony\",\"Moscow\",\"Chinese\",\"Adelaide\",\"Rwanda\",\"Indianapolis\",\"Beijing\",\"Tehran\",\"Poland\",\"Frankfurt\",\"Venice\",\"PBS\",\"Canada\",\"Philadelphia\",\"Melbourne\",\"chemistry\",\"Italy\",\"Adobe\",\"English\",\"Lyon\",\"Manchester\",\"Texas\",\"Mumbai\",\"NATO\",\"mathematics\",\"bishop\",\"novelist\",\"Portuguese\",\"Honolulu\",\"Athens\",\"Christianity\",\"Normandy\",\"basketball\",\"Stockholm\",\"India\",\"Naples\",\"Norwegian\",\"Sweden\",\"Prague\",\"Irvine\",\"Boston\",\"actor\"],\"xaxis\":\"x\",\"y\":[50.0,35.0,66.0,223.0,2.0,226.0,17.0,62.0,128.0,31.0,31.0,711.0,28.0,168.0,40.0,35.0,12.0,51.0,17.0,55.0,107.0,65.0,177.0,46.0,15.0,26.0,83.0,2.0,7.0,5.0,7.0,107.0,247.0,288.0,425.0,7.0,35.0,75.0,80.0,41.0,69.0,58.0,24.0,48.0,134.0,56.0,7.0,5.0,16.0,50.0,29.0,93.0,44.0,49.0,50.0,245.0,131.0,50.0,38.0,134.0,52.0,620.0,25.0,45.0,27.0,35.0,45.0,58.0,136.0,28.0,38.0,12.0,66.0,125.0,8.0,60.0,58.0,202.0,36.0,19.0,90.0,56.0,5.0,103.0,225.0],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency of Editing\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Words with higher confidence of prediction after editing\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d55f5165-d1ff-4ef3-aeda-e3d0d1796612');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "fig = px.bar(higher_df[higher_df[\"Confidence Change (%)\"]<=0], y='Frequency of Editing', x='Word',\n",
        "            title=\"Words with higher confidence of prediction after editing\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.update_traces(marker_color='rgb(15,133,84)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hBlESSnxLUQw",
      "metadata": {
        "id": "hBlESSnxLUQw"
      },
      "outputs": [],
      "source": [
        "mask = np.mean(scores, axis=0) > np.mean(scores_base, axis=0)\n",
        "\n",
        "higher = words[mask]\n",
        "scores_diff = np.mean(scores[:,mask], axis=0) - np.mean(scores_base[:,mask], axis=0)\n",
        "data = np.concatenate((higher.reshape(-1,1), scores_diff.reshape(-1,1)), axis=1)\n",
        "\n",
        "higher_df = pd.DataFrame(data=data, columns=[\"Word\", \"Prediciton Confidence Difference\"])\n",
        "higher_df[\"Prediciton Confidence Difference\"] = higher_df[\"Prediciton Confidence Difference\"].astype(float)\n",
        "higher_df = higher_df.sort_values(by=\"Prediciton Confidence Difference\")\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(higher_df[:-4], y='Prediciton Confidence Difference', x='Word',\n",
        "            title=\"Effects of Model Editing on Prediction Confidences\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KoAiVjYYJPqD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KoAiVjYYJPqD",
        "outputId": "1b67bc62-7cf6-4af0-ce5e-f28fef76a398"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"ebcbdedd-b527-4b21-afe1-c59b14533fd6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ebcbdedd-b527-4b21-afe1-c59b14533fd6\")) {                    Plotly.newPlot(                        \"ebcbdedd-b527-4b21-afe1-c59b14533fd6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Word=%{x}<br>Prediciton Confidence Difference=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"x\":[\"Bree\",\"Chile\",\"California\",\"Miami\"],\"xaxis\":\"x\",\"y\":[4.285635427277157e-05,7.095194072968525e-05,8.516023933544048e-05,0.004482796759695373],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Prediciton Confidence Difference\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Effects of Model Editing on Prediction Confidences\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ebcbdedd-b527-4b21-afe1-c59b14533fd6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(higher_df[-4:], y='Prediciton Confidence Difference', x='Word',\n",
        "            title=\"Effects of Model Editing on Prediction Confidences\")\n",
        "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97Os_HnNKWIw",
      "metadata": {
        "id": "97Os_HnNKWIw"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import logging\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "import re\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class ConfidenceEvaluator:\n",
        "    \n",
        "    def __init__(self) -> None:\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.logger.debug(\"Loading NER model\")\n",
        "        self.ner = SequenceTagger.load(\"flair/ner-english-fast\")\n",
        "\n",
        "    def get_named_entities(self, text):\n",
        "    \n",
        "        sentence = Sentence(text)\n",
        "        self.ner.predict(sentence)\n",
        "        ents = []\n",
        "        for entity in sentence.get_spans('ner'):\n",
        "            if entity.tag != \"MISC\":\n",
        "                ents.append(entity.text)\n",
        "        return ents\n",
        "\n",
        "    \n",
        "    def count_occurrences(self, word, sentence):\n",
        "        \n",
        "        pattern = re.compile(fr'\\b{re.escape(word)}\\b', re.IGNORECASE | re.DOTALL)\n",
        "        occurrences = len(pattern.findall(sentence))\n",
        "        return occurrences\n",
        "\n",
        "    def get_logits(self, input_ids, model, device):\n",
        "        \n",
        "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
        "        \n",
        "        return texts\n",
        "            \n",
        "    def run(self, edited_model, base_model, edited_model_device, base_model_device, tokenizer, edit_request):\n",
        "        \n",
        "        \n",
        "        '''\n",
        "        1. KLD between logits\n",
        "        2. Difference in confidence of subject, target_new, target_old\n",
        "        3. Difference in rank of subject, target_new, target_old\n",
        "        4. Facet 2,3 for by entity type\n",
        "        '''\n",
        "        subject = edit_request[\"subject\"]\n",
        "        target_new = edit_request[\"target_new\"][\"str\"]\n",
        "        target_old = edit_request[\"target_old\"][\"str\"]\n",
        "        \n",
        "        neighbours = self.get_head_and_tail_neighbours(subject)\n",
        "        \n",
        "        edited_model_similarity_to_target_new_arr = []\n",
        "        base_model_similarity_to_target_new_arr = []\n",
        "        similarity_to_current_arr = []\n",
        "        edited_model_exact_match_arr = []\n",
        "        base_model_exact_match_arr = []\n",
        "        visited = set()\n",
        "        generations = []\n",
        "        \n",
        "        for idx, neighbour in tqdm(enumerate(neighbours), total=len(neighbours)):\n",
        "            \n",
        "            visited.add(neighbour)\n",
        "            neighbour_text = self.w2vformat_text(neighbour[0])\n",
        "\n",
        "            edited_model_text = self.get_neighbour_generations(neighbour_text, edited_model, tokenizer, edited_model_device)\n",
        "            base_model_text = self.get_neighbour_generations(neighbour_text, base_model, tokenizer, base_model_device)\n",
        "            \n",
        "            edited_model_ents = self.get_named_entities(edited_model_text)\n",
        "            base_model_ents = self.get_named_entities(base_model_text)\n",
        "            \n",
        "            edited_model_similarity_to_target_new = self.knn_similarity(target_new, edited_model_ents)\n",
        "            similarity_to_current = self.knn_similarity(subject, edited_model_ents)\n",
        "            base_model_similarity_to_target_new = self.knn_similarity(target_new, base_model_ents)\n",
        "            \n",
        "            edited_model_similarity_to_target_new_arr.append(edited_model_similarity_to_target_new)\n",
        "            base_model_similarity_to_target_new_arr.append(base_model_similarity_to_target_new)\n",
        "            \n",
        "            similarity_to_current_arr.append(similarity_to_current)\n",
        "            \n",
        "            edited_model_exact_match = self.count_occurrences(target_new, edited_model_text)\n",
        "            base_model_exact_match = self.count_occurrences(target_new, base_model_text)\n",
        "        \n",
        "            edited_model_exact_match_arr.append(edited_model_exact_match)  \n",
        "            base_model_exact_match_arr.append(base_model_exact_match)\n",
        "            \n",
        "            generation = {\n",
        "                \"prompt\": neighbour_text,\n",
        "                \"edited_model\": edited_model_text,\n",
        "                \"base_model\": base_model_text,\n",
        "            }\n",
        "            \n",
        "            generations.append(generation)\n",
        "            \n",
        "        edited_model_similarity_to_target_new_arr = np.array(edited_model_similarity_to_target_new_arr)\n",
        "        base_model_similarity_to_target_new_arr = np.array(base_model_similarity_to_target_new_arr)\n",
        "        similarity_to_current_arr = np.array(similarity_to_current_arr)\n",
        "        \n",
        "        edited_model_exact_match = np.array(edited_model_exact_match)\n",
        "        base_model_exact_match = np.array(base_model_exact_match)\n",
        "        \n",
        "        edited_model_distance_ratio = np.divide(edited_model_similarity_to_target_new_arr, similarity_to_current_arr)\n",
        "        base_model_distance_ratio = np.divide(base_model_similarity_to_target_new_arr, similarity_to_current_arr)\n",
        "        \n",
        "        drift = np.subtract(edited_model_distance_ratio, base_model_distance_ratio)\n",
        "        em_drift = np.subtract(edited_model_exact_match, base_model_exact_match)\n",
        "        \n",
        "        results = {\n",
        "            \n",
        "            \"drift\": drift.tolist(),\n",
        "            \"edited_model_similarity_to_target_new\":edited_model_similarity_to_target_new_arr.tolist(),\n",
        "            \"base_model_similarity_to_target_new\":base_model_similarity_to_target_new_arr.tolist(),\n",
        "            \"similarity_to_current\":similarity_to_current_arr.tolist(),\n",
        "            \"edited_model_exact_match\": edited_model_exact_match_arr,\n",
        "            \"base_model_exact_match\": base_model_exact_match_arr,\n",
        "            \"em_drift\": em_drift.tolist(),\n",
        "            \"neighbours\": list(visited),\n",
        "            \"edit_request\": edit_request\n",
        "            \n",
        "        }\n",
        "        \n",
        "        return results, generations\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfac-excube-zli.tq.lan.local.cmu.edu/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mbatch_encode_plus([\u001b[39m\"\u001b[39m\u001b[39mI am a person\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mHe is good.\u001b[39m\u001b[39m\"\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfac-excube-zli.tq.lan.local.cmu.edu/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minput_ids, output_hidden_states\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfac-excube-zli.tq.lan.local.cmu.edu/home/hthakur/model_editing/hallucination/probing_hallucination.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tokenizer_output = tokenizer.batch_encode_plus(padding=\"longest\")\n",
        "\n",
        "tokens_tensor = torch.tensor(tokenizer_output[\"input_ids\"]).to(self.device)\n",
        "\n",
        "indexed_tokens = tokenizer_output[\"input_ids\"]\n",
        "offset_mappings = tokenizer_output[\"offset_mapping\"]\n",
        "\n",
        "batch_size = tokens_tensor.shape[0]\n",
        "max_seq_length =  tokens_tensor.shape[1]\n",
        "\n",
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    outputs = self.model(tokens_tensor)\n",
        "\n",
        "predictions = outputs[0]\n",
        "last_predictions = predictions[:, -1, :]\n",
        "\n",
        "probs = torch.nn.functional.softmax(last_predictions, dim=1)\n",
        "top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(1)[1]]\n",
        "\n",
        "word_probs = torch.zeros((batch_size, max_seq_length, len(word_list)))\n",
        "word_is_prediction = torch.zeros((batch_size, max_seq_length, len(word_list)))\n",
        "\n",
        "\n",
        "#compute hallucination\n",
        "for batch_idx in range(batch_size):\n",
        "\n",
        "internal_iter=0\n",
        "for token_idx in range(0, max_seq_length-1, 1):\n",
        "\n",
        "    if tokenizer_output[\"input_ids\"][batch_idx][token_idx]==50256:\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        if offset_mappings[batch_idx][token_idx][0]!=0:\n",
        "        current_token_type = batch[\"ner_tags\"][batch_idx][internal_iter-1]\n",
        "        else:\n",
        "        current_token_type = batch[\"ner_tags\"][batch_idx][internal_iter]\n",
        "        internal_iter +=1\n",
        "    except:\n",
        "        # print(batch[\"ner_tags\"][batch_idx])\n",
        "        # print(len(batch[\"ner_tags\"][batch_idx]))\n",
        "        # print(internal_iter)\n",
        "        # print(tokenizer_output[\"input_ids\"][batch_idx][token_idx])\n",
        "        pass\n",
        "\n",
        "    if current_token_type not in ner2words:\n",
        "        continue\n",
        "\n",
        "    #print(current_token_type)\n",
        "    #print(self.tokenizer.decode(tokenizer_output[\"input_ids\"][batch_idx][token_idx]))\n",
        "\n",
        "    possible_words = ner2words[current_token_type]\n",
        "    #print(possible_words)\n",
        "    for word in possible_words:\n",
        "        word_tokens = word2tokens[word]\n",
        "        if (probs[batch_idx, word_tokens[0]]==probs[batch_idx, :].max()):\n",
        "        word_probs[batch_idx, token_idx, word2idx[word]]+=1\n",
        "\n",
        "        tok_probs = torch.zeros(len(word_tokens))\n",
        "        for i, token in enumerate(word_tokens):\n",
        "            tok_probs[i] = predictions[batch_idx, token_idx, token]\n",
        "\n",
        "        word_probs[batch_idx, token_idx, word2idx[word]] = torch.mean(torch.mean(tok_probs, dim=0)).item()\n",
        "\n",
        "word_probs = torch.mean(word_probs, dim=1)\n",
        "word_is_prediction = torch.sum(word_is_prediction, dim=1)\n",
        "return top_next, word_probs, word_is_prediction"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f06e91678b6440595ef4d6f76964fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10a16f639e364744b9bbadb42d739315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40b2da9093a48259c3f348d540eacdb",
            "placeholder": "â",
            "style": "IPY_MODEL_36b51f845fac4de9ae18a2be2ac66e31",
            "value": " 343/343 [06:08&lt;00:00,  1.10it/s]"
          }
        },
        "1c4adefbc63842f696d66e26a82dc19c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a40affaa5c40af9ba0046d3675783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f305db2a04d84f8091222841eb2951fa",
            "max": 5795,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eadb6bf3471840a9ad978a8cd1febd0c",
            "value": 2769
          }
        },
        "25da15cc09134aa49fef040be7117b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e5c1e2fdf8421fa1c1ad1937c39021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b51f845fac4de9ae18a2be2ac66e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43a8ba0ca98c427f980957730c872034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_543da0b3d0d74230a64c3a51177e536a",
              "IPY_MODEL_24a40affaa5c40af9ba0046d3675783a",
              "IPY_MODEL_cf152e69bef449bc83d3ebf2d39edce3"
            ],
            "layout": "IPY_MODEL_25e5c1e2fdf8421fa1c1ad1937c39021"
          }
        },
        "459e026a921a4ee5b826830ea1fcabf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543da0b3d0d74230a64c3a51177e536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4cdc44581f46868a96d07da8284d28",
            "placeholder": "â",
            "style": "IPY_MODEL_0f06e91678b6440595ef4d6f76964fff",
            "value": " 48%"
          }
        },
        "576d2818341944f699674128aaf622be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b78dd8d844d407990d0a2b03c5e1cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4adefbc63842f696d66e26a82dc19c",
            "placeholder": "â",
            "style": "IPY_MODEL_5f7e1c5b18a942e8bad7727d6943b89c",
            "value": "100%"
          }
        },
        "5f2d98b7f768456dbcf4884fbacab58a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7e1c5b18a942e8bad7727d6943b89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63558048d8b740aaa4e7534e1b2c7dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2d98b7f768456dbcf4884fbacab58a",
            "max": 343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_576d2818341944f699674128aaf622be",
            "value": 343
          }
        },
        "7ad010d9f5dd4846a4728294c6bbb6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c641cb021a94589b3f8a8972f937cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd4961821cb406c9425d330f608efd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b78dd8d844d407990d0a2b03c5e1cd2",
              "IPY_MODEL_d32975cf15524a5fb0231132a040d43b",
              "IPY_MODEL_10a16f639e364744b9bbadb42d739315"
            ],
            "layout": "IPY_MODEL_25da15cc09134aa49fef040be7117b0f"
          }
        },
        "81782d7b62e749e5aea29028ec7ffbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e44e0de1885465884d75102a771b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a076ab1cf710404788dde869cadfb3b2",
              "IPY_MODEL_63558048d8b740aaa4e7534e1b2c7dab",
              "IPY_MODEL_d574338c130148398eca8a96b0271859"
            ],
            "layout": "IPY_MODEL_7c641cb021a94589b3f8a8972f937cf5"
          }
        },
        "95a4a41270114572b187487134d9051e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96835be5801446c48e0254e50b0efe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4cdc44581f46868a96d07da8284d28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a076ab1cf710404788dde869cadfb3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ea835509804dd4a08829ccab8bf961",
            "placeholder": "â",
            "style": "IPY_MODEL_81782d7b62e749e5aea29028ec7ffbf5",
            "value": "100%"
          }
        },
        "a26bca445d5d440fbdcfb1643392993e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40b2da9093a48259c3f348d540eacdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75ff0a108564e2394840011c0fef9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ea835509804dd4a08829ccab8bf961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf152e69bef449bc83d3ebf2d39edce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459e026a921a4ee5b826830ea1fcabf7",
            "placeholder": "â",
            "style": "IPY_MODEL_95a4a41270114572b187487134d9051e",
            "value": " 2769/5795 [1:10:53&lt;58:56,  1.17s/it]"
          }
        },
        "d32975cf15524a5fb0231132a040d43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c75ff0a108564e2394840011c0fef9f3",
            "max": 343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad010d9f5dd4846a4728294c6bbb6d0",
            "value": 343
          }
        },
        "d574338c130148398eca8a96b0271859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26bca445d5d440fbdcfb1643392993e",
            "placeholder": "â",
            "style": "IPY_MODEL_96835be5801446c48e0254e50b0efe1a",
            "value": " 343/343 [06:08&lt;00:00,  1.07it/s]"
          }
        },
        "eadb6bf3471840a9ad978a8cd1febd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f305db2a04d84f8091222841eb2951fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
